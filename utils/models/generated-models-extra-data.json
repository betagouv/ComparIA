{
  "timestamp": 1770784106.0,
  "models": [
    {
      "model_name": "mistral-medium-3.1",
      "median": 1136.4698198633514,
      "p2.5": 1095.8601939804964,
      "p97.5": 1178.1015247764763,
      "rank": 1,
      "rank_p2.5": 1,
      "rank_p97.5": 8,
      "total_output_tokens": 353926,
      "conso_all_conv": 0.0,
      "n_match": 191,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.6797393277083724,
      "win_rate": 0.5832258064516129,
      "useful": 5,
      "creative": 3,
      "complete": 12,
      "clear_formatting": 8,
      "incorrect": 4,
      "superficial": 1,
      "instructions_not_followed": 0,
      "total_prefs": 33,
      "positive_prefs_ratio": 0.8484848484848485
    },
    {
      "model_name": "gemini-3-flash-preview",
      "median": 1128.464266031655,
      "p2.5": 1112.2824729427816,
      "p97.5": 1144.7518740537437,
      "rank": 2,
      "rank_p2.5": 1,
      "rank_p97.5": 4,
      "total_output_tokens": 1215590,
      "conso_all_conv": 106.34608564439998,
      "n_match": 1262,
      "mean_conso_per_match": 0.08426789670713151,
      "mean_conso_per_token": 8.748515999999998e-05,
      "mean_win_prob": 0.6698772782232936,
      "win_rate": 0.5719809825673534,
      "useful": 269,
      "creative": 83,
      "complete": 276,
      "clear_formatting": 220,
      "incorrect": 51,
      "superficial": 55,
      "instructions_not_followed": 16,
      "total_prefs": 970,
      "positive_prefs_ratio": 0.8742268041237113
    },
    {
      "model_name": "mistral-large-2512",
      "median": 1122.0299937894038,
      "p2.5": 1111.2216634758477,
      "p97.5": 1132.5135533348835,
      "rank": 3,
      "rank_p2.5": 1,
      "rank_p97.5": 4,
      "total_output_tokens": 6526340,
      "conso_all_conv": 328.8872032187999,
      "n_match": 3140,
      "mean_conso_per_match": 0.1047411475219108,
      "mean_conso_per_token": 5.0393819999999986e-05,
      "mean_win_prob": 0.6618490883409148,
      "win_rate": 0.5630509554140127,
      "useful": 771,
      "creative": 217,
      "complete": 741,
      "clear_formatting": 568,
      "incorrect": 140,
      "superficial": 132,
      "instructions_not_followed": 88,
      "total_prefs": 2657,
      "positive_prefs_ratio": 0.8645088445615355
    },
    {
      "model_name": "mistral-medium-2508",
      "median": 1118.1185944608787,
      "p2.5": 1110.3954053618104,
      "p97.5": 1125.5445905162824,
      "rank": 4,
      "rank_p2.5": 2,
      "rank_p97.5": 4,
      "total_output_tokens": 9918628,
      "conso_all_conv": 197.4459287101467,
      "n_match": 6358,
      "mean_conso_per_match": 0.03105472298052008,
      "mean_conso_per_token": 1.9906576666666667e-05,
      "mean_win_prob": 0.6569260462960075,
      "win_rate": 0.5899433695139217,
      "useful": 847,
      "creative": 235,
      "complete": 818,
      "clear_formatting": 670,
      "incorrect": 192,
      "superficial": 164,
      "instructions_not_followed": 85,
      "total_prefs": 3011,
      "positive_prefs_ratio": 0.8535370308867486
    },
    {
      "model_name": "gemini-2.5-flash",
      "median": 1106.1853442608585,
      "p2.5": 1097.7091570309806,
      "p97.5": 1114.7391081077692,
      "rank": 5,
      "rank_p2.5": 4,
      "rank_p97.5": 8,
      "total_output_tokens": 6381859,
      "conso_all_conv": 558.3179557124398,
      "n_match": 4927,
      "mean_conso_per_match": 0.11331803444539067,
      "mean_conso_per_token": 8.748515999999996e-05,
      "mean_win_prob": 0.6417167220443732,
      "win_rate": 0.5783245382585752,
      "useful": 652,
      "creative": 205,
      "complete": 705,
      "clear_formatting": 540,
      "incorrect": 151,
      "superficial": 135,
      "instructions_not_followed": 53,
      "total_prefs": 2441,
      "positive_prefs_ratio": 0.8611224907824662
    },
    {
      "model_name": "gemini-3-pro-preview",
      "median": 1101.4503656049492,
      "p2.5": 1091.5044942355617,
      "p97.5": 1111.864378399643,
      "rank": 6,
      "rank_p2.5": 5,
      "rank_p97.5": 9,
      "total_output_tokens": 5465093,
      "conso_all_conv": 293.81378335669996,
      "n_match": 3210,
      "mean_conso_per_match": 0.0915307736313707,
      "mean_conso_per_token": 5.376189999999999e-05,
      "mean_win_prob": 0.6356066427576355,
      "win_rate": 0.5553489096573209,
      "useful": 671,
      "creative": 214,
      "complete": 626,
      "clear_formatting": 462,
      "incorrect": 99,
      "superficial": 131,
      "instructions_not_followed": 71,
      "total_prefs": 2274,
      "positive_prefs_ratio": 0.8676341248900615
    },
    {
      "model_name": "qwen3-max-2025-09-23",
      "median": 1100.6886230819205,
      "p2.5": 1090.7252265042764,
      "p97.5": 1110.6268006706698,
      "rank": 7,
      "rank_p2.5": 5,
      "rank_p97.5": 9,
      "total_output_tokens": 3641902,
      "conso_all_conv": 207.90715326303993,
      "n_match": 3283,
      "mean_conso_per_match": 0.06332840489279315,
      "mean_conso_per_token": 5.708751999999998e-05,
      "mean_win_prob": 0.6346198758377717,
      "win_rate": 0.5672212065813528,
      "useful": 439,
      "creative": 136,
      "complete": 385,
      "clear_formatting": 376,
      "incorrect": 144,
      "superficial": 112,
      "instructions_not_followed": 50,
      "total_prefs": 1642,
      "positive_prefs_ratio": 0.8136419001218027
    },
    {
      "model_name": "gemini-2.0-flash",
      "median": 1099.5960746957326,
      "p2.5": 1092.5967201924757,
      "p97.5": 1106.4712860186312,
      "rank": 8,
      "rank_p2.5": 5,
      "rank_p97.5": 9,
      "total_output_tokens": 12296785,
      "conso_all_conv": 1075.7862032105998,
      "n_match": 8684,
      "mean_conso_per_match": 0.12388141446460153,
      "mean_conso_per_token": 8.748515999999998e-05,
      "mean_win_prob": 0.6332027746282586,
      "win_rate": 0.6317699216950714,
      "useful": 2128,
      "creative": 677,
      "complete": 2179,
      "clear_formatting": 1909,
      "incorrect": 376,
      "superficial": 397,
      "instructions_not_followed": 112,
      "total_prefs": 7778,
      "positive_prefs_ratio": 0.8862175366418102
    },
    {
      "model_name": "deepseek-v3-0324",
      "median": 1091.2693482251975,
      "p2.5": 1083.0867981034223,
      "p97.5": 1100.7493234301296,
      "rank": 9,
      "rank_p2.5": 7,
      "rank_p97.5": 11,
      "total_output_tokens": 4435392,
      "conso_all_conv": 208.57759099007998,
      "n_match": 4385,
      "mean_conso_per_match": 0.04756615529990422,
      "mean_conso_per_token": 4.7025739999999995e-05,
      "mean_win_prob": 0.6223347154914951,
      "win_rate": 0.5851128848346636,
      "useful": 1141,
      "creative": 336,
      "complete": 1012,
      "clear_formatting": 1043,
      "incorrect": 230,
      "superficial": 288,
      "instructions_not_followed": 79,
      "total_prefs": 4129,
      "positive_prefs_ratio": 0.8554129329135384
    },
    {
      "model_name": "magistral-medium",
      "median": 1088.793838264289,
      "p2.5": 1075.5191891890993,
      "p97.5": 1101.3528550501637,
      "rank": 10,
      "rank_p2.5": 7,
      "rank_p97.5": 14,
      "total_output_tokens": 2039837,
      "conso_all_conv": 40.60617162800334,
      "n_match": 2207,
      "mean_conso_per_match": 0.01839880907476363,
      "mean_conso_per_token": 1.9906576666666667e-05,
      "mean_win_prob": 0.6190814217227704,
      "win_rate": 0.5809968282736747,
      "useful": 146,
      "creative": 41,
      "complete": 150,
      "clear_formatting": 104,
      "incorrect": 50,
      "superficial": 28,
      "instructions_not_followed": 3,
      "total_prefs": 522,
      "positive_prefs_ratio": 0.8448275862068966
    },
    {
      "model_name": "gemma-3-27b",
      "median": 1082.4611469374108,
      "p2.5": 1076.342543956293,
      "p97.5": 1089.1443437606854,
      "rank": 11,
      "rank_p2.5": 10,
      "rank_p97.5": 15,
      "total_output_tokens": 11441861,
      "conso_all_conv": 73.61987041832333,
      "n_match": 8583,
      "mean_conso_per_match": 0.00857740538486815,
      "mean_conso_per_token": 6.434256666666666e-06,
      "mean_win_prob": 0.6107152793947536,
      "win_rate": 0.5692613305371083,
      "useful": 1618,
      "creative": 530,
      "complete": 1791,
      "clear_formatting": 1327,
      "incorrect": 447,
      "superficial": 329,
      "instructions_not_followed": 159,
      "total_prefs": 6201,
      "positive_prefs_ratio": 0.8492178680857926
    },
    {
      "model_name": "deepseek-v3-chat",
      "median": 1077.9803289005106,
      "p2.5": 1069.4267652873864,
      "p97.5": 1087.1562775957882,
      "rank": 12,
      "rank_p2.5": 10,
      "rank_p97.5": 19,
      "total_output_tokens": 5638296,
      "conso_all_conv": 265.14504173904,
      "n_match": 5388,
      "mean_conso_per_match": 0.049210289855055676,
      "mean_conso_per_token": 4.7025739999999995e-05,
      "mean_win_prob": 0.6047594570124205,
      "win_rate": 0.6141481069042317,
      "useful": 1330,
      "creative": 390,
      "complete": 1245,
      "clear_formatting": 1399,
      "incorrect": 314,
      "superficial": 285,
      "instructions_not_followed": 81,
      "total_prefs": 5044,
      "positive_prefs_ratio": 0.8651863600317209
    },
    {
      "model_name": "deepseek-chat-v3.1",
      "median": 1077.278498008336,
      "p2.5": 1066.911836900315,
      "p97.5": 1088.8318503810087,
      "rank": 13,
      "rank_p2.5": 10,
      "rank_p97.5": 20,
      "total_output_tokens": 3396229,
      "conso_all_conv": 159.71018193446,
      "n_match": 2527,
      "mean_conso_per_match": 0.06320149661039176,
      "mean_conso_per_token": 4.702574e-05,
      "mean_win_prob": 0.6038239995762236,
      "win_rate": 0.5254768500197864,
      "useful": 365,
      "creative": 118,
      "complete": 335,
      "clear_formatting": 286,
      "incorrect": 108,
      "superficial": 108,
      "instructions_not_followed": 58,
      "total_prefs": 1378,
      "positive_prefs_ratio": 0.8011611030478955
    },
    {
      "model_name": "gpt-5.1",
      "median": 1074.8421756460432,
      "p2.5": 1065.0625023134821,
      "p97.5": 1085.2770186903397,
      "rank": 14,
      "rank_p2.5": 11,
      "rank_p97.5": 21,
      "total_output_tokens": 3899672,
      "conso_all_conv": 185.27513257567995,
      "n_match": 3189,
      "mean_conso_per_match": 0.058098191463054234,
      "mean_conso_per_token": 4.751043999999999e-05,
      "mean_win_prob": 0.6005713831907888,
      "win_rate": 0.5270429601756036,
      "useful": 495,
      "creative": 138,
      "complete": 473,
      "clear_formatting": 393,
      "incorrect": 79,
      "superficial": 147,
      "instructions_not_followed": 63,
      "total_prefs": 1788,
      "positive_prefs_ratio": 0.8383668903803132
    },
    {
      "model_name": "DeepSeek-V3.2",
      "median": 1074.2593072643726,
      "p2.5": 1061.2310809567077,
      "p97.5": 1087.3142838674307,
      "rank": 15,
      "rank_p2.5": 10,
      "rank_p97.5": 23,
      "total_output_tokens": 2019538,
      "conso_all_conv": 94.97026890811999,
      "n_match": 1843,
      "mean_conso_per_match": 0.051530259852479644,
      "mean_conso_per_token": 4.7025739999999995e-05,
      "mean_win_prob": 0.5997920260793798,
      "win_rate": 0.5554259359739555,
      "useful": 440,
      "creative": 204,
      "complete": 443,
      "clear_formatting": 328,
      "incorrect": 124,
      "superficial": 115,
      "instructions_not_followed": 67,
      "total_prefs": 1721,
      "positive_prefs_ratio": 0.8221963974433469
    },
    {
      "model_name": "claude-4-5-sonnet",
      "median": 1071.783102985043,
      "p2.5": 1064.3878785592426,
      "p97.5": 1078.8986081552023,
      "rank": 16,
      "rank_p2.5": 13,
      "rank_p97.5": 21,
      "total_output_tokens": 6835493,
      "conso_all_conv": 598.0041987838798,
      "n_match": 6519,
      "mean_conso_per_match": 0.0917325047988771,
      "mean_conso_per_token": 8.748515999999998e-05,
      "mean_win_prob": 0.5964760454586694,
      "win_rate": 0.5354793680012272,
      "useful": 1249,
      "creative": 539,
      "complete": 916,
      "clear_formatting": 695,
      "incorrect": 173,
      "superficial": 274,
      "instructions_not_followed": 97,
      "total_prefs": 3943,
      "positive_prefs_ratio": 0.862033984275932
    },
    {
      "model_name": "glm-4.5",
      "median": 1071.6732615240812,
      "p2.5": 1059.829988189519,
      "p97.5": 1085.0482069158845,
      "rank": 17,
      "rank_p2.5": 11,
      "rank_p97.5": 25,
      "total_output_tokens": 5128869,
      "conso_all_conv": 109.79790435558,
      "n_match": 2178,
      "mean_conso_per_match": 0.050412260952975206,
      "mean_conso_per_token": 2.140782e-05,
      "mean_win_prob": 0.5963287665208331,
      "win_rate": 0.5414882866329811,
      "useful": 227,
      "creative": 75,
      "complete": 282,
      "clear_formatting": 209,
      "incorrect": 48,
      "superficial": 57,
      "instructions_not_followed": 33,
      "total_prefs": 931,
      "positive_prefs_ratio": 0.8517722878625135
    },
    {
      "model_name": "gpt-5.2",
      "median": 1069.136709179328,
      "p2.5": 1058.6503671931741,
      "p97.5": 1079.3698944421228,
      "rank": 18,
      "rank_p2.5": 13,
      "rank_p97.5": 26,
      "total_output_tokens": 3178262,
      "conso_all_conv": 151.00062605527995,
      "n_match": 2832,
      "mean_conso_per_match": 0.05331943010426552,
      "mean_conso_per_token": 4.751043999999999e-05,
      "mean_win_prob": 0.5929233837228672,
      "win_rate": 0.5164548022598869,
      "useful": 577,
      "creative": 126,
      "complete": 452,
      "clear_formatting": 438,
      "incorrect": 92,
      "superficial": 198,
      "instructions_not_followed": 70,
      "total_prefs": 1953,
      "positive_prefs_ratio": 0.815668202764977
    },
    {
      "model_name": "kimi-k2-thinking",
      "median": 1067.8252124632727,
      "p2.5": 1051.5274509238893,
      "p97.5": 1083.4458012787793,
      "rank": 19,
      "rank_p2.5": 11,
      "rank_p97.5": 29,
      "total_output_tokens": 2122820,
      "conso_all_conv": 121.18652920639997,
      "n_match": 1304,
      "mean_conso_per_match": 0.09293445491288341,
      "mean_conso_per_token": 5.7087519999999986e-05,
      "mean_win_prob": 0.5911595008562106,
      "win_rate": 0.5399769938650306,
      "useful": 263,
      "creative": 58,
      "complete": 251,
      "clear_formatting": 199,
      "incorrect": 65,
      "superficial": 82,
      "instructions_not_followed": 48,
      "total_prefs": 966,
      "positive_prefs_ratio": 0.7981366459627329
    },
    {
      "model_name": "grok-4.1-fast",
      "median": 1066.2743248368533,
      "p2.5": 1054.3311033314103,
      "p97.5": 1077.5817033335736,
      "rank": 20,
      "rank_p2.5": 14,
      "rank_p97.5": 28,
      "total_output_tokens": 2819447,
      "conso_all_conv": 719.3445255809365,
      "n_match": 2553,
      "mean_conso_per_match": 0.28176440484956383,
      "mean_conso_per_token": 0.0002551367433333333,
      "mean_win_prob": 0.5890709388552419,
      "win_rate": 0.5295064629847238,
      "useful": 473,
      "creative": 167,
      "complete": 377,
      "clear_formatting": 336,
      "incorrect": 127,
      "superficial": 140,
      "instructions_not_followed": 55,
      "total_prefs": 1675,
      "positive_prefs_ratio": 0.8077611940298507
    },
    {
      "model_name": "gpt-oss-120b",
      "median": 1064.6319425595402,
      "p2.5": 1052.2167209133306,
      "p97.5": 1077.1001379385148,
      "rank": 21,
      "rank_p2.5": 14,
      "rank_p97.5": 29,
      "total_output_tokens": 5412255,
      "conso_all_conv": 18.11400564675,
      "n_match": 2315,
      "mean_conso_per_match": 0.007824624469438445,
      "mean_conso_per_token": 3.3468500000000004e-06,
      "mean_win_prob": 0.5868560289633313,
      "win_rate": 0.5229299913569576,
      "useful": 349,
      "creative": 119,
      "complete": 459,
      "clear_formatting": 310,
      "incorrect": 134,
      "superficial": 104,
      "instructions_not_followed": 76,
      "total_prefs": 1551,
      "positive_prefs_ratio": 0.7975499677627337
    },
    {
      "model_name": "grok-4-fast",
      "median": 1063.0426934493335,
      "p2.5": 1052.233818274299,
      "p97.5": 1074.6461264914349,
      "rank": 22,
      "rank_p2.5": 15,
      "rank_p97.5": 29,
      "total_output_tokens": 3521762,
      "conso_all_conv": 898.5308874750866,
      "n_match": 2623,
      "mean_conso_per_match": 0.34255847787841653,
      "mean_conso_per_token": 0.0002551367433333333,
      "mean_win_prob": 0.5847097813311337,
      "win_rate": 0.5293971766501335,
      "useful": 228,
      "creative": 53,
      "complete": 176,
      "clear_formatting": 137,
      "incorrect": 61,
      "superficial": 52,
      "instructions_not_followed": 20,
      "total_prefs": 727,
      "positive_prefs_ratio": 0.8170563961485557
    },
    {
      "model_name": "gemma-3-12b",
      "median": 1062.899970159246,
      "p2.5": 1056.265573731515,
      "p97.5": 1070.4323104340885,
      "rank": 23,
      "rank_p2.5": 18,
      "rank_p97.5": 27,
      "total_output_tokens": 10680566,
      "conso_all_conv": 46.238377530973324,
      "n_match": 8288,
      "mean_conso_per_match": 0.005578954817926318,
      "mean_conso_per_token": 4.329206666666666e-06,
      "mean_win_prob": 0.5845168950335101,
      "win_rate": 0.5528173262548263,
      "useful": 1429,
      "creative": 418,
      "complete": 1557,
      "clear_formatting": 1201,
      "incorrect": 506,
      "superficial": 378,
      "instructions_not_followed": 210,
      "total_prefs": 5699,
      "positive_prefs_ratio": 0.8080364976311634
    },
    {
      "model_name": "claude-4-sonnet",
      "median": 1062.734506530794,
      "p2.5": 1051.0804797566554,
      "p97.5": 1074.7322403297835,
      "rank": 24,
      "rank_p2.5": 15,
      "rank_p97.5": 29,
      "total_output_tokens": 1853912,
      "conso_all_conv": 162.18978794591996,
      "n_match": 2540,
      "mean_conso_per_match": 0.06385424722280314,
      "mean_conso_per_token": 8.748515999999998e-05,
      "mean_win_prob": 0.5842932469540095,
      "win_rate": 0.5355651831429696,
      "useful": 234,
      "creative": 62,
      "complete": 198,
      "clear_formatting": 215,
      "incorrect": 41,
      "superficial": 64,
      "instructions_not_followed": 20,
      "total_prefs": 834,
      "positive_prefs_ratio": 0.8501199040767387
    },
    {
      "model_name": "grok-3-mini-beta",
      "median": 1060.3242727566726,
      "p2.5": 1045.6075376126498,
      "p97.5": 1075.0158704873663,
      "rank": 25,
      "rank_p2.5": 15,
      "rank_p97.5": 32,
      "total_output_tokens": 3474752,
      "conso_all_conv": 39.83854131029333,
      "n_match": 1537,
      "mean_conso_per_match": 0.02591967554345695,
      "mean_conso_per_token": 1.1465146666666665e-05,
      "mean_win_prob": 0.5810320019634347,
      "win_rate": 0.5305338541666668,
      "useful": 404,
      "creative": 102,
      "complete": 350,
      "clear_formatting": 320,
      "incorrect": 102,
      "superficial": 106,
      "instructions_not_followed": 47,
      "total_prefs": 1431,
      "positive_prefs_ratio": 0.8218029350104822
    },
    {
      "model_name": "mistral-small-2506",
      "median": 1058.6242849493146,
      "p2.5": 1051.1103055499516,
      "p97.5": 1066.5984752927143,
      "rank": 26,
      "rank_p2.5": 20,
      "rank_p97.5": 30,
      "total_output_tokens": 4434038,
      "conso_all_conv": 26.662964223373333,
      "n_match": 5510,
      "mean_conso_per_match": 0.004839013470666667,
      "mean_conso_per_token": 6.0132466666666666e-06,
      "mean_win_prob": 0.5787279715419086,
      "win_rate": 0.5236805807622504,
      "useful": 681,
      "creative": 172,
      "complete": 551,
      "clear_formatting": 544,
      "incorrect": 243,
      "superficial": 234,
      "instructions_not_followed": 76,
      "total_prefs": 2501,
      "positive_prefs_ratio": 0.7788884446221511
    },
    {
      "model_name": "kimi-k2",
      "median": 1056.603730964427,
      "p2.5": 1044.5372052887742,
      "p97.5": 1070.8005454392896,
      "rank": 27,
      "rank_p2.5": 18,
      "rank_p97.5": 33,
      "total_output_tokens": 1996422,
      "conso_all_conv": 113.97078085343996,
      "n_match": 1746,
      "mean_conso_per_match": 0.0652753613135395,
      "mean_conso_per_token": 5.708751999999998e-05,
      "mean_win_prob": 0.5759855189845751,
      "win_rate": 0.5120103388856978,
      "useful": 388,
      "creative": 114,
      "complete": 247,
      "clear_formatting": 242,
      "incorrect": 87,
      "superficial": 113,
      "instructions_not_followed": 35,
      "total_prefs": 1226,
      "positive_prefs_ratio": 0.8083197389885808
    },
    {
      "model_name": "deepseek-r1-0528",
      "median": 1055.292508342916,
      "p2.5": 1042.41347128767,
      "p97.5": 1066.8618680679822,
      "rank": 28,
      "rank_p2.5": 20,
      "rank_p97.5": 34,
      "total_output_tokens": 3893178,
      "conso_all_conv": 183.07957640171998,
      "n_match": 2097,
      "mean_conso_per_match": 0.0873054727714449,
      "mean_conso_per_token": 4.7025739999999995e-05,
      "mean_win_prob": 0.5742035983812075,
      "win_rate": 0.5195946590367192,
      "useful": 310,
      "creative": 91,
      "complete": 281,
      "clear_formatting": 223,
      "incorrect": 92,
      "superficial": 89,
      "instructions_not_followed": 45,
      "total_prefs": 1131,
      "positive_prefs_ratio": 0.8001768346595933
    },
    {
      "model_name": "command-a",
      "median": 1055.1027896311891,
      "p2.5": 1048.141614292336,
      "p97.5": 1062.3437037630586,
      "rank": 29,
      "rank_p2.5": 23,
      "rank_p97.5": 31,
      "total_output_tokens": 7603505,
      "conso_all_conv": 138.55514865768333,
      "n_match": 7866,
      "mean_conso_per_match": 0.017614435374737267,
      "mean_conso_per_token": 1.8222536666666665e-05,
      "mean_win_prob": 0.5739456330894819,
      "win_rate": 0.5454881769641495,
      "useful": 1543,
      "creative": 360,
      "complete": 1390,
      "clear_formatting": 1298,
      "incorrect": 365,
      "superficial": 417,
      "instructions_not_followed": 145,
      "total_prefs": 5518,
      "positive_prefs_ratio": 0.8320043494019572
    },
    {
      "model_name": "magistral-small-2506",
      "median": 1049.0267379776064,
      "p2.5": 1038.481768457883,
      "p97.5": 1058.7601603053506,
      "rank": 30,
      "rank_p2.5": 26,
      "rank_p97.5": 35,
      "total_output_tokens": 2445603,
      "conso_all_conv": 14.706014087739998,
      "n_match": 3147,
      "mean_conso_per_match": 0.0046730264022052746,
      "mean_conso_per_token": 6.013246666666666e-06,
      "mean_win_prob": 0.5656657968772842,
      "win_rate": 0.52184361093452,
      "useful": 248,
      "creative": 53,
      "complete": 198,
      "clear_formatting": 181,
      "incorrect": 88,
      "superficial": 84,
      "instructions_not_followed": 32,
      "total_prefs": 884,
      "positive_prefs_ratio": 0.7692307692307693
    },
    {
      "model_name": "claude-3-7-sonnet",
      "median": 1047.9949564274168,
      "p2.5": 1038.4783899931845,
      "p97.5": 1058.1577401011582,
      "rank": 31,
      "rank_p2.5": 26,
      "rank_p97.5": 35,
      "total_output_tokens": 3546728,
      "conso_all_conv": 310.2860665564799,
      "n_match": 3907,
      "mean_conso_per_match": 0.07941798478538006,
      "mean_conso_per_token": 8.748515999999998e-05,
      "mean_win_prob": 0.5642564764160243,
      "win_rate": 0.524225748656258,
      "useful": 1003,
      "creative": 230,
      "complete": 774,
      "clear_formatting": 822,
      "incorrect": 140,
      "superficial": 318,
      "instructions_not_followed": 46,
      "total_prefs": 3333,
      "positive_prefs_ratio": 0.8487848784878488
    },
    {
      "model_name": "Qwen3-Coder-480B-A35B-Instruct",
      "median": 1046.841819818561,
      "p2.5": 1033.1650641378385,
      "p97.5": 1061.8445408589473,
      "rank": 32,
      "rank_p2.5": 24,
      "rank_p97.5": 37,
      "total_output_tokens": 1507175,
      "conso_all_conv": 45.558584464999996,
      "n_match": 1557,
      "mean_conso_per_match": 0.02926049098587026,
      "mean_conso_per_token": 3.0227799999999995e-05,
      "mean_win_prob": 0.5626803248042114,
      "win_rate": 0.5199228295819935,
      "useful": 316,
      "creative": 74,
      "complete": 217,
      "clear_formatting": 245,
      "incorrect": 73,
      "superficial": 111,
      "instructions_not_followed": 39,
      "total_prefs": 1075,
      "positive_prefs_ratio": 0.7925581395348837
    },
    {
      "model_name": "glm-4.6",
      "median": 1044.6073589518637,
      "p2.5": 1032.908329505012,
      "p97.5": 1055.4549270455036,
      "rank": 33,
      "rank_p2.5": 28,
      "rank_p97.5": 37,
      "total_output_tokens": 7571593,
      "conso_all_conv": 162.09130005726,
      "n_match": 2769,
      "mean_conso_per_match": 0.05853784761908993,
      "mean_conso_per_token": 2.1407820000000003e-05,
      "mean_win_prob": 0.559623067245928,
      "win_rate": 0.5069447453954496,
      "useful": 339,
      "creative": 125,
      "complete": 387,
      "clear_formatting": 266,
      "incorrect": 104,
      "superficial": 111,
      "instructions_not_followed": 65,
      "total_prefs": 1397,
      "positive_prefs_ratio": 0.7995705082319255
    },
    {
      "model_name": "llama-3.1-nemotron-70b-instruct",
      "median": 1043.3650288643594,
      "p2.5": 1036.022860303368,
      "p97.5": 1050.590338573114,
      "rank": 34,
      "rank_p2.5": 30,
      "rank_p97.5": 36,
      "total_output_tokens": 7426282,
      "conso_all_conv": 92.59632991613334,
      "n_match": 6709,
      "mean_conso_per_match": 0.01380180800657823,
      "mean_conso_per_token": 1.2468733333333335e-05,
      "mean_win_prob": 0.557921563104075,
      "win_rate": 0.5452863107664778,
      "useful": 1544,
      "creative": 487,
      "complete": 1473,
      "clear_formatting": 1431,
      "incorrect": 381,
      "superficial": 395,
      "instructions_not_followed": 136,
      "total_prefs": 5847,
      "positive_prefs_ratio": 0.8440225756798359
    },
    {
      "model_name": "glm-4.7",
      "median": 1036.4984037133686,
      "p2.5": 1015.9276943209886,
      "p97.5": 1056.957717273028,
      "rank": 35,
      "rank_p2.5": 27,
      "rank_p97.5": 44,
      "total_output_tokens": 2012950,
      "conso_all_conv": 43.092871269,
      "n_match": 820,
      "mean_conso_per_match": 0.052552282035365855,
      "mean_conso_per_token": 2.140782e-05,
      "mean_win_prob": 0.5484968080794734,
      "win_rate": 0.4835243902439024,
      "useful": 126,
      "creative": 39,
      "complete": 143,
      "clear_formatting": 109,
      "incorrect": 43,
      "superficial": 47,
      "instructions_not_followed": 30,
      "total_prefs": 537,
      "positive_prefs_ratio": 0.776536312849162
    },
    {
      "model_name": "gemma-3-4b",
      "median": 1035.21990626276,
      "p2.5": 1028.617452169055,
      "p97.5": 1041.6762432477155,
      "rank": 36,
      "rank_p2.5": 34,
      "rank_p97.5": 39,
      "total_output_tokens": 11444303,
      "conso_all_conv": 36.696310160206664,
      "n_match": 9361,
      "mean_conso_per_match": 0.0039201271402848695,
      "mean_conso_per_token": 3.206513333333333e-06,
      "mean_win_prob": 0.5467385579531175,
      "win_rate": 0.5116579425275077,
      "useful": 1429,
      "creative": 423,
      "complete": 1539,
      "clear_formatting": 1241,
      "incorrect": 748,
      "superficial": 393,
      "instructions_not_followed": 263,
      "total_prefs": 6036,
      "positive_prefs_ratio": 0.7673956262425448
    },
    {
      "model_name": "gemma-3n-e4b-it",
      "median": 1033.0155932572084,
      "p2.5": 1024.5256462040086,
      "p97.5": 1041.847712374013,
      "rank": 37,
      "rank_p2.5": 34,
      "rank_p97.5": 41,
      "total_output_tokens": 5324129,
      "conso_all_conv": 17.071890626886667,
      "n_match": 4676,
      "mean_conso_per_match": 0.0036509603564770458,
      "mean_conso_per_token": 3.2065133333333334e-06,
      "mean_win_prob": 0.543704796481743,
      "win_rate": 0.4968156544054748,
      "useful": 504,
      "creative": 168,
      "complete": 500,
      "clear_formatting": 429,
      "incorrect": 252,
      "superficial": 208,
      "instructions_not_followed": 113,
      "total_prefs": 2174,
      "positive_prefs_ratio": 0.7364305427782889
    },
    {
      "model_name": "gpt-4.1-mini",
      "median": 1030.8173244484074,
      "p2.5": 1023.8562509790809,
      "p97.5": 1037.8277364677351,
      "rank": 38,
      "rank_p2.5": 35,
      "rank_p97.5": 41,
      "total_output_tokens": 5550374,
      "conso_all_conv": 73.10073823583333,
      "n_match": 7173,
      "mean_conso_per_match": 0.010191096923997398,
      "mean_conso_per_token": 1.3170416666666667e-05,
      "mean_win_prob": 0.5406766528753802,
      "win_rate": 0.5152977269557941,
      "useful": 1227,
      "creative": 286,
      "complete": 945,
      "clear_formatting": 1010,
      "incorrect": 244,
      "superficial": 455,
      "instructions_not_followed": 97,
      "total_prefs": 4264,
      "positive_prefs_ratio": 0.8133208255159474
    },
    {
      "model_name": "gemini-1.5-pro",
      "median": 1030.071100850156,
      "p2.5": 1022.2161600277361,
      "p97.5": 1037.5858052491897,
      "rank": 39,
      "rank_p2.5": 35,
      "rank_p97.5": 42,
      "total_output_tokens": 6034223,
      "conso_all_conv": 1011.3126436118333,
      "n_match": 7387,
      "mean_conso_per_match": 0.13690437845022788,
      "mean_conso_per_token": 0.00016759616666666666,
      "mean_win_prob": 0.5396481444648186,
      "win_rate": 0.5830743197509137,
      "useful": 2118,
      "creative": 683,
      "complete": 1630,
      "clear_formatting": 1959,
      "incorrect": 461,
      "superficial": 655,
      "instructions_not_followed": 202,
      "total_prefs": 7708,
      "positive_prefs_ratio": 0.8290088220031137
    },
    {
      "model_name": "deepseek-r1",
      "median": 1024.64399329869,
      "p2.5": 1014.6795204338654,
      "p97.5": 1034.981246335006,
      "rank": 40,
      "rank_p2.5": 36,
      "rank_p97.5": 45,
      "total_output_tokens": 3693582,
      "conso_all_conv": 173.69342680068,
      "n_match": 3510,
      "mean_conso_per_match": 0.04948530678082051,
      "mean_conso_per_token": 4.7025739999999995e-05,
      "mean_win_prob": 0.5321601957399885,
      "win_rate": 0.5313019943019943,
      "useful": 826,
      "creative": 284,
      "complete": 783,
      "clear_formatting": 667,
      "incorrect": 171,
      "superficial": 207,
      "instructions_not_followed": 112,
      "total_prefs": 3050,
      "positive_prefs_ratio": 0.839344262295082
    },
    {
      "model_name": "EuroLLM-22B-Instruct-2512",
      "median": 1022.9899841735698,
      "p2.5": 997.8820770642762,
      "p97.5": 1049.3285188344132,
      "rank": 41,
      "rank_p2.5": 31,
      "rank_p97.5": 52,
      "total_output_tokens": 373047,
      "conso_all_conv": 2.1385192842799996,
      "n_match": 495,
      "mean_conso_per_match": 0.0043202409783434335,
      "mean_conso_per_token": 5.7325733333333326e-06,
      "mean_win_prob": 0.5298756680233072,
      "win_rate": 0.44686868686868686,
      "useful": 127,
      "creative": 22,
      "complete": 81,
      "clear_formatting": 95,
      "incorrect": 38,
      "superficial": 49,
      "instructions_not_followed": 19,
      "total_prefs": 431,
      "positive_prefs_ratio": 0.7540603248259861
    },
    {
      "model_name": "qwen3-32b",
      "median": 1019.8991082731843,
      "p2.5": 1008.4713327432332,
      "p97.5": 1030.1439754480818,
      "rank": 42,
      "rank_p2.5": 39,
      "rank_p97.5": 48,
      "total_output_tokens": 4586242,
      "conso_all_conv": 32.72714773747999,
      "n_match": 2352,
      "mean_conso_per_match": 0.013914603629880947,
      "mean_conso_per_token": 7.1359399999999974e-06,
      "mean_win_prob": 0.5256039722598065,
      "win_rate": 0.5059914893617021,
      "useful": 515,
      "creative": 145,
      "complete": 420,
      "clear_formatting": 323,
      "incorrect": 208,
      "superficial": 179,
      "instructions_not_followed": 97,
      "total_prefs": 1887,
      "positive_prefs_ratio": 0.7435082140964494
    },
    {
      "model_name": "mistral-large-2411",
      "median": 1017.9878007044575,
      "p2.5": 1011.3784299196437,
      "p97.5": 1024.613341039268,
      "rank": 43,
      "rank_p2.5": 40,
      "rank_p97.5": 47,
      "total_output_tokens": 7677266,
      "conso_all_conv": 152.82808421939336,
      "n_match": 8829,
      "mean_conso_per_match": 0.017309784145361124,
      "mean_conso_per_token": 1.990657666666667e-05,
      "mean_win_prob": 0.5229610244104481,
      "win_rate": 0.5274413863404689,
      "useful": 1898,
      "creative": 355,
      "complete": 1451,
      "clear_formatting": 1608,
      "incorrect": 393,
      "superficial": 666,
      "instructions_not_followed": 140,
      "total_prefs": 6511,
      "positive_prefs_ratio": 0.8158500998310552
    },
    {
      "model_name": "llama-maverick",
      "median": 1014.7822986866493,
      "p2.5": 1005.8691786483275,
      "p97.5": 1025.041198064023,
      "rank": 44,
      "rank_p2.5": 40,
      "rank_p97.5": 49,
      "total_output_tokens": 3015469,
      "conso_all_conv": 45.51147851223,
      "n_match": 3849,
      "mean_conso_per_match": 0.011824234479664847,
      "mean_conso_per_token": 1.509267e-05,
      "mean_win_prob": 0.5185264225483007,
      "win_rate": 0.48251234086775785,
      "useful": 433,
      "creative": 86,
      "complete": 321,
      "clear_formatting": 306,
      "incorrect": 137,
      "superficial": 239,
      "instructions_not_followed": 76,
      "total_prefs": 1598,
      "positive_prefs_ratio": 0.7171464330413017
    },
    {
      "model_name": "gpt-oss-20b",
      "median": 1014.4460917786778,
      "p2.5": 1003.2262271574795,
      "p97.5": 1024.3766432240675,
      "rank": 45,
      "rank_p2.5": 40,
      "rank_p97.5": 50,
      "total_output_tokens": 4742155,
      "conso_all_conv": 14.540285010716666,
      "n_match": 2719,
      "mean_conso_per_match": 0.005347659069774426,
      "mean_conso_per_token": 3.0661766666666664e-06,
      "mean_win_prob": 0.5180611754067206,
      "win_rate": 0.45679911699779246,
      "useful": 317,
      "creative": 103,
      "complete": 319,
      "clear_formatting": 268,
      "incorrect": 159,
      "superficial": 142,
      "instructions_not_followed": 98,
      "total_prefs": 1406,
      "positive_prefs_ratio": 0.7162162162162162
    },
    {
      "model_name": "mistral-saba",
      "median": 1014.3828210476474,
      "p2.5": 1006.0661271267809,
      "p97.5": 1022.5152858125998,
      "rank": 46,
      "rank_p2.5": 41,
      "rank_p97.5": 49,
      "total_output_tokens": 4349650,
      "conso_all_conv": 26.155518363666665,
      "n_match": 4934,
      "mean_conso_per_match": 0.005301077901026888,
      "mean_conso_per_token": 6.0132466666666666e-06,
      "mean_win_prob": 0.5179736182228161,
      "win_rate": 0.48257855260490573,
      "useful": 745,
      "creative": 170,
      "complete": 587,
      "clear_formatting": 586,
      "incorrect": 241,
      "superficial": 337,
      "instructions_not_followed": 113,
      "total_prefs": 2779,
      "positive_prefs_ratio": 0.751349406261245
    },
    {
      "model_name": "gpt-5-mini",
      "median": 1012.0671233276421,
      "p2.5": 1003.6386165106413,
      "p97.5": 1021.0087049823221,
      "rank": 47,
      "rank_p2.5": 42,
      "rank_p97.5": 50,
      "total_output_tokens": 5219237,
      "conso_all_conv": 48.230916924629994,
      "n_match": 4459,
      "mean_conso_per_match": 0.010816532165200716,
      "mean_conso_per_token": 9.24099e-06,
      "mean_win_prob": 0.5147685698572521,
      "win_rate": 0.473140421713773,
      "useful": 477,
      "creative": 111,
      "complete": 468,
      "clear_formatting": 285,
      "incorrect": 122,
      "superficial": 207,
      "instructions_not_followed": 123,
      "total_prefs": 1793,
      "positive_prefs_ratio": 0.7479085331846068
    },
    {
      "model_name": "llama-4-scout",
      "median": 1010.3406557427395,
      "p2.5": 1002.7186259447222,
      "p97.5": 1017.4148909235756,
      "rank": 48,
      "rank_p2.5": 43,
      "rank_p97.5": 51,
      "total_output_tokens": 5195356,
      "conso_all_conv": 26.137264546839997,
      "n_match": 6565,
      "mean_conso_per_match": 0.0039813045768225435,
      "mean_conso_per_token": 5.03089e-06,
      "mean_win_prob": 0.5123785468735157,
      "win_rate": 0.4864204112718964,
      "useful": 1005,
      "creative": 224,
      "complete": 846,
      "clear_formatting": 807,
      "incorrect": 355,
      "superficial": 499,
      "instructions_not_followed": 143,
      "total_prefs": 3879,
      "positive_prefs_ratio": 0.7429749935550399
    },
    {
      "model_name": "mistral-small-3.1-24b",
      "median": 1004.4200201036565,
      "p2.5": 996.8077575390157,
      "p97.5": 1012.5087541744489,
      "rank": 49,
      "rank_p2.5": 46,
      "rank_p97.5": 53,
      "total_output_tokens": 4470466,
      "conso_all_conv": 26.882014772946665,
      "n_match": 5079,
      "mean_conso_per_match": 0.005292777076776268,
      "mean_conso_per_token": 6.0132466666666666e-06,
      "mean_win_prob": 0.5041806219854251,
      "win_rate": 0.4945107304587517,
      "useful": 1108,
      "creative": 247,
      "complete": 791,
      "clear_formatting": 916,
      "incorrect": 268,
      "superficial": 430,
      "instructions_not_followed": 130,
      "total_prefs": 3890,
      "positive_prefs_ratio": 0.787146529562982
    },
    {
      "model_name": "o4-mini",
      "median": 1002.0481567670117,
      "p2.5": 990.8420442065715,
      "p97.5": 1012.3162368080086,
      "rank": 50,
      "rank_p2.5": 47,
      "rank_p97.5": 55,
      "total_output_tokens": 2940457,
      "conso_all_conv": 15.205769650586666,
      "n_match": 2830,
      "mean_conso_per_match": 0.005373063480772673,
      "mean_conso_per_token": 5.171226666666666e-06,
      "mean_win_prob": 0.5008963606355553,
      "win_rate": 0.4738494167550371,
      "useful": 527,
      "creative": 111,
      "complete": 374,
      "clear_formatting": 286,
      "incorrect": 133,
      "superficial": 210,
      "instructions_not_followed": 45,
      "total_prefs": 1686,
      "positive_prefs_ratio": 0.7698695136417556
    },
    {
      "model_name": "gemma-2-27b-it-q8",
      "median": 1000.5781320746341,
      "p2.5": 975.5700987415867,
      "p97.5": 1025.8779121609764,
      "rank": 51,
      "rank_p2.5": 40,
      "rank_p97.5": 63,
      "total_output_tokens": 449540,
      "conso_all_conv": 2.8924557419333334,
      "n_match": 762,
      "mean_conso_per_match": 0.0037958736770778655,
      "mean_conso_per_token": 6.434256666666667e-06,
      "mean_win_prob": 0.49886101074090466,
      "win_rate": 0.5826115485564304,
      "useful": 318,
      "creative": 97,
      "complete": 178,
      "clear_formatting": 305,
      "incorrect": 63,
      "superficial": 91,
      "instructions_not_followed": 29,
      "total_prefs": 1081,
      "positive_prefs_ratio": 0.8307123034227567
    },
    {
      "model_name": "gpt-5",
      "median": 999.3482157177224,
      "p2.5": 989.4707026290199,
      "p97.5": 1008.6769061026309,
      "rank": 52,
      "rank_p2.5": 48,
      "rank_p97.5": 55,
      "total_output_tokens": 4019540,
      "conso_all_conv": 190.97011399759995,
      "n_match": 3843,
      "mean_conso_per_match": 0.0496929778812386,
      "mean_conso_per_token": 4.751043999999999e-05,
      "mean_win_prob": 0.4971582561736023,
      "win_rate": 0.45334721499219155,
      "useful": 144,
      "creative": 54,
      "complete": 158,
      "clear_formatting": 68,
      "incorrect": 29,
      "superficial": 57,
      "instructions_not_followed": 32,
      "total_prefs": 542,
      "positive_prefs_ratio": 0.7822878228782287
    },
    {
      "model_name": "lfm2-8b-a1b",
      "median": 995.7885321767604,
      "p2.5": 983.8706046792518,
      "p97.5": 1007.6239141278718,
      "rank": 53,
      "rank_p2.5": 49,
      "rank_p97.5": 58,
      "total_output_tokens": 1746646,
      "conso_all_conv": 4.865288255153334,
      "n_match": 2276,
      "mean_conso_per_match": 0.0021376486182571766,
      "mean_conso_per_token": 2.7855033333333337e-06,
      "mean_win_prob": 0.4922311821608464,
      "win_rate": 0.4696990333919156,
      "useful": 293,
      "creative": 56,
      "complete": 199,
      "clear_formatting": 232,
      "incorrect": 190,
      "superficial": 175,
      "instructions_not_followed": 86,
      "total_prefs": 1231,
      "positive_prefs_ratio": 0.6336311941510967
    },
    {
      "model_name": "aya-expanse-32b",
      "median": 990.3850545076917,
      "p2.5": 981.9090100007257,
      "p97.5": 998.9488260473206,
      "rank": 54,
      "rank_p2.5": 52,
      "rank_p97.5": 60,
      "total_output_tokens": 4082212,
      "conso_all_conv": 29.130419899279993,
      "n_match": 5113,
      "mean_conso_per_match": 0.005697324447345979,
      "mean_conso_per_token": 7.135939999999998e-06,
      "mean_win_prob": 0.48475688163584535,
      "win_rate": 0.46256796401329947,
      "useful": 722,
      "creative": 142,
      "complete": 527,
      "clear_formatting": 513,
      "incorrect": 277,
      "superficial": 353,
      "instructions_not_followed": 109,
      "total_prefs": 2643,
      "positive_prefs_ratio": 0.7203934922436626
    },
    {
      "model_name": "qwen3-30b-a3b",
      "median": 987.7834851720252,
      "p2.5": 978.8053849767813,
      "p97.5": 996.8664478272945,
      "rank": 55,
      "rank_p2.5": 52,
      "rank_p97.5": 62,
      "total_output_tokens": 6628258,
      "conso_all_conv": 20.323410020246666,
      "n_match": 3825,
      "mean_conso_per_match": 0.0053133098092148145,
      "mean_conso_per_token": 3.0661766666666664e-06,
      "mean_win_prob": 0.48116116666937253,
      "win_rate": 0.454989539748954,
      "useful": 347,
      "creative": 92,
      "complete": 375,
      "clear_formatting": 287,
      "incorrect": 225,
      "superficial": 191,
      "instructions_not_followed": 112,
      "total_prefs": 1629,
      "positive_prefs_ratio": 0.6758747697974218
    },
    {
      "model_name": "qwen-3-8b",
      "median": 987.6061979120927,
      "p2.5": 977.457231632802,
      "p97.5": 998.6672023054713,
      "rank": 56,
      "rank_p2.5": 52,
      "rank_p97.5": 63,
      "total_output_tokens": 6392571,
      "conso_all_conv": 24.08631256806,
      "n_match": 3245,
      "mean_conso_per_match": 0.007422592470896764,
      "mean_conso_per_token": 3.7678599999999997e-06,
      "mean_win_prob": 0.4809162135045945,
      "win_rate": 0.4323697996918336,
      "useful": 311,
      "creative": 84,
      "complete": 314,
      "clear_formatting": 222,
      "incorrect": 247,
      "superficial": 153,
      "instructions_not_followed": 99,
      "total_prefs": 1430,
      "positive_prefs_ratio": 0.651048951048951
    },
    {
      "model_name": "llama-3.3-70b",
      "median": 986.1296496469465,
      "p2.5": 979.9268583117666,
      "p97.5": 992.0406829263549,
      "rank": 57,
      "rank_p2.5": 54,
      "rank_p97.5": 62,
      "total_output_tokens": 8015717,
      "conso_all_conv": 99.94583774846667,
      "n_match": 9845,
      "mean_conso_per_match": 0.010151938826659896,
      "mean_conso_per_token": 1.2468733333333335e-05,
      "mean_win_prob": 0.4788765433374813,
      "win_rate": 0.47193905535804975,
      "useful": 1643,
      "creative": 340,
      "complete": 1272,
      "clear_formatting": 1223,
      "incorrect": 556,
      "superficial": 790,
      "instructions_not_followed": 191,
      "total_prefs": 6015,
      "positive_prefs_ratio": 0.7444721529509559
    },
    {
      "model_name": "mistral-small-24b-instruct-2501",
      "median": 984.3344665980067,
      "p2.5": 973.9914113855426,
      "p97.5": 994.45201374902,
      "rank": 58,
      "rank_p2.5": 53,
      "rank_p97.5": 64,
      "total_output_tokens": 2818040,
      "conso_all_conv": 16.94556963653333,
      "n_match": 3318,
      "mean_conso_per_match": 0.005107163844645368,
      "mean_conso_per_token": 6.013246666666666e-06,
      "mean_win_prob": 0.47639783839994443,
      "win_rate": 0.4952350813743219,
      "useful": 745,
      "creative": 155,
      "complete": 536,
      "clear_formatting": 656,
      "incorrect": 204,
      "superficial": 307,
      "instructions_not_followed": 71,
      "total_prefs": 2674,
      "positive_prefs_ratio": 0.7823485415108452
    },
    {
      "model_name": "o3-mini",
      "median": 980.7429983155654,
      "p2.5": 966.9929029475512,
      "p97.5": 994.54570678682,
      "rank": 59,
      "rank_p2.5": 53,
      "rank_p97.5": 68,
      "total_output_tokens": 1655945,
      "conso_all_conv": 8.563266942533334,
      "n_match": 1619,
      "mean_conso_per_match": 0.005289232206629607,
      "mean_conso_per_token": 5.171226666666667e-06,
      "mean_win_prob": 0.47144303296775514,
      "win_rate": 0.51142063001853,
      "useful": 350,
      "creative": 85,
      "complete": 254,
      "clear_formatting": 230,
      "incorrect": 49,
      "superficial": 133,
      "instructions_not_followed": 28,
      "total_prefs": 1129,
      "positive_prefs_ratio": 0.8139946855624446
    },
    {
      "model_name": "gpt-4o-mini-2024-07-18",
      "median": 980.65826535713,
      "p2.5": 973.520376376709,
      "p97.5": 988.1225836113406,
      "rank": 60,
      "rank_p2.5": 56,
      "rank_p97.5": 65,
      "total_output_tokens": 5207480,
      "conso_all_conv": 26.929059442133333,
      "n_match": 6990,
      "mean_conso_per_match": 0.0038525120804196473,
      "mean_conso_per_token": 5.171226666666666e-06,
      "mean_win_prob": 0.47132620703894984,
      "win_rate": 0.49947067238912735,
      "useful": 1491,
      "creative": 319,
      "complete": 856,
      "clear_formatting": 1282,
      "incorrect": 369,
      "superficial": 599,
      "instructions_not_followed": 110,
      "total_prefs": 5026,
      "positive_prefs_ratio": 0.7855153203342619
    },
    {
      "model_name": "Apertus-70B-Instruct-2509",
      "median": 978.2225058014048,
      "p2.5": 966.3053477957858,
      "p97.5": 989.5733767316161,
      "rank": 61,
      "rank_p2.5": 55,
      "rank_p97.5": 68,
      "total_output_tokens": 2346718,
      "conso_all_conv": 29.260600950533334,
      "n_match": 2415,
      "mean_conso_per_match": 0.01211619086978606,
      "mean_conso_per_token": 1.2468733333333333e-05,
      "mean_win_prob": 0.4679694356462587,
      "win_rate": 0.41113871635610766,
      "useful": 252,
      "creative": 46,
      "complete": 174,
      "clear_formatting": 155,
      "incorrect": 132,
      "superficial": 183,
      "instructions_not_followed": 78,
      "total_prefs": 1020,
      "positive_prefs_ratio": 0.6147058823529412
    },
    {
      "model_name": "gpt-4.1-nano",
      "median": 977.2096130524985,
      "p2.5": 969.1839088245116,
      "p97.5": 984.9126369228114,
      "rank": 62,
      "rank_p2.5": 58,
      "rank_p97.5": 67,
      "total_output_tokens": 3563423,
      "conso_all_conv": 20.927662570929996,
      "n_match": 5717,
      "mean_conso_per_match": 0.003660602163884904,
      "mean_conso_per_token": 5.872909999999999e-06,
      "mean_win_prob": 0.4665744648024418,
      "win_rate": 0.46743047052649994,
      "useful": 928,
      "creative": 159,
      "complete": 529,
      "clear_formatting": 649,
      "incorrect": 276,
      "superficial": 448,
      "instructions_not_followed": 103,
      "total_prefs": 3092,
      "positive_prefs_ratio": 0.732535575679172
    },
    {
      "model_name": "minimax-m2",
      "median": 976.3142292162099,
      "p2.5": 963.6684496707841,
      "p97.5": 989.2006072988642,
      "rank": 63,
      "rank_p2.5": 55,
      "rank_p97.5": 69,
      "total_output_tokens": 3898613,
      "conso_all_conv": 31.567329368533333,
      "n_match": 2160,
      "mean_conso_per_match": 0.014614504337283951,
      "mean_conso_per_token": 8.097066666666666e-06,
      "mean_win_prob": 0.4653418021375933,
      "win_rate": 0.4370324074074074,
      "useful": 288,
      "creative": 66,
      "complete": 234,
      "clear_formatting": 166,
      "incorrect": 127,
      "superficial": 144,
      "instructions_not_followed": 75,
      "total_prefs": 1100,
      "positive_prefs_ratio": 0.6854545454545454
    },
    {
      "model_name": "aya-expanse-8b",
      "median": 972.5648327470834,
      "p2.5": 956.5518219061602,
      "p97.5": 988.4911713123083,
      "rank": 64,
      "rank_p2.5": 56,
      "rank_p97.5": 72,
      "total_output_tokens": 1057810,
      "conso_all_conv": 3.9856799865999997,
      "n_match": 1302,
      "mean_conso_per_match": 0.003061198146390169,
      "mean_conso_per_token": 3.7678599999999997e-06,
      "mean_win_prob": 0.46018520179190664,
      "win_rate": 0.5014285714285714,
      "useful": 243,
      "creative": 55,
      "complete": 133,
      "clear_formatting": 223,
      "incorrect": 149,
      "superficial": 104,
      "instructions_not_followed": 31,
      "total_prefs": 938,
      "positive_prefs_ratio": 0.697228144989339
    },
    {
      "model_name": "llama-3.1-70b",
      "median": 971.2992602009906,
      "p2.5": 962.6317668889652,
      "p97.5": 980.0001895866712,
      "rank": 65,
      "rank_p2.5": 61,
      "rank_p97.5": 69,
      "total_output_tokens": 4057254,
      "conso_all_conv": 50.588818191600005,
      "n_match": 5583,
      "mean_conso_per_match": 0.009061224823858141,
      "mean_conso_per_token": 1.2468733333333335e-05,
      "mean_win_prob": 0.45844663659701973,
      "win_rate": 0.530445996775927,
      "useful": 1532,
      "creative": 365,
      "complete": 1047,
      "clear_formatting": 1305,
      "incorrect": 463,
      "superficial": 621,
      "instructions_not_followed": 177,
      "total_prefs": 5510,
      "positive_prefs_ratio": 0.7711433756805808
    },
    {
      "model_name": "jamba-1.5-large",
      "median": 970.3032689000186,
      "p2.5": 922.1464643631258,
      "p97.5": 1015.7962176002284,
      "rank": 66,
      "rank_p2.5": 45,
      "rank_p97.5": 82,
      "total_output_tokens": 143976,
      "conso_all_conv": 6.840363109439998,
      "n_match": 172,
      "mean_conso_per_match": 0.03976955296186046,
      "mean_conso_per_token": 4.751043999999999e-05,
      "mean_win_prob": 0.45707915723429754,
      "win_rate": 0.5449418604651162,
      "useful": 44,
      "creative": 11,
      "complete": 18,
      "clear_formatting": 57,
      "incorrect": 15,
      "superficial": 13,
      "instructions_not_followed": 4,
      "total_prefs": 162,
      "positive_prefs_ratio": 0.8024691358024691
    },
    {
      "model_name": "claude-3-5-sonnet-v2",
      "median": 970.1765962992393,
      "p2.5": 962.1418649798869,
      "p97.5": 978.4518095549429,
      "rank": 67,
      "rank_p2.5": 62,
      "rank_p97.5": 70,
      "total_output_tokens": 3224219,
      "conso_all_conv": 282.07131509003995,
      "n_match": 5683,
      "mean_conso_per_match": 0.049634227536519436,
      "mean_conso_per_token": 8.748515999999998e-05,
      "mean_win_prob": 0.45690528643282347,
      "win_rate": 0.4921080415273623,
      "useful": 1301,
      "creative": 291,
      "complete": 721,
      "clear_formatting": 905,
      "incorrect": 250,
      "superficial": 606,
      "instructions_not_followed": 94,
      "total_prefs": 4168,
      "positive_prefs_ratio": 0.7720729366602687
    },
    {
      "model_name": "phi-4",
      "median": 965.7908502856119,
      "p2.5": 959.8637323670275,
      "p97.5": 971.9243374217256,
      "rank": 68,
      "rank_p2.5": 65,
      "rank_p97.5": 71,
      "total_output_tokens": 8226489,
      "conso_all_conv": 37.92312711132,
      "n_match": 9968,
      "mean_conso_per_match": 0.003804487069755217,
      "mean_conso_per_token": 4.60988e-06,
      "mean_win_prob": 0.4508925178341852,
      "win_rate": 0.46780074245008524,
      "useful": 1626,
      "creative": 336,
      "complete": 1193,
      "clear_formatting": 1311,
      "incorrect": 731,
      "superficial": 760,
      "instructions_not_followed": 253,
      "total_prefs": 6210,
      "positive_prefs_ratio": 0.7191626409017713
    },
    {
      "model_name": "ministral-8b-instruct-2410",
      "median": 961.8620067458638,
      "p2.5": 956.3112645056369,
      "p97.5": 968.5581169302711,
      "rank": 69,
      "rank_p2.5": 67,
      "rank_p97.5": 72,
      "total_output_tokens": 7488476,
      "conso_all_conv": 28.215529181359997,
      "n_match": 9278,
      "mean_conso_per_match": 0.003041121920819142,
      "mean_conso_per_token": 3.7678599999999997e-06,
      "mean_win_prob": 0.4455187602323125,
      "win_rate": 0.47576819407008086,
      "useful": 1796,
      "creative": 412,
      "complete": 1332,
      "clear_formatting": 1695,
      "incorrect": 876,
      "superficial": 927,
      "instructions_not_followed": 274,
      "total_prefs": 7312,
      "positive_prefs_ratio": 0.7159463894967177
    },
    {
      "model_name": "gpt-4o-2024-08-06",
      "median": 960.8435832332941,
      "p2.5": 952.1598651653576,
      "p97.5": 969.521281487235,
      "rank": 70,
      "rank_p2.5": 66,
      "rank_p97.5": 73,
      "total_output_tokens": 3903917,
      "conso_all_conv": 341.53480337171993,
      "n_match": 5896,
      "mean_conso_per_match": 0.05792652703048167,
      "mean_conso_per_token": 8.748515999999998e-05,
      "mean_win_prob": 0.4441278834897516,
      "win_rate": 0.48863297150610585,
      "useful": 1230,
      "creative": 243,
      "complete": 593,
      "clear_formatting": 1002,
      "incorrect": 275,
      "superficial": 590,
      "instructions_not_followed": 115,
      "total_prefs": 4048,
      "positive_prefs_ratio": 0.7579051383399209
    },
    {
      "model_name": "Apertus-8B-Instruct-2509",
      "median": 960.0750129152215,
      "p2.5": 897.5695839819098,
      "p97.5": 1018.3914152543823,
      "rank": 71,
      "rank_p2.5": 44,
      "rank_p97.5": 83,
      "total_output_tokens": 52304,
      "conso_all_conv": 0.19707414943999998,
      "n_match": 86,
      "mean_conso_per_match": 0.002291559877209302,
      "mean_conso_per_token": 3.7678599999999997e-06,
      "mean_win_prob": 0.4430788303920943,
      "win_rate": 0.46880952380952384,
      "useful": 2,
      "creative": 0,
      "complete": 3,
      "clear_formatting": 2,
      "incorrect": 3,
      "superficial": 5,
      "instructions_not_followed": 0,
      "total_prefs": 15,
      "positive_prefs_ratio": 0.4666666666666667
    },
    {
      "model_name": "qwen2.5-32b-instruct",
      "median": 958.9521430777111,
      "p2.5": 897.3755567452323,
      "p97.5": 1016.3279675525384,
      "rank": 72,
      "rank_p2.5": 44,
      "rank_p97.5": 83,
      "total_output_tokens": 75812,
      "conso_all_conv": 0.5409898832799999,
      "n_match": 142,
      "mean_conso_per_match": 0.003809787910422534,
      "mean_conso_per_token": 7.135939999999998e-06,
      "mean_win_prob": 0.44154711922363155,
      "win_rate": 0.5557042253521126,
      "useful": 52,
      "creative": 16,
      "complete": 43,
      "clear_formatting": 57,
      "incorrect": 13,
      "superficial": 21,
      "instructions_not_followed": 15,
      "total_prefs": 217,
      "positive_prefs_ratio": 0.7741935483870968
    },
    {
      "model_name": "llama-3.1-405b",
      "median": 955.7654366778364,
      "p2.5": 949.5791769955232,
      "p97.5": 962.660765663043,
      "rank": 73,
      "rank_p2.5": 69,
      "rank_p97.5": 75,
      "total_output_tokens": 10383810,
      "conso_all_conv": 2470.579070314,
      "n_match": 9973,
      "mean_conso_per_match": 0.24772676930853305,
      "mean_conso_per_token": 0.00023792606666666667,
      "mean_win_prob": 0.4372064150532003,
      "win_rate": 0.4950747166783673,
      "useful": 2224,
      "creative": 556,
      "complete": 1579,
      "clear_formatting": 1788,
      "incorrect": 947,
      "superficial": 890,
      "instructions_not_followed": 437,
      "total_prefs": 8421,
      "positive_prefs_ratio": 0.7299608122550766
    },
    {
      "model_name": "gemma-2-9b-it",
      "median": 951.6911584966574,
      "p2.5": 942.9794258768871,
      "p97.5": 961.2291174265769,
      "rank": 74,
      "rank_p2.5": 70,
      "rank_p97.5": 76,
      "total_output_tokens": 3108609,
      "conso_all_conv": 12.149055331769999,
      "n_match": 5115,
      "mean_conso_per_match": 0.002375181883043988,
      "mean_conso_per_token": 3.908196666666666e-06,
      "mean_win_prob": 0.4316710505845071,
      "win_rate": 0.5068660801564027,
      "useful": 1250,
      "creative": 403,
      "complete": 771,
      "clear_formatting": 1197,
      "incorrect": 472,
      "superficial": 595,
      "instructions_not_followed": 177,
      "total_prefs": 4865,
      "positive_prefs_ratio": 0.7442959917780062
    },
    {
      "model_name": "qwq-32b",
      "median": 947.0072163225104,
      "p2.5": 932.0841232110957,
      "p97.5": 962.8804664136812,
      "rank": 75,
      "rank_p2.5": 70,
      "rank_p97.5": 80,
      "total_output_tokens": 1895013,
      "conso_all_conv": 13.522699067219996,
      "n_match": 1566,
      "mean_conso_per_match": 0.008635184589540228,
      "mean_conso_per_token": 7.135939999999998e-06,
      "mean_win_prob": 0.4253287566739331,
      "win_rate": 0.4485997442455243,
      "useful": 291,
      "creative": 139,
      "complete": 343,
      "clear_formatting": 233,
      "incorrect": 140,
      "superficial": 105,
      "instructions_not_followed": 92,
      "total_prefs": 1343,
      "positive_prefs_ratio": 0.7490692479523455
    },
    {
      "model_name": "gpt-5-nano",
      "median": 944.6578672491062,
      "p2.5": 933.8375059453672,
      "p97.5": 954.8143858837535,
      "rank": 76,
      "rank_p2.5": 72,
      "rank_p97.5": 79,
      "total_output_tokens": 3723743,
      "conso_all_conv": 15.59827534041,
      "n_match": 3583,
      "mean_conso_per_match": 0.004353412040304214,
      "mean_conso_per_token": 4.18887e-06,
      "mean_win_prob": 0.4221567817453329,
      "win_rate": 0.39687412782584425,
      "useful": 302,
      "creative": 69,
      "complete": 282,
      "clear_formatting": 182,
      "incorrect": 147,
      "superficial": 188,
      "instructions_not_followed": 166,
      "total_prefs": 1336,
      "positive_prefs_ratio": 0.625
    },
    {
      "model_name": "deepseek-r1-distill-llama-70b",
      "median": 944.2056230505632,
      "p2.5": 932.5914136095929,
      "p97.5": 954.817637328895,
      "rank": 77,
      "rank_p2.5": 72,
      "rank_p97.5": 79,
      "total_output_tokens": 2863519,
      "conso_all_conv": 35.70445480593334,
      "n_match": 2981,
      "mean_conso_per_match": 0.011977341431041039,
      "mean_conso_per_token": 1.2468733333333335e-05,
      "mean_win_prob": 0.42154691495602004,
      "win_rate": 0.4397953706809795,
      "useful": 489,
      "creative": 130,
      "complete": 355,
      "clear_formatting": 363,
      "incorrect": 190,
      "superficial": 342,
      "instructions_not_followed": 126,
      "total_prefs": 1995,
      "positive_prefs_ratio": 0.6701754385964912
    },
    {
      "model_name": "hermes-3-llama-3.1-405b",
      "median": 940.0338329859642,
      "p2.5": 932.7024148705617,
      "p97.5": 947.4373635726256,
      "rank": 78,
      "rank_p2.5": 74,
      "rank_p97.5": 79,
      "total_output_tokens": 4092822,
      "conso_all_conv": 973.7890400268,
      "n_match": 6735,
      "mean_conso_per_match": 0.144586345957951,
      "mean_conso_per_token": 0.00023792606666666667,
      "mean_win_prob": 0.41593264110506944,
      "win_rate": 0.46634743875278395,
      "useful": 1450,
      "creative": 285,
      "complete": 830,
      "clear_formatting": 1109,
      "incorrect": 426,
      "superficial": 753,
      "instructions_not_followed": 184,
      "total_prefs": 5037,
      "positive_prefs_ratio": 0.7294024220766329
    },
    {
      "model_name": "hermes-4-70b",
      "median": 934.1551923878044,
      "p2.5": 922.7804513402339,
      "p97.5": 944.778766232408,
      "rank": 79,
      "rank_p2.5": 75,
      "rank_p97.5": 83,
      "total_output_tokens": 1465378,
      "conso_all_conv": 18.271407514533333,
      "n_match": 3199,
      "mean_conso_per_match": 0.005711599723205168,
      "mean_conso_per_token": 1.2468733333333333e-05,
      "mean_win_prob": 0.4080584620780003,
      "win_rate": 0.37180907668231616,
      "useful": 292,
      "creative": 56,
      "complete": 133,
      "clear_formatting": 179,
      "incorrect": 168,
      "superficial": 274,
      "instructions_not_followed": 110,
      "total_prefs": 1212,
      "positive_prefs_ratio": 0.5445544554455446
    },
    {
      "model_name": "llama-3.1-8b",
      "median": 931.9706187297918,
      "p2.5": 926.2009148597415,
      "p97.5": 938.1685265916046,
      "rank": 80,
      "rank_p2.5": 77,
      "rank_p97.5": 82,
      "total_output_tokens": 7372632,
      "conso_all_conv": 27.779045207519996,
      "n_match": 10444,
      "mean_conso_per_match": 0.002659809001103025,
      "mean_conso_per_token": 3.7678599999999993e-06,
      "mean_win_prob": 0.405144013473085,
      "win_rate": 0.4424234009957871,
      "useful": 1540,
      "creative": 373,
      "complete": 1014,
      "clear_formatting": 1159,
      "incorrect": 1043,
      "superficial": 978,
      "instructions_not_followed": 404,
      "total_prefs": 6511,
      "positive_prefs_ratio": 0.6275533712179389
    },
    {
      "model_name": "c4ai-command-r-08-2024",
      "median": 927.7151418306971,
      "p2.5": 919.8568132570358,
      "p97.5": 935.8531017303254,
      "rank": 81,
      "rank_p2.5": 78,
      "rank_p97.5": 83,
      "total_output_tokens": 4319206,
      "conso_all_conv": 32.640023781699995,
      "n_match": 5959,
      "mean_conso_per_match": 0.005477433089729819,
      "mean_conso_per_token": 7.556949999999999e-06,
      "mean_win_prob": 0.3994859127883386,
      "win_rate": 0.42968786709179396,
      "useful": 1075,
      "creative": 255,
      "complete": 843,
      "clear_formatting": 796,
      "incorrect": 471,
      "superficial": 660,
      "instructions_not_followed": 163,
      "total_prefs": 4263,
      "positive_prefs_ratio": 0.6964578935022285
    },
    {
      "model_name": "qwen2.5-7b-instruct",
      "median": 924.8650333948219,
      "p2.5": 906.1961727303783,
      "p97.5": 941.8619637650589,
      "rank": 82,
      "rank_p2.5": 76,
      "rank_p97.5": 83,
      "total_output_tokens": 1186919,
      "conso_all_conv": 4.305576367276667,
      "n_match": 1417,
      "mean_conso_per_match": 0.0030385154320936255,
      "mean_conso_per_token": 3.6275233333333336e-06,
      "mean_win_prob": 0.39571107140389744,
      "win_rate": 0.49383909668313336,
      "useful": 402,
      "creative": 104,
      "complete": 284,
      "clear_formatting": 380,
      "incorrect": 231,
      "superficial": 203,
      "instructions_not_followed": 88,
      "total_prefs": 1692,
      "positive_prefs_ratio": 0.6914893617021277
    },
    {
      "model_name": "qwen2.5-coder-32b-instruct",
      "median": 924.4623131280374,
      "p2.5": 917.6091595133253,
      "p97.5": 932.1772288721302,
      "rank": 83,
      "rank_p2.5": 79,
      "rank_p97.5": 83,
      "total_output_tokens": 6149486,
      "conso_all_conv": 43.882363126839984,
      "n_match": 7299,
      "mean_conso_per_match": 0.006012106196306341,
      "mean_conso_per_token": 7.1359399999999974e-06,
      "mean_win_prob": 0.3951786628063842,
      "win_rate": 0.43789423208658723,
      "useful": 1379,
      "creative": 293,
      "complete": 923,
      "clear_formatting": 1142,
      "incorrect": 790,
      "superficial": 742,
      "instructions_not_followed": 234,
      "total_prefs": 5503,
      "positive_prefs_ratio": 0.6790841359258586
    },
    {
      "model_name": "mixtral-8x7b-instruct-v0.1",
      "median": 882.8739728644196,
      "p2.5": 869.4634215384922,
      "p97.5": 896.4480289127155,
      "rank": 84,
      "rank_p2.5": 84,
      "rank_p97.5": 86,
      "total_output_tokens": 1575791,
      "conso_all_conv": 7.2642074150800005,
      "n_match": 2560,
      "mean_conso_per_match": 0.0028375810215156253,
      "mean_conso_per_token": 4.60988e-06,
      "mean_win_prob": 0.34170176350917003,
      "win_rate": 0.43488671874999996,
      "useful": 727,
      "creative": 164,
      "complete": 375,
      "clear_formatting": 503,
      "incorrect": 256,
      "superficial": 389,
      "instructions_not_followed": 159,
      "total_prefs": 2573,
      "positive_prefs_ratio": 0.687524290711232
    },
    {
      "model_name": "lfm-40b",
      "median": 880.0844663012888,
      "p2.5": 868.6099655165212,
      "p97.5": 890.9578756465498,
      "rank": 85,
      "rank_p2.5": 84,
      "rank_p97.5": 86,
      "total_output_tokens": 2000824,
      "conso_all_conv": 8.661980599626665,
      "n_match": 3578,
      "mean_conso_per_match": 0.0024209001116899565,
      "mean_conso_per_token": 4.329206666666666e-06,
      "mean_win_prob": 0.3382348009721951,
      "win_rate": 0.416296813862493,
      "useful": 841,
      "creative": 166,
      "complete": 419,
      "clear_formatting": 647,
      "incorrect": 357,
      "superficial": 572,
      "instructions_not_followed": 121,
      "total_prefs": 3123,
      "positive_prefs_ratio": 0.6637848222862632
    },
    {
      "model_name": "olmo-3-32b-think",
      "median": 867.8207579197996,
      "p2.5": 849.6952312483934,
      "p97.5": 886.0247766289709,
      "rank": 86,
      "rank_p2.5": 84,
      "rank_p97.5": 88,
      "total_output_tokens": 2845759,
      "conso_all_conv": 20.307165478459993,
      "n_match": 1196,
      "mean_conso_per_match": 0.016979235349882937,
      "mean_conso_per_token": 7.1359399999999974e-06,
      "mean_win_prob": 0.32319439223691965,
      "win_rate": 0.3349247491638796,
      "useful": 113,
      "creative": 33,
      "complete": 99,
      "clear_formatting": 59,
      "incorrect": 117,
      "superficial": 100,
      "instructions_not_followed": 107,
      "total_prefs": 628,
      "positive_prefs_ratio": 0.4840764331210191
    },
    {
      "model_name": "phi-3.5-mini-instruct",
      "median": 860.0981847050815,
      "p2.5": 845.1673671860806,
      "p97.5": 873.9334426000527,
      "rank": 87,
      "rank_p2.5": 86,
      "rank_p97.5": 88,
      "total_output_tokens": 2149046,
      "conso_all_conv": 6.589354700793333,
      "n_match": 2535,
      "mean_conso_per_match": 0.0025993509667823797,
      "mean_conso_per_token": 3.0661766666666664e-06,
      "mean_win_prob": 0.3138985932327813,
      "win_rate": 0.4021104536489152,
      "useful": 636,
      "creative": 226,
      "complete": 477,
      "clear_formatting": 533,
      "incorrect": 428,
      "superficial": 449,
      "instructions_not_followed": 300,
      "total_prefs": 3049,
      "positive_prefs_ratio": 0.6139717940308298
    },
    {
      "model_name": "mistral-nemo-2407",
      "median": 850.3167854240436,
      "p2.5": 841.3820890386244,
      "p97.5": 859.7425359866302,
      "rank": 88,
      "rank_p2.5": 87,
      "rank_p97.5": 89,
      "total_output_tokens": 3305342,
      "conso_all_conv": 14.30950862201333,
      "n_match": 6251,
      "mean_conso_per_match": 0.0022891551147037805,
      "mean_conso_per_token": 4.329206666666666e-06,
      "mean_win_prob": 0.3023279790045121,
      "win_rate": 0.37482482802751566,
      "useful": 1413,
      "creative": 225,
      "complete": 661,
      "clear_formatting": 900,
      "incorrect": 638,
      "superficial": 1088,
      "instructions_not_followed": 292,
      "total_prefs": 5217,
      "positive_prefs_ratio": 0.6131876557408472
    },
    {
      "model_name": "mixtral-8x22b-instruct-v0.1",
      "median": 839.6134114322812,
      "p2.5": 830.4736029497274,
      "p97.5": 848.654977889496,
      "rank": 89,
      "rank_p2.5": 88,
      "rank_p97.5": 90,
      "total_output_tokens": 3041056,
      "conso_all_conv": 53.644106197759996,
      "n_match": 5455,
      "mean_conso_per_match": 0.009833933308480293,
      "mean_conso_per_token": 1.7639959999999998e-05,
      "mean_win_prob": 0.2899370564206755,
      "win_rate": 0.36710357470210814,
      "useful": 1117,
      "creative": 203,
      "complete": 516,
      "clear_formatting": 702,
      "incorrect": 535,
      "superficial": 934,
      "instructions_not_followed": 276,
      "total_prefs": 4283,
      "positive_prefs_ratio": 0.5925752976885361
    },
    {
      "model_name": "chocolatine-2-14b-instruct-v2.0.3-q8",
      "median": 816.4314784982405,
      "p2.5": 800.9981901293503,
      "p97.5": 833.2594322043738,
      "rank": 90,
      "rank_p2.5": 90,
      "rank_p97.5": 91,
      "total_output_tokens": 533384,
      "conso_all_conv": 1.9348629056266669,
      "n_match": 1796,
      "mean_conso_per_match": 0.0010773178761841128,
      "mean_conso_per_token": 3.6275233333333336e-06,
      "mean_win_prob": 0.26411516240464195,
      "win_rate": 0.3317316258351893,
      "useful": 280,
      "creative": 37,
      "complete": 100,
      "clear_formatting": 199,
      "incorrect": 161,
      "superficial": 370,
      "instructions_not_followed": 50,
      "total_prefs": 1197,
      "positive_prefs_ratio": 0.5146198830409356
    },
    {
      "model_name": "Yi-1.5-9B-Chat",
      "median": 763.8334490554777,
      "p2.5": 660.8634751571569,
      "p97.5": 854.2760895712536,
      "rank": 91,
      "rank_p2.5": 88,
      "rank_p97.5": 93,
      "total_output_tokens": 47531,
      "conso_all_conv": 0.1857604957633333,
      "n_match": 65,
      "mean_conso_per_match": 0.0028578537809743586,
      "mean_conso_per_token": 3.908196666666666e-06,
      "mean_win_prob": 0.21100247288159402,
      "win_rate": 0.32599999999999996,
      "useful": 16,
      "creative": 5,
      "complete": 14,
      "clear_formatting": 19,
      "incorrect": 12,
      "superficial": 17,
      "instructions_not_followed": 14,
      "total_prefs": 97,
      "positive_prefs_ratio": 0.5567010309278351
    },
    {
      "model_name": "chocolatine-14b-instruct-dpo-v1.2-q4",
      "median": 748.7312082949651,
      "p2.5": 700.5208344117561,
      "p97.5": 794.105024203587,
      "rank": 92,
      "rank_p2.5": 91,
      "rank_p97.5": 93,
      "total_output_tokens": 131187,
      "conso_all_conv": 0.6047563275600001,
      "n_match": 309,
      "mean_conso_per_match": 0.001957140218640777,
      "mean_conso_per_token": 4.609880000000001e-06,
      "mean_win_prob": 0.19720591247765598,
      "win_rate": 0.2402265372168285,
      "useful": 83,
      "creative": 17,
      "complete": 39,
      "clear_formatting": 43,
      "incorrect": 52,
      "superficial": 107,
      "instructions_not_followed": 50,
      "total_prefs": 391,
      "positive_prefs_ratio": 0.46547314578005117
    },
    {
      "model_name": "qwen2-7b-instruct",
      "median": 727.0276089739601,
      "p2.5": 630.2983794413032,
      "p97.5": 809.6227922371297,
      "rank": 93,
      "rank_p2.5": 91,
      "rank_p97.5": 93,
      "total_output_tokens": 43550,
      "conso_all_conv": 0.15797864116666668,
      "n_match": 80,
      "mean_conso_per_match": 0.0019747330145833335,
      "mean_conso_per_token": 3.6275233333333336e-06,
      "mean_win_prob": 0.17852204152240891,
      "win_rate": 0.2525,
      "useful": 19,
      "creative": 4,
      "complete": 12,
      "clear_formatting": 22,
      "incorrect": 11,
      "superficial": 14,
      "instructions_not_followed": 7,
      "total_prefs": 89,
      "positive_prefs_ratio": 0.6404494382022472
    }
  ]
}
