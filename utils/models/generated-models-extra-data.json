[
  {
    "model_name": "gemini-2.5-flash",
    "median": 1116.8543065571685,
    "p2.5": 1095.8659658635388,
    "p97.5": 1141.4376227789676,
    "rank": 4,
    "rank_p2.5": 3,
    "rank_p97.5": 6,
    "total_output_tokens": 617870.0,
    "conso_all_conv": 7.704056264666664,
    "n_match": 812,
    "mean_conso_per_match": 0.009487754020525449,
    "mean_conso_per_token": 0.00001246873333333333,
    "mean_win_prob": 0.6830116182798468,
    "win_rate": 0.6178694581280788
  },
  {
    "model_name": "gemini-2.0-flash-exp",
    "median": 1103.899798627593,
    "p2.5": 1088.9957712848586,
    "p97.5": 1119.7037662741361,
    "rank": 5,
    "rank_p2.5": 4,
    "rank_p97.5": 7,
    "total_output_tokens": 3936799.0,
    "conso_all_conv": 32.51257944803336,
    "n_match": 2816,
    "mean_conso_per_match": 0.011545660315352755,
    "mean_conso_per_token": 8.25863333333334e-6,
    "mean_win_prob": 0.6669971896177344,
    "win_rate": 0.653934659090909
  },
  {
    "model_name": "gemini-2.0-flash-001",
    "median": 1090.4829018542523,
    "p2.5": 1079.984869743548,
    "p97.5": 1104.6469714889365,
    "rank": 6,
    "rank_p2.5": 5,
    "rank_p97.5": 10,
    "total_output_tokens": 8359986.0,
    "conso_all_conv": 69.04205904580027,
    "n_match": 5903,
    "mean_conso_per_match": 0.011696096738234843,
    "mean_conso_per_token": 8.258633333333366e-6,
    "mean_win_prob": 0.6500337997913367,
    "win_rate": null
  },
  {
    "model_name": "gemma-3-27b",
    "median": 1089.2299554011934,
    "p2.5": 1077.8146632540484,
    "p97.5": 1104.8733020627637,
    "rank": 7,
    "rank_p2.5": 5,
    "rank_p97.5": 10,
    "total_output_tokens": 6498374.0,
    "conso_all_conv": 41.81220623199328,
    "n_match": 4859,
    "mean_conso_per_match": 0.008605105213417015,
    "mean_conso_per_token": 6.434256666666659e-6,
    "mean_win_prob": 0.6484312190011655,
    "win_rate": null
  },
  {
    "model_name": "deepseek-v3-0324",
    "median": 1085.4083150597367,
    "p2.5": 1073.1859140013564,
    "p97.5": 1101.4160217670533,
    "rank": 8,
    "rank_p2.5": 6,
    "rank_p97.5": 11,
    "total_output_tokens": 4428337.0,
    "conso_all_conv": 208.24582439437953,
    "n_match": 4832,
    "mean_conso_per_match": 0.04309723186969775,
    "mean_conso_per_token": 0.000047025739999999894,
    "mean_win_prob": 0.643524558131932,
    "win_rate": null
  },
  {
    "model_name": "glm-4.5",
    "median": 1079.9485870555238,
    "p2.5": 1033.11059998577,
    "p97.5": 1127.05587669211,
    "rank": 9,
    "rank_p2.5": 4,
    "rank_p97.5": 24,
    "total_output_tokens": 122648.0,
    "conso_all_conv": 19.304065444399992,
    "n_match": 127,
    "mean_conso_per_match": 0.15200051531023615,
    "mean_conso_per_token": 0.00015739404999999993,
    "mean_win_prob": 0.636467488642974,
    "win_rate": null
  },
  {
    "model_name": "deepseek-v3-chat",
    "median": 1073.8708128183625,
    "p2.5": 1063.352786202261,
    "p97.5": 1088.5573584726687,
    "rank": 10,
    "rank_p2.5": 9,
    "rank_p97.5": 14,
    "total_output_tokens": 5638296.0,
    "conso_all_conv": 265.14504173903885,
    "n_match": 5394,
    "mean_conso_per_match": 0.04915555093419333,
    "mean_conso_per_token": 0.00004702573999999979,
    "mean_win_prob": 0.6285489460249408,
    "win_rate": 0.6146811271783463
  },
  {
    "model_name": "gpt-oss-120b",
    "median": 1072.7563814857135,
    "p2.5": 1050.1617727263588,
    "p97.5": 1096.0116966599826,
    "rank": 11,
    "rank_p2.5": 7,
    "rank_p97.5": 16,
    "total_output_tokens": 948315.0,
    "conso_all_conv": 3.17386805775,
    "n_match": 842,
    "mean_conso_per_match": 0.0037694394985154393,
    "mean_conso_per_token": 3.34685e-6,
    "mean_win_prob": 0.6270900989429337,
    "win_rate": null
  },
  {
    "model_name": "gemma-3-12b",
    "median": 1065.8387631208773,
    "p2.5": 1054.9228794996325,
    "p97.5": 1082.204254521723,
    "rank": 12,
    "rank_p2.5": 10,
    "rank_p97.5": 16,
    "total_output_tokens": 5733918.0,
    "conso_all_conv": 24.82331603171999,
    "n_match": 4522,
    "mean_conso_per_match": 0.005489455115373726,
    "mean_conso_per_token": 4.329206666666665e-6,
    "mean_win_prob": 0.6179889464814592,
    "win_rate": 0.5777532065457762
  },
  {
    "model_name": "grok-3-mini-beta",
    "median": 1059.1480749513441,
    "p2.5": 1040.7201757002285,
    "p97.5": 1078.2067687687838,
    "rank": 14,
    "rank_p2.5": 11,
    "rank_p97.5": 19,
    "total_output_tokens": 3468359.0,
    "conso_all_conv": 213.04395157500025,
    "n_match": 1572,
    "mean_conso_per_match": 0.1355241422232826,
    "mean_conso_per_token": 0.00006142500000000007,
    "mean_win_prob": 0.6091152813526198,
    "win_rate": null
  },
  {
    "model_name": "command-a",
    "median": 1056.719981367411,
    "p2.5": 1045.0848224641375,
    "p97.5": 1072.938966702457,
    "rank": 15,
    "rank_p2.5": 12,
    "rank_p97.5": 19,
    "total_output_tokens": 4137991.0,
    "conso_all_conv": 75.40469272383669,
    "n_match": 4415,
    "mean_conso_per_match": 0.01707920559996301,
    "mean_conso_per_token": 0.000018222536666666672,
    "mean_win_prob": 0.6058786916891241,
    "win_rate": null
  },
  {
    "model_name": "gemini-1.5-pro-001",
    "median": 1050.4284338747275,
    "p2.5": 1033.3435061705172,
    "p97.5": 1069.4608880960902,
    "rank": 16,
    "rank_p2.5": 12,
    "rank_p97.5": 23,
    "total_output_tokens": 1731076.0,
    "conso_all_conv": 229.9379183586667,
    "n_match": 2360,
    "mean_conso_per_match": 0.0974313213384181,
    "mean_conso_per_token": 0.00013282947620940196,
    "mean_win_prob": 0.5974543230288275,
    "win_rate": 0.6779703389830509
  },
  {
    "model_name": "magistral-small-2506",
    "median": 1048.9910983338118,
    "p2.5": 1029.9941101629554,
    "p97.5": 1069.7366055164557,
    "rank": 17,
    "rank_p2.5": 13,
    "rank_p97.5": 25,
    "total_output_tokens": 334874.0,
    "conso_all_conv": 2.0136799642533343,
    "n_match": 1037,
    "mean_conso_per_match": 0.001941832173821923,
    "mean_conso_per_token": 6.013246666666669e-6,
    "mean_win_prob": 0.5955223936353997,
    "win_rate": null
  },
  {
    "model_name": "claude-3-7-sonnet",
    "median": 1043.7524747280897,
    "p2.5": 1031.750617467149,
    "p97.5": 1060.901291826728,
    "rank": 18,
    "rank_p2.5": 15,
    "rank_p97.5": 24,
    "total_output_tokens": 3546728.0,
    "conso_all_conv": 476.1074466279997,
    "n_match": 3909,
    "mean_conso_per_match": 0.12179776071322582,
    "mean_conso_per_token": 0.0001342384999999999,
    "mean_win_prob": 0.5884593817107391,
    "win_rate": 0.5242363775901765
  },
  {
    "model_name": "claude-4-sonnet",
    "median": 1043.289464515503,
    "p2.5": 1025.2236422169115,
    "p97.5": 1064.8567293658293,
    "rank": 19,
    "rank_p2.5": 13,
    "rank_p97.5": 26,
    "total_output_tokens": 385602.0,
    "conso_all_conv": 23.685602849999988,
    "n_match": 1092,
    "mean_conso_per_match": 0.02169011249999999,
    "mean_conso_per_token": 0.00006142499999999998,
    "mean_win_prob": 0.5878335397532999,
    "win_rate": null
  },
  {
    "model_name": "gemma-3-4b",
    "median": 1039.0791153272,
    "p2.5": 1028.0526266257768,
    "p97.5": 1054.7498594391648,
    "rank": 20,
    "rank_p2.5": 17,
    "rank_p97.5": 25,
    "total_output_tokens": 6678174.0,
    "conso_all_conv": 21.413653973319974,
    "n_match": 5382,
    "mean_conso_per_match": 0.0039787539898402035,
    "mean_conso_per_token": 3.2065133333333296e-6,
    "mean_win_prob": 0.5821312724078959,
    "win_rate": 0.5376570048309179
  },
  {
    "model_name": "llama-3.1-nemotron-70b-instruct",
    "median": 1038.4661224675822,
    "p2.5": 1027.6808718500283,
    "p97.5": 1053.933052476198,
    "rank": 21,
    "rank_p2.5": 18,
    "rank_p97.5": 25,
    "total_output_tokens": 7403970.0,
    "conso_all_conv": 92.31812753799979,
    "n_match": 6838,
    "mean_conso_per_match": 0.013500749859315557,
    "mean_conso_per_token": 0.000012468733333333304,
    "mean_win_prob": 0.5812994304469272,
    "win_rate": null
  },
  {
    "model_name": "qwen3-32b",
    "median": 1035.2313576471079,
    "p2.5": 1014.6611833404249,
    "p97.5": 1056.4677025382687,
    "rank": 22,
    "rank_p2.5": 16,
    "rank_p97.5": 29,
    "total_output_tokens": 1412357.0,
    "conso_all_conv": 10.078494810580002,
    "n_match": 748,
    "mean_conso_per_match": 0.013473923543556152,
    "mean_conso_per_token": 7.135940000000002e-6,
    "mean_win_prob": 0.5769032139178458,
    "win_rate": null
  },
  {
    "model_name": "kimi-k2",
    "median": 1032.3432529996915,
    "p2.5": 989.1867553743307,
    "p97.5": 1079.3785808450418,
    "rank": 23,
    "rank_p2.5": 10,
    "rank_p97.5": 38,
    "total_output_tokens": 105815.0,
    "conso_all_conv": 6.040715928800002,
    "n_match": 154,
    "mean_conso_per_match": 0.039225428109090923,
    "mean_conso_per_token": 0.00005708752000000002,
    "mean_win_prob": 0.572969143470125,
    "win_rate": null
  },
  {
    "model_name": "gpt-4.1-mini",
    "median": 1028.5433393975343,
    "p2.5": 1018.1479575400293,
    "p97.5": 1044.8975312315902,
    "rank": 24,
    "rank_p2.5": 21,
    "rank_p97.5": 28,
    "total_output_tokens": 4581959.0,
    "conso_all_conv": 57.1312249152667,
    "n_match": 5695,
    "mean_conso_per_match": 0.01003182175860697,
    "mean_conso_per_token": 0.00001246873333333334,
    "mean_win_prob": 0.5677809215177921,
    "win_rate": 0.5160280948200175
  },
  {
    "model_name": "deepseek-r1",
    "median": 1023.1281973461519,
    "p2.5": 1010.2436193209899,
    "p97.5": 1038.9707731586197,
    "rank": 25,
    "rank_p2.5": 23,
    "rank_p97.5": 31,
    "total_output_tokens": 3662507.0,
    "conso_all_conv": 172.2321019301802,
    "n_match": 3799,
    "mean_conso_per_match": 0.045336167920552825,
    "mean_conso_per_token": 0.00004702574000000005,
    "mean_win_prob": 0.5603654621033086,
    "win_rate": null
  },
  {
    "model_name": "gpt-oss-20b",
    "median": 1019.2460450275557,
    "p2.5": 999.6091010546901,
    "p97.5": 1039.5691978773432,
    "rank": 29,
    "rank_p2.5": 23,
    "rank_p97.5": 35,
    "total_output_tokens": 537902.0,
    "conso_all_conv": 1.6493025613533339,
    "n_match": 1085,
    "mean_conso_per_match": 0.0015200945265929345,
    "mean_conso_per_token": 3.0661766666666677e-6,
    "mean_win_prob": 0.5550349535997852,
    "win_rate": null
  },
  {
    "model_name": "gemini-1.5-pro-002",
    "median": 1014.9291256651384,
    "p2.5": 1003.923234640257,
    "p97.5": 1030.5048655221847,
    "rank": 30,
    "rank_p2.5": 25,
    "rank_p97.5": 34,
    "total_output_tokens": 4303147.0,
    "conso_all_conv": 576.9527534425324,
    "n_match": 5035,
    "mean_conso_per_match": 0.11458843166683862,
    "mean_conso_per_token": 0.00013407693333333313,
    "mean_win_prob": 0.5490949912321552,
    "win_rate": 0.5422303872889772
  },
  {
    "model_name": "mistral-large-2411",
    "median": 1013.5074949600257,
    "p2.5": 1003.0854065190052,
    "p97.5": 1028.3106961661636,
    "rank": 31,
    "rank_p2.5": 26,
    "rank_p97.5": 34,
    "total_output_tokens": 7677266.0,
    "conso_all_conv": 152.82808421939288,
    "n_match": 8880,
    "mean_conso_per_match": 0.017210369844526226,
    "mean_conso_per_token": 0.000019906576666666606,
    "mean_win_prob": 0.5471362439553301,
    "win_rate": 0.5269031531531531
  },
  {
    "model_name": "llama-4-scout",
    "median": 1006.2588839335458,
    "p2.5": 993.3582776442427,
    "p97.5": 1022.0130775909638,
    "rank": 34,
    "rank_p2.5": 28,
    "rank_p97.5": 37,
    "total_output_tokens": 2450373.0,
    "conso_all_conv": 12.327557021970001,
    "n_match": 3273,
    "mean_conso_per_match": 0.0037664396645187906,
    "mean_conso_per_token": 5.0308900000000005e-6,
    "mean_win_prob": 0.5371314467656412,
    "win_rate": null
  },
  {
    "model_name": "gemma-3n-e4b-it",
    "median": 1003.4180686281011,
    "p2.5": 985.2009943926889,
    "p97.5": 1024.6992767570007,
    "rank": 35,
    "rank_p2.5": 27,
    "rank_p97.5": 40,
    "total_output_tokens": 360025.0,
    "conso_all_conv": 1.1544249628333332,
    "n_match": 1087,
    "mean_conso_per_match": 0.0010620284846672799,
    "mean_conso_per_token": 3.206513333333333e-6,
    "mean_win_prob": 0.5332035358714943,
    "win_rate": null
  },
  {
    "model_name": "mistral-small-3.1-24b",
    "median": 1000.0860472777736,
    "p2.5": 989.2973652990787,
    "p97.5": 1016.4064136559376,
    "rank": 36,
    "rank_p2.5": 31,
    "rank_p97.5": 39,
    "total_output_tokens": 4470466.0,
    "conso_all_conv": 26.882014772946615,
    "n_match": 5104,
    "mean_conso_per_match": 0.0052668524241666565,
    "mean_conso_per_token": 6.013246666666655e-6,
    "mean_win_prob": 0.5285923975459302,
    "win_rate": 0.49401449843260187
  },
  {
    "model_name": "o4-mini",
    "median": 998.7504523399293,
    "p2.5": 985.2384647828313,
    "p97.5": 1016.496801521083,
    "rank": 37,
    "rank_p2.5": 31,
    "rank_p97.5": 40,
    "total_output_tokens": 2288087.0,
    "conso_all_conv": 140.5457439749999,
    "n_match": 2088,
    "mean_conso_per_match": 0.06731118006465513,
    "mean_conso_per_token": 0.00006142499999999996,
    "mean_win_prob": 0.5267430130095039,
    "win_rate": null
  },
  {
    "model_name": "gemma-2-27b-it-q8",
    "median": 997.2704091061615,
    "p2.5": 971.9901121785248,
    "p97.5": 1024.1757997930513,
    "rank": 38,
    "rank_p2.5": 27,
    "rank_p97.5": 45,
    "total_output_tokens": 449540.0,
    "conso_all_conv": 2.8924557419333348,
    "n_match": 762,
    "mean_conso_per_match": 0.0037958736770778673,
    "mean_conso_per_token": 6.43425666666667e-6,
    "mean_win_prob": 0.5246929799063921,
    "win_rate": 0.5821391076115486
  },
  {
    "model_name": "mistral-saba",
    "median": 988.9521063819325,
    "p2.5": 977.426849602903,
    "p97.5": 1004.8535536932063,
    "rank": 39,
    "rank_p2.5": 35,
    "rank_p97.5": 43,
    "total_output_tokens": 3043927.0,
    "conso_all_conv": 18.303883886326695,
    "n_match": 3572,
    "mean_conso_per_match": 0.005124267605354618,
    "mean_conso_per_token": 6.013246666666676e-6,
    "mean_win_prob": 0.5131617978345631,
    "win_rate": null
  },
  {
    "model_name": "aya-expanse-32b",
    "median": 985.2726761159423,
    "p2.5": 972.7255796635352,
    "p97.5": 1001.0647253379599,
    "rank": 40,
    "rank_p2.5": 36,
    "rank_p97.5": 45,
    "total_output_tokens": 2836974.0,
    "conso_all_conv": 20.24447624556002,
    "n_match": 3552,
    "mean_conso_per_match": 0.005699458402466222,
    "mean_conso_per_token": 7.135940000000007e-6,
    "mean_win_prob": 0.5080581239614764,
    "win_rate": 0.47371903153153155
  },
  {
    "model_name": "qwen3-30b-a3b",
    "median": 982.233011846409,
    "p2.5": 951.6128596528081,
    "p97.5": 1009.5507956563041,
    "rank": 41,
    "rank_p2.5": 32,
    "rank_p97.5": 55,
    "total_output_tokens": 134107.0,
    "conso_all_conv": 0.4111957542366668,
    "n_match": 416,
    "mean_conso_per_match": 0.00098845133229968,
    "mean_conso_per_token": 3.0661766666666677e-6,
    "mean_win_prob": 0.5038414484176588,
    "win_rate": null
  },
  {
    "model_name": "mistral-small-24b-instruct-2501",
    "median": 979.2042215668171,
    "p2.5": 965.6000742152407,
    "p97.5": 997.7753654920365,
    "rank": 42,
    "rank_p2.5": 38,
    "rank_p97.5": 48,
    "total_output_tokens": 2818040.0,
    "conso_all_conv": 16.945569636533325,
    "n_match": 3319,
    "mean_conso_per_match": 0.005105625078798832,
    "mean_conso_per_token": 6.013246666666663e-6,
    "mean_win_prob": 0.499640083674661,
    "win_rate": 0.49546851461283525
  },
  {
    "model_name": "o3-mini",
    "median": 978.2825996693506,
    "p2.5": 961.343511755771,
    "p97.5": 996.2735589358539,
    "rank": 43,
    "rank_p2.5": 37,
    "rank_p97.5": 50,
    "total_output_tokens": 1655945.0,
    "conso_all_conv": 101.71642162500001,
    "n_match": 1620,
    "mean_conso_per_match": 0.06278791458333334,
    "mean_conso_per_token": 0.000061425,
    "mean_win_prob": 0.4983617917351386,
    "win_rate": 0.5113641975308642
  },
  {
    "model_name": "llama-3.3-70b",
    "median": 976.6082797284494,
    "p2.5": 966.7872575165584,
    "p97.5": 992.3459247875346,
    "rank": 44,
    "rank_p2.5": 40,
    "rank_p97.5": 48,
    "total_output_tokens": 5635427.0,
    "conso_all_conv": 70.26663648246695,
    "n_match": 6738,
    "mean_conso_per_match": 0.010428411469644842,
    "mean_conso_per_token": 0.000012468733333333384,
    "mean_win_prob": 0.4960397410653855,
    "win_rate": null
  },
  {
    "model_name": "gpt-4o-mini-2024-07-18",
    "median": 975.9644656521456,
    "p2.5": 964.6952162209553,
    "p97.5": 992.3173848156125,
    "rank": 45,
    "rank_p2.5": 40,
    "rank_p97.5": 48,
    "total_output_tokens": 5207480.0,
    "conso_all_conv": 39.34466317595,
    "n_match": 6994,
    "mean_conso_per_match": 0.005625488014862739,
    "mean_conso_per_token": 7.55541320868251e-6,
    "mean_win_prob": 0.4951469566441382,
    "win_rate": 0.49948956248212756
  },
  {
    "model_name": "gpt-4.1-nano",
    "median": 969.2075521107754,
    "p2.5": 957.5511447208632,
    "p97.5": 984.733756754896,
    "rank": 46,
    "rank_p2.5": 43,
    "rank_p97.5": 51,
    "total_output_tokens": 2762342.0,
    "conso_all_conv": 20.874880376900013,
    "n_match": 4300,
    "mean_conso_per_match": 0.004854623343465119,
    "mean_conso_per_token": 7.556950000000005e-6,
    "mean_win_prob": 0.4857818120675204,
    "win_rate": 0.46347906976744185
  },
  {
    "model_name": "llama-3.1-70b",
    "median": 967.0775267573949,
    "p2.5": 955.1256989064282,
    "p97.5": 983.4496850717654,
    "rank": 48,
    "rank_p2.5": 44,
    "rank_p97.5": 52,
    "total_output_tokens": 4057254.0,
    "conso_all_conv": 50.58881819159994,
    "n_match": 5584,
    "mean_conso_per_match": 0.009059602111676206,
    "mean_conso_per_token": 0.00001246873333333332,
    "mean_win_prob": 0.4828319688246592,
    "win_rate": 0.53059276504298
  },
  {
    "model_name": "aya-expanse-8b",
    "median": 966.9425177938376,
    "p2.5": 950.2703393876989,
    "p97.5": 986.1889495634188,
    "rank": 49,
    "rank_p2.5": 41,
    "rank_p97.5": 55,
    "total_output_tokens": 1057810.0,
    "conso_all_conv": 3.9856799865999943,
    "n_match": 1302,
    "mean_conso_per_match": 0.0030611981463901645,
    "mean_conso_per_token": 3.7678599999999946e-6,
    "mean_win_prob": 0.4826450444566156,
    "win_rate": 0.5014285714285713
  },
  {
    "model_name": "jamba-1.5-large",
    "median": 966.0870577309806,
    "p2.5": 921.6745421619885,
    "p97.5": 1011.2852690355498,
    "rank": 50,
    "rank_p2.5": 31,
    "rank_p97.5": 62,
    "total_output_tokens": 143976.0,
    "conso_all_conv": 6.84036310944,
    "n_match": 172,
    "mean_conso_per_match": 0.039769552961860466,
    "mean_conso_per_token": 0.00004751044,
    "mean_win_prob": 0.4814607726416122,
    "win_rate": 0.5449418604651162
  },
  {
    "model_name": "claude-3-5-sonnet-v2",
    "median": 965.1315048087347,
    "p2.5": 953.8372764999883,
    "p97.5": 980.7515316688558,
    "rank": 51,
    "rank_p2.5": 45,
    "rank_p97.5": 53,
    "total_output_tokens": 3224219.0,
    "conso_all_conv": 432.81432223149943,
    "n_match": 5685,
    "mean_conso_per_match": 0.07613268640835522,
    "mean_conso_per_token": 0.00013423849999999983,
    "mean_win_prob": 0.4801382342322256,
    "win_rate": 0.49167810026385234
  },
  {
    "model_name": "phi-4",
    "median": 961.3410591004875,
    "p2.5": 951.0256001857991,
    "p97.5": 976.5435416253407,
    "rank": 52,
    "rank_p2.5": 47,
    "rank_p97.5": 54,
    "total_output_tokens": 6547451.0,
    "conso_all_conv": 30.182963415880074,
    "n_match": 8003,
    "mean_conso_per_match": 0.0037714561309359082,
    "mean_conso_per_token": 4.609880000000011e-6,
    "mean_win_prob": 0.47489548227779943,
    "win_rate": null
  },
  {
    "model_name": "qwen2.5-32b-instruct",
    "median": 960.0537249785664,
    "p2.5": 901.5044497549627,
    "p97.5": 1017.0488512406313,
    "rank": 53,
    "rank_p2.5": 30,
    "rank_p97.5": 64,
    "total_output_tokens": 75812.0,
    "conso_all_conv": 0.53108519856,
    "n_match": 142,
    "mean_conso_per_match": 0.003740036609577465,
    "mean_conso_per_token": 7.005292019205403e-6,
    "mean_win_prob": 0.4731162843336879,
    "win_rate": 0.5557042253521126
  },
  {
    "model_name": "ministral-8b-instruct-2410",
    "median": 957.8303388504945,
    "p2.5": 947.7296518557133,
    "p97.5": 973.7459970485235,
    "rank": 54,
    "rank_p2.5": 49,
    "rank_p97.5": 55,
    "total_output_tokens": 7488476.0,
    "conso_all_conv": 28.215529181359944,
    "n_match": 9388,
    "mean_conso_per_match": 0.0030054888348274335,
    "mean_conso_per_token": 3.7678599999999925e-6,
    "mean_win_prob": 0.47004521826789003,
    "win_rate": null
  },
  {
    "model_name": "gpt-4o-2024-08-06",
    "median": 955.7319600408189,
    "p2.5": 944.8217969767022,
    "p97.5": 971.5590094880162,
    "rank": 55,
    "rank_p2.5": 49,
    "rank_p97.5": 57,
    "total_output_tokens": 3903917.0,
    "conso_all_conv": 239.79810172500032,
    "n_match": 5900,
    "mean_conso_per_match": 0.0406437460550848,
    "mean_conso_per_token": 0.00006142500000000008,
    "mean_win_prob": 0.4671491104668001,
    "win_rate": 0.48838983050847457
  },
  {
    "model_name": "llama-3.1-405b",
    "median": 951.841176320751,
    "p2.5": 942.4733191108163,
    "p97.5": 966.905487180133,
    "rank": 56,
    "rank_p2.5": 52,
    "rank_p97.5": 58,
    "total_output_tokens": 10356576.0,
    "conso_all_conv": 2464.0993918144136,
    "n_match": 10102,
    "mean_conso_per_match": 0.24392193543995383,
    "mean_conso_per_token": 0.00023792606666666797,
    "mean_win_prob": 0.46178569435639044,
    "win_rate": null
  },
  {
    "model_name": "gemma-2-9b-it",
    "median": 947.3861444033739,
    "p2.5": 935.7245460994129,
    "p97.5": 963.1214048981182,
    "rank": 57,
    "rank_p2.5": 53,
    "rank_p97.5": 59,
    "total_output_tokens": 3108609.0,
    "conso_all_conv": 12.132379056593326,
    "n_match": 5116,
    "mean_conso_per_match": 0.0023714579860424794,
    "mean_conso_per_token": 3.902832120923965e-6,
    "mean_win_prob": 0.45565609247621636,
    "win_rate": 0.5066673182173574
  },
  {
    "model_name": "deepseek-r1-distill-llama-70b",
    "median": 946.541324966285,
    "p2.5": 932.311606179598,
    "p97.5": 964.1704469452195,
    "rank": 58,
    "rank_p2.5": 52,
    "rank_p97.5": 60,
    "total_output_tokens": 2339110.0,
    "conso_all_conv": 29.165738827333318,
    "n_match": 2559,
    "mean_conso_per_match": 0.011397318807086096,
    "mean_conso_per_token": 0.000012468733333333326,
    "mean_win_prob": 0.4544952513196748,
    "win_rate": null
  },
  {
    "model_name": "qwq-32b",
    "median": 945.3698557334931,
    "p2.5": 928.4241965281998,
    "p97.5": 965.342917017599,
    "rank": 59,
    "rank_p2.5": 52,
    "rank_p97.5": 60,
    "total_output_tokens": 1895013.0,
    "conso_all_conv": 13.522699067219982,
    "n_match": 1596,
    "mean_conso_per_match": 0.00847286908973683,
    "mean_conso_per_token": 7.135939999999991e-6,
    "mean_win_prob": 0.45288642682099567,
    "win_rate": null
  },
  {
    "model_name": "hermes-3-llama-3.1-405b",
    "median": 935.9114486968854,
    "p2.5": 925.2226168464956,
    "p97.5": 950.4436349655814,
    "rank": 60,
    "rank_p2.5": 57,
    "rank_p97.5": 61,
    "total_output_tokens": 4092822.0,
    "conso_all_conv": 973.7890400268018,
    "n_match": 6781,
    "mean_conso_per_match": 0.14360552131349386,
    "mean_conso_per_token": 0.0002379260666666671,
    "mean_win_prob": 0.4399369063847157,
    "win_rate": 0.46617755493290075
  },
  {
    "model_name": "c4ai-command-r-08-2024",
    "median": 922.8873687901358,
    "p2.5": 912.5189834810415,
    "p97.5": 937.4155373054418,
    "rank": 61,
    "rank_p2.5": 59,
    "rank_p97.5": 64,
    "total_output_tokens": 4319206.0,
    "conso_all_conv": 32.640023781700094,
    "n_match": 5999,
    "mean_conso_per_match": 0.0054409107820803625,
    "mean_conso_per_token": 7.556950000000022e-6,
    "mean_win_prob": 0.42224375810166187,
    "win_rate": null
  },
  {
    "model_name": "qwen2.5-7b-instruct",
    "median": 921.3938845585155,
    "p2.5": 901.8089518982316,
    "p97.5": 943.8664137125056,
    "rank": 62,
    "rank_p2.5": 59,
    "rank_p97.5": 65,
    "total_output_tokens": 1186919.0,
    "conso_all_conv": 4.305576367276666,
    "n_match": 1420,
    "mean_conso_per_match": 0.003032096033293427,
    "mean_conso_per_token": 3.627523333333333e-6,
    "mean_win_prob": 0.4202266728588782,
    "win_rate": 0.49303521126760563
  },
  {
    "model_name": "qwen2.5-coder-32b-instruct",
    "median": 919.037317665624,
    "p2.5": 908.7423720125037,
    "p97.5": 933.4682334552044,
    "rank": 63,
    "rank_p2.5": 60,
    "rank_p97.5": 65,
    "total_output_tokens": 6149486.0,
    "conso_all_conv": 43.88236312683993,
    "n_match": 7330,
    "mean_conso_per_match": 0.005986679826308312,
    "mean_conso_per_token": 7.135939999999988e-6,
    "mean_win_prob": 0.41704931104873566,
    "win_rate": 0.4368676671214188
  },
  {
    "model_name": "llama-3.1-8b",
    "median": 918.0251185667212,
    "p2.5": 907.5347045335699,
    "p97.5": 932.9545872448064,
    "rank": 64,
    "rank_p2.5": 60,
    "rank_p97.5": 65,
    "total_output_tokens": 5669724.0,
    "conso_all_conv": 21.362726270639936,
    "n_match": 8256,
    "mean_conso_per_match": 0.0025875395192151087,
    "mean_conso_per_token": 3.7678599999999887e-6,
    "mean_win_prob": 0.4156866376439725,
    "win_rate": null
  },
  {
    "model_name": "mixtral-8x7b-instruct-v0.1",
    "median": 880.6132405186363,
    "p2.5": 864.1679362952361,
    "p97.5": 897.441111550972,
    "rank": 65,
    "rank_p2.5": 64,
    "rank_p97.5": 67,
    "total_output_tokens": 1575791.0,
    "conso_all_conv": 7.264207415080014,
    "n_match": 2560,
    "mean_conso_per_match": 0.0028375810215156305,
    "mean_conso_per_token": 4.6098800000000085e-6,
    "mean_win_prob": 0.3663595023724305,
    "win_rate": 0.43490624999999994
  },
  {
    "model_name": "lfm-40b",
    "median": 876.3421962407285,
    "p2.5": 862.199047374268,
    "p97.5": 893.4929338520805,
    "rank": 66,
    "rank_p2.5": 65,
    "rank_p97.5": 67,
    "total_output_tokens": 2000824.0,
    "conso_all_conv": 16.524071780533344,
    "n_match": 3578,
    "mean_conso_per_match": 0.004618242532289923,
    "mean_conso_per_token": 8.25863333333334e-6,
    "mean_win_prob": 0.3608768701970416,
    "win_rate": 0.4159418669647848
  },
  {
    "model_name": "phi-3.5-mini-instruct",
    "median": 856.9139860955881,
    "p2.5": 840.7277351149019,
    "p97.5": 876.2837207192179,
    "rank": 68,
    "rank_p2.5": 67,
    "rank_p97.5": 69,
    "total_output_tokens": 2149046.0,
    "conso_all_conv": 6.5893547007933195,
    "n_match": 2535,
    "mean_conso_per_match": 0.0025993509667823745,
    "mean_conso_per_token": 3.06617666666666e-6,
    "mean_win_prob": 0.33638983054386684,
    "win_rate": 0.40230769230769226
  },
  {
    "model_name": "mistral-nemo-2407",
    "median": 846.0066011580345,
    "p2.5": 834.8416319424274,
    "p97.5": 861.1048298845149,
    "rank": 69,
    "rank_p2.5": 67,
    "rank_p97.5": 70,
    "total_output_tokens": 3305342.0,
    "conso_all_conv": 14.309508622013322,
    "n_match": 6253,
    "mean_conso_per_match": 0.0022884229365126053,
    "mean_conso_per_token": 4.3292066666666635e-6,
    "mean_win_prob": 0.32299186950482534,
    "win_rate": 0.3746761554453863
  },
  {
    "model_name": "mixtral-8x22b-instruct-v0.1",
    "median": 835.6929488125052,
    "p2.5": 824.0231806369972,
    "p97.5": 850.678536642809,
    "rank": 70,
    "rank_p2.5": 69,
    "rank_p97.5": 71,
    "total_output_tokens": 3041056.0,
    "conso_all_conv": 53.62491392128022,
    "n_match": 5458,
    "mean_conso_per_match": 0.0098250117114841,
    "mean_conso_per_token": 0.000017633648943419725,
    "mean_win_prob": 0.31057171781481846,
    "win_rate": 0.366685599120557
  },
  {
    "model_name": "chocolatine-2-14b-instruct-v2.0.3-q8",
    "median": 811.9876387945934,
    "p2.5": 794.8663304960954,
    "p97.5": 832.2372226143393,
    "rank": 71,
    "rank_p2.5": 70,
    "rank_p97.5": 72,
    "total_output_tokens": 533384.0,
    "conso_all_conv": 1.9348629056266666,
    "n_match": 1796,
    "mean_conso_per_match": 0.0010773178761841128,
    "mean_conso_per_token": 3.627523333333333e-6,
    "mean_win_prob": 0.2830008059006913,
    "win_rate": 0.33153674832962143
  },
  {
    "model_name": "Yi-1.5-9B-Chat",
    "median": 759.9365023411453,
    "p2.5": 660.8300056771259,
    "p97.5": 853.5849146317939,
    "rank": 72,
    "rank_p2.5": 68,
    "rank_p97.5": 74,
    "total_output_tokens": 47531.0,
    "conso_all_conv": 0.18274336793666668,
    "n_match": 65,
    "mean_conso_per_match": 0.002811436429794872,
    "mean_conso_per_token": 3.844719613234872e-6,
    "mean_win_prob": 0.22765853620162194,
    "win_rate": 0.32599999999999996
  },
  {
    "model_name": "chocolatine-14b-instruct-dpo-v1.2-q4",
    "median": 746.5961604189429,
    "p2.5": 693.6522826995795,
    "p97.5": 793.1148597780511,
    "rank": 73,
    "rank_p2.5": 72,
    "rank_p97.5": 74,
    "total_output_tokens": 131187.0,
    "conso_all_conv": 0.6022485528400003,
    "n_match": 309,
    "mean_conso_per_match": 0.0019490244428478976,
    "mean_conso_per_token": 4.590763969295741e-6,
    "mean_win_prob": 0.2146890665795374,
    "win_rate": 0.2402265372168285
  },
  {
    "model_name": "qwen2-7b-instruct",
    "median": 726.0918722334577,
    "p2.5": 632.1553290856037,
    "p97.5": 808.6024488965832,
    "rank": 74,
    "rank_p2.5": 71,
    "rank_p97.5": 74,
    "total_output_tokens": 43550.0,
    "conso_all_conv": 0.15307785714333338,
    "n_match": 80,
    "mean_conso_per_match": 0.0019134732142916673,
    "mean_conso_per_token": 3.514990979181019e-6,
    "mean_win_prob": 0.19574469713763326,
    "win_rate": 0.2525
  }
]
