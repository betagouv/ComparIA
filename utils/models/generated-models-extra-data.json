{
  "timestamp": 1770179221.0,
  "models": [
    {
      "model_name": "mistral-medium-3.1",
      "median": 1136.3268707965503,
      "p2.5": 1094.2446652485128,
      "p97.5": 1181.622096618173,
      "rank": 1,
      "rank_p2.5": 1,
      "rank_p97.5": 8,
      "total_output_tokens": 353926,
      "conso_all_conv": 0.0,
      "n_match": 191,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.6795679665281671,
      "win_rate": 0.5832258064516129,
      "useful": 5,
      "creative": 3,
      "complete": 12,
      "clear_formatting": 8,
      "incorrect": 4,
      "superficial": 1,
      "instructions_not_followed": 0,
      "total_prefs": 33,
      "positive_prefs_ratio": 0.8484848484848485
    },
    {
      "model_name": "gemini-3-flash-preview",
      "median": 1128.0963880266022,
      "p2.5": 1110.18816120195,
      "p97.5": 1145.7008696166372,
      "rank": 2,
      "rank_p2.5": 1,
      "rank_p97.5": 4,
      "total_output_tokens": 948201,
      "conso_all_conv": 82.95351619715998,
      "n_match": 973,
      "mean_conso_per_match": 0.08525541233007193,
      "mean_conso_per_token": 8.748515999999998e-05,
      "mean_win_prob": 0.6694254263174676,
      "win_rate": 0.5728057553956835,
      "useful": 200,
      "creative": 61,
      "complete": 193,
      "clear_formatting": 170,
      "incorrect": 41,
      "superficial": 44,
      "instructions_not_followed": 13,
      "total_prefs": 722,
      "positive_prefs_ratio": 0.8642659279778393
    },
    {
      "model_name": "mistral-large-2512",
      "median": 1120.5661174138568,
      "p2.5": 1109.4290567935545,
      "p97.5": 1131.583924790477,
      "rank": 3,
      "rank_p2.5": 1,
      "rank_p97.5": 4,
      "total_output_tokens": 5803385,
      "conso_all_conv": 292.45473908069994,
      "n_match": 2723,
      "mean_conso_per_match": 0.10740166694113108,
      "mean_conso_per_token": 5.0393819999999986e-05,
      "mean_win_prob": 0.6600162661515026,
      "win_rate": 0.5632243848696291,
      "useful": 671,
      "creative": 174,
      "complete": 627,
      "clear_formatting": 490,
      "incorrect": 122,
      "superficial": 108,
      "instructions_not_followed": 79,
      "total_prefs": 2271,
      "positive_prefs_ratio": 0.8639365918097754
    },
    {
      "model_name": "mistral-medium-2508",
      "median": 1118.0257466129892,
      "p2.5": 1110.0407460022714,
      "p97.5": 1125.9029973200902,
      "rank": 4,
      "rank_p2.5": 2,
      "rank_p97.5": 4,
      "total_output_tokens": 9520618,
      "conso_all_conv": 189.5229121310467,
      "n_match": 6128,
      "mean_conso_per_match": 0.030927368167599004,
      "mean_conso_per_token": 1.990657666666667e-05,
      "mean_win_prob": 0.6568151662596042,
      "win_rate": 0.5871405255426799,
      "useful": 800,
      "creative": 212,
      "complete": 770,
      "clear_formatting": 629,
      "incorrect": 179,
      "superficial": 146,
      "instructions_not_followed": 80,
      "total_prefs": 2816,
      "positive_prefs_ratio": 0.8561789772727273
    },
    {
      "model_name": "gemini-2.5-flash",
      "median": 1105.8424269112988,
      "p2.5": 1097.3864312402077,
      "p97.5": 1115.3415622178718,
      "rank": 5,
      "rank_p2.5": 4,
      "rank_p97.5": 8,
      "total_output_tokens": 6138427,
      "conso_all_conv": 537.0212682433199,
      "n_match": 4731,
      "mean_conso_per_match": 0.11351115371873176,
      "mean_conso_per_token": 8.748515999999999e-05,
      "mean_win_prob": 0.6412839743578328,
      "win_rate": 0.5790065525258931,
      "useful": 600,
      "creative": 194,
      "complete": 663,
      "clear_formatting": 502,
      "incorrect": 143,
      "superficial": 125,
      "instructions_not_followed": 47,
      "total_prefs": 2274,
      "positive_prefs_ratio": 0.8614775725593667
    },
    {
      "model_name": "qwen3-max-2025-09-23",
      "median": 1102.499619048421,
      "p2.5": 1092.7206467935787,
      "p97.5": 1112.2408823341,
      "rank": 6,
      "rank_p2.5": 4,
      "rank_p97.5": 9,
      "total_output_tokens": 3458868,
      "conso_all_conv": 197.45819612735994,
      "n_match": 3108,
      "mean_conso_per_match": 0.0635322381362162,
      "mean_conso_per_token": 5.708751999999998e-05,
      "mean_win_prob": 0.6369730718514893,
      "win_rate": 0.5737045381396846,
      "useful": 401,
      "creative": 126,
      "complete": 361,
      "clear_formatting": 347,
      "incorrect": 131,
      "superficial": 102,
      "instructions_not_followed": 46,
      "total_prefs": 1514,
      "positive_prefs_ratio": 0.8157199471598415
    },
    {
      "model_name": "gemini-3-pro-preview",
      "median": 1102.1144530421132,
      "p2.5": 1090.085520421102,
      "p97.5": 1112.343883603519,
      "rank": 7,
      "rank_p2.5": 4,
      "rank_p97.5": 9,
      "total_output_tokens": 4879833,
      "conso_all_conv": 262.34909376269997,
      "n_match": 2865,
      "mean_conso_per_match": 0.09157036431507852,
      "mean_conso_per_token": 5.376189999999999e-05,
      "mean_win_prob": 0.6364750473873861,
      "win_rate": 0.554303664921466,
      "useful": 596,
      "creative": 189,
      "complete": 560,
      "clear_formatting": 419,
      "incorrect": 82,
      "superficial": 110,
      "instructions_not_followed": 61,
      "total_prefs": 2017,
      "positive_prefs_ratio": 0.8745661874070402
    },
    {
      "model_name": "gemini-2.0-flash",
      "median": 1099.3537843052413,
      "p2.5": 1092.6195781877616,
      "p97.5": 1106.8201893302362,
      "rank": 8,
      "rank_p2.5": 5,
      "rank_p97.5": 9,
      "total_output_tokens": 12296785,
      "conso_all_conv": 1075.7862032105998,
      "n_match": 8684,
      "mean_conso_per_match": 0.12388141446460153,
      "mean_conso_per_token": 8.748515999999998e-05,
      "mean_win_prob": 0.632897676872256,
      "win_rate": 0.6317699216950714,
      "useful": 2128,
      "creative": 677,
      "complete": 2179,
      "clear_formatting": 1909,
      "incorrect": 376,
      "superficial": 397,
      "instructions_not_followed": 112,
      "total_prefs": 7778,
      "positive_prefs_ratio": 0.8862175366418102
    },
    {
      "model_name": "deepseek-v3-0324",
      "median": 1091.3106264161256,
      "p2.5": 1081.9782314603467,
      "p97.5": 1100.9888378794521,
      "rank": 9,
      "rank_p2.5": 7,
      "rank_p97.5": 12,
      "total_output_tokens": 4435392,
      "conso_all_conv": 208.57759099007998,
      "n_match": 4385,
      "mean_conso_per_match": 0.04756615529990422,
      "mean_conso_per_token": 4.7025739999999995e-05,
      "mean_win_prob": 0.6223996896715935,
      "win_rate": 0.5851128848346637,
      "useful": 1141,
      "creative": 336,
      "complete": 1012,
      "clear_formatting": 1043,
      "incorrect": 230,
      "superficial": 288,
      "instructions_not_followed": 79,
      "total_prefs": 4129,
      "positive_prefs_ratio": 0.8554129329135384
    },
    {
      "model_name": "magistral-medium",
      "median": 1089.2502004001021,
      "p2.5": 1077.0229296590473,
      "p97.5": 1101.7461004559461,
      "rank": 10,
      "rank_p2.5": 7,
      "rank_p97.5": 14,
      "total_output_tokens": 2039837,
      "conso_all_conv": 40.60617162800334,
      "n_match": 2207,
      "mean_conso_per_match": 0.01839880907476363,
      "mean_conso_per_token": 1.9906576666666667e-05,
      "mean_win_prob": 0.6196930694463499,
      "win_rate": 0.5809968282736747,
      "useful": 146,
      "creative": 41,
      "complete": 150,
      "clear_formatting": 104,
      "incorrect": 50,
      "superficial": 28,
      "instructions_not_followed": 3,
      "total_prefs": 522,
      "positive_prefs_ratio": 0.8448275862068966
    },
    {
      "model_name": "gemma-3-27b",
      "median": 1082.7163477910226,
      "p2.5": 1076.4788486254847,
      "p97.5": 1089.486057090573,
      "rank": 11,
      "rank_p2.5": 10,
      "rank_p97.5": 15,
      "total_output_tokens": 11203777,
      "conso_all_conv": 72.08797685409667,
      "n_match": 8373,
      "mean_conso_per_match": 0.008609575642433616,
      "mean_conso_per_token": 6.434256666666666e-06,
      "mean_win_prob": 0.611065874901126,
      "win_rate": 0.5698972889048131,
      "useful": 1588,
      "creative": 524,
      "complete": 1756,
      "clear_formatting": 1300,
      "incorrect": 434,
      "superficial": 314,
      "instructions_not_followed": 151,
      "total_prefs": 6067,
      "positive_prefs_ratio": 0.8518213284984342
    },
    {
      "model_name": "deepseek-chat-v3.1",
      "median": 1078.00969958409,
      "p2.5": 1065.4583330353382,
      "p97.5": 1089.9256411186386,
      "rank": 12,
      "rank_p2.5": 10,
      "rank_p97.5": 21,
      "total_output_tokens": 3150274,
      "conso_all_conv": 148.14396605276,
      "n_match": 2324,
      "mean_conso_per_match": 0.06374525217416523,
      "mean_conso_per_token": 4.7025739999999995e-05,
      "mean_win_prob": 0.6048116583019952,
      "win_rate": 0.5211273666092943,
      "useful": 325,
      "creative": 104,
      "complete": 293,
      "clear_formatting": 255,
      "incorrect": 104,
      "superficial": 97,
      "instructions_not_followed": 56,
      "total_prefs": 1234,
      "positive_prefs_ratio": 0.7917341977309562
    },
    {
      "model_name": "deepseek-v3-chat",
      "median": 1077.9956862417694,
      "p2.5": 1069.8993485085498,
      "p97.5": 1086.6266188834118,
      "rank": 13,
      "rank_p2.5": 10,
      "rank_p97.5": 19,
      "total_output_tokens": 5638296,
      "conso_all_conv": 265.14504173904,
      "n_match": 5388,
      "mean_conso_per_match": 0.049210289855055676,
      "mean_conso_per_token": 4.7025739999999995e-05,
      "mean_win_prob": 0.6047929898900393,
      "win_rate": 0.6141481069042317,
      "useful": 1330,
      "creative": 390,
      "complete": 1245,
      "clear_formatting": 1399,
      "incorrect": 314,
      "superficial": 285,
      "instructions_not_followed": 81,
      "total_prefs": 5044,
      "positive_prefs_ratio": 0.8651863600317209
    },
    {
      "model_name": "gpt-5.2",
      "median": 1076.4828373228208,
      "p2.5": 1064.566599529933,
      "p97.5": 1087.328891318246,
      "rank": 14,
      "rank_p2.5": 10,
      "rank_p97.5": 22,
      "total_output_tokens": 2668065,
      "conso_all_conv": 126.76094209859997,
      "n_match": 2367,
      "mean_conso_per_match": 0.05355341871508237,
      "mean_conso_per_token": 4.751043999999999e-05,
      "mean_win_prob": 0.602775976439592,
      "win_rate": 0.529467680608365,
      "useful": 484,
      "creative": 108,
      "complete": 380,
      "clear_formatting": 363,
      "incorrect": 71,
      "superficial": 161,
      "instructions_not_followed": 57,
      "total_prefs": 1624,
      "positive_prefs_ratio": 0.8220443349753694
    },
    {
      "model_name": "DeepSeek-V3.2",
      "median": 1074.5949713072214,
      "p2.5": 1061.204693119383,
      "p97.5": 1088.431292104418,
      "rank": 15,
      "rank_p2.5": 10,
      "rank_p97.5": 25,
      "total_output_tokens": 1774031,
      "conso_all_conv": 83.42512055793999,
      "n_match": 1633,
      "mean_conso_per_match": 0.05108703034778934,
      "mean_conso_per_token": 4.7025739999999995e-05,
      "mean_win_prob": 0.6002545489898781,
      "win_rate": 0.5502265768524188,
      "useful": 398,
      "creative": 186,
      "complete": 397,
      "clear_formatting": 294,
      "incorrect": 117,
      "superficial": 109,
      "instructions_not_followed": 61,
      "total_prefs": 1562,
      "positive_prefs_ratio": 0.8162612035851472
    },
    {
      "model_name": "gpt-5.1",
      "median": 1073.601416970732,
      "p2.5": 1063.0100028552536,
      "p97.5": 1084.1459737335344,
      "rank": 16,
      "rank_p2.5": 11,
      "rank_p97.5": 23,
      "total_output_tokens": 3614412,
      "conso_all_conv": 171.72230446127995,
      "n_match": 2974,
      "mean_conso_per_match": 0.05774119181616676,
      "mean_conso_per_token": 4.751043999999999e-05,
      "mean_win_prob": 0.5989256271172112,
      "win_rate": 0.5281573638197714,
      "useful": 449,
      "creative": 124,
      "complete": 433,
      "clear_formatting": 360,
      "incorrect": 70,
      "superficial": 132,
      "instructions_not_followed": 54,
      "total_prefs": 1622,
      "positive_prefs_ratio": 0.842170160295931
    },
    {
      "model_name": "claude-4-5-sonnet",
      "median": 1072.0167997044362,
      "p2.5": 1064.6365440137693,
      "p97.5": 1079.5543671299567,
      "rank": 17,
      "rank_p2.5": 13,
      "rank_p97.5": 22,
      "total_output_tokens": 6471276,
      "conso_all_conv": 566.1406162641599,
      "n_match": 6138,
      "mean_conso_per_match": 0.09223535618510263,
      "mean_conso_per_token": 8.748515999999999e-05,
      "mean_win_prob": 0.5968034272098997,
      "win_rate": 0.5363734115347019,
      "useful": 1173,
      "creative": 512,
      "complete": 870,
      "clear_formatting": 623,
      "incorrect": 161,
      "superficial": 249,
      "instructions_not_followed": 92,
      "total_prefs": 3680,
      "positive_prefs_ratio": 0.8635869565217391
    },
    {
      "model_name": "glm-4.5",
      "median": 1071.8631448398442,
      "p2.5": 1059.7140521461595,
      "p97.5": 1084.2270639583412,
      "rank": 18,
      "rank_p2.5": 11,
      "rank_p97.5": 25,
      "total_output_tokens": 5128869,
      "conso_all_conv": 109.79790435558,
      "n_match": 2178,
      "mean_conso_per_match": 0.050412260952975206,
      "mean_conso_per_token": 2.140782e-05,
      "mean_win_prob": 0.5965974700900935,
      "win_rate": 0.5414882866329811,
      "useful": 227,
      "creative": 75,
      "complete": 282,
      "clear_formatting": 209,
      "incorrect": 48,
      "superficial": 57,
      "instructions_not_followed": 33,
      "total_prefs": 931,
      "positive_prefs_ratio": 0.8517722878625135
    },
    {
      "model_name": "grok-4.1-fast",
      "median": 1068.735591349157,
      "p2.5": 1056.6855683833921,
      "p97.5": 1080.6245900256552,
      "rank": 19,
      "rank_p2.5": 13,
      "rank_p97.5": 27,
      "total_output_tokens": 2573029,
      "conso_all_conv": 656.4742395622233,
      "n_match": 2311,
      "mean_conso_per_match": 0.28406501062839606,
      "mean_conso_per_token": 0.0002551367433333333,
      "mean_win_prob": 0.5923987719075315,
      "win_rate": 0.532081350064907,
      "useful": 424,
      "creative": 159,
      "complete": 350,
      "clear_formatting": 307,
      "incorrect": 118,
      "superficial": 120,
      "instructions_not_followed": 48,
      "total_prefs": 1526,
      "positive_prefs_ratio": 0.8125819134993447
    },
    {
      "model_name": "kimi-k2-thinking",
      "median": 1067.2983643342166,
      "p2.5": 1051.2745278140626,
      "p97.5": 1084.2852400745212,
      "rank": 20,
      "rank_p2.5": 11,
      "rank_p97.5": 30,
      "total_output_tokens": 1849764,
      "conso_all_conv": 105.59843934527997,
      "n_match": 1129,
      "mean_conso_per_match": 0.09353271864063771,
      "mean_conso_per_token": 5.7087519999999986e-05,
      "mean_win_prob": 0.5904652115076863,
      "win_rate": 0.5386802480070859,
      "useful": 225,
      "creative": 44,
      "complete": 209,
      "clear_formatting": 167,
      "incorrect": 52,
      "superficial": 71,
      "instructions_not_followed": 39,
      "total_prefs": 807,
      "positive_prefs_ratio": 0.7992565055762082
    },
    {
      "model_name": "gpt-oss-120b",
      "median": 1065.7381312035204,
      "p2.5": 1053.5090798747128,
      "p97.5": 1078.2806754413543,
      "rank": 21,
      "rank_p2.5": 14,
      "rank_p97.5": 29,
      "total_output_tokens": 4963016,
      "conso_all_conv": 16.6104700996,
      "n_match": 2127,
      "mean_conso_per_match": 0.007809341842783263,
      "mean_conso_per_token": 3.34685e-06,
      "mean_win_prob": 0.5883633282708796,
      "win_rate": 0.5258607714016933,
      "useful": 327,
      "creative": 111,
      "complete": 424,
      "clear_formatting": 289,
      "incorrect": 121,
      "superficial": 90,
      "instructions_not_followed": 69,
      "total_prefs": 1431,
      "positive_prefs_ratio": 0.8043326345213138
    },
    {
      "model_name": "gemma-3-12b",
      "median": 1063.4446227907656,
      "p2.5": 1057.2682654163955,
      "p97.5": 1069.7929899939236,
      "rank": 22,
      "rank_p2.5": 18,
      "rank_p97.5": 27,
      "total_output_tokens": 10427965,
      "conso_all_conv": 45.14481559776666,
      "n_match": 8085,
      "mean_conso_per_match": 0.005583774347280972,
      "mean_conso_per_token": 4.329206666666666e-06,
      "mean_win_prob": 0.5852683860147119,
      "win_rate": 0.5551329622758194,
      "useful": 1388,
      "creative": 409,
      "complete": 1518,
      "clear_formatting": 1169,
      "incorrect": 487,
      "superficial": 363,
      "instructions_not_followed": 205,
      "total_prefs": 5539,
      "positive_prefs_ratio": 0.8095324065715833
    },
    {
      "model_name": "claude-4-sonnet",
      "median": 1062.7685091893009,
      "p2.5": 1051.6628897600258,
      "p97.5": 1073.6121403319926,
      "rank": 23,
      "rank_p2.5": 16,
      "rank_p97.5": 30,
      "total_output_tokens": 1853912,
      "conso_all_conv": 162.18978794591996,
      "n_match": 2540,
      "mean_conso_per_match": 0.06385424722280314,
      "mean_conso_per_token": 8.748515999999998e-05,
      "mean_win_prob": 0.5843548562485997,
      "win_rate": 0.5355651831429696,
      "useful": 234,
      "creative": 62,
      "complete": 198,
      "clear_formatting": 215,
      "incorrect": 41,
      "superficial": 64,
      "instructions_not_followed": 20,
      "total_prefs": 834,
      "positive_prefs_ratio": 0.8501199040767387
    },
    {
      "model_name": "grok-4-fast",
      "median": 1062.451867863535,
      "p2.5": 1051.5751173950143,
      "p97.5": 1074.4231052513385,
      "rank": 24,
      "rank_p2.5": 16,
      "rank_p97.5": 30,
      "total_output_tokens": 3521762,
      "conso_all_conv": 898.5308874750866,
      "n_match": 2623,
      "mean_conso_per_match": 0.34255847787841653,
      "mean_conso_per_token": 0.0002551367433333333,
      "mean_win_prob": 0.5839268487478416,
      "win_rate": 0.5293971766501335,
      "useful": 228,
      "creative": 53,
      "complete": 176,
      "clear_formatting": 137,
      "incorrect": 61,
      "superficial": 52,
      "instructions_not_followed": 20,
      "total_prefs": 727,
      "positive_prefs_ratio": 0.8170563961485557
    },
    {
      "model_name": "grok-3-mini-beta",
      "median": 1060.0914330943306,
      "p2.5": 1045.574620103872,
      "p97.5": 1075.7172963767168,
      "rank": 25,
      "rank_p2.5": 15,
      "rank_p97.5": 32,
      "total_output_tokens": 3474752,
      "conso_all_conv": 39.83854131029333,
      "n_match": 1537,
      "mean_conso_per_match": 0.02591967554345695,
      "mean_conso_per_token": 1.1465146666666665e-05,
      "mean_win_prob": 0.5807327089224541,
      "win_rate": 0.5305338541666667,
      "useful": 404,
      "creative": 102,
      "complete": 350,
      "clear_formatting": 320,
      "incorrect": 102,
      "superficial": 106,
      "instructions_not_followed": 47,
      "total_prefs": 1431,
      "positive_prefs_ratio": 0.8218029350104822
    },
    {
      "model_name": "kimi-k2",
      "median": 1059.3854246764197,
      "p2.5": 1044.9357869666533,
      "p97.5": 1073.1639513097407,
      "rank": 26,
      "rank_p2.5": 17,
      "rank_p97.5": 33,
      "total_output_tokens": 1847328,
      "conso_all_conv": 105.45937414655997,
      "n_match": 1571,
      "mean_conso_per_match": 0.06712881868017821,
      "mean_conso_per_token": 5.708751999999998e-05,
      "mean_win_prob": 0.5797761570851532,
      "win_rate": 0.5203639846743295,
      "useful": 358,
      "creative": 97,
      "complete": 220,
      "clear_formatting": 222,
      "incorrect": 76,
      "superficial": 98,
      "instructions_not_followed": 30,
      "total_prefs": 1101,
      "positive_prefs_ratio": 0.8147138964577657
    },
    {
      "model_name": "mistral-small-2506",
      "median": 1058.799401077619,
      "p2.5": 1050.9650596000065,
      "p97.5": 1066.208406829008,
      "rank": 27,
      "rank_p2.5": 21,
      "rank_p97.5": 30,
      "total_output_tokens": 4162155,
      "conso_all_conv": 25.028064679899998,
      "n_match": 5151,
      "mean_conso_per_match": 0.004858874913589594,
      "mean_conso_per_token": 6.0132466666666666e-06,
      "mean_win_prob": 0.5789817648849578,
      "win_rate": 0.5255173752669384,
      "useful": 606,
      "creative": 158,
      "complete": 492,
      "clear_formatting": 479,
      "incorrect": 222,
      "superficial": 204,
      "instructions_not_followed": 60,
      "total_prefs": 2221,
      "positive_prefs_ratio": 0.7811796488068438
    },
    {
      "model_name": "deepseek-r1-0528",
      "median": 1055.9677309961294,
      "p2.5": 1042.297517436147,
      "p97.5": 1068.076740271923,
      "rank": 28,
      "rank_p2.5": 19,
      "rank_p97.5": 33,
      "total_output_tokens": 3510682,
      "conso_all_conv": 165.09241895468,
      "n_match": 1899,
      "mean_conso_per_match": 0.086936502872396,
      "mean_conso_per_token": 4.702574e-05,
      "mean_win_prob": 0.575138210014572,
      "win_rate": 0.5232596103212217,
      "useful": 266,
      "creative": 79,
      "complete": 247,
      "clear_formatting": 197,
      "incorrect": 80,
      "superficial": 76,
      "instructions_not_followed": 36,
      "total_prefs": 981,
      "positive_prefs_ratio": 0.8042813455657493
    },
    {
      "model_name": "command-a",
      "median": 1054.6827794235548,
      "p2.5": 1048.0951359970481,
      "p97.5": 1061.5525197165057,
      "rank": 29,
      "rank_p2.5": 24,
      "rank_p97.5": 32,
      "total_output_tokens": 7439909,
      "conso_all_conv": 135.57401454916334,
      "n_match": 7693,
      "mean_conso_per_match": 0.0176230358181676,
      "mean_conso_per_token": 1.822253666666667e-05,
      "mean_win_prob": 0.5733914065953097,
      "win_rate": 0.5440517353438191,
      "useful": 1491,
      "creative": 355,
      "complete": 1337,
      "clear_formatting": 1252,
      "incorrect": 354,
      "superficial": 408,
      "instructions_not_followed": 140,
      "total_prefs": 5337,
      "positive_prefs_ratio": 0.8309911935544313
    },
    {
      "model_name": "Qwen3-Coder-480B-A35B-Instruct",
      "median": 1049.9031202117474,
      "p2.5": 1033.9295498888434,
      "p97.5": 1064.1621608219566,
      "rank": 30,
      "rank_p2.5": 22,
      "rank_p97.5": 36,
      "total_output_tokens": 1362329,
      "conso_all_conv": 41.18020854619999,
      "n_match": 1385,
      "mean_conso_per_match": 0.029733002560433208,
      "mean_conso_per_token": 3.0227799999999995e-05,
      "mean_win_prob": 0.5668799162822064,
      "win_rate": 0.5229573391178597,
      "useful": 252,
      "creative": 62,
      "complete": 167,
      "clear_formatting": 190,
      "incorrect": 58,
      "superficial": 93,
      "instructions_not_followed": 31,
      "total_prefs": 853,
      "positive_prefs_ratio": 0.7866354044548651
    },
    {
      "model_name": "magistral-small-2506",
      "median": 1048.382613949801,
      "p2.5": 1038.231674366318,
      "p97.5": 1058.7308627010689,
      "rank": 31,
      "rank_p2.5": 26,
      "rank_p97.5": 35,
      "total_output_tokens": 2445603,
      "conso_all_conv": 14.706014087739998,
      "n_match": 3147,
      "mean_conso_per_match": 0.0046730264022052746,
      "mean_conso_per_token": 6.013246666666666e-06,
      "mean_win_prob": 0.5648041262731391,
      "win_rate": 0.52184361093452,
      "useful": 248,
      "creative": 53,
      "complete": 198,
      "clear_formatting": 181,
      "incorrect": 88,
      "superficial": 84,
      "instructions_not_followed": 32,
      "total_prefs": 884,
      "positive_prefs_ratio": 0.7692307692307693
    },
    {
      "model_name": "claude-3-7-sonnet",
      "median": 1048.2678059861219,
      "p2.5": 1038.2030359224602,
      "p97.5": 1057.7567347148995,
      "rank": 32,
      "rank_p2.5": 27,
      "rank_p97.5": 35,
      "total_output_tokens": 3546728,
      "conso_all_conv": 310.2860665564799,
      "n_match": 3907,
      "mean_conso_per_match": 0.07941798478538006,
      "mean_conso_per_token": 8.748515999999998e-05,
      "mean_win_prob": 0.5646473093578714,
      "win_rate": 0.524225748656258,
      "useful": 1003,
      "creative": 230,
      "complete": 774,
      "clear_formatting": 822,
      "incorrect": 140,
      "superficial": 318,
      "instructions_not_followed": 46,
      "total_prefs": 3333,
      "positive_prefs_ratio": 0.8487848784878488
    },
    {
      "model_name": "llama-3.1-nemotron-70b-instruct",
      "median": 1043.6045840063093,
      "p2.5": 1036.1244208541107,
      "p97.5": 1051.2225204418319,
      "rank": 33,
      "rank_p2.5": 30,
      "rank_p97.5": 36,
      "total_output_tokens": 7426282,
      "conso_all_conv": 92.59632991613334,
      "n_match": 6709,
      "mean_conso_per_match": 0.01380180800657823,
      "mean_conso_per_token": 1.2468733333333335e-05,
      "mean_win_prob": 0.558268567791439,
      "win_rate": 0.5452863107664778,
      "useful": 1544,
      "creative": 487,
      "complete": 1473,
      "clear_formatting": 1431,
      "incorrect": 381,
      "superficial": 395,
      "instructions_not_followed": 136,
      "total_prefs": 5847,
      "positive_prefs_ratio": 0.8440225756798359
    },
    {
      "model_name": "glm-4.6",
      "median": 1043.0970790612905,
      "p2.5": 1031.7685787288594,
      "p97.5": 1054.1230369056418,
      "rank": 34,
      "rank_p2.5": 28,
      "rank_p97.5": 37,
      "total_output_tokens": 7129634,
      "conso_all_conv": 152.62992133788,
      "n_match": 2621,
      "mean_conso_per_match": 0.058233468652376955,
      "mean_conso_per_token": 2.140782e-05,
      "mean_win_prob": 0.5575733196070535,
      "win_rate": 0.5038496756962991,
      "useful": 319,
      "creative": 117,
      "complete": 365,
      "clear_formatting": 249,
      "incorrect": 98,
      "superficial": 100,
      "instructions_not_followed": 60,
      "total_prefs": 1308,
      "positive_prefs_ratio": 0.8027522935779816
    },
    {
      "model_name": "glm-4.7",
      "median": 1036.2150131840178,
      "p2.5": 1013.448139588945,
      "p97.5": 1057.9686083030197,
      "rank": 35,
      "rank_p2.5": 27,
      "rank_p97.5": 45,
      "total_output_tokens": 1616823,
      "conso_all_conv": 34.612655755860004,
      "n_match": 658,
      "mean_conso_per_match": 0.05260282029765958,
      "mean_conso_per_token": 2.1407820000000003e-05,
      "mean_win_prob": 0.5481271628371293,
      "win_rate": 0.47074468085106386,
      "useful": 107,
      "creative": 33,
      "complete": 124,
      "clear_formatting": 92,
      "incorrect": 33,
      "superficial": 41,
      "instructions_not_followed": 29,
      "total_prefs": 459,
      "positive_prefs_ratio": 0.775599128540305
    },
    {
      "model_name": "gemma-3-4b",
      "median": 1035.4382152555852,
      "p2.5": 1029.189714120669,
      "p97.5": 1041.8256240864255,
      "rank": 36,
      "rank_p2.5": 34,
      "rank_p97.5": 39,
      "total_output_tokens": 11215500,
      "conso_all_conv": 35.96265029,
      "n_match": 9158,
      "mean_conso_per_match": 0.003926910929242192,
      "mean_conso_per_token": 3.2065133333333334e-06,
      "mean_win_prob": 0.5470589803845023,
      "win_rate": 0.512464511902162,
      "useful": 1396,
      "creative": 416,
      "complete": 1503,
      "clear_formatting": 1212,
      "incorrect": 728,
      "superficial": 378,
      "instructions_not_followed": 254,
      "total_prefs": 5887,
      "positive_prefs_ratio": 0.7689825038219806
    },
    {
      "model_name": "gemma-3n-e4b-it",
      "median": 1031.4136339100912,
      "p2.5": 1023.0979994080865,
      "p97.5": 1040.5036354836845,
      "rank": 37,
      "rank_p2.5": 34,
      "rank_p97.5": 41,
      "total_output_tokens": 5083978,
      "conso_all_conv": 16.301843243373334,
      "n_match": 4473,
      "mean_conso_per_match": 0.0036444988248095986,
      "mean_conso_per_token": 3.2065133333333334e-06,
      "mean_win_prob": 0.5415190861630047,
      "win_rate": 0.4958663089649006,
      "useful": 475,
      "creative": 162,
      "complete": 464,
      "clear_formatting": 401,
      "incorrect": 238,
      "superficial": 190,
      "instructions_not_followed": 108,
      "total_prefs": 2038,
      "positive_prefs_ratio": 0.7369970559371933
    },
    {
      "model_name": "gpt-4.1-mini",
      "median": 1030.7829679202357,
      "p2.5": 1023.9744601260239,
      "p97.5": 1038.0662362284977,
      "rank": 38,
      "rank_p2.5": 35,
      "rank_p97.5": 40,
      "total_output_tokens": 5550374,
      "conso_all_conv": 73.10073823583333,
      "n_match": 7173,
      "mean_conso_per_match": 0.010191096923997398,
      "mean_conso_per_token": 1.3170416666666667e-05,
      "mean_win_prob": 0.5406501590144065,
      "win_rate": 0.5152977269557941,
      "useful": 1227,
      "creative": 286,
      "complete": 945,
      "clear_formatting": 1010,
      "incorrect": 244,
      "superficial": 455,
      "instructions_not_followed": 97,
      "total_prefs": 4264,
      "positive_prefs_ratio": 0.8133208255159474
    },
    {
      "model_name": "gemini-1.5-pro",
      "median": 1029.946434758468,
      "p2.5": 1022.3230519851302,
      "p97.5": 1037.3306268727658,
      "rank": 39,
      "rank_p2.5": 35,
      "rank_p97.5": 41,
      "total_output_tokens": 6034223,
      "conso_all_conv": 1011.3126436118333,
      "n_match": 7387,
      "mean_conso_per_match": 0.13690437845022788,
      "mean_conso_per_token": 0.00016759616666666666,
      "mean_win_prob": 0.5394972746988902,
      "win_rate": 0.5830743197509137,
      "useful": 2118,
      "creative": 683,
      "complete": 1630,
      "clear_formatting": 1959,
      "incorrect": 461,
      "superficial": 655,
      "instructions_not_followed": 202,
      "total_prefs": 7708,
      "positive_prefs_ratio": 0.8290088220031137
    },
    {
      "model_name": "deepseek-r1",
      "median": 1024.1814183795195,
      "p2.5": 1014.086706325747,
      "p97.5": 1034.7128581610436,
      "rank": 40,
      "rank_p2.5": 36,
      "rank_p97.5": 45,
      "total_output_tokens": 3693582,
      "conso_all_conv": 173.69342680068,
      "n_match": 3510,
      "mean_conso_per_match": 0.04948530678082051,
      "mean_conso_per_token": 4.7025739999999995e-05,
      "mean_win_prob": 0.5315432556280325,
      "win_rate": 0.5313019943019943,
      "useful": 826,
      "creative": 284,
      "complete": 783,
      "clear_formatting": 667,
      "incorrect": 171,
      "superficial": 207,
      "instructions_not_followed": 112,
      "total_prefs": 3050,
      "positive_prefs_ratio": 0.839344262295082
    },
    {
      "model_name": "qwen3-32b",
      "median": 1019.5980478803097,
      "p2.5": 1007.5187154944817,
      "p97.5": 1031.7086519750085,
      "rank": 41,
      "rank_p2.5": 38,
      "rank_p97.5": 48,
      "total_output_tokens": 4245812,
      "conso_all_conv": 30.29785968327999,
      "n_match": 2158,
      "mean_conso_per_match": 0.01403978669290083,
      "mean_conso_per_token": 7.135939999999998e-06,
      "mean_win_prob": 0.5252102910158156,
      "win_rate": 0.5020269016697587,
      "useful": 485,
      "creative": 139,
      "complete": 397,
      "clear_formatting": 312,
      "incorrect": 187,
      "superficial": 167,
      "instructions_not_followed": 85,
      "total_prefs": 1772,
      "positive_prefs_ratio": 0.7522573363431151
    },
    {
      "model_name": "mistral-large-2411",
      "median": 1017.7805250042902,
      "p2.5": 1011.2330486150995,
      "p97.5": 1024.0475926682573,
      "rank": 42,
      "rank_p2.5": 40,
      "rank_p97.5": 47,
      "total_output_tokens": 7677266,
      "conso_all_conv": 152.82808421939336,
      "n_match": 8829,
      "mean_conso_per_match": 0.017309784145361124,
      "mean_conso_per_token": 1.990657666666667e-05,
      "mean_win_prob": 0.5226971697345342,
      "win_rate": 0.527441386340469,
      "useful": 1898,
      "creative": 355,
      "complete": 1451,
      "clear_formatting": 1608,
      "incorrect": 393,
      "superficial": 666,
      "instructions_not_followed": 140,
      "total_prefs": 6511,
      "positive_prefs_ratio": 0.8158500998310552
    },
    {
      "model_name": "llama-maverick",
      "median": 1014.6818452756368,
      "p2.5": 1004.8358227631333,
      "p97.5": 1024.2592008946635,
      "rank": 43,
      "rank_p2.5": 40,
      "rank_p97.5": 49,
      "total_output_tokens": 2880450,
      "conso_all_conv": 43.473681301499994,
      "n_match": 3666,
      "mean_conso_per_match": 0.011858614648527003,
      "mean_conso_per_token": 1.5092669999999998e-05,
      "mean_win_prob": 0.5184106940626225,
      "win_rate": 0.48111565739225315,
      "useful": 400,
      "creative": 76,
      "complete": 293,
      "clear_formatting": 272,
      "incorrect": 120,
      "superficial": 223,
      "instructions_not_followed": 69,
      "total_prefs": 1453,
      "positive_prefs_ratio": 0.7164487267721955
    },
    {
      "model_name": "mistral-saba",
      "median": 1014.2194138238686,
      "p2.5": 1006.1441132782754,
      "p97.5": 1021.9192991114306,
      "rank": 44,
      "rank_p2.5": 41,
      "rank_p97.5": 49,
      "total_output_tokens": 4349650,
      "conso_all_conv": 26.155518363666665,
      "n_match": 4934,
      "mean_conso_per_match": 0.005301077901026888,
      "mean_conso_per_token": 6.0132466666666666e-06,
      "mean_win_prob": 0.5177708287099839,
      "win_rate": 0.48257855260490573,
      "useful": 745,
      "creative": 170,
      "complete": 587,
      "clear_formatting": 586,
      "incorrect": 241,
      "superficial": 337,
      "instructions_not_followed": 113,
      "total_prefs": 2779,
      "positive_prefs_ratio": 0.751349406261245
    },
    {
      "model_name": "EuroLLM-22B-Instruct-2512",
      "median": 1013.954376961198,
      "p2.5": 982.9916304614825,
      "p97.5": 1045.7589615978109,
      "rank": 45,
      "rank_p2.5": 32,
      "rank_p97.5": 60,
      "total_output_tokens": 260645,
      "conso_all_conv": 1.4941665764666665,
      "n_match": 346,
      "mean_conso_per_match": 0.004318400510019267,
      "mean_conso_per_token": 5.7325733333333326e-06,
      "mean_win_prob": 0.517404079994749,
      "win_rate": 0.45523121387283233,
      "useful": 97,
      "creative": 20,
      "complete": 61,
      "clear_formatting": 70,
      "incorrect": 24,
      "superficial": 34,
      "instructions_not_followed": 14,
      "total_prefs": 320,
      "positive_prefs_ratio": 0.775
    },
    {
      "model_name": "gpt-oss-20b",
      "median": 1013.2380446412851,
      "p2.5": 1002.0902824054225,
      "p97.5": 1024.40353176847,
      "rank": 46,
      "rank_p2.5": 40,
      "rank_p97.5": 50,
      "total_output_tokens": 4304191,
      "conso_all_conv": 13.197410013076667,
      "n_match": 2499,
      "mean_conso_per_match": 0.0052810764358049885,
      "mean_conso_per_token": 3.066176666666667e-06,
      "mean_win_prob": 0.516412782918306,
      "win_rate": 0.4535828662930344,
      "useful": 297,
      "creative": 102,
      "complete": 292,
      "clear_formatting": 247,
      "incorrect": 142,
      "superficial": 133,
      "instructions_not_followed": 84,
      "total_prefs": 1297,
      "positive_prefs_ratio": 0.723207401696222
    },
    {
      "model_name": "gpt-5-mini",
      "median": 1011.4098891933436,
      "p2.5": 1002.6738690517188,
      "p97.5": 1021.6317718593873,
      "rank": 47,
      "rank_p2.5": 41,
      "rank_p97.5": 50,
      "total_output_tokens": 4791225,
      "conso_all_conv": 44.27566231274999,
      "n_match": 4110,
      "mean_conso_per_match": 0.01077266722937956,
      "mean_conso_per_token": 9.24099e-06,
      "mean_win_prob": 0.5138825250357583,
      "win_rate": 0.47117060111949377,
      "useful": 430,
      "creative": 102,
      "complete": 421,
      "clear_formatting": 260,
      "incorrect": 108,
      "superficial": 179,
      "instructions_not_followed": 110,
      "total_prefs": 1610,
      "positive_prefs_ratio": 0.753416149068323
    },
    {
      "model_name": "llama-4-scout",
      "median": 1009.5737794282447,
      "p2.5": 1002.6663977531879,
      "p97.5": 1017.0003451121268,
      "rank": 48,
      "rank_p2.5": 43,
      "rank_p97.5": 51,
      "total_output_tokens": 5078918,
      "conso_all_conv": 25.551477777019997,
      "n_match": 6404,
      "mean_conso_per_match": 0.003989924699722048,
      "mean_conso_per_token": 5.03089e-06,
      "mean_win_prob": 0.5113408309670182,
      "win_rate": 0.48567613991255465,
      "useful": 973,
      "creative": 220,
      "complete": 828,
      "clear_formatting": 786,
      "incorrect": 340,
      "superficial": 484,
      "instructions_not_followed": 131,
      "total_prefs": 3762,
      "positive_prefs_ratio": 0.7461456671982988
    },
    {
      "model_name": "mistral-small-3.1-24b",
      "median": 1004.4643237801531,
      "p2.5": 996.0511984085847,
      "p97.5": 1012.4999653890181,
      "rank": 49,
      "rank_p2.5": 45,
      "rank_p97.5": 53,
      "total_output_tokens": 4470466,
      "conso_all_conv": 26.882014772946665,
      "n_match": 5079,
      "mean_conso_per_match": 0.005292777076776268,
      "mean_conso_per_token": 6.0132466666666666e-06,
      "mean_win_prob": 0.5042666923948425,
      "win_rate": 0.4945107304587517,
      "useful": 1108,
      "creative": 247,
      "complete": 791,
      "clear_formatting": 916,
      "incorrect": 268,
      "superficial": 430,
      "instructions_not_followed": 130,
      "total_prefs": 3890,
      "positive_prefs_ratio": 0.787146529562982
    },
    {
      "model_name": "o4-mini",
      "median": 1001.6963862054683,
      "p2.5": 991.3557638273381,
      "p97.5": 1013.0599993481973,
      "rank": 50,
      "rank_p2.5": 46,
      "rank_p97.5": 55,
      "total_output_tokens": 2940457,
      "conso_all_conv": 15.205769650586666,
      "n_match": 2830,
      "mean_conso_per_match": 0.005373063480772673,
      "mean_conso_per_token": 5.171226666666666e-06,
      "mean_win_prob": 0.5004343955057601,
      "win_rate": 0.4738494167550371,
      "useful": 527,
      "creative": 111,
      "complete": 374,
      "clear_formatting": 286,
      "incorrect": 133,
      "superficial": 210,
      "instructions_not_followed": 45,
      "total_prefs": 1686,
      "positive_prefs_ratio": 0.7698695136417556
    },
    {
      "model_name": "gemma-2-27b-it-q8",
      "median": 1000.0019074377633,
      "p2.5": 977.1253588105999,
      "p97.5": 1024.8157857194572,
      "rank": 51,
      "rank_p2.5": 40,
      "rank_p97.5": 62,
      "total_output_tokens": 449540,
      "conso_all_conv": 2.8924557419333334,
      "n_match": 762,
      "mean_conso_per_match": 0.0037958736770778655,
      "mean_conso_per_token": 6.434256666666667e-06,
      "mean_win_prob": 0.4980885662475079,
      "win_rate": 0.5826115485564304,
      "useful": 318,
      "creative": 97,
      "complete": 178,
      "clear_formatting": 305,
      "incorrect": 63,
      "superficial": 91,
      "instructions_not_followed": 29,
      "total_prefs": 1081,
      "positive_prefs_ratio": 0.8307123034227567
    },
    {
      "model_name": "gpt-5",
      "median": 999.2838849632026,
      "p2.5": 990.3879990277264,
      "p97.5": 1008.2705542128886,
      "rank": 52,
      "rank_p2.5": 48,
      "rank_p97.5": 55,
      "total_output_tokens": 4019540,
      "conso_all_conv": 190.97011399759995,
      "n_match": 3843,
      "mean_conso_per_match": 0.0496929778812386,
      "mean_conso_per_token": 4.751043999999999e-05,
      "mean_win_prob": 0.4970946216472743,
      "win_rate": 0.45334721499219155,
      "useful": 144,
      "creative": 54,
      "complete": 158,
      "clear_formatting": 68,
      "incorrect": 29,
      "superficial": 57,
      "instructions_not_followed": 32,
      "total_prefs": 542,
      "positive_prefs_ratio": 0.7822878228782287
    },
    {
      "model_name": "lfm2-8b-a1b",
      "median": 996.5166769058501,
      "p2.5": 983.5273481044769,
      "p97.5": 1008.3512451913541,
      "rank": 53,
      "rank_p2.5": 48,
      "rank_p97.5": 59,
      "total_output_tokens": 1640033,
      "conso_all_conv": 4.568317388276667,
      "n_match": 2130,
      "mean_conso_per_match": 0.0021447499475477313,
      "mean_conso_per_token": 2.7855033333333337e-06,
      "mean_win_prob": 0.49326465624278226,
      "win_rate": 0.46863615023474176,
      "useful": 267,
      "creative": 52,
      "complete": 184,
      "clear_formatting": 214,
      "incorrect": 174,
      "superficial": 164,
      "instructions_not_followed": 76,
      "total_prefs": 1131,
      "positive_prefs_ratio": 0.6339522546419099
    },
    {
      "model_name": "aya-expanse-32b",
      "median": 990.1949430372096,
      "p2.5": 982.2430473057217,
      "p97.5": 998.3204926079748,
      "rank": 54,
      "rank_p2.5": 52,
      "rank_p97.5": 60,
      "total_output_tokens": 4082212,
      "conso_all_conv": 29.130419899279993,
      "n_match": 5113,
      "mean_conso_per_match": 0.005697324447345979,
      "mean_conso_per_token": 7.135939999999998e-06,
      "mean_win_prob": 0.48452064833220676,
      "win_rate": 0.46256796401329947,
      "useful": 722,
      "creative": 142,
      "complete": 527,
      "clear_formatting": 513,
      "incorrect": 277,
      "superficial": 353,
      "instructions_not_followed": 109,
      "total_prefs": 2643,
      "positive_prefs_ratio": 0.7203934922436626
    },
    {
      "model_name": "qwen-3-8b",
      "median": 988.1738368488508,
      "p2.5": 978.53314468069,
      "p97.5": 998.1620984265256,
      "rank": 55,
      "rank_p2.5": 52,
      "rank_p97.5": 62,
      "total_output_tokens": 6059023,
      "conso_all_conv": 22.829550400779997,
      "n_match": 3059,
      "mean_conso_per_match": 0.007463076299699247,
      "mean_conso_per_token": 3.7678599999999997e-06,
      "mean_win_prob": 0.4817273926037259,
      "win_rate": 0.4339146779993462,
      "useful": 284,
      "creative": 80,
      "complete": 292,
      "clear_formatting": 203,
      "incorrect": 221,
      "superficial": 134,
      "instructions_not_followed": 87,
      "total_prefs": 1301,
      "positive_prefs_ratio": 0.6602613374327441
    },
    {
      "model_name": "qwen3-30b-a3b",
      "median": 988.0639329791754,
      "p2.5": 978.1557094319086,
      "p97.5": 997.6501277510969,
      "rank": 56,
      "rank_p2.5": 52,
      "rank_p97.5": 62,
      "total_output_tokens": 6299219,
      "conso_all_conv": 19.31451831602333,
      "n_match": 3628,
      "mean_conso_per_match": 0.005323737132310731,
      "mean_conso_per_token": 3.0661766666666664e-06,
      "mean_win_prob": 0.4815755388145933,
      "win_rate": 0.45714640198511164,
      "useful": 320,
      "creative": 86,
      "complete": 348,
      "clear_formatting": 267,
      "incorrect": 206,
      "superficial": 173,
      "instructions_not_followed": 106,
      "total_prefs": 1506,
      "positive_prefs_ratio": 0.6779548472775564
    },
    {
      "model_name": "llama-3.3-70b",
      "median": 985.5447216204826,
      "p2.5": 979.4416657771322,
      "p97.5": 991.6421290684075,
      "rank": 57,
      "rank_p2.5": 54,
      "rank_p97.5": 62,
      "total_output_tokens": 7880938,
      "conso_all_conv": 98.26531433853334,
      "n_match": 9667,
      "mean_conso_per_match": 0.010165026827199063,
      "mean_conso_per_token": 1.2468733333333335e-05,
      "mean_win_prob": 0.4780959322604436,
      "win_rate": 0.4733588496948381,
      "useful": 1614,
      "creative": 334,
      "complete": 1258,
      "clear_formatting": 1207,
      "incorrect": 536,
      "superficial": 777,
      "instructions_not_followed": 187,
      "total_prefs": 5913,
      "positive_prefs_ratio": 0.7463216641298833
    },
    {
      "model_name": "mistral-small-24b-instruct-2501",
      "median": 984.2817214600645,
      "p2.5": 974.6929181131427,
      "p97.5": 994.8730040878348,
      "rank": 58,
      "rank_p2.5": 53,
      "rank_p97.5": 64,
      "total_output_tokens": 2818040,
      "conso_all_conv": 16.94556963653333,
      "n_match": 3318,
      "mean_conso_per_match": 0.005107163844645368,
      "mean_conso_per_token": 6.013246666666666e-06,
      "mean_win_prob": 0.47635235200443404,
      "win_rate": 0.4952350813743219,
      "useful": 745,
      "creative": 155,
      "complete": 536,
      "clear_formatting": 656,
      "incorrect": 204,
      "superficial": 307,
      "instructions_not_followed": 71,
      "total_prefs": 2674,
      "positive_prefs_ratio": 0.7823485415108452
    },
    {
      "model_name": "o3-mini",
      "median": 981.1949353466516,
      "p2.5": 966.4530048989777,
      "p97.5": 995.1767466561865,
      "rank": 59,
      "rank_p2.5": 53,
      "rank_p97.5": 68,
      "total_output_tokens": 1655945,
      "conso_all_conv": 8.563266942533334,
      "n_match": 1619,
      "mean_conso_per_match": 0.005289232206629607,
      "mean_conso_per_token": 5.171226666666667e-06,
      "mean_win_prob": 0.472093888599696,
      "win_rate": 0.51142063001853,
      "useful": 350,
      "creative": 85,
      "complete": 254,
      "clear_formatting": 230,
      "incorrect": 49,
      "superficial": 133,
      "instructions_not_followed": 28,
      "total_prefs": 1129,
      "positive_prefs_ratio": 0.8139946855624446
    },
    {
      "model_name": "gpt-4o-mini-2024-07-18",
      "median": 980.7354726807534,
      "p2.5": 972.8709479951109,
      "p97.5": 988.0706257697881,
      "rank": 60,
      "rank_p2.5": 56,
      "rank_p97.5": 65,
      "total_output_tokens": 5207480,
      "conso_all_conv": 26.929059442133333,
      "n_match": 6990,
      "mean_conso_per_match": 0.0038525120804196473,
      "mean_conso_per_token": 5.171226666666666e-06,
      "mean_win_prob": 0.47146039730615813,
      "win_rate": 0.49947067238912735,
      "useful": 1491,
      "creative": 319,
      "complete": 856,
      "clear_formatting": 1282,
      "incorrect": 369,
      "superficial": 599,
      "instructions_not_followed": 110,
      "total_prefs": 5026,
      "positive_prefs_ratio": 0.7855153203342619
    },
    {
      "model_name": "gpt-4.1-nano",
      "median": 976.8705571863431,
      "p2.5": 968.6731278138309,
      "p97.5": 985.1734089477778,
      "rank": 61,
      "rank_p2.5": 58,
      "rank_p97.5": 67,
      "total_output_tokens": 3563423,
      "conso_all_conv": 20.927662570929996,
      "n_match": 5717,
      "mean_conso_per_match": 0.003660602163884904,
      "mean_conso_per_token": 5.872909999999999e-06,
      "mean_win_prob": 0.466135820974965,
      "win_rate": 0.46743047052649994,
      "useful": 928,
      "creative": 159,
      "complete": 529,
      "clear_formatting": 649,
      "incorrect": 276,
      "superficial": 448,
      "instructions_not_followed": 103,
      "total_prefs": 3092,
      "positive_prefs_ratio": 0.732535575679172
    },
    {
      "model_name": "minimax-m2",
      "median": 975.5080188885627,
      "p2.5": 961.534723455124,
      "p97.5": 988.886103059413,
      "rank": 62,
      "rank_p2.5": 56,
      "rank_p97.5": 70,
      "total_output_tokens": 3604237,
      "conso_all_conv": 29.183747271466665,
      "n_match": 1992,
      "mean_conso_per_match": 0.014650475537884872,
      "mean_conso_per_token": 8.097066666666666e-06,
      "mean_win_prob": 0.4642606306819486,
      "win_rate": 0.432394578313253,
      "useful": 258,
      "creative": 61,
      "complete": 209,
      "clear_formatting": 153,
      "incorrect": 110,
      "superficial": 125,
      "instructions_not_followed": 62,
      "total_prefs": 978,
      "positive_prefs_ratio": 0.696319018404908
    },
    {
      "model_name": "Apertus-70B-Instruct-2509",
      "median": 975.4992669306093,
      "p2.5": 963.0184819712373,
      "p97.5": 987.3082901437551,
      "rank": 63,
      "rank_p2.5": 56,
      "rank_p97.5": 69,
      "total_output_tokens": 2173028,
      "conso_all_conv": 27.09490665786667,
      "n_match": 2227,
      "mean_conso_per_match": 0.012166549913725492,
      "mean_conso_per_token": 1.2468733333333335e-05,
      "mean_win_prob": 0.4642485892877616,
      "win_rate": 0.4106286484059273,
      "useful": 228,
      "creative": 42,
      "complete": 146,
      "clear_formatting": 134,
      "incorrect": 115,
      "superficial": 156,
      "instructions_not_followed": 68,
      "total_prefs": 889,
      "positive_prefs_ratio": 0.6186726659167604
    },
    {
      "model_name": "jamba-1.5-large",
      "median": 971.5645865192669,
      "p2.5": 924.2544112082371,
      "p97.5": 1013.6265688081879,
      "rank": 64,
      "rank_p2.5": 44,
      "rank_p97.5": 82,
      "total_output_tokens": 143976,
      "conso_all_conv": 6.840363109439998,
      "n_match": 172,
      "mean_conso_per_match": 0.03976955296186046,
      "mean_conso_per_token": 4.751043999999999e-05,
      "mean_win_prob": 0.45883980407650465,
      "win_rate": 0.5449418604651163,
      "useful": 44,
      "creative": 11,
      "complete": 18,
      "clear_formatting": 57,
      "incorrect": 15,
      "superficial": 13,
      "instructions_not_followed": 4,
      "total_prefs": 162,
      "positive_prefs_ratio": 0.8024691358024691
    },
    {
      "model_name": "aya-expanse-8b",
      "median": 971.1130919954544,
      "p2.5": 954.2375760343717,
      "p97.5": 986.7092301521647,
      "rank": 65,
      "rank_p2.5": 57,
      "rank_p97.5": 72,
      "total_output_tokens": 1057810,
      "conso_all_conv": 3.9856799865999997,
      "n_match": 1302,
      "mean_conso_per_match": 0.003061198146390169,
      "mean_conso_per_token": 3.7678599999999997e-06,
      "mean_win_prob": 0.4582197942019967,
      "win_rate": 0.5014285714285714,
      "useful": 243,
      "creative": 55,
      "complete": 133,
      "clear_formatting": 223,
      "incorrect": 149,
      "superficial": 104,
      "instructions_not_followed": 31,
      "total_prefs": 938,
      "positive_prefs_ratio": 0.697228144989339
    },
    {
      "model_name": "llama-3.1-70b",
      "median": 970.6859609901564,
      "p2.5": 962.3582155519568,
      "p97.5": 979.2611855393471,
      "rank": 66,
      "rank_p2.5": 62,
      "rank_p97.5": 69,
      "total_output_tokens": 4057254,
      "conso_all_conv": 50.588818191600005,
      "n_match": 5583,
      "mean_conso_per_match": 0.009061224823858141,
      "mean_conso_per_token": 1.2468733333333335e-05,
      "mean_win_prob": 0.4576333673006023,
      "win_rate": 0.530445996775927,
      "useful": 1532,
      "creative": 365,
      "complete": 1047,
      "clear_formatting": 1305,
      "incorrect": 463,
      "superficial": 621,
      "instructions_not_followed": 177,
      "total_prefs": 5510,
      "positive_prefs_ratio": 0.7711433756805808
    },
    {
      "model_name": "claude-3-5-sonnet-v2",
      "median": 970.1021387272456,
      "p2.5": 961.4238224854978,
      "p97.5": 978.764718880882,
      "rank": 67,
      "rank_p2.5": 62,
      "rank_p97.5": 70,
      "total_output_tokens": 3224219,
      "conso_all_conv": 282.07131509003995,
      "n_match": 5683,
      "mean_conso_per_match": 0.049634227536519436,
      "mean_conso_per_token": 8.748515999999998e-05,
      "mean_win_prob": 0.4568320130896421,
      "win_rate": 0.4921080415273623,
      "useful": 1301,
      "creative": 291,
      "complete": 721,
      "clear_formatting": 905,
      "incorrect": 250,
      "superficial": 606,
      "instructions_not_followed": 94,
      "total_prefs": 4168,
      "positive_prefs_ratio": 0.7720729366602687
    },
    {
      "model_name": "phi-4",
      "median": 965.7443850195498,
      "p2.5": 960.0861307564336,
      "p97.5": 971.8897592435981,
      "rank": 68,
      "rank_p2.5": 64,
      "rank_p97.5": 71,
      "total_output_tokens": 8226489,
      "conso_all_conv": 37.92312711132,
      "n_match": 9968,
      "mean_conso_per_match": 0.003804487069755217,
      "mean_conso_per_token": 4.60988e-06,
      "mean_win_prob": 0.45085826524679345,
      "win_rate": 0.46780074245008524,
      "useful": 1626,
      "creative": 336,
      "complete": 1193,
      "clear_formatting": 1311,
      "incorrect": 731,
      "superficial": 760,
      "instructions_not_followed": 253,
      "total_prefs": 6210,
      "positive_prefs_ratio": 0.7191626409017713
    },
    {
      "model_name": "ministral-8b-instruct-2410",
      "median": 961.7570132743169,
      "p2.5": 955.5463145774266,
      "p97.5": 968.074368911177,
      "rank": 69,
      "rank_p2.5": 66,
      "rank_p97.5": 73,
      "total_output_tokens": 7488476,
      "conso_all_conv": 28.215529181359997,
      "n_match": 9278,
      "mean_conso_per_match": 0.003041121920819142,
      "mean_conso_per_token": 3.7678599999999997e-06,
      "mean_win_prob": 0.4454050973891244,
      "win_rate": 0.47576819407008086,
      "useful": 1796,
      "creative": 412,
      "complete": 1332,
      "clear_formatting": 1695,
      "incorrect": 876,
      "superficial": 927,
      "instructions_not_followed": 274,
      "total_prefs": 7312,
      "positive_prefs_ratio": 0.7159463894967177
    },
    {
      "model_name": "gpt-4o-2024-08-06",
      "median": 960.8090804500569,
      "p2.5": 952.7468928215746,
      "p97.5": 969.974793725235,
      "rank": 70,
      "rank_p2.5": 66,
      "rank_p97.5": 73,
      "total_output_tokens": 3903917,
      "conso_all_conv": 341.53480337171993,
      "n_match": 5896,
      "mean_conso_per_match": 0.05792652703048167,
      "mean_conso_per_token": 8.748515999999998e-05,
      "mean_win_prob": 0.4441106393175794,
      "win_rate": 0.48863297150610585,
      "useful": 1230,
      "creative": 243,
      "complete": 593,
      "clear_formatting": 1002,
      "incorrect": 275,
      "superficial": 590,
      "instructions_not_followed": 115,
      "total_prefs": 4048,
      "positive_prefs_ratio": 0.7579051383399209
    },
    {
      "model_name": "qwen2.5-32b-instruct",
      "median": 958.9789870757877,
      "p2.5": 898.2407454309757,
      "p97.5": 1021.5299816098343,
      "rank": 71,
      "rank_p2.5": 41,
      "rank_p97.5": 83,
      "total_output_tokens": 75812,
      "conso_all_conv": 0.5409898832799999,
      "n_match": 142,
      "mean_conso_per_match": 0.003809787910422534,
      "mean_conso_per_token": 7.135939999999998e-06,
      "mean_win_prob": 0.4416137596215693,
      "win_rate": 0.5557042253521126,
      "useful": 52,
      "creative": 16,
      "complete": 43,
      "clear_formatting": 57,
      "incorrect": 13,
      "superficial": 21,
      "instructions_not_followed": 15,
      "total_prefs": 217,
      "positive_prefs_ratio": 0.7741935483870968
    },
    {
      "model_name": "Apertus-8B-Instruct-2509",
      "median": 958.4416183267942,
      "p2.5": 903.9195225718838,
      "p97.5": 1014.6674205452691,
      "rank": 72,
      "rank_p2.5": 45,
      "rank_p97.5": 83,
      "total_output_tokens": 52304,
      "conso_all_conv": 0.19707414943999998,
      "n_match": 86,
      "mean_conso_per_match": 0.002291559877209302,
      "mean_conso_per_token": 3.7678599999999997e-06,
      "mean_win_prob": 0.44088117180683034,
      "win_rate": 0.46880952380952384,
      "useful": 2,
      "creative": 0,
      "complete": 3,
      "clear_formatting": 2,
      "incorrect": 3,
      "superficial": 5,
      "instructions_not_followed": 0,
      "total_prefs": 15,
      "positive_prefs_ratio": 0.4666666666666667
    },
    {
      "model_name": "llama-3.1-405b",
      "median": 955.716943927588,
      "p2.5": 949.2188806516727,
      "p97.5": 962.0611079596499,
      "rank": 73,
      "rank_p2.5": 69,
      "rank_p97.5": 75,
      "total_output_tokens": 10383810,
      "conso_all_conv": 2470.579070314,
      "n_match": 9973,
      "mean_conso_per_match": 0.24772676930853305,
      "mean_conso_per_token": 0.00023792606666666667,
      "mean_win_prob": 0.4371707735244224,
      "win_rate": 0.4950747166783672,
      "useful": 2224,
      "creative": 556,
      "complete": 1579,
      "clear_formatting": 1788,
      "incorrect": 947,
      "superficial": 890,
      "instructions_not_followed": 437,
      "total_prefs": 8421,
      "positive_prefs_ratio": 0.7299608122550766
    },
    {
      "model_name": "gemma-2-9b-it",
      "median": 951.3142773929405,
      "p2.5": 942.5166748429302,
      "p97.5": 960.3991471690938,
      "rank": 74,
      "rank_p2.5": 70,
      "rank_p97.5": 76,
      "total_output_tokens": 3108609,
      "conso_all_conv": 12.149055331769999,
      "n_match": 5115,
      "mean_conso_per_match": 0.002375181883043988,
      "mean_conso_per_token": 3.908196666666666e-06,
      "mean_win_prob": 0.4311905949930325,
      "win_rate": 0.5068660801564027,
      "useful": 1250,
      "creative": 403,
      "complete": 771,
      "clear_formatting": 1197,
      "incorrect": 472,
      "superficial": 595,
      "instructions_not_followed": 177,
      "total_prefs": 4865,
      "positive_prefs_ratio": 0.7442959917780062
    },
    {
      "model_name": "qwq-32b",
      "median": 947.500661975615,
      "p2.5": 931.9426291996947,
      "p97.5": 963.0522855284704,
      "rank": 75,
      "rank_p2.5": 69,
      "rank_p97.5": 79,
      "total_output_tokens": 1895013,
      "conso_all_conv": 13.522699067219996,
      "n_match": 1566,
      "mean_conso_per_match": 0.008635184589540228,
      "mean_conso_per_token": 7.135939999999998e-06,
      "mean_win_prob": 0.4260268272929281,
      "win_rate": 0.4485997442455243,
      "useful": 291,
      "creative": 139,
      "complete": 343,
      "clear_formatting": 233,
      "incorrect": 140,
      "superficial": 105,
      "instructions_not_followed": 92,
      "total_prefs": 1343,
      "positive_prefs_ratio": 0.7490692479523455
    },
    {
      "model_name": "gpt-5-nano",
      "median": 945.3477894155928,
      "p2.5": 934.6680433969384,
      "p97.5": 955.8145927506911,
      "rank": 76,
      "rank_p2.5": 72,
      "rank_p97.5": 78,
      "total_output_tokens": 3498273,
      "conso_all_conv": 14.65381082151,
      "n_match": 3344,
      "mean_conso_per_match": 0.004382120460977871,
      "mean_conso_per_token": 4.18887e-06,
      "mean_win_prob": 0.4231188476790912,
      "win_rate": 0.3978708133971292,
      "useful": 271,
      "creative": 62,
      "complete": 255,
      "clear_formatting": 167,
      "incorrect": 130,
      "superficial": 165,
      "instructions_not_followed": 148,
      "total_prefs": 1198,
      "positive_prefs_ratio": 0.6302170283806344
    },
    {
      "model_name": "deepseek-r1-distill-llama-70b",
      "median": 944.184624458092,
      "p2.5": 933.9779286306643,
      "p97.5": 955.9196252980248,
      "rank": 77,
      "rank_p2.5": 72,
      "rank_p97.5": 79,
      "total_output_tokens": 2863519,
      "conso_all_conv": 35.70445480593334,
      "n_match": 2981,
      "mean_conso_per_match": 0.011977341431041039,
      "mean_conso_per_token": 1.2468733333333335e-05,
      "mean_win_prob": 0.42154991944242054,
      "win_rate": 0.4397953706809795,
      "useful": 489,
      "creative": 130,
      "complete": 355,
      "clear_formatting": 363,
      "incorrect": 190,
      "superficial": 342,
      "instructions_not_followed": 126,
      "total_prefs": 1995,
      "positive_prefs_ratio": 0.6701754385964912
    },
    {
      "model_name": "hermes-3-llama-3.1-405b",
      "median": 940.1245220856963,
      "p2.5": 932.0640847348748,
      "p97.5": 947.3607212330361,
      "rank": 78,
      "rank_p2.5": 74,
      "rank_p97.5": 80,
      "total_output_tokens": 4092822,
      "conso_all_conv": 973.7890400268,
      "n_match": 6735,
      "mean_conso_per_match": 0.144586345957951,
      "mean_conso_per_token": 0.00023792606666666667,
      "mean_win_prob": 0.416086088357126,
      "win_rate": 0.46634743875278395,
      "useful": 1450,
      "creative": 285,
      "complete": 830,
      "clear_formatting": 1109,
      "incorrect": 426,
      "superficial": 753,
      "instructions_not_followed": 184,
      "total_prefs": 5037,
      "positive_prefs_ratio": 0.7294024220766329
    },
    {
      "model_name": "hermes-4-70b",
      "median": 934.1904225753556,
      "p2.5": 923.475718836555,
      "p97.5": 946.4052353108669,
      "rank": 79,
      "rank_p2.5": 75,
      "rank_p97.5": 82,
      "total_output_tokens": 1398542,
      "conso_all_conv": 17.438047253466667,
      "n_match": 3038,
      "mean_conso_per_match": 0.005739976054465658,
      "mean_conso_per_token": 1.2468733333333333e-05,
      "mean_win_prob": 0.4081375648971059,
      "win_rate": 0.36948582729070534,
      "useful": 273,
      "creative": 54,
      "complete": 124,
      "clear_formatting": 167,
      "incorrect": 155,
      "superficial": 253,
      "instructions_not_followed": 102,
      "total_prefs": 1128,
      "positive_prefs_ratio": 0.5478723404255319
    },
    {
      "model_name": "llama-3.1-8b",
      "median": 931.9897986792737,
      "p2.5": 925.8030895506952,
      "p97.5": 938.503187466636,
      "rank": 80,
      "rank_p2.5": 77,
      "rank_p97.5": 82,
      "total_output_tokens": 7372632,
      "conso_all_conv": 27.779045207519996,
      "n_match": 10444,
      "mean_conso_per_match": 0.002659809001103025,
      "mean_conso_per_token": 3.7678599999999993e-06,
      "mean_win_prob": 0.4052017688864367,
      "win_rate": 0.4424234009957871,
      "useful": 1540,
      "creative": 373,
      "complete": 1014,
      "clear_formatting": 1159,
      "incorrect": 1043,
      "superficial": 978,
      "instructions_not_followed": 404,
      "total_prefs": 6511,
      "positive_prefs_ratio": 0.6275533712179389
    },
    {
      "model_name": "c4ai-command-r-08-2024",
      "median": 927.777312903736,
      "p2.5": 919.4977227037333,
      "p97.5": 936.0539946479241,
      "rank": 81,
      "rank_p2.5": 78,
      "rank_p97.5": 83,
      "total_output_tokens": 4319206,
      "conso_all_conv": 32.640023781699995,
      "n_match": 5959,
      "mean_conso_per_match": 0.005477433089729819,
      "mean_conso_per_token": 7.556949999999999e-06,
      "mean_win_prob": 0.39960085178925336,
      "win_rate": 0.42968786709179396,
      "useful": 1075,
      "creative": 255,
      "complete": 843,
      "clear_formatting": 796,
      "incorrect": 471,
      "superficial": 660,
      "instructions_not_followed": 163,
      "total_prefs": 4263,
      "positive_prefs_ratio": 0.6964578935022285
    },
    {
      "model_name": "qwen2.5-7b-instruct",
      "median": 925.0976894506989,
      "p2.5": 906.7603360859058,
      "p97.5": 942.2312645972773,
      "rank": 82,
      "rank_p2.5": 76,
      "rank_p97.5": 83,
      "total_output_tokens": 1186919,
      "conso_all_conv": 4.305576367276667,
      "n_match": 1417,
      "mean_conso_per_match": 0.0030385154320936255,
      "mean_conso_per_token": 3.6275233333333336e-06,
      "mean_win_prob": 0.3960513840154857,
      "win_rate": 0.49383909668313336,
      "useful": 402,
      "creative": 104,
      "complete": 284,
      "clear_formatting": 380,
      "incorrect": 231,
      "superficial": 203,
      "instructions_not_followed": 88,
      "total_prefs": 1692,
      "positive_prefs_ratio": 0.6914893617021277
    },
    {
      "model_name": "qwen2.5-coder-32b-instruct",
      "median": 924.4192564287723,
      "p2.5": 917.5744251609516,
      "p97.5": 932.324643411939,
      "rank": 83,
      "rank_p2.5": 79,
      "rank_p97.5": 83,
      "total_output_tokens": 6149486,
      "conso_all_conv": 43.882363126839984,
      "n_match": 7299,
      "mean_conso_per_match": 0.006012106196306341,
      "mean_conso_per_token": 7.1359399999999974e-06,
      "mean_win_prob": 0.39515441720401645,
      "win_rate": 0.43789423208658723,
      "useful": 1379,
      "creative": 293,
      "complete": 923,
      "clear_formatting": 1142,
      "incorrect": 790,
      "superficial": 742,
      "instructions_not_followed": 234,
      "total_prefs": 5503,
      "positive_prefs_ratio": 0.6790841359258586
    },
    {
      "model_name": "mixtral-8x7b-instruct-v0.1",
      "median": 883.0656986464123,
      "p2.5": 870.6414073202596,
      "p97.5": 896.0995052186839,
      "rank": 84,
      "rank_p2.5": 84,
      "rank_p97.5": 86,
      "total_output_tokens": 1575791,
      "conso_all_conv": 7.2642074150800005,
      "n_match": 2560,
      "mean_conso_per_match": 0.0028375810215156253,
      "mean_conso_per_token": 4.60988e-06,
      "mean_win_prob": 0.3419748267041058,
      "win_rate": 0.43488671874999996,
      "useful": 727,
      "creative": 164,
      "complete": 375,
      "clear_formatting": 503,
      "incorrect": 256,
      "superficial": 389,
      "instructions_not_followed": 159,
      "total_prefs": 2573,
      "positive_prefs_ratio": 0.687524290711232
    },
    {
      "model_name": "lfm-40b",
      "median": 879.9864976322983,
      "p2.5": 869.3385460567808,
      "p97.5": 891.2464858169906,
      "rank": 85,
      "rank_p2.5": 84,
      "rank_p97.5": 86,
      "total_output_tokens": 2000824,
      "conso_all_conv": 8.661980599626665,
      "n_match": 3578,
      "mean_conso_per_match": 0.0024209001116899565,
      "mean_conso_per_token": 4.329206666666666e-06,
      "mean_win_prob": 0.33814755590519974,
      "win_rate": 0.416296813862493,
      "useful": 841,
      "creative": 166,
      "complete": 419,
      "clear_formatting": 647,
      "incorrect": 357,
      "superficial": 572,
      "instructions_not_followed": 121,
      "total_prefs": 3123,
      "positive_prefs_ratio": 0.6637848222862632
    },
    {
      "model_name": "olmo-3-32b-think",
      "median": 872.4734796486587,
      "p2.5": 853.6473707281698,
      "p97.5": 892.647496416323,
      "rank": 86,
      "rank_p2.5": 84,
      "rank_p97.5": 87,
      "total_output_tokens": 2330995,
      "conso_all_conv": 16.633840460299993,
      "n_match": 994,
      "mean_conso_per_match": 0.016734245935915486,
      "mean_conso_per_token": 7.135939999999997e-06,
      "mean_win_prob": 0.3288954531461895,
      "win_rate": 0.3467907444668008,
      "useful": 98,
      "creative": 29,
      "complete": 83,
      "clear_formatting": 48,
      "incorrect": 95,
      "superficial": 82,
      "instructions_not_followed": 85,
      "total_prefs": 520,
      "positive_prefs_ratio": 0.49615384615384617
    },
    {
      "model_name": "phi-3.5-mini-instruct",
      "median": 859.619874532005,
      "p2.5": 845.7517625422477,
      "p97.5": 873.0213197788177,
      "rank": 87,
      "rank_p2.5": 86,
      "rank_p97.5": 88,
      "total_output_tokens": 2149046,
      "conso_all_conv": 6.589354700793333,
      "n_match": 2535,
      "mean_conso_per_match": 0.0025993509667823797,
      "mean_conso_per_token": 3.0661766666666664e-06,
      "mean_win_prob": 0.3133617512274764,
      "win_rate": 0.4021104536489152,
      "useful": 636,
      "creative": 226,
      "complete": 477,
      "clear_formatting": 533,
      "incorrect": 428,
      "superficial": 449,
      "instructions_not_followed": 300,
      "total_prefs": 3049,
      "positive_prefs_ratio": 0.6139717940308298
    },
    {
      "model_name": "mistral-nemo-2407",
      "median": 850.2121964399659,
      "p2.5": 841.6922955219943,
      "p97.5": 858.3266432205286,
      "rank": 88,
      "rank_p2.5": 87,
      "rank_p97.5": 89,
      "total_output_tokens": 3305342,
      "conso_all_conv": 14.30950862201333,
      "n_match": 6251,
      "mean_conso_per_match": 0.0022891551147037805,
      "mean_conso_per_token": 4.329206666666666e-06,
      "mean_win_prob": 0.3022397561809575,
      "win_rate": 0.37482482802751566,
      "useful": 1413,
      "creative": 225,
      "complete": 661,
      "clear_formatting": 900,
      "incorrect": 638,
      "superficial": 1088,
      "instructions_not_followed": 292,
      "total_prefs": 5217,
      "positive_prefs_ratio": 0.6131876557408472
    },
    {
      "model_name": "mixtral-8x22b-instruct-v0.1",
      "median": 839.8389375378208,
      "p2.5": 829.6537414294743,
      "p97.5": 848.4793113745809,
      "rank": 89,
      "rank_p2.5": 88,
      "rank_p97.5": 90,
      "total_output_tokens": 3041056,
      "conso_all_conv": 53.644106197759996,
      "n_match": 5455,
      "mean_conso_per_match": 0.009833933308480293,
      "mean_conso_per_token": 1.7639959999999998e-05,
      "mean_win_prob": 0.2902292446405549,
      "win_rate": 0.36710357470210814,
      "useful": 1117,
      "creative": 203,
      "complete": 516,
      "clear_formatting": 702,
      "incorrect": 535,
      "superficial": 934,
      "instructions_not_followed": 276,
      "total_prefs": 4283,
      "positive_prefs_ratio": 0.5925752976885361
    },
    {
      "model_name": "chocolatine-2-14b-instruct-v2.0.3-q8",
      "median": 816.8677985893993,
      "p2.5": 799.8761881727602,
      "p97.5": 833.2829771124457,
      "rank": 90,
      "rank_p2.5": 90,
      "rank_p97.5": 91,
      "total_output_tokens": 533384,
      "conso_all_conv": 1.9348629056266669,
      "n_match": 1796,
      "mean_conso_per_match": 0.0010773178761841128,
      "mean_conso_per_token": 3.6275233333333336e-06,
      "mean_win_prob": 0.2646214642043346,
      "win_rate": 0.3317316258351893,
      "useful": 280,
      "creative": 37,
      "complete": 100,
      "clear_formatting": 199,
      "incorrect": 161,
      "superficial": 370,
      "instructions_not_followed": 50,
      "total_prefs": 1197,
      "positive_prefs_ratio": 0.5146198830409356
    },
    {
      "model_name": "Yi-1.5-9B-Chat",
      "median": 764.1705277778625,
      "p2.5": 664.4480567309652,
      "p97.5": 850.3967137388739,
      "rank": 91,
      "rank_p2.5": 88,
      "rank_p97.5": 93,
      "total_output_tokens": 47531,
      "conso_all_conv": 0.1857604957633333,
      "n_match": 65,
      "mean_conso_per_match": 0.0028578537809743586,
      "mean_conso_per_token": 3.908196666666666e-06,
      "mean_win_prob": 0.21134908039900374,
      "win_rate": 0.32599999999999996,
      "useful": 16,
      "creative": 5,
      "complete": 14,
      "clear_formatting": 19,
      "incorrect": 12,
      "superficial": 17,
      "instructions_not_followed": 14,
      "total_prefs": 97,
      "positive_prefs_ratio": 0.5567010309278351
    },
    {
      "model_name": "chocolatine-14b-instruct-dpo-v1.2-q4",
      "median": 746.9049982075096,
      "p2.5": 703.0127997775492,
      "p97.5": 789.018635604388,
      "rank": 92,
      "rank_p2.5": 91,
      "rank_p97.5": 93,
      "total_output_tokens": 131187,
      "conso_all_conv": 0.6047563275600001,
      "n_match": 309,
      "mean_conso_per_match": 0.001957140218640777,
      "mean_conso_per_token": 4.609880000000001e-06,
      "mean_win_prob": 0.19561217453551033,
      "win_rate": 0.2402265372168285,
      "useful": 83,
      "creative": 17,
      "complete": 39,
      "clear_formatting": 43,
      "incorrect": 52,
      "superficial": 107,
      "instructions_not_followed": 50,
      "total_prefs": 391,
      "positive_prefs_ratio": 0.46547314578005117
    },
    {
      "model_name": "qwen2-7b-instruct",
      "median": 726.5978410991387,
      "p2.5": 626.5259324850103,
      "p97.5": 806.0570798140373,
      "rank": 93,
      "rank_p2.5": 91,
      "rank_p97.5": 93,
      "total_output_tokens": 43550,
      "conso_all_conv": 0.15797864116666668,
      "n_match": 80,
      "mean_conso_per_match": 0.0019747330145833335,
      "mean_conso_per_token": 3.6275233333333336e-06,
      "mean_win_prob": 0.17819468156096058,
      "win_rate": 0.2525,
      "useful": 19,
      "creative": 4,
      "complete": 12,
      "clear_formatting": 22,
      "incorrect": 11,
      "superficial": 14,
      "instructions_not_followed": 7,
      "total_prefs": 89,
      "positive_prefs_ratio": 0.6404494382022472
    }
  ]
}
