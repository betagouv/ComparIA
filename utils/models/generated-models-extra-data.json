{
  "timestamp": 1762944889.727227,
  "models": [
    {
      "model_name": "mistral-medium-3.1",
      "median": 1153.6133964033788,
      "p2.5": 1137.4117137791848,
      "p97.5": 1169.9454392640728,
      "rank": 1,
      "rank_p2.5": 1,
      "rank_p97.5": 1,
      "total_output_tokens": 2313992,
      "conso_all_conv": 0.0,
      "n_match": 1264,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.7005585291739652,
      "win_rate": 0.6228028503562946,
      "useful": 66,
      "creative": 27,
      "complete": 109,
      "clear_formatting": 77,
      "incorrect": 24,
      "superficial": 8,
      "instructions_not_followed": 6,
      "total_prefs": 317,
      "positive_prefs_ratio": 0.8801261829652997
    },
    {
      "model_name": "gemini-2.5-flash",
      "median": 1119.3789280248275,
      "p2.5": 1106.0772201607408,
      "p97.5": 1132.5360291512152,
      "rank": 2,
      "rank_p2.5": 2,
      "rank_p97.5": 4,
      "total_output_tokens": 2535895,
      "conso_all_conv": 0.0,
      "n_match": 1748,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.6586519548465487,
      "win_rate": 0.600308924485126,
      "useful": 155,
      "creative": 55,
      "complete": 205,
      "clear_formatting": 143,
      "incorrect": 45,
      "superficial": 29,
      "instructions_not_followed": 10,
      "total_prefs": 642,
      "positive_prefs_ratio": 0.8691588785046729
    },
    {
      "model_name": "qwen3-max-2025-09-23",
      "median": 1108.77210798943,
      "p2.5": 1086.7126750688267,
      "p97.5": 1131.6478238571033,
      "rank": 3,
      "rank_p2.5": 2,
      "rank_p97.5": 9,
      "total_output_tokens": 820050,
      "conso_all_conv": 0.0,
      "n_match": 740,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.6451536656307086,
      "win_rate": 0.5900811907983762,
      "useful": 42,
      "creative": 11,
      "complete": 52,
      "clear_formatting": 37,
      "incorrect": 25,
      "superficial": 5,
      "instructions_not_followed": 7,
      "total_prefs": 179,
      "positive_prefs_ratio": 0.7932960893854749
    },
    {
      "model_name": "gemini-2.0-flash",
      "median": 1106.975745159955,
      "p2.5": 1099.8451615257077,
      "p97.5": 1114.4424260725705,
      "rank": 4,
      "rank_p2.5": 2,
      "rank_p97.5": 6,
      "total_output_tokens": 12296785,
      "conso_all_conv": 0.0,
      "n_match": 8684,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.6428458782062819,
      "win_rate": 0.6317699216950714,
      "useful": 2128,
      "creative": 677,
      "complete": 2179,
      "clear_formatting": 1909,
      "incorrect": 376,
      "superficial": 397,
      "instructions_not_followed": 112,
      "total_prefs": 7778,
      "positive_prefs_ratio": 0.8862175366418102
    },
    {
      "model_name": "deepseek-v3-0324",
      "median": 1099.3717047608748,
      "p2.5": 1090.786215656465,
      "p97.5": 1108.7842267861615,
      "rank": 5,
      "rank_p2.5": 3,
      "rank_p97.5": 9,
      "total_output_tokens": 4435392,
      "conso_all_conv": 0.0,
      "n_match": 4385,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.6330108431033353,
      "win_rate": 0.5851128848346637,
      "useful": 1141,
      "creative": 336,
      "complete": 1012,
      "clear_formatting": 1043,
      "incorrect": 230,
      "superficial": 288,
      "instructions_not_followed": 79,
      "total_prefs": 4129,
      "positive_prefs_ratio": 0.8554129329135384
    },
    {
      "model_name": "gemma-3-27b",
      "median": 1095.7616256790739,
      "p2.5": 1087.2285008015888,
      "p97.5": 1103.877413937186,
      "rank": 6,
      "rank_p2.5": 4,
      "rank_p97.5": 11,
      "total_output_tokens": 7969475,
      "conso_all_conv": 0.0,
      "n_match": 5792,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.6283054990422692,
      "win_rate": 0.5873411602209945,
      "useful": 1189,
      "creative": 400,
      "complete": 1366,
      "clear_formatting": 1008,
      "incorrect": 300,
      "superficial": 207,
      "instructions_not_followed": 99,
      "total_prefs": 4569,
      "positive_prefs_ratio": 0.8673670387393303
    },
    {
      "model_name": "gpt-oss-120b",
      "median": 1094.2688598731306,
      "p2.5": 1075.3032869688916,
      "p97.5": 1115.2153084999197,
      "rank": 7,
      "rank_p2.5": 3,
      "rank_p97.5": 15,
      "total_output_tokens": 1810874,
      "conso_all_conv": 0.0,
      "n_match": 795,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.6263533090720176,
      "win_rate": 0.5760984848484848,
      "useful": 105,
      "creative": 46,
      "complete": 162,
      "clear_formatting": 110,
      "incorrect": 44,
      "superficial": 23,
      "instructions_not_followed": 23,
      "total_prefs": 513,
      "positive_prefs_ratio": 0.8245614035087719
    },
    {
      "model_name": "magistral-medium",
      "median": 1088.5269698662275,
      "p2.5": 1072.5427304386144,
      "p97.5": 1104.5006424815442,
      "rank": 8,
      "rank_p2.5": 5,
      "rank_p97.5": 16,
      "total_output_tokens": 1174811,
      "conso_all_conv": 0.0,
      "n_match": 1200,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.6188098527317161,
      "win_rate": 0.5756583333333333,
      "useful": 71,
      "creative": 20,
      "complete": 74,
      "clear_formatting": 43,
      "incorrect": 31,
      "superficial": 16,
      "instructions_not_followed": 2,
      "total_prefs": 257,
      "positive_prefs_ratio": 0.8093385214007782
    },
    {
      "model_name": "mistral-medium-2508",
      "median": 1086.6218329904666,
      "p2.5": 1065.77471330478,
      "p97.5": 1108.0015165186849,
      "rank": 9,
      "rank_p2.5": 4,
      "rank_p97.5": 19,
      "total_output_tokens": 641804,
      "conso_all_conv": 0.0,
      "n_match": 695,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.6162952657670098,
      "win_rate": 0.5731168831168831,
      "useful": 62,
      "creative": 9,
      "complete": 40,
      "clear_formatting": 38,
      "incorrect": 21,
      "superficial": 8,
      "instructions_not_followed": 4,
      "total_prefs": 182,
      "positive_prefs_ratio": 0.8186813186813187
    },
    {
      "model_name": "deepseek-chat-v3.1",
      "median": 1086.4806180367768,
      "p2.5": 1064.0123483387047,
      "p97.5": 1107.5232996794223,
      "rank": 10,
      "rank_p2.5": 4,
      "rank_p97.5": 20,
      "total_output_tokens": 957319,
      "conso_all_conv": 0.0,
      "n_match": 618,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.6161086506481478,
      "win_rate": 0.49267100977198697,
      "useful": 46,
      "creative": 22,
      "complete": 48,
      "clear_formatting": 33,
      "incorrect": 16,
      "superficial": 12,
      "instructions_not_followed": 7,
      "total_prefs": 184,
      "positive_prefs_ratio": 0.8097826086956522
    },
    {
      "model_name": "deepseek-v3-chat",
      "median": 1084.8922679255409,
      "p2.5": 1076.3920574475314,
      "p97.5": 1094.338116735882,
      "rank": 11,
      "rank_p2.5": 7,
      "rank_p97.5": 15,
      "total_output_tokens": 5638296,
      "conso_all_conv": 0.0,
      "n_match": 5388,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.6140075331515226,
      "win_rate": 0.6141481069042316,
      "useful": 1330,
      "creative": 390,
      "complete": 1245,
      "clear_formatting": 1399,
      "incorrect": 314,
      "superficial": 285,
      "instructions_not_followed": 81,
      "total_prefs": 5044,
      "positive_prefs_ratio": 0.8651863600317209
    },
    {
      "model_name": "deepseek-r1-0528",
      "median": 1083.2951858058493,
      "p2.5": 1062.0456412749559,
      "p97.5": 1107.9834243316297,
      "rank": 12,
      "rank_p2.5": 4,
      "rank_p97.5": 21,
      "total_output_tokens": 810952,
      "conso_all_conv": 0.0,
      "n_match": 483,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.6118909908462874,
      "win_rate": 0.5522869022869024,
      "useful": 26,
      "creative": 11,
      "complete": 26,
      "clear_formatting": 13,
      "incorrect": 6,
      "superficial": 3,
      "instructions_not_followed": 1,
      "total_prefs": 86,
      "positive_prefs_ratio": 0.8837209302325582
    },
    {
      "model_name": "glm-4.5",
      "median": 1080.3750575068093,
      "p2.5": 1058.6839038955372,
      "p97.5": 1102.7855473631985,
      "rank": 13,
      "rank_p2.5": 5,
      "rank_p97.5": 22,
      "total_output_tokens": 1675737,
      "conso_all_conv": 0.0,
      "n_match": 723,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.6080112600081283,
      "win_rate": 0.5749584487534626,
      "useful": 85,
      "creative": 26,
      "complete": 83,
      "clear_formatting": 68,
      "incorrect": 18,
      "superficial": 11,
      "instructions_not_followed": 7,
      "total_prefs": 298,
      "positive_prefs_ratio": 0.8791946308724832
    },
    {
      "model_name": "claude-4-5-sonnet",
      "median": 1078.0604697604495,
      "p2.5": 1065.0848282666764,
      "p97.5": 1093.102085162741,
      "rank": 14,
      "rank_p2.5": 8,
      "rank_p97.5": 20,
      "total_output_tokens": 2108477,
      "conso_all_conv": 0.0,
      "n_match": 1707,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.60492728487588,
      "win_rate": 0.5386174575278265,
      "useful": 130,
      "creative": 30,
      "complete": 90,
      "clear_formatting": 73,
      "incorrect": 24,
      "superficial": 19,
      "instructions_not_followed": 14,
      "total_prefs": 380,
      "positive_prefs_ratio": 0.85
    },
    {
      "model_name": "gemma-3-12b",
      "median": 1075.154146122644,
      "p2.5": 1066.6210790210837,
      "p97.5": 1083.5145629604676,
      "rank": 15,
      "rank_p2.5": 11,
      "rank_p97.5": 19,
      "total_output_tokens": 7228796,
      "conso_all_conv": 0.0,
      "n_match": 5440,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.6010442463977742,
      "win_rate": 0.5728308823529411,
      "useful": 996,
      "creative": 298,
      "complete": 1164,
      "clear_formatting": 851,
      "incorrect": 322,
      "superficial": 249,
      "instructions_not_followed": 136,
      "total_prefs": 4016,
      "positive_prefs_ratio": 0.8239541832669323
    },
    {
      "model_name": "mistral-small-2506",
      "median": 1073.2145562905703,
      "p2.5": 1060.2494242310934,
      "p97.5": 1088.1821285491276,
      "rank": 16,
      "rank_p2.5": 10,
      "rank_p97.5": 21,
      "total_output_tokens": 1226525,
      "conso_all_conv": 0.0,
      "n_match": 1511,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.5984464413569088,
      "win_rate": 0.5501125082726671,
      "useful": 77,
      "creative": 25,
      "complete": 85,
      "clear_formatting": 61,
      "incorrect": 46,
      "superficial": 25,
      "instructions_not_followed": 5,
      "total_prefs": 324,
      "positive_prefs_ratio": 0.7654320987654321
    },
    {
      "model_name": "grok-3-mini-beta",
      "median": 1072.1382771564365,
      "p2.5": 1057.5458824861075,
      "p97.5": 1086.5035525707904,
      "rank": 17,
      "rank_p2.5": 10,
      "rank_p97.5": 23,
      "total_output_tokens": 3474752,
      "conso_all_conv": 0.0,
      "n_match": 1537,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.5970027700160891,
      "win_rate": 0.5305338541666667,
      "useful": 404,
      "creative": 102,
      "complete": 350,
      "clear_formatting": 320,
      "incorrect": 102,
      "superficial": 106,
      "instructions_not_followed": 47,
      "total_prefs": 1431,
      "positive_prefs_ratio": 0.8218029350104822
    },
    {
      "model_name": "kimi-k2",
      "median": 1069.8206370327878,
      "p2.5": 1043.4172561503256,
      "p97.5": 1098.925972289589,
      "rank": 18,
      "rank_p2.5": 7,
      "rank_p97.5": 27,
      "total_output_tokens": 649399,
      "conso_all_conv": 0.0,
      "n_match": 388,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.5938889135732601,
      "win_rate": 0.5255584415584416,
      "useful": 95,
      "creative": 16,
      "complete": 43,
      "clear_formatting": 35,
      "incorrect": 17,
      "superficial": 22,
      "instructions_not_followed": 1,
      "total_prefs": 229,
      "positive_prefs_ratio": 0.8253275109170306
    },
    {
      "model_name": "claude-4-sonnet",
      "median": 1065.6869973941075,
      "p2.5": 1052.3020271939183,
      "p97.5": 1079.696697847871,
      "rank": 19,
      "rank_p2.5": 13,
      "rank_p97.5": 24,
      "total_output_tokens": 1444221,
      "conso_all_conv": 0.0,
      "n_match": 1843,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.5883185595675812,
      "win_rate": 0.5314983713355049,
      "useful": 176,
      "creative": 48,
      "complete": 159,
      "clear_formatting": 171,
      "incorrect": 32,
      "superficial": 48,
      "instructions_not_followed": 15,
      "total_prefs": 649,
      "positive_prefs_ratio": 0.8536209553158706
    },
    {
      "model_name": "command-a",
      "median": 1064.9970306037299,
      "p2.5": 1056.904255801746,
      "p97.5": 1072.887742495351,
      "rank": 20,
      "rank_p2.5": 15,
      "rank_p97.5": 23,
      "total_output_tokens": 5366757,
      "conso_all_conv": 0.0,
      "n_match": 5402,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.5873867817195165,
      "win_rate": 0.5611181044057756,
      "useful": 1111,
      "creative": 256,
      "complete": 1024,
      "clear_formatting": 957,
      "incorrect": 252,
      "superficial": 274,
      "instructions_not_followed": 95,
      "total_prefs": 3969,
      "positive_prefs_ratio": 0.8435374149659864
    },
    {
      "model_name": "grok-4-fast",
      "median": 1062.4285099879755,
      "p2.5": 1046.8041810601064,
      "p97.5": 1078.9075815255383,
      "rank": 21,
      "rank_p2.5": 14,
      "rank_p97.5": 26,
      "total_output_tokens": 1757378,
      "conso_all_conv": 0.0,
      "n_match": 1237,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.5839132332639216,
      "win_rate": 0.5286407766990291,
      "useful": 88,
      "creative": 14,
      "complete": 56,
      "clear_formatting": 41,
      "incorrect": 22,
      "superficial": 16,
      "instructions_not_followed": 4,
      "total_prefs": 241,
      "positive_prefs_ratio": 0.8257261410788381
    },
    {
      "model_name": "magistral-small-2506",
      "median": 1057.7967915839736,
      "p2.5": 1043.986288157268,
      "p97.5": 1071.1956168584468,
      "rank": 22,
      "rank_p2.5": 17,
      "rank_p97.5": 27,
      "total_output_tokens": 1460656,
      "conso_all_conv": 0.0,
      "n_match": 1844,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.5776310224473579,
      "win_rate": 0.526950623982637,
      "useful": 171,
      "creative": 32,
      "complete": 128,
      "clear_formatting": 112,
      "incorrect": 49,
      "superficial": 44,
      "instructions_not_followed": 17,
      "total_prefs": 553,
      "positive_prefs_ratio": 0.8010849909584087
    },
    {
      "model_name": "claude-3-7-sonnet",
      "median": 1056.1850756945407,
      "p2.5": 1046.8488630337554,
      "p97.5": 1066.1983371651597,
      "rank": 23,
      "rank_p2.5": 19,
      "rank_p97.5": 26,
      "total_output_tokens": 3546728,
      "conso_all_conv": 0.0,
      "n_match": 3907,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.575439676209234,
      "win_rate": 0.524225748656258,
      "useful": 1003,
      "creative": 230,
      "complete": 774,
      "clear_formatting": 822,
      "incorrect": 140,
      "superficial": 318,
      "instructions_not_followed": 46,
      "total_prefs": 3333,
      "positive_prefs_ratio": 0.8487848784878488
    },
    {
      "model_name": "llama-3.1-nemotron-70b-instruct",
      "median": 1050.9484001945336,
      "p2.5": 1043.0789537636774,
      "p97.5": 1058.9760171617377,
      "rank": 24,
      "rank_p2.5": 21,
      "rank_p97.5": 28,
      "total_output_tokens": 7426282,
      "conso_all_conv": 0.0,
      "n_match": 6709,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.5683021035431755,
      "win_rate": 0.5452863107664778,
      "useful": 1544,
      "creative": 487,
      "complete": 1473,
      "clear_formatting": 1431,
      "incorrect": 381,
      "superficial": 395,
      "instructions_not_followed": 136,
      "total_prefs": 5847,
      "positive_prefs_ratio": 0.8440225756798359
    },
    {
      "model_name": "Qwen3-Coder-480B-A35B-Instruct",
      "median": 1048.4739284357893,
      "p2.5": 1011.9295477501978,
      "p97.5": 1084.9259622150014,
      "rank": 25,
      "rank_p2.5": 12,
      "rank_p97.5": 40,
      "total_output_tokens": 311678,
      "conso_all_conv": 0.0,
      "n_match": 213,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.56492060547074,
      "win_rate": 0.5093809523809524,
      "useful": 16,
      "creative": 7,
      "complete": 12,
      "clear_formatting": 12,
      "incorrect": 9,
      "superficial": 5,
      "instructions_not_followed": 1,
      "total_prefs": 62,
      "positive_prefs_ratio": 0.7580645161290323
    },
    {
      "model_name": "gemma-3-4b",
      "median": 1047.1627306003886,
      "p2.5": 1038.515089253455,
      "p97.5": 1054.4674581758902,
      "rank": 26,
      "rank_p2.5": 23,
      "rank_p97.5": 29,
      "total_output_tokens": 8022690,
      "conso_all_conv": 0.0,
      "n_match": 6393,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.5631266371679466,
      "win_rate": 0.5265165024245269,
      "useful": 1064,
      "creative": 323,
      "complete": 1183,
      "clear_formatting": 939,
      "incorrect": 516,
      "superficial": 233,
      "instructions_not_followed": 176,
      "total_prefs": 4434,
      "positive_prefs_ratio": 0.7913847541723049
    },
    {
      "model_name": "qwen3-32b",
      "median": 1045.1282001379018,
      "p2.5": 1027.8134383753063,
      "p97.5": 1063.2900574008822,
      "rank": 27,
      "rank_p2.5": 20,
      "rank_p97.5": 33,
      "total_output_tokens": 1934836,
      "conso_all_conv": 0.0,
      "n_match": 921,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.5603401962084207,
      "win_rate": 0.5512758996728462,
      "useful": 249,
      "creative": 61,
      "complete": 200,
      "clear_formatting": 169,
      "incorrect": 87,
      "superficial": 66,
      "instructions_not_followed": 36,
      "total_prefs": 868,
      "positive_prefs_ratio": 0.782258064516129
    },
    {
      "model_name": "glm-4.6",
      "median": 1044.9683482732614,
      "p2.5": 1021.4499683336971,
      "p97.5": 1070.0666818232035,
      "rank": 28,
      "rank_p2.5": 18,
      "rank_p97.5": 35,
      "total_output_tokens": 1517275,
      "conso_all_conv": 0.0,
      "n_match": 554,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.5601211260360722,
      "win_rate": 0.5415398550724638,
      "useful": 44,
      "creative": 14,
      "complete": 52,
      "clear_formatting": 27,
      "incorrect": 7,
      "superficial": 5,
      "instructions_not_followed": 3,
      "total_prefs": 152,
      "positive_prefs_ratio": 0.9013157894736842
    },
    {
      "model_name": "gpt-4.1-mini",
      "median": 1038.75020909779,
      "p2.5": 1031.1294333887024,
      "p97.5": 1046.0169639517906,
      "rank": 29,
      "rank_p2.5": 26,
      "rank_p97.5": 32,
      "total_output_tokens": 5263656,
      "conso_all_conv": 0.0,
      "n_match": 6635,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.5515845550136748,
      "win_rate": 0.5160033167495854,
      "useful": 1195,
      "creative": 277,
      "complete": 907,
      "clear_formatting": 981,
      "incorrect": 237,
      "superficial": 448,
      "instructions_not_followed": 95,
      "total_prefs": 4140,
      "positive_prefs_ratio": 0.8115942028985508
    },
    {
      "model_name": "gemini-1.5-pro",
      "median": 1036.6285079589875,
      "p2.5": 1028.7255195427435,
      "p97.5": 1044.9057443847944,
      "rank": 30,
      "rank_p2.5": 26,
      "rank_p97.5": 33,
      "total_output_tokens": 6034223,
      "conso_all_conv": 0.0,
      "n_match": 7387,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.5486656307390791,
      "win_rate": 0.5830743197509137,
      "useful": 2118,
      "creative": 683,
      "complete": 1630,
      "clear_formatting": 1959,
      "incorrect": 461,
      "superficial": 655,
      "instructions_not_followed": 202,
      "total_prefs": 7708,
      "positive_prefs_ratio": 0.8290088220031137
    },
    {
      "model_name": "gpt-oss-20b",
      "median": 1033.841186537096,
      "p2.5": 1017.8440581812717,
      "p97.5": 1050.2238926594903,
      "rank": 31,
      "rank_p2.5": 25,
      "rank_p97.5": 37,
      "total_output_tokens": 1519110,
      "conso_all_conv": 0.0,
      "n_match": 1130,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.5448267259460922,
      "win_rate": 0.5040070921985815,
      "useful": 77,
      "creative": 33,
      "complete": 101,
      "clear_formatting": 94,
      "incorrect": 22,
      "superficial": 32,
      "instructions_not_followed": 21,
      "total_prefs": 380,
      "positive_prefs_ratio": 0.8026315789473685
    },
    {
      "model_name": "deepseek-r1",
      "median": 1033.8408386855235,
      "p2.5": 1023.8836982794687,
      "p97.5": 1044.045327490546,
      "rank": 32,
      "rank_p2.5": 27,
      "rank_p97.5": 35,
      "total_output_tokens": 3693582,
      "conso_all_conv": 0.0,
      "n_match": 3510,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.5448262465733126,
      "win_rate": 0.5313019943019943,
      "useful": 826,
      "creative": 284,
      "complete": 783,
      "clear_formatting": 667,
      "incorrect": 171,
      "superficial": 207,
      "instructions_not_followed": 112,
      "total_prefs": 3050,
      "positive_prefs_ratio": 0.839344262295082
    },
    {
      "model_name": "gemma-3n-e4b-it",
      "median": 1028.7352425089848,
      "p2.5": 1014.3906188854103,
      "p97.5": 1041.7920580843193,
      "rank": 33,
      "rank_p2.5": 28,
      "rank_p97.5": 39,
      "total_output_tokens": 1884993,
      "conso_all_conv": 0.0,
      "n_match": 1729,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.5377832383171172,
      "win_rate": 0.48936342592592585,
      "useful": 110,
      "creative": 40,
      "complete": 143,
      "clear_formatting": 109,
      "incorrect": 56,
      "superficial": 42,
      "instructions_not_followed": 26,
      "total_prefs": 526,
      "positive_prefs_ratio": 0.7642585551330798
    },
    {
      "model_name": "mistral-large-2411",
      "median": 1025.1501116253476,
      "p2.5": 1018.4696615798879,
      "p97.5": 1031.3240630967293,
      "rank": 34,
      "rank_p2.5": 32,
      "rank_p97.5": 38,
      "total_output_tokens": 7677266,
      "conso_all_conv": 0.0,
      "n_match": 8829,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.5328301844679385,
      "win_rate": 0.5274413863404689,
      "useful": 1898,
      "creative": 355,
      "complete": 1451,
      "clear_formatting": 1608,
      "incorrect": 393,
      "superficial": 666,
      "instructions_not_followed": 140,
      "total_prefs": 6511,
      "positive_prefs_ratio": 0.8158500998310552
    },
    {
      "model_name": "gpt-5-mini",
      "median": 1022.7456996217229,
      "p2.5": 1005.5999005742992,
      "p97.5": 1039.8259900462847,
      "rank": 35,
      "rank_p2.5": 28,
      "rank_p97.5": 42,
      "total_output_tokens": 1232192,
      "conso_all_conv": 0.0,
      "n_match": 1061,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.5295054315755693,
      "win_rate": 0.4860283018867925,
      "useful": 53,
      "creative": 12,
      "complete": 77,
      "clear_formatting": 33,
      "incorrect": 16,
      "superficial": 23,
      "instructions_not_followed": 11,
      "total_prefs": 225,
      "positive_prefs_ratio": 0.7777777777777778
    },
    {
      "model_name": "llama-4-scout",
      "median": 1018.9298690901317,
      "p2.5": 1010.1648295729483,
      "p97.5": 1028.5583968532858,
      "rank": 36,
      "rank_p2.5": 33,
      "rank_p97.5": 41,
      "total_output_tokens": 3240442,
      "conso_all_conv": 0.0,
      "n_match": 3920,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.524224960884198,
      "win_rate": 0.4948071519795658,
      "useful": 632,
      "creative": 168,
      "complete": 568,
      "clear_formatting": 523,
      "incorrect": 217,
      "superficial": 287,
      "instructions_not_followed": 77,
      "total_prefs": 2472,
      "positive_prefs_ratio": 0.764967637540453
    },
    {
      "model_name": "llama-maverick",
      "median": 1018.1069176697026,
      "p2.5": 1001.2782425739139,
      "p97.5": 1035.783112489947,
      "rank": 37,
      "rank_p2.5": 30,
      "rank_p97.5": 43,
      "total_output_tokens": 903179,
      "conso_all_conv": 0.0,
      "n_match": 1109,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.5230855725141756,
      "win_rate": 0.5072497745716862,
      "useful": 64,
      "creative": 10,
      "complete": 53,
      "clear_formatting": 36,
      "incorrect": 19,
      "superficial": 32,
      "instructions_not_followed": 7,
      "total_prefs": 221,
      "positive_prefs_ratio": 0.7375565610859729
    },
    {
      "model_name": "mistral-saba",
      "median": 1017.4074911891114,
      "p2.5": 1008.6722978139687,
      "p97.5": 1025.7328874315465,
      "rank": 38,
      "rank_p2.5": 34,
      "rank_p97.5": 42,
      "total_output_tokens": 3980832,
      "conso_all_conv": 0.0,
      "n_match": 4479,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.5221170686556426,
      "win_rate": 0.47729850413038627,
      "useful": 718,
      "creative": 164,
      "complete": 557,
      "clear_formatting": 557,
      "incorrect": 236,
      "superficial": 332,
      "instructions_not_followed": 112,
      "total_prefs": 2676,
      "positive_prefs_ratio": 0.7458893871449925
    },
    {
      "model_name": "gpt-5",
      "median": 1016.1308721926468,
      "p2.5": 1003.0979133451935,
      "p97.5": 1028.4226577245665,
      "rank": 39,
      "rank_p2.5": 33,
      "rank_p97.5": 43,
      "total_output_tokens": 2188266,
      "conso_all_conv": 0.0,
      "n_match": 2241,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.520349017350464,
      "win_rate": 0.4595714285714286,
      "useful": 76,
      "creative": 30,
      "complete": 89,
      "clear_formatting": 41,
      "incorrect": 16,
      "superficial": 28,
      "instructions_not_followed": 13,
      "total_prefs": 293,
      "positive_prefs_ratio": 0.8054607508532423
    },
    {
      "model_name": "mistral-small-3.1-24b",
      "median": 1012.5437366199828,
      "p2.5": 1004.4227584103437,
      "p97.5": 1020.8712951444693,
      "rank": 40,
      "rank_p2.5": 36,
      "rank_p97.5": 43,
      "total_output_tokens": 4470466,
      "conso_all_conv": 0.0,
      "n_match": 5079,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.5153792536244266,
      "win_rate": 0.4945107304587517,
      "useful": 1108,
      "creative": 247,
      "complete": 791,
      "clear_formatting": 916,
      "incorrect": 268,
      "superficial": 430,
      "instructions_not_followed": 130,
      "total_prefs": 3890,
      "positive_prefs_ratio": 0.787146529562982
    },
    {
      "model_name": "o4-mini",
      "median": 1011.7139206383494,
      "p2.5": 999.6174144985097,
      "p97.5": 1022.5985324792551,
      "rank": 41,
      "rank_p2.5": 35,
      "rank_p97.5": 44,
      "total_output_tokens": 2756371,
      "conso_all_conv": 0.0,
      "n_match": 2640,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.5142292915231579,
      "win_rate": 0.4683327017809777,
      "useful": 518,
      "creative": 109,
      "complete": 361,
      "clear_formatting": 277,
      "incorrect": 128,
      "superficial": 207,
      "instructions_not_followed": 44,
      "total_prefs": 1644,
      "positive_prefs_ratio": 0.7694647201946472
    },
    {
      "model_name": "gemma-2-27b-it-q8",
      "median": 1006.5011005073405,
      "p2.5": 983.663323859036,
      "p97.5": 1030.119236831573,
      "rank": 42,
      "rank_p2.5": 32,
      "rank_p97.5": 51,
      "total_output_tokens": 449540,
      "conso_all_conv": 0.0,
      "n_match": 762,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.5070037726592129,
      "win_rate": 0.5826115485564305,
      "useful": 318,
      "creative": 97,
      "complete": 178,
      "clear_formatting": 305,
      "incorrect": 63,
      "superficial": 91,
      "instructions_not_followed": 29,
      "total_prefs": 1081,
      "positive_prefs_ratio": 0.8307123034227567
    },
    {
      "model_name": "qwen-3-8b",
      "median": 997.9087687387289,
      "p2.5": 976.0213592479912,
      "p97.5": 1020.5897109998813,
      "rank": 43,
      "rank_p2.5": 37,
      "rank_p97.5": 54,
      "total_output_tokens": 1309819,
      "conso_all_conv": 0.0,
      "n_match": 629,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.4950937811332391,
      "win_rate": 0.4689825119236884,
      "useful": 25,
      "creative": 7,
      "complete": 31,
      "clear_formatting": 25,
      "incorrect": 22,
      "superficial": 9,
      "instructions_not_followed": 8,
      "total_prefs": 127,
      "positive_prefs_ratio": 0.6929133858267716
    },
    {
      "model_name": "aya-expanse-32b",
      "median": 996.880182739068,
      "p2.5": 987.8057825292564,
      "p97.5": 1005.5909975176396,
      "rank": 44,
      "rank_p2.5": 42,
      "rank_p97.5": 49,
      "total_output_tokens": 3743043,
      "conso_all_conv": 0.0,
      "n_match": 4636,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.49366852032572117,
      "win_rate": 0.46457722174288174,
      "useful": 702,
      "creative": 134,
      "complete": 502,
      "clear_formatting": 498,
      "incorrect": 264,
      "superficial": 343,
      "instructions_not_followed": 107,
      "total_prefs": 2550,
      "positive_prefs_ratio": 0.72
    },
    {
      "model_name": "qwen3-30b-a3b",
      "median": 995.3266965059895,
      "p2.5": 977.4710696094838,
      "p97.5": 1012.3675629735123,
      "rank": 45,
      "rank_p2.5": 40,
      "rank_p97.5": 54,
      "total_output_tokens": 1731590,
      "conso_all_conv": 0.0,
      "n_match": 1071,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.4915162759455913,
      "win_rate": 0.44886915887850465,
      "useful": 64,
      "creative": 20,
      "complete": 74,
      "clear_formatting": 36,
      "incorrect": 34,
      "superficial": 28,
      "instructions_not_followed": 11,
      "total_prefs": 267,
      "positive_prefs_ratio": 0.7265917602996255
    },
    {
      "model_name": "mistral-small-24b-instruct-2501",
      "median": 991.5759882410246,
      "p2.5": 980.8542784033915,
      "p97.5": 1001.7143350465519,
      "rank": 46,
      "rank_p2.5": 43,
      "rank_p97.5": 52,
      "total_output_tokens": 2818040,
      "conso_all_conv": 0.0,
      "n_match": 3318,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.4863220664147257,
      "win_rate": 0.4952350813743219,
      "useful": 745,
      "creative": 155,
      "complete": 536,
      "clear_formatting": 656,
      "incorrect": 204,
      "superficial": 307,
      "instructions_not_followed": 71,
      "total_prefs": 2674,
      "positive_prefs_ratio": 0.7823485415108452
    },
    {
      "model_name": "llama-3.3-70b",
      "median": 988.6036838432656,
      "p2.5": 981.5050263866109,
      "p97.5": 995.7925793383955,
      "rank": 47,
      "rank_p2.5": 45,
      "rank_p97.5": 52,
      "total_output_tokens": 6317141,
      "conso_all_conv": 0.0,
      "n_match": 7524,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.4822085261707563,
      "win_rate": 0.47345606805795565,
      "useful": 1359,
      "creative": 269,
      "complete": 1055,
      "clear_formatting": 1010,
      "incorrect": 425,
      "superficial": 581,
      "instructions_not_followed": 137,
      "total_prefs": 4836,
      "positive_prefs_ratio": 0.7636476426799007
    },
    {
      "model_name": "o3-mini",
      "median": 988.512926969055,
      "p2.5": 973.666819950701,
      "p97.5": 1003.9959308229372,
      "rank": 48,
      "rank_p2.5": 43,
      "rank_p97.5": 56,
      "total_output_tokens": 1655945,
      "conso_all_conv": 0.0,
      "n_match": 1619,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.4820829662728864,
      "win_rate": 0.51142063001853,
      "useful": 350,
      "creative": 85,
      "complete": 254,
      "clear_formatting": 230,
      "incorrect": 49,
      "superficial": 133,
      "instructions_not_followed": 28,
      "total_prefs": 1129,
      "positive_prefs_ratio": 0.8139946855624446
    },
    {
      "model_name": "gpt-4o-mini-2024-07-18",
      "median": 987.4448073959322,
      "p2.5": 979.8450543747612,
      "p97.5": 995.3277448108414,
      "rank": 49,
      "rank_p2.5": 45,
      "rank_p97.5": 53,
      "total_output_tokens": 5207480,
      "conso_all_conv": 0.0,
      "n_match": 6990,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.48060546056782777,
      "win_rate": 0.49947067238912735,
      "useful": 1491,
      "creative": 319,
      "complete": 856,
      "clear_formatting": 1282,
      "incorrect": 369,
      "superficial": 599,
      "instructions_not_followed": 110,
      "total_prefs": 5026,
      "positive_prefs_ratio": 0.7855153203342619
    },
    {
      "model_name": "gpt-4.1-nano",
      "median": 984.3755159173506,
      "p2.5": 975.7338400459244,
      "p97.5": 992.9823069330804,
      "rank": 50,
      "rank_p2.5": 45,
      "rank_p97.5": 55,
      "total_output_tokens": 3326985,
      "conso_all_conv": 0.0,
      "n_match": 5196,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.47636212481246876,
      "win_rate": 0.4660161662817552,
      "useful": 902,
      "creative": 156,
      "complete": 508,
      "clear_formatting": 633,
      "incorrect": 264,
      "superficial": 427,
      "instructions_not_followed": 100,
      "total_prefs": 2990,
      "positive_prefs_ratio": 0.7354515050167224
    },
    {
      "model_name": "Apertus-70B-Instruct-2509",
      "median": 978.6470014040681,
      "p2.5": 955.855089649086,
      "p97.5": 1001.7900103865159,
      "rank": 51,
      "rank_p2.5": 43,
      "rank_p97.5": 63,
      "total_output_tokens": 673824,
      "conso_all_conv": 0.0,
      "n_match": 634,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.4684533240440317,
      "win_rate": 0.4186255924170616,
      "useful": 45,
      "creative": 4,
      "complete": 34,
      "clear_formatting": 26,
      "incorrect": 23,
      "superficial": 22,
      "instructions_not_followed": 11,
      "total_prefs": 165,
      "positive_prefs_ratio": 0.6606060606060606
    },
    {
      "model_name": "aya-expanse-8b",
      "median": 978.2060106153351,
      "p2.5": 962.7140100719342,
      "p97.5": 995.1442235642505,
      "rank": 52,
      "rank_p2.5": 45,
      "rank_p97.5": 60,
      "total_output_tokens": 1057810,
      "conso_all_conv": 0.0,
      "n_match": 1302,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.46784516436958323,
      "win_rate": 0.5014285714285713,
      "useful": 243,
      "creative": 55,
      "complete": 133,
      "clear_formatting": 223,
      "incorrect": 149,
      "superficial": 104,
      "instructions_not_followed": 31,
      "total_prefs": 938,
      "positive_prefs_ratio": 0.697228144989339
    },
    {
      "model_name": "llama-3.1-70b",
      "median": 977.8756809613153,
      "p2.5": 968.3302304615529,
      "p97.5": 986.1422398972034,
      "rank": 53,
      "rank_p2.5": 50,
      "rank_p97.5": 58,
      "total_output_tokens": 4057254,
      "conso_all_conv": 0.0,
      "n_match": 5583,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.46738968323109364,
      "win_rate": 0.530445996775927,
      "useful": 1532,
      "creative": 365,
      "complete": 1047,
      "clear_formatting": 1305,
      "incorrect": 463,
      "superficial": 621,
      "instructions_not_followed": 177,
      "total_prefs": 5510,
      "positive_prefs_ratio": 0.7711433756805808
    },
    {
      "model_name": "jamba-1.5-large",
      "median": 977.1105264072376,
      "p2.5": 931.2094957089098,
      "p97.5": 1019.3438937922948,
      "rank": 54,
      "rank_p2.5": 37,
      "rank_p97.5": 69,
      "total_output_tokens": 143976,
      "conso_all_conv": 0.0,
      "n_match": 172,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.4663348651542026,
      "win_rate": 0.5449418604651162,
      "useful": 44,
      "creative": 11,
      "complete": 18,
      "clear_formatting": 57,
      "incorrect": 15,
      "superficial": 13,
      "instructions_not_followed": 4,
      "total_prefs": 162,
      "positive_prefs_ratio": 0.8024691358024691
    },
    {
      "model_name": "claude-3-5-sonnet-v2",
      "median": 977.0952708670663,
      "p2.5": 967.9787795381454,
      "p97.5": 985.0530870450266,
      "rank": 55,
      "rank_p2.5": 50,
      "rank_p97.5": 58,
      "total_output_tokens": 3224219,
      "conso_all_conv": 0.0,
      "n_match": 5683,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.46631383764611534,
      "win_rate": 0.4921080415273623,
      "useful": 1301,
      "creative": 291,
      "complete": 721,
      "clear_formatting": 905,
      "incorrect": 250,
      "superficial": 606,
      "instructions_not_followed": 94,
      "total_prefs": 4168,
      "positive_prefs_ratio": 0.7720729366602687
    },
    {
      "model_name": "phi-4",
      "median": 972.2455766098037,
      "p2.5": 965.8144421321941,
      "p97.5": 979.0686104079768,
      "rank": 56,
      "rank_p2.5": 53,
      "rank_p97.5": 59,
      "total_output_tokens": 7380487,
      "conso_all_conv": 0.0,
      "n_match": 8856,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.4596362235687073,
      "win_rate": 0.47371654432524,
      "useful": 1578,
      "creative": 327,
      "complete": 1140,
      "clear_formatting": 1273,
      "incorrect": 678,
      "superficial": 724,
      "instructions_not_followed": 234,
      "total_prefs": 5954,
      "positive_prefs_ratio": 0.725226738327175
    },
    {
      "model_name": "ministral-8b-instruct-2410",
      "median": 969.1535953288551,
      "p2.5": 962.2188138362676,
      "p97.5": 975.9445053987138,
      "rank": 57,
      "rank_p2.5": 54,
      "rank_p97.5": 61,
      "total_output_tokens": 7488476,
      "conso_all_conv": 0.0,
      "n_match": 9278,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.45538671794226293,
      "win_rate": 0.47576819407008086,
      "useful": 1796,
      "creative": 412,
      "complete": 1332,
      "clear_formatting": 1695,
      "incorrect": 876,
      "superficial": 927,
      "instructions_not_followed": 274,
      "total_prefs": 7312,
      "positive_prefs_ratio": 0.7159463894967177
    },
    {
      "model_name": "gpt-4o-2024-08-06",
      "median": 967.2429501582794,
      "p2.5": 958.6769026084156,
      "p97.5": 976.716600906973,
      "rank": 58,
      "rank_p2.5": 54,
      "rank_p97.5": 62,
      "total_output_tokens": 3903917,
      "conso_all_conv": 0.0,
      "n_match": 5896,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.45276417023628757,
      "win_rate": 0.48863297150610585,
      "useful": 1230,
      "creative": 243,
      "complete": 593,
      "clear_formatting": 1002,
      "incorrect": 275,
      "superficial": 590,
      "instructions_not_followed": 115,
      "total_prefs": 4048,
      "positive_prefs_ratio": 0.7579051383399209
    },
    {
      "model_name": "Apertus-8B-Instruct-2509",
      "median": 965.5265223525507,
      "p2.5": 909.8991466954581,
      "p97.5": 1021.8426942729635,
      "rank": 59,
      "rank_p2.5": 36,
      "rank_p97.5": 71,
      "total_output_tokens": 52304,
      "conso_all_conv": 0.0,
      "n_match": 86,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.4504105352830747,
      "win_rate": 0.46869047619047627,
      "useful": 2,
      "creative": 0,
      "complete": 3,
      "clear_formatting": 2,
      "incorrect": 3,
      "superficial": 5,
      "instructions_not_followed": 0,
      "total_prefs": 15,
      "positive_prefs_ratio": 0.4666666666666667
    },
    {
      "model_name": "qwen2.5-32b-instruct",
      "median": 965.2919552477254,
      "p2.5": 908.5471706640614,
      "p97.5": 1022.8376164002183,
      "rank": 60,
      "rank_p2.5": 36,
      "rank_p97.5": 71,
      "total_output_tokens": 75812,
      "conso_all_conv": 0.0,
      "n_match": 142,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.4500890643411808,
      "win_rate": 0.5557042253521126,
      "useful": 52,
      "creative": 16,
      "complete": 43,
      "clear_formatting": 57,
      "incorrect": 13,
      "superficial": 21,
      "instructions_not_followed": 15,
      "total_prefs": 217,
      "positive_prefs_ratio": 0.7741935483870968
    },
    {
      "model_name": "llama-3.1-405b",
      "median": 962.6279474783253,
      "p2.5": 956.330294651929,
      "p97.5": 969.524329577834,
      "rank": 61,
      "rank_p2.5": 57,
      "rank_p97.5": 63,
      "total_output_tokens": 10383810,
      "conso_all_conv": 0.0,
      "n_match": 9973,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.44644117692730456,
      "win_rate": 0.4950747166783672,
      "useful": 2224,
      "creative": 556,
      "complete": 1579,
      "clear_formatting": 1788,
      "incorrect": 947,
      "superficial": 890,
      "instructions_not_followed": 437,
      "total_prefs": 8421,
      "positive_prefs_ratio": 0.7299608122550766
    },
    {
      "model_name": "gemma-2-9b-it",
      "median": 958.0776533870489,
      "p2.5": 949.7418422777088,
      "p97.5": 966.7251020865763,
      "rank": 62,
      "rank_p2.5": 58,
      "rank_p97.5": 65,
      "total_output_tokens": 3108609,
      "conso_all_conv": 0.0,
      "n_match": 5115,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.4402242939304192,
      "win_rate": 0.5068660801564027,
      "useful": 1250,
      "creative": 403,
      "complete": 771,
      "clear_formatting": 1197,
      "incorrect": 472,
      "superficial": 595,
      "instructions_not_followed": 177,
      "total_prefs": 4865,
      "positive_prefs_ratio": 0.7442959917780062
    },
    {
      "model_name": "gpt-5-nano",
      "median": 956.8603417597878,
      "p2.5": 938.2067935339219,
      "p97.5": 975.3471288416172,
      "rank": 63,
      "rank_p2.5": 54,
      "rank_p97.5": 67,
      "total_output_tokens": 901659,
      "conso_all_conv": 0.0,
      "n_match": 921,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.43856429682614395,
      "win_rate": 0.38946796959826274,
      "useful": 32,
      "creative": 8,
      "complete": 30,
      "clear_formatting": 19,
      "incorrect": 10,
      "superficial": 16,
      "instructions_not_followed": 12,
      "total_prefs": 127,
      "positive_prefs_ratio": 0.7007874015748031
    },
    {
      "model_name": "deepseek-r1-distill-llama-70b",
      "median": 956.3911086835237,
      "p2.5": 945.0279036174488,
      "p97.5": 968.001877780594,
      "rank": 64,
      "rank_p2.5": 58,
      "rank_p97.5": 66,
      "total_output_tokens": 2700318,
      "conso_all_conv": 0.0,
      "n_match": 2884,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.437924795518688,
      "win_rate": 0.44295769764216364,
      "useful": 486,
      "creative": 129,
      "complete": 351,
      "clear_formatting": 363,
      "incorrect": 186,
      "superficial": 339,
      "instructions_not_followed": 124,
      "total_prefs": 1978,
      "positive_prefs_ratio": 0.6718907987866531
    },
    {
      "model_name": "qwq-32b",
      "median": 956.2254960738883,
      "p2.5": 940.7743264299728,
      "p97.5": 971.6984507967288,
      "rank": 65,
      "rank_p2.5": 56,
      "rank_p97.5": 66,
      "total_output_tokens": 1895013,
      "conso_all_conv": 0.0,
      "n_match": 1566,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.43769913796002025,
      "win_rate": 0.4485997442455243,
      "useful": 291,
      "creative": 139,
      "complete": 343,
      "clear_formatting": 233,
      "incorrect": 140,
      "superficial": 105,
      "instructions_not_followed": 92,
      "total_prefs": 1343,
      "positive_prefs_ratio": 0.7490692479523455
    },
    {
      "model_name": "hermes-3-llama-3.1-405b",
      "median": 947.2764322877174,
      "p2.5": 939.9404036068952,
      "p97.5": 954.6515519508488,
      "rank": 66,
      "rank_p2.5": 63,
      "rank_p97.5": 67,
      "total_output_tokens": 4092822,
      "conso_all_conv": 0.0,
      "n_match": 6735,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.42554671364050994,
      "win_rate": 0.466347438752784,
      "useful": 1450,
      "creative": 285,
      "complete": 830,
      "clear_formatting": 1109,
      "incorrect": 426,
      "superficial": 753,
      "instructions_not_followed": 184,
      "total_prefs": 5037,
      "positive_prefs_ratio": 0.7294024220766329
    },
    {
      "model_name": "c4ai-command-r-08-2024",
      "median": 935.2411371904865,
      "p2.5": 927.2879938304116,
      "p97.5": 943.3895957066703,
      "rank": 67,
      "rank_p2.5": 66,
      "rank_p97.5": 70,
      "total_output_tokens": 4319206,
      "conso_all_conv": 0.0,
      "n_match": 5959,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.40934709447456646,
      "win_rate": 0.42968786709179396,
      "useful": 1075,
      "creative": 255,
      "complete": 843,
      "clear_formatting": 796,
      "incorrect": 471,
      "superficial": 660,
      "instructions_not_followed": 163,
      "total_prefs": 4263,
      "positive_prefs_ratio": 0.6964578935022285
    },
    {
      "model_name": "llama-3.1-8b",
      "median": 932.6180788039671,
      "p2.5": 925.886275118517,
      "p97.5": 939.628307289511,
      "rank": 68,
      "rank_p2.5": 66,
      "rank_p97.5": 71,
      "total_output_tokens": 6563396,
      "conso_all_conv": 0.0,
      "n_match": 9242,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.4058409968471171,
      "win_rate": 0.4422281138404935,
      "useful": 1493,
      "creative": 365,
      "complete": 979,
      "clear_formatting": 1124,
      "incorrect": 984,
      "superficial": 945,
      "instructions_not_followed": 392,
      "total_prefs": 6282,
      "positive_prefs_ratio": 0.6305316778096147
    },
    {
      "model_name": "qwen2.5-coder-32b-instruct",
      "median": 931.743381476819,
      "p2.5": 923.6470064869247,
      "p97.5": 939.4024619953975,
      "rank": 69,
      "rank_p2.5": 66,
      "rank_p97.5": 71,
      "total_output_tokens": 6149486,
      "conso_all_conv": 0.0,
      "n_match": 7299,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.40467392835095933,
      "win_rate": 0.43789423208658723,
      "useful": 1379,
      "creative": 293,
      "complete": 923,
      "clear_formatting": 1142,
      "incorrect": 790,
      "superficial": 742,
      "instructions_not_followed": 234,
      "total_prefs": 5503,
      "positive_prefs_ratio": 0.6790841359258586
    },
    {
      "model_name": "qwen2.5-7b-instruct",
      "median": 931.6867069233417,
      "p2.5": 913.3779180437084,
      "p97.5": 950.2565167567371,
      "rank": 70,
      "rank_p2.5": 65,
      "rank_p97.5": 71,
      "total_output_tokens": 1186919,
      "conso_all_conv": 0.0,
      "n_match": 1417,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.4045983467061999,
      "win_rate": 0.49383909668313336,
      "useful": 402,
      "creative": 104,
      "complete": 284,
      "clear_formatting": 380,
      "incorrect": 231,
      "superficial": 203,
      "instructions_not_followed": 88,
      "total_prefs": 1692,
      "positive_prefs_ratio": 0.6914893617021277
    },
    {
      "model_name": "hermes-4-70b",
      "median": 927.4101816610985,
      "p2.5": 907.291601343386,
      "p97.5": 947.5106745363714,
      "rank": 71,
      "rank_p2.5": 65,
      "rank_p97.5": 71,
      "total_output_tokens": 418099,
      "conso_all_conv": 0.0,
      "n_match": 917,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.39890826122313133,
      "win_rate": 0.3686150490730643,
      "useful": 34,
      "creative": 9,
      "complete": 20,
      "clear_formatting": 22,
      "incorrect": 21,
      "superficial": 37,
      "instructions_not_followed": 18,
      "total_prefs": 161,
      "positive_prefs_ratio": 0.5279503105590062
    },
    {
      "model_name": "mixtral-8x7b-instruct-v0.1",
      "median": 889.6798668900851,
      "p2.5": 877.1231385330966,
      "p97.5": 902.3026724802509,
      "rank": 72,
      "rank_p2.5": 72,
      "rank_p97.5": 73,
      "total_output_tokens": 1575791,
      "conso_all_conv": 0.0,
      "n_match": 2560,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.3500060745384522,
      "win_rate": 0.43488671874999996,
      "useful": 727,
      "creative": 164,
      "complete": 375,
      "clear_formatting": 503,
      "incorrect": 256,
      "superficial": 389,
      "instructions_not_followed": 159,
      "total_prefs": 2573,
      "positive_prefs_ratio": 0.687524290711232
    },
    {
      "model_name": "lfm-40b",
      "median": 886.7960705210011,
      "p2.5": 876.4624994271882,
      "p97.5": 897.3018444957013,
      "rank": 73,
      "rank_p2.5": 72,
      "rank_p97.5": 73,
      "total_output_tokens": 2000824,
      "conso_all_conv": 0.0,
      "n_match": 3578,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.3463775175670706,
      "win_rate": 0.416296813862493,
      "useful": 841,
      "creative": 166,
      "complete": 419,
      "clear_formatting": 647,
      "incorrect": 357,
      "superficial": 572,
      "instructions_not_followed": 121,
      "total_prefs": 3123,
      "positive_prefs_ratio": 0.6637848222862632
    },
    {
      "model_name": "phi-3.5-mini-instruct",
      "median": 865.8600935457503,
      "p2.5": 852.2358407736144,
      "p97.5": 879.1263946365787,
      "rank": 74,
      "rank_p2.5": 74,
      "rank_p97.5": 75,
      "total_output_tokens": 2149046,
      "conso_all_conv": 0.0,
      "n_match": 2535,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.3205678124785916,
      "win_rate": 0.4021104536489152,
      "useful": 636,
      "creative": 226,
      "complete": 477,
      "clear_formatting": 533,
      "incorrect": 428,
      "superficial": 449,
      "instructions_not_followed": 300,
      "total_prefs": 3049,
      "positive_prefs_ratio": 0.6139717940308298
    },
    {
      "model_name": "mistral-nemo-2407",
      "median": 856.5722931075636,
      "p2.5": 848.6311489264818,
      "p97.5": 865.2860718166869,
      "rank": 75,
      "rank_p2.5": 74,
      "rank_p97.5": 76,
      "total_output_tokens": 3305342,
      "conso_all_conv": 0.0,
      "n_match": 6251,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.3094359746691093,
      "win_rate": 0.37482482802751566,
      "useful": 1413,
      "creative": 225,
      "complete": 661,
      "clear_formatting": 900,
      "incorrect": 638,
      "superficial": 1088,
      "instructions_not_followed": 292,
      "total_prefs": 5217,
      "positive_prefs_ratio": 0.6131876557408472
    },
    {
      "model_name": "mixtral-8x22b-instruct-v0.1",
      "median": 846.6079017278391,
      "p2.5": 837.3292785898036,
      "p97.5": 855.4437798239006,
      "rank": 76,
      "rank_p2.5": 75,
      "rank_p97.5": 77,
      "total_output_tokens": 3041056,
      "conso_all_conv": 0.0,
      "n_match": 5455,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.29772406913987115,
      "win_rate": 0.3671035747021082,
      "useful": 1117,
      "creative": 203,
      "complete": 516,
      "clear_formatting": 702,
      "incorrect": 535,
      "superficial": 934,
      "instructions_not_followed": 276,
      "total_prefs": 4283,
      "positive_prefs_ratio": 0.5925752976885361
    },
    {
      "model_name": "chocolatine-2-14b-instruct-v2.0.3-q8",
      "median": 823.5642707654758,
      "p2.5": 806.4018615434038,
      "p97.5": 840.2748492369085,
      "rank": 77,
      "rank_p2.5": 77,
      "rank_p97.5": 78,
      "total_output_tokens": 533384,
      "conso_all_conv": 0.0,
      "n_match": 1796,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.27160176569262134,
      "win_rate": 0.3317316258351893,
      "useful": 280,
      "creative": 37,
      "complete": 100,
      "clear_formatting": 199,
      "incorrect": 161,
      "superficial": 370,
      "instructions_not_followed": 50,
      "total_prefs": 1197,
      "positive_prefs_ratio": 0.5146198830409356
    },
    {
      "model_name": "Yi-1.5-9B-Chat",
      "median": 769.8117505805739,
      "p2.5": 673.9833919379994,
      "p97.5": 856.9871225495503,
      "rank": 78,
      "rank_p2.5": 75,
      "rank_p97.5": 80,
      "total_output_tokens": 47531,
      "conso_all_conv": 0.0,
      "n_match": 65,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.21626911993678474,
      "win_rate": 0.32599999999999996,
      "useful": 16,
      "creative": 5,
      "complete": 14,
      "clear_formatting": 19,
      "incorrect": 12,
      "superficial": 17,
      "instructions_not_followed": 14,
      "total_prefs": 97,
      "positive_prefs_ratio": 0.5567010309278351
    },
    {
      "model_name": "chocolatine-14b-instruct-dpo-v1.2-q4",
      "median": 754.1553361650665,
      "p2.5": 705.1279482222199,
      "p97.5": 797.764204201392,
      "rank": 79,
      "rank_p2.5": 78,
      "rank_p97.5": 80,
      "total_output_tokens": 131187,
      "conso_all_conv": 0.0,
      "n_match": 309,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.2016901072885292,
      "win_rate": 0.24022653721682843,
      "useful": 83,
      "creative": 17,
      "complete": 39,
      "clear_formatting": 43,
      "incorrect": 52,
      "superficial": 107,
      "instructions_not_followed": 50,
      "total_prefs": 391,
      "positive_prefs_ratio": 0.46547314578005117
    },
    {
      "model_name": "qwen2-7b-instruct",
      "median": 732.6994018810178,
      "p2.5": 631.7701341215611,
      "p97.5": 813.3249752102455,
      "rank": 80,
      "rank_p2.5": 78,
      "rank_p97.5": 80,
      "total_output_tokens": 43550,
      "conso_all_conv": 0.0,
      "n_match": 80,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.18285142889827388,
      "win_rate": 0.2525,
      "useful": 19,
      "creative": 4,
      "complete": 12,
      "clear_formatting": 22,
      "incorrect": 11,
      "superficial": 14,
      "instructions_not_followed": 7,
      "total_prefs": 89,
      "positive_prefs_ratio": 0.6404494382022472
    }
  ]
}