{
  "timestamp": 1762166691.050267,
  "models": [
    {
      "model_name": "mistral-medium-3.1",
      "median": 1148.8626540936216,
      "p2.5": 1126.7564545282644,
      "p97.5": 1172.8696158784637,
      "rank": 1,
      "rank_p2.5": 1,
      "rank_p97.5": 3,
      "total_output_tokens": 1267622,
      "conso_all_conv": 20.252986837300018,
      "n_match": 675,
      "mean_conso_per_match": 0.030004424944148175,
      "mean_conso_per_token": 1.5977150000000014e-05,
      "mean_win_prob": 0.6945286892182525,
      "win_rate": 0.6027151335311572,
      "useful": 28,
      "creative": 12,
      "complete": 44,
      "clear_formatting": 36,
      "incorrect": 9,
      "superficial": 3,
      "instructions_not_followed": 2,
      "total_prefs": 134,
      "positive_prefs_ratio": 0.8955223880597015
    },
    {
      "model_name": "gemini-2.5-flash",
      "median": 1128.8907468720877,
      "p2.5": 1109.7198947648917,
      "p97.5": 1146.6725817850895,
      "rank": 2,
      "rank_p2.5": 1,
      "rank_p97.5": 4,
      "total_output_tokens": 1574894,
      "conso_all_conv": 137.77985357304,
      "n_match": 1042,
      "mean_conso_per_match": 0.13222634699907868,
      "mean_conso_per_token": 8.748515999999999e-05,
      "mean_win_prob": 0.6702100874630238,
      "win_rate": 0.5973416506717851,
      "useful": 109,
      "creative": 45,
      "complete": 142,
      "clear_formatting": 97,
      "incorrect": 27,
      "superficial": 18,
      "instructions_not_followed": 9,
      "total_prefs": 447,
      "positive_prefs_ratio": 0.8791946308724832
    },
    {
      "model_name": "qwen3-max-2025-09-23",
      "median": 1112.1237927574043,
      "p2.5": 1073.0400905866104,
      "p97.5": 1151.3472855359958,
      "rank": 3,
      "rank_p2.5": 1,
      "rank_p97.5": 17,
      "total_output_tokens": 221734,
      "conso_all_conv": 12.658244159680002,
      "n_match": 199,
      "mean_conso_per_match": 0.06360926713407036,
      "mean_conso_per_token": 5.7087520000000013e-05,
      "mean_win_prob": 0.6491213750097014,
      "win_rate": 0.5498484848484849,
      "useful": 8,
      "creative": 0,
      "complete": 10,
      "clear_formatting": 7,
      "incorrect": 6,
      "superficial": 2,
      "instructions_not_followed": 1,
      "total_prefs": 34,
      "positive_prefs_ratio": 0.7352941176470589
    },
    {
      "model_name": "gemini-2.0-flash",
      "median": 1106.1852335462809,
      "p2.5": 1098.735987318689,
      "p97.5": 1113.6121945367845,
      "rank": 4,
      "rank_p2.5": 3,
      "rank_p97.5": 8,
      "total_output_tokens": 12296785,
      "conso_all_conv": 0.0,
      "n_match": 8684,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.6415178202373321,
      "win_rate": 0.6317699216950713,
      "useful": 2128,
      "creative": 677,
      "complete": 2179,
      "clear_formatting": 1909,
      "incorrect": 376,
      "superficial": 397,
      "instructions_not_followed": 112,
      "total_prefs": 7778,
      "positive_prefs_ratio": 0.8862175366418102
    },
    {
      "model_name": "deepseek-chat-v3.1",
      "median": 1100.1872066305505,
      "p2.5": 1067.6625170334733,
      "p97.5": 1134.4708320523107,
      "rank": 5,
      "rank_p2.5": 2,
      "rank_p97.5": 18,
      "total_output_tokens": 509605,
      "conso_all_conv": 23.964552232700008,
      "n_match": 314,
      "mean_conso_per_match": 0.07632023004044589,
      "mean_conso_per_token": 4.7025740000000016e-05,
      "mean_win_prob": 0.633771835663853,
      "win_rate": 0.5103225806451613,
      "useful": 29,
      "creative": 12,
      "complete": 26,
      "clear_formatting": 20,
      "incorrect": 7,
      "superficial": 3,
      "instructions_not_followed": 3,
      "total_prefs": 100,
      "positive_prefs_ratio": 0.87
    },
    {
      "model_name": "deepseek-v3-0324",
      "median": 1099.2061129461827,
      "p2.5": 1089.169834047654,
      "p97.5": 1108.6295523820663,
      "rank": 6,
      "rank_p2.5": 4,
      "rank_p97.5": 11,
      "total_output_tokens": 4435392,
      "conso_all_conv": 208.57759099007947,
      "n_match": 4385,
      "mean_conso_per_match": 0.0475661552999041,
      "mean_conso_per_token": 4.702573999999988e-05,
      "mean_win_prob": 0.6324987163281275,
      "win_rate": 0.5851128848346637,
      "useful": 1141,
      "creative": 336,
      "complete": 1012,
      "clear_formatting": 1043,
      "incorrect": 230,
      "superficial": 288,
      "instructions_not_followed": 79,
      "total_prefs": 4129,
      "positive_prefs_ratio": 0.8554129329135384
    },
    {
      "model_name": "gemma-3-27b",
      "median": 1098.4177795695725,
      "p2.5": 1089.8334444947552,
      "p97.5": 1106.7841698536392,
      "rank": 7,
      "rank_p2.5": 4,
      "rank_p97.5": 11,
      "total_output_tokens": 7212658,
      "conso_all_conv": 46.40809282088669,
      "n_match": 5223,
      "mean_conso_per_match": 0.008885332724657607,
      "mean_conso_per_token": 6.43425666666667e-06,
      "mean_win_prob": 0.6314745159135933,
      "win_rate": 0.5971108558299828,
      "useful": 1143,
      "creative": 386,
      "complete": 1317,
      "clear_formatting": 976,
      "incorrect": 281,
      "superficial": 203,
      "instructions_not_followed": 94,
      "total_prefs": 4400,
      "positive_prefs_ratio": 0.8686363636363637
    },
    {
      "model_name": "gpt-oss-120b",
      "median": 1094.4439715934177,
      "p2.5": 1070.7498853249901,
      "p97.5": 1115.5871206215145,
      "rank": 8,
      "rank_p2.5": 3,
      "rank_p97.5": 17,
      "total_output_tokens": 1534455,
      "conso_all_conv": 5.135590716749996,
      "n_match": 684,
      "mean_conso_per_match": 0.007508173562499994,
      "mean_conso_per_token": 3.3468499999999974e-06,
      "mean_win_prob": 0.6262955327354,
      "win_rate": 0.5710834553440703,
      "useful": 96,
      "creative": 43,
      "complete": 150,
      "clear_formatting": 101,
      "incorrect": 37,
      "superficial": 23,
      "instructions_not_followed": 19,
      "total_prefs": 469,
      "positive_prefs_ratio": 0.8315565031982942
    },
    {
      "model_name": "glm-4.5",
      "median": 1094.4429494283982,
      "p2.5": 1059.6497504454883,
      "p97.5": 1128.9699856992524,
      "rank": 9,
      "rank_p2.5": 2,
      "rank_p97.5": 22,
      "total_output_tokens": 603261,
      "conso_all_conv": 12.914502901020004,
      "n_match": 274,
      "mean_conso_per_match": 0.04713322226649636,
      "mean_conso_per_token": 2.1407820000000007e-05,
      "mean_win_prob": 0.6262941971370625,
      "win_rate": 0.602,
      "useful": 60,
      "creative": 15,
      "complete": 39,
      "clear_formatting": 39,
      "incorrect": 6,
      "superficial": 6,
      "instructions_not_followed": 6,
      "total_prefs": 171,
      "positive_prefs_ratio": 0.8947368421052632
    },
    {
      "model_name": "magistral-medium",
      "median": 1093.9626492853645,
      "p2.5": 1072.2087492592389,
      "p97.5": 1118.4230332378713,
      "rank": 10,
      "rank_p2.5": 3,
      "rank_p97.5": 17,
      "total_output_tokens": 566459,
      "conso_all_conv": 9.050400411849994,
      "n_match": 643,
      "mean_conso_per_match": 0.014075272802255045,
      "mean_conso_per_token": 1.597714999999999e-05,
      "mean_win_prob": 0.6256664268631636,
      "win_rate": 0.5984136858475895,
      "useful": 26,
      "creative": 13,
      "complete": 36,
      "clear_formatting": 18,
      "incorrect": 13,
      "superficial": 6,
      "instructions_not_followed": 0,
      "total_prefs": 112,
      "positive_prefs_ratio": 0.8303571428571429
    },
    {
      "model_name": "deepseek-v3-chat",
      "median": 1084.4939316465811,
      "p2.5": 1075.3190121397467,
      "p97.5": 1093.3855457406564,
      "rank": 11,
      "rank_p2.5": 8,
      "rank_p97.5": 16,
      "total_output_tokens": 5638296,
      "conso_all_conv": 265.14504173903936,
      "n_match": 5388,
      "mean_conso_per_match": 0.04921028985505556,
      "mean_conso_per_token": 4.702573999999989e-05,
      "mean_win_prob": 0.6132145927762054,
      "win_rate": 0.6141481069042317,
      "useful": 1330,
      "creative": 390,
      "complete": 1245,
      "clear_formatting": 1399,
      "incorrect": 314,
      "superficial": 285,
      "instructions_not_followed": 81,
      "total_prefs": 5044,
      "positive_prefs_ratio": 0.8651863600317209
    },
    {
      "model_name": "claude-4-5-sonnet",
      "median": 1083.4467377148103,
      "p2.5": 1063.4835620584086,
      "p97.5": 1102.725662596209,
      "rank": 12,
      "rank_p2.5": 6,
      "rank_p97.5": 20,
      "total_output_tokens": 1423558,
      "conso_all_conv": 124.54019939928013,
      "n_match": 790,
      "mean_conso_per_match": 0.15764582202440522,
      "mean_conso_per_token": 8.748516000000009e-05,
      "mean_win_prob": 0.6118289483825059,
      "win_rate": 0.5251392405063291,
      "useful": 54,
      "creative": 13,
      "complete": 39,
      "clear_formatting": 26,
      "incorrect": 11,
      "superficial": 3,
      "instructions_not_followed": 11,
      "total_prefs": 157,
      "positive_prefs_ratio": 0.8407643312101911
    },
    {
      "model_name": "deepseek-r1-0528",
      "median": 1078.4485110383425,
      "p2.5": 1028.077815230644,
      "p97.5": 1132.588166605991,
      "rank": 13,
      "rank_p2.5": 2,
      "rank_p97.5": 34,
      "total_output_tokens": 170822,
      "conso_all_conv": 8.03303095828,
      "n_match": 103,
      "mean_conso_per_match": 0.07799059182796116,
      "mean_conso_per_token": 4.7025739999999995e-05,
      "mean_win_prob": 0.6051932205904643,
      "win_rate": 0.5056862745098039,
      "useful": 8,
      "creative": 4,
      "complete": 8,
      "clear_formatting": 4,
      "incorrect": 5,
      "superficial": 1,
      "instructions_not_followed": 0,
      "total_prefs": 30,
      "positive_prefs_ratio": 0.8
    },
    {
      "model_name": "gemma-3-12b",
      "median": 1077.250676434032,
      "p2.5": 1068.7761778820336,
      "p97.5": 1085.8752897024697,
      "rank": 14,
      "rank_p2.5": 11,
      "rank_p97.5": 19,
      "total_output_tokens": 6469153,
      "conso_all_conv": 28.00630029528668,
      "n_match": 4863,
      "mean_conso_per_match": 0.0057590582552512195,
      "mean_conso_per_token": 4.329206666666669e-06,
      "mean_win_prob": 0.6035976854289518,
      "win_rate": 0.5748498560263267,
      "useful": 972,
      "creative": 289,
      "complete": 1129,
      "clear_formatting": 826,
      "incorrect": 299,
      "superficial": 241,
      "instructions_not_followed": 130,
      "total_prefs": 3886,
      "positive_prefs_ratio": 0.8275862068965517
    },
    {
      "model_name": "grok-4-fast",
      "median": 1073.242456631076,
      "p2.5": 1052.3306114172085,
      "p97.5": 1096.6229636648523,
      "rank": 15,
      "rank_p2.5": 8,
      "rank_p97.5": 25,
      "total_output_tokens": 926120,
      "conso_all_conv": 2904.152564299998,
      "n_match": 637,
      "mean_conso_per_match": 4.5591092061224465,
      "mean_conso_per_token": 0.003135827499999998,
      "mean_win_prob": 0.5982444738198398,
      "win_rate": 0.5672955974842768,
      "useful": 46,
      "creative": 4,
      "complete": 28,
      "clear_formatting": 11,
      "incorrect": 9,
      "superficial": 5,
      "instructions_not_followed": 2,
      "total_prefs": 105,
      "positive_prefs_ratio": 0.8476190476190476
    },
    {
      "model_name": "grok-3-mini-beta",
      "median": 1072.7767081515042,
      "p2.5": 1058.196822559194,
      "p97.5": 1088.7141723383463,
      "rank": 16,
      "rank_p2.5": 10,
      "rank_p97.5": 22,
      "total_output_tokens": 3474752,
      "conso_all_conv": 1630.7706086400008,
      "n_match": 1537,
      "mean_conso_per_match": 1.0610088540273264,
      "mean_conso_per_token": 0.00046932000000000023,
      "mean_win_prob": 0.5976210565462857,
      "win_rate": 0.5305338541666668,
      "useful": 404,
      "creative": 102,
      "complete": 350,
      "clear_formatting": 320,
      "incorrect": 102,
      "superficial": 106,
      "instructions_not_followed": 47,
      "total_prefs": 1431,
      "positive_prefs_ratio": 0.8218029350104822
    },
    {
      "model_name": "mistral-small-2506",
      "median": 1070.508477809139,
      "p2.5": 1050.746387400386,
      "p97.5": 1087.9153077672693,
      "rank": 17,
      "rank_p2.5": 10,
      "rank_p97.5": 25,
      "total_output_tokens": 645842,
      "conso_all_conv": 3.8836072536933326,
      "n_match": 742,
      "mean_conso_per_match": 0.005233972040017968,
      "mean_conso_per_token": 6.013246666666666e-06,
      "mean_win_prob": 0.5945809753880781,
      "win_rate": 0.561417004048583,
      "useful": 33,
      "creative": 12,
      "complete": 27,
      "clear_formatting": 21,
      "incorrect": 26,
      "superficial": 11,
      "instructions_not_followed": 3,
      "total_prefs": 133,
      "positive_prefs_ratio": 0.6992481203007519
    },
    {
      "model_name": "magistral-small-2506",
      "median": 1067.9213169585728,
      "p2.5": 1050.9146667288524,
      "p97.5": 1086.1442665339841,
      "rank": 18,
      "rank_p2.5": 12,
      "rank_p97.5": 26,
      "total_output_tokens": 924646,
      "conso_all_conv": 5.560124477346671,
      "n_match": 1053,
      "mean_conso_per_match": 0.005280270158923714,
      "mean_conso_per_token": 6.013246666666671e-06,
      "mean_win_prob": 0.5911055493074616,
      "win_rate": 0.555361216730038,
      "useful": 124,
      "creative": 27,
      "complete": 90,
      "clear_formatting": 86,
      "incorrect": 35,
      "superficial": 33,
      "instructions_not_followed": 14,
      "total_prefs": 409,
      "positive_prefs_ratio": 0.7995110024449877
    },
    {
      "model_name": "command-a",
      "median": 1066.7462964664728,
      "p2.5": 1058.6406726337775,
      "p97.5": 1075.8707024566406,
      "rank": 19,
      "rank_p2.5": 15,
      "rank_p97.5": 23,
      "total_output_tokens": 4819688,
      "conso_all_conv": 87.82694130189314,
      "n_match": 4831,
      "mean_conso_per_match": 0.01817986779173942,
      "mean_conso_per_token": 1.8222536666666628e-05,
      "mean_win_prob": 0.5895244069277102,
      "win_rate": 0.5679958592132506,
      "useful": 1031,
      "creative": 245,
      "complete": 983,
      "clear_formatting": 921,
      "incorrect": 241,
      "superficial": 266,
      "instructions_not_followed": 90,
      "total_prefs": 3777,
      "positive_prefs_ratio": 0.8419380460683081
    },
    {
      "model_name": "mistral-medium-2508",
      "median": 1066.1869659666968,
      "p2.5": 1019.430592447008,
      "p97.5": 1110.3167385084053,
      "rank": 20,
      "rank_p2.5": 5,
      "rank_p97.5": 37,
      "total_output_tokens": 134880,
      "conso_all_conv": 2.154997991999999,
      "n_match": 154,
      "mean_conso_per_match": 0.013993493454545447,
      "mean_conso_per_token": 1.5977149999999993e-05,
      "mean_win_prob": 0.5887711764826035,
      "win_rate": 0.5632467532467533,
      "useful": 10,
      "creative": 1,
      "complete": 7,
      "clear_formatting": 4,
      "incorrect": 4,
      "superficial": 0,
      "instructions_not_followed": 1,
      "total_prefs": 27,
      "positive_prefs_ratio": 0.8148148148148148
    },
    {
      "model_name": "claude-4-sonnet",
      "median": 1065.1874956812978,
      "p2.5": 1048.347045809243,
      "p97.5": 1081.7908741920348,
      "rank": 21,
      "rank_p2.5": 13,
      "rank_p97.5": 26,
      "total_output_tokens": 950171,
      "conso_all_conv": 83.12586196235993,
      "n_match": 1127,
      "mean_conso_per_match": 0.07375852880422354,
      "mean_conso_per_token": 8.748515999999994e-05,
      "mean_win_prob": 0.5874243089088312,
      "win_rate": 0.537619893428064,
      "useful": 119,
      "creative": 37,
      "complete": 105,
      "clear_formatting": 128,
      "incorrect": 23,
      "superficial": 33,
      "instructions_not_followed": 11,
      "total_prefs": 456,
      "positive_prefs_ratio": 0.8530701754385965
    },
    {
      "model_name": "kimi-k2",
      "median": 1061.7262688189771,
      "p2.5": 1023.5247567281207,
      "p97.5": 1097.628112840691,
      "rank": 22,
      "rank_p2.5": 7,
      "rank_p97.5": 36,
      "total_output_tokens": 376507,
      "conso_all_conv": 21.493850892639998,
      "n_match": 207,
      "mean_conso_per_match": 0.1038350284668599,
      "mean_conso_per_token": 5.708751999999999e-05,
      "mean_win_prob": 0.5827511772966911,
      "win_rate": 0.5792610837438423,
      "useful": 66,
      "creative": 15,
      "complete": 28,
      "clear_formatting": 28,
      "incorrect": 8,
      "superficial": 17,
      "instructions_not_followed": 0,
      "total_prefs": 162,
      "positive_prefs_ratio": 0.845679012345679
    },
    {
      "model_name": "glm-4.6",
      "median": 1060.8826768411618,
      "p2.5": 1006.7184692139548,
      "p97.5": 1112.4289357065709,
      "rank": 23,
      "rank_p2.5": 4,
      "rank_p97.5": 42,
      "total_output_tokens": 287292,
      "conso_all_conv": 6.150295423440001,
      "n_match": 121,
      "mean_conso_per_match": 0.050828887797024803,
      "mean_conso_per_token": 2.1407820000000003e-05,
      "mean_win_prob": 0.5816101905104675,
      "win_rate": 0.5257983193277311,
      "useful": 10,
      "creative": 0,
      "complete": 8,
      "clear_formatting": 4,
      "incorrect": 0,
      "superficial": 1,
      "instructions_not_followed": 0,
      "total_prefs": 23,
      "positive_prefs_ratio": 0.9565217391304348
    },
    {
      "model_name": "claude-3-7-sonnet",
      "median": 1055.7961075873036,
      "p2.5": 1045.3355065084695,
      "p97.5": 1065.5822435709015,
      "rank": 24,
      "rank_p2.5": 19,
      "rank_p97.5": 28,
      "total_output_tokens": 3546728,
      "conso_all_conv": 310.286066556479,
      "n_match": 3907,
      "mean_conso_per_match": 0.07941798478537983,
      "mean_conso_per_token": 8.748515999999972e-05,
      "mean_win_prob": 0.5747145148799039,
      "win_rate": 0.5242257486562579,
      "useful": 1003,
      "creative": 230,
      "complete": 774,
      "clear_formatting": 822,
      "incorrect": 140,
      "superficial": 318,
      "instructions_not_followed": 46,
      "total_prefs": 3333,
      "positive_prefs_ratio": 0.8487848784878488
    },
    {
      "model_name": "llama-3.1-nemotron-70b-instruct",
      "median": 1050.2712186509725,
      "p2.5": 1042.6009421666558,
      "p97.5": 1058.0892292718804,
      "rank": 25,
      "rank_p2.5": 22,
      "rank_p97.5": 29,
      "total_output_tokens": 7426282,
      "conso_all_conv": 92.59632991613324,
      "n_match": 6709,
      "mean_conso_per_match": 0.013801808006578214,
      "mean_conso_per_token": 1.2468733333333321e-05,
      "mean_win_prob": 0.5671957833323135,
      "win_rate": 0.5452863107664777,
      "useful": 1544,
      "creative": 487,
      "complete": 1473,
      "clear_formatting": 1431,
      "incorrect": 381,
      "superficial": 395,
      "instructions_not_followed": 136,
      "total_prefs": 5847,
      "positive_prefs_ratio": 0.8440225756798359
    },
    {
      "model_name": "Qwen3-Coder-480B-A35B-Instruct",
      "median": 1050.1458850526278,
      "p2.5": 993.285061554523,
      "p97.5": 1109.2665929115778,
      "rank": 26,
      "rank_p2.5": 5,
      "rank_p97.5": 46,
      "total_output_tokens": 196474,
      "conso_all_conv": 5.9389767772,
      "n_match": 98,
      "mean_conso_per_match": 0.06060180384897959,
      "mean_conso_per_token": 3.02278e-05,
      "mean_win_prob": 0.5670248944037644,
      "win_rate": 0.4976595744680851,
      "useful": 11,
      "creative": 5,
      "complete": 4,
      "clear_formatting": 4,
      "incorrect": 5,
      "superficial": 3,
      "instructions_not_followed": 0,
      "total_prefs": 32,
      "positive_prefs_ratio": 0.75
    },
    {
      "model_name": "qwen3-32b",
      "median": 1048.8783365901722,
      "p2.5": 1029.3845703846498,
      "p97.5": 1066.9694624571357,
      "rank": 27,
      "rank_p2.5": 19,
      "rank_p97.5": 34,
      "total_output_tokens": 1715714,
      "conso_all_conv": 12.24323216116,
      "n_match": 829,
      "mean_conso_per_match": 0.014768675707068758,
      "mean_conso_per_token": 7.13594e-06,
      "mean_win_prob": 0.5652958565348777,
      "win_rate": 0.5591151515151515,
      "useful": 232,
      "creative": 60,
      "complete": 184,
      "clear_formatting": 162,
      "incorrect": 84,
      "superficial": 63,
      "instructions_not_followed": 34,
      "total_prefs": 819,
      "positive_prefs_ratio": 0.778998778998779
    },
    {
      "model_name": "gemma-3-4b",
      "median": 1048.3947167745832,
      "p2.5": 1040.3140696774283,
      "p97.5": 1056.4411279047256,
      "rank": 28,
      "rank_p2.5": 22,
      "rank_p97.5": 30,
      "total_output_tokens": 7331151,
      "conso_all_conv": 23.507433430179997,
      "n_match": 5794,
      "mean_conso_per_match": 0.004057202870241629,
      "mean_conso_per_token": 3.206513333333333e-06,
      "mean_win_prob": 0.5646357958564941,
      "win_rate": 0.5317897825336556,
      "useful": 1036,
      "creative": 315,
      "complete": 1150,
      "clear_formatting": 921,
      "incorrect": 495,
      "superficial": 222,
      "instructions_not_followed": 172,
      "total_prefs": 4311,
      "positive_prefs_ratio": 0.7937833449315704
    },
    {
      "model_name": "gemma-3n-e4b-it",
      "median": 1043.114925446883,
      "p2.5": 1024.7488492776888,
      "p97.5": 1062.8706585999792,
      "rank": 29,
      "rank_p2.5": 20,
      "rank_p97.5": 35,
      "total_output_tokens": 1078939,
      "conso_all_conv": 3.4596322893533356,
      "n_match": 933,
      "mean_conso_per_match": 0.0037080731933047542,
      "mean_conso_per_token": 3.2065133333333355e-06,
      "mean_win_prob": 0.5574173475234657,
      "win_rate": 0.505021505376344,
      "useful": 82,
      "creative": 33,
      "complete": 107,
      "clear_formatting": 86,
      "incorrect": 37,
      "superficial": 31,
      "instructions_not_followed": 17,
      "total_prefs": 393,
      "positive_prefs_ratio": 0.7837150127226463
    },
    {
      "model_name": "gpt-4.1-mini",
      "median": 1039.1024981910914,
      "p2.5": 1031.0763970300573,
      "p97.5": 1046.7000532356167,
      "rank": 30,
      "rank_p2.5": 27,
      "rank_p97.5": 33,
      "total_output_tokens": 4924632,
      "conso_all_conv": 64.85945537000003,
      "n_match": 6078,
      "mean_conso_per_match": 0.010671183838433702,
      "mean_conso_per_token": 1.3170416666666674e-05,
      "mean_win_prob": 0.5519175838969468,
      "win_rate": 0.5149917709019092,
      "useful": 1163,
      "creative": 270,
      "complete": 882,
      "clear_formatting": 949,
      "incorrect": 224,
      "superficial": 435,
      "instructions_not_followed": 92,
      "total_prefs": 4015,
      "positive_prefs_ratio": 0.8129514321295144
    },
    {
      "model_name": "gpt-oss-20b",
      "median": 1036.6219177323828,
      "p2.5": 1016.6279103811855,
      "p97.5": 1058.0604625536305,
      "rank": 31,
      "rank_p2.5": 23,
      "rank_p97.5": 38,
      "total_output_tokens": 1023293,
      "conso_all_conv": 3.1375971197633317,
      "n_match": 758,
      "mean_conso_per_match": 0.004139310184384342,
      "mean_conso_per_token": 3.066176666666665e-06,
      "mean_win_prob": 0.5485120449799132,
      "win_rate": 0.5144782034346104,
      "useful": 70,
      "creative": 32,
      "complete": 93,
      "clear_formatting": 88,
      "incorrect": 19,
      "superficial": 29,
      "instructions_not_followed": 21,
      "total_prefs": 352,
      "positive_prefs_ratio": 0.8039772727272727
    },
    {
      "model_name": "gemini-1.5-pro",
      "median": 1035.6790790956206,
      "p2.5": 1028.390603709137,
      "p97.5": 1044.6441458208176,
      "rank": 32,
      "rank_p2.5": 27,
      "rank_p97.5": 34,
      "total_output_tokens": 6034223,
      "conso_all_conv": 0.0,
      "n_match": 7387,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.5472166264139652,
      "win_rate": 0.5830743197509137,
      "useful": 2118,
      "creative": 683,
      "complete": 1630,
      "clear_formatting": 1959,
      "incorrect": 461,
      "superficial": 655,
      "instructions_not_followed": 202,
      "total_prefs": 7708,
      "positive_prefs_ratio": 0.8290088220031137
    },
    {
      "model_name": "deepseek-r1",
      "median": 1033.8099195862892,
      "p2.5": 1023.3367260947334,
      "p97.5": 1044.266258158138,
      "rank": 33,
      "rank_p2.5": 28,
      "rank_p97.5": 36,
      "total_output_tokens": 3693582,
      "conso_all_conv": 173.69342680068021,
      "n_match": 3510,
      "mean_conso_per_match": 0.049485306780820575,
      "mean_conso_per_token": 4.7025740000000056e-05,
      "mean_win_prob": 0.5446469227517879,
      "win_rate": 0.5313019943019943,
      "useful": 826,
      "creative": 284,
      "complete": 783,
      "clear_formatting": 667,
      "incorrect": 171,
      "superficial": 207,
      "instructions_not_followed": 112,
      "total_prefs": 3050,
      "positive_prefs_ratio": 0.839344262295082
    },
    {
      "model_name": "gpt-5-mini",
      "median": 1029.6924468762104,
      "p2.5": 1005.384717287546,
      "p97.5": 1053.8921193441613,
      "rank": 34,
      "rank_p2.5": 24,
      "rank_p97.5": 42,
      "total_output_tokens": 620324,
      "conso_all_conv": 5.73240788076,
      "n_match": 539,
      "mean_conso_per_match": 0.01063526508489796,
      "mean_conso_per_token": 9.240990000000001e-06,
      "mean_win_prob": 0.5389794951120567,
      "win_rate": 0.4939219330855018,
      "useful": 27,
      "creative": 7,
      "complete": 44,
      "clear_formatting": 18,
      "incorrect": 5,
      "superficial": 9,
      "instructions_not_followed": 3,
      "total_prefs": 113,
      "positive_prefs_ratio": 0.8495575221238938
    },
    {
      "model_name": "mistral-large-2411",
      "median": 1024.5030219708142,
      "p2.5": 1017.7143423801413,
      "p97.5": 1031.7780031121574,
      "rank": 35,
      "rank_p2.5": 32,
      "rank_p97.5": 38,
      "total_output_tokens": 7677266,
      "conso_all_conv": 152.8280842193933,
      "n_match": 8829,
      "mean_conso_per_match": 0.017309784145361117,
      "mean_conso_per_token": 1.9906576666666664e-05,
      "mean_win_prob": 0.5318251163123312,
      "win_rate": 0.527441386340469,
      "useful": 1898,
      "creative": 355,
      "complete": 1451,
      "clear_formatting": 1608,
      "incorrect": 393,
      "superficial": 666,
      "instructions_not_followed": 140,
      "total_prefs": 6511,
      "positive_prefs_ratio": 0.8158500998310552
    },
    {
      "model_name": "llama-4-scout",
      "median": 1018.9509056431737,
      "p2.5": 1008.8860368240369,
      "p97.5": 1029.790719187461,
      "rank": 36,
      "rank_p2.5": 33,
      "rank_p97.5": 41,
      "total_output_tokens": 2856478,
      "conso_all_conv": 14.370626605420009,
      "n_match": 3406,
      "mean_conso_per_match": 0.004219209220616561,
      "mean_conso_per_token": 5.030890000000003e-06,
      "mean_win_prob": 0.5241594590366577,
      "win_rate": 0.49648529411764714,
      "useful": 611,
      "creative": 160,
      "complete": 537,
      "clear_formatting": 500,
      "incorrect": 203,
      "superficial": 272,
      "instructions_not_followed": 74,
      "total_prefs": 2357,
      "positive_prefs_ratio": 0.7670767925328807
    },
    {
      "model_name": "gpt-5",
      "median": 1013.9673418915138,
      "p2.5": 996.5104807818731,
      "p97.5": 1030.693065656762,
      "rank": 37,
      "rank_p2.5": 33,
      "rank_p97.5": 45,
      "total_output_tokens": 967868,
      "conso_all_conv": 45.98383454191998,
      "n_match": 1092,
      "mean_conso_per_match": 0.042109738591501814,
      "mean_conso_per_token": 4.751043999999998e-05,
      "mean_win_prob": 0.5172716090628965,
      "win_rate": 0.4612465627864345,
      "useful": 33,
      "creative": 12,
      "complete": 42,
      "clear_formatting": 18,
      "incorrect": 6,
      "superficial": 10,
      "instructions_not_followed": 5,
      "total_prefs": 126,
      "positive_prefs_ratio": 0.8333333333333334
    },
    {
      "model_name": "llama-maverick",
      "median": 1013.2565444505882,
      "p2.5": 987.9002703089213,
      "p97.5": 1035.9944327668268,
      "rank": 38,
      "rank_p2.5": 31,
      "rank_p97.5": 49,
      "total_output_tokens": 456481,
      "conso_all_conv": 6.889517094269995,
      "n_match": 559,
      "mean_conso_per_match": 0.012324717521055448,
      "mean_conso_per_token": 1.509266999999999e-05,
      "mean_win_prob": 0.516288804021962,
      "win_rate": 0.486427289048474,
      "useful": 22,
      "creative": 6,
      "complete": 18,
      "clear_formatting": 19,
      "incorrect": 9,
      "superficial": 6,
      "instructions_not_followed": 3,
      "total_prefs": 83,
      "positive_prefs_ratio": 0.7831325301204819
    },
    {
      "model_name": "o4-mini",
      "median": 1012.2300167119748,
      "p2.5": 1000.0263162130514,
      "p97.5": 1023.7219169218764,
      "rank": 39,
      "rank_p2.5": 35,
      "rank_p97.5": 44,
      "total_output_tokens": 2626142,
      "conso_all_conv": 13.580375540853348,
      "n_match": 2520,
      "mean_conso_per_match": 0.005389037913037043,
      "mean_conso_per_token": 5.171226666666672e-06,
      "mean_win_prob": 0.5148693076472337,
      "win_rate": 0.4673531746031746,
      "useful": 508,
      "creative": 108,
      "complete": 356,
      "clear_formatting": 270,
      "incorrect": 124,
      "superficial": 203,
      "instructions_not_followed": 43,
      "total_prefs": 1612,
      "positive_prefs_ratio": 0.7704714640198511
    },
    {
      "model_name": "mistral-small-3.1-24b",
      "median": 1012.1209760071758,
      "p2.5": 1003.2921403546206,
      "p97.5": 1020.5991984361782,
      "rank": 40,
      "rank_p2.5": 36,
      "rank_p97.5": 43,
      "total_output_tokens": 4470466,
      "conso_all_conv": 26.882014772946647,
      "n_match": 5079,
      "mean_conso_per_match": 0.005292777076776264,
      "mean_conso_per_token": 6.013246666666662e-06,
      "mean_win_prob": 0.5147185159033105,
      "win_rate": 0.4945107304587517,
      "useful": 1108,
      "creative": 247,
      "complete": 791,
      "clear_formatting": 916,
      "incorrect": 268,
      "superficial": 430,
      "instructions_not_followed": 130,
      "total_prefs": 3890,
      "positive_prefs_ratio": 0.787146529562982
    },
    {
      "model_name": "mistral-saba",
      "median": 1010.0337146291546,
      "p2.5": 1001.0635362346832,
      "p97.5": 1019.0921239837776,
      "rank": 41,
      "rank_p2.5": 37,
      "rank_p97.5": 44,
      "total_output_tokens": 3490208,
      "conso_all_conv": 20.987481621973405,
      "n_match": 3944,
      "mean_conso_per_match": 0.005321369579607861,
      "mean_conso_per_token": 6.013246666666687e-06,
      "mean_win_prob": 0.5118317781686801,
      "win_rate": 0.4697767630644343,
      "useful": 681,
      "creative": 156,
      "complete": 516,
      "clear_formatting": 521,
      "incorrect": 217,
      "superficial": 327,
      "instructions_not_followed": 109,
      "total_prefs": 2527,
      "positive_prefs_ratio": 0.7415908191531461
    },
    {
      "model_name": "Apertus-70B-Instruct-2509",
      "median": 1007.1996060573665,
      "p2.5": 941.4856254890663,
      "p97.5": 1070.0036107187889,
      "rank": 42,
      "rank_p2.5": 18,
      "rank_p97.5": 65,
      "total_output_tokens": 92469,
      "conso_all_conv": 1.1529713026000001,
      "n_match": 89,
      "mean_conso_per_match": 0.012954733737078653,
      "mean_conso_per_token": 1.2468733333333335e-05,
      "mean_win_prob": 0.5079115231651958,
      "win_rate": 0.4638372093023256,
      "useful": 3,
      "creative": 1,
      "complete": 2,
      "clear_formatting": 0,
      "incorrect": 1,
      "superficial": 1,
      "instructions_not_followed": 1,
      "total_prefs": 9,
      "positive_prefs_ratio": 0.6666666666666666
    },
    {
      "model_name": "gemma-2-27b-it-q8",
      "median": 1003.9484506806577,
      "p2.5": 978.9693612496596,
      "p97.5": 1028.0928393420227,
      "rank": 43,
      "rank_p2.5": 34,
      "rank_p97.5": 52,
      "total_output_tokens": 449540,
      "conso_all_conv": 2.8924557419333343,
      "n_match": 762,
      "mean_conso_per_match": 0.0037958736770778664,
      "mean_conso_per_token": 6.434256666666669e-06,
      "mean_win_prob": 0.5034140665913477,
      "win_rate": 0.5826115485564304,
      "useful": 318,
      "creative": 97,
      "complete": 178,
      "clear_formatting": 305,
      "incorrect": 63,
      "superficial": 91,
      "instructions_not_followed": 29,
      "total_prefs": 1081,
      "positive_prefs_ratio": 0.8307123034227567
    },
    {
      "model_name": "qwen3-30b-a3b",
      "median": 999.3207531007959,
      "p2.5": 974.8730981442072,
      "p97.5": 1022.534193220067,
      "rank": 44,
      "rank_p2.5": 36,
      "rank_p97.5": 54,
      "total_output_tokens": 827675,
      "conso_all_conv": 2.537797772583332,
      "n_match": 570,
      "mean_conso_per_match": 0.004452276794005845,
      "mean_conso_per_token": 3.0661766666666647e-06,
      "mean_win_prob": 0.4970130791027926,
      "win_rate": 0.45509666080843586,
      "useful": 37,
      "creative": 12,
      "complete": 35,
      "clear_formatting": 19,
      "incorrect": 19,
      "superficial": 15,
      "instructions_not_followed": 5,
      "total_prefs": 142,
      "positive_prefs_ratio": 0.7253521126760564
    },
    {
      "model_name": "aya-expanse-32b",
      "median": 995.8601693060491,
      "p2.5": 985.8553769797651,
      "p97.5": 1005.1281690196247,
      "rank": 45,
      "rank_p2.5": 42,
      "rank_p97.5": 49,
      "total_output_tokens": 3307611,
      "conso_all_conv": 23.602913639340073,
      "n_match": 4054,
      "mean_conso_per_match": 0.005822129659432677,
      "mean_conso_per_token": 7.135940000000022e-06,
      "mean_win_prob": 0.4922280185520432,
      "win_rate": 0.4701578687715836,
      "useful": 661,
      "creative": 130,
      "complete": 471,
      "clear_formatting": 480,
      "incorrect": 241,
      "superficial": 321,
      "instructions_not_followed": 99,
      "total_prefs": 2403,
      "positive_prefs_ratio": 0.7249271743653766
    },
    {
      "model_name": "mistral-small-24b-instruct-2501",
      "median": 990.9958515956844,
      "p2.5": 980.2911373559716,
      "p97.5": 1002.1825210675153,
      "rank": 46,
      "rank_p2.5": 43,
      "rank_p97.5": 52,
      "total_output_tokens": 2818040,
      "conso_all_conv": 16.945569636533342,
      "n_match": 3318,
      "mean_conso_per_match": 0.0051071638446453715,
      "mean_conso_per_token": 6.01324666666667e-06,
      "mean_win_prob": 0.48550599842196407,
      "win_rate": 0.4952350813743219,
      "useful": 745,
      "creative": 155,
      "complete": 536,
      "clear_formatting": 656,
      "incorrect": 204,
      "superficial": 307,
      "instructions_not_followed": 71,
      "total_prefs": 2674,
      "positive_prefs_ratio": 0.7823485415108452
    },
    {
      "model_name": "o3-mini",
      "median": 989.3900754640231,
      "p2.5": 975.1306461257526,
      "p97.5": 1004.3552893603805,
      "rank": 47,
      "rank_p2.5": 42,
      "rank_p97.5": 54,
      "total_output_tokens": 1655945,
      "conso_all_conv": 8.563266942533337,
      "n_match": 1619,
      "mean_conso_per_match": 0.005289232206629609,
      "mean_conso_per_token": 5.171226666666669e-06,
      "mean_win_prob": 0.4832883435335579,
      "win_rate": 0.51142063001853,
      "useful": 350,
      "creative": 85,
      "complete": 254,
      "clear_formatting": 230,
      "incorrect": 49,
      "superficial": 133,
      "instructions_not_followed": 28,
      "total_prefs": 1129,
      "positive_prefs_ratio": 0.8139946855624446
    },
    {
      "model_name": "llama-3.3-70b",
      "median": 986.8666324989579,
      "p2.5": 979.7872249601027,
      "p97.5": 994.0686360448292,
      "rank": 48,
      "rank_p2.5": 45,
      "rank_p97.5": 53,
      "total_output_tokens": 6044909,
      "conso_all_conv": 75.37235834526696,
      "n_match": 7120,
      "mean_conso_per_match": 0.010586005385571202,
      "mean_conso_per_token": 1.2468733333333382e-05,
      "mean_win_prob": 0.4798050316204729,
      "win_rate": 0.4730341340075854,
      "useful": 1344,
      "creative": 266,
      "complete": 1031,
      "clear_formatting": 994,
      "incorrect": 411,
      "superficial": 563,
      "instructions_not_followed": 132,
      "total_prefs": 4741,
      "positive_prefs_ratio": 0.7667158827251634
    },
    {
      "model_name": "gpt-4o-mini-2024-07-18",
      "median": 986.6033024198152,
      "p2.5": 979.2774635557814,
      "p97.5": 994.6729348981037,
      "rank": 49,
      "rank_p2.5": 45,
      "rank_p97.5": 53,
      "total_output_tokens": 5207480,
      "conso_all_conv": 26.92905944213318,
      "n_match": 6990,
      "mean_conso_per_match": 0.003852512080419625,
      "mean_conso_per_token": 5.1712266666666375e-06,
      "mean_win_prob": 0.47944166513342285,
      "win_rate": 0.4994706723891274,
      "useful": 1491,
      "creative": 319,
      "complete": 856,
      "clear_formatting": 1282,
      "incorrect": 369,
      "superficial": 599,
      "instructions_not_followed": 110,
      "total_prefs": 5026,
      "positive_prefs_ratio": 0.7855153203342619
    },
    {
      "model_name": "gpt-4.1-nano",
      "median": 983.7403221730285,
      "p2.5": 975.0711019144551,
      "p97.5": 992.3111270316522,
      "rank": 50,
      "rank_p2.5": 46,
      "rank_p97.5": 54,
      "total_output_tokens": 3046683,
      "conso_all_conv": 17.89289505752994,
      "n_match": 4646,
      "mean_conso_per_match": 0.0038512473218962422,
      "mean_conso_per_token": 5.8729099999999805e-06,
      "mean_win_prob": 0.47549280990212905,
      "win_rate": 0.4719436074042187,
      "useful": 861,
      "creative": 149,
      "complete": 481,
      "clear_formatting": 609,
      "incorrect": 245,
      "superficial": 415,
      "instructions_not_followed": 94,
      "total_prefs": 2854,
      "positive_prefs_ratio": 0.7358093903293623
    },
    {
      "model_name": "aya-expanse-8b",
      "median": 977.243088052832,
      "p2.5": 960.2885384199706,
      "p97.5": 992.9236322489377,
      "rank": 51,
      "rank_p2.5": 46,
      "rank_p97.5": 60,
      "total_output_tokens": 1057810,
      "conso_all_conv": 3.9856799865999952,
      "n_match": 1302,
      "mean_conso_per_match": 0.0030611981463901654,
      "mean_conso_per_token": 3.7678599999999955e-06,
      "mean_win_prob": 0.46654503739766673,
      "win_rate": 0.5014285714285713,
      "useful": 243,
      "creative": 55,
      "complete": 133,
      "clear_formatting": 223,
      "incorrect": 149,
      "superficial": 104,
      "instructions_not_followed": 31,
      "total_prefs": 938,
      "positive_prefs_ratio": 0.697228144989339
    },
    {
      "model_name": "jamba-1.5-large",
      "median": 976.8573295487417,
      "p2.5": 930.7290317803967,
      "p97.5": 1023.6183379558314,
      "rank": 52,
      "rank_p2.5": 35,
      "rank_p97.5": 68,
      "total_output_tokens": 143976,
      "conso_all_conv": 6.8403631094399975,
      "n_match": 172,
      "mean_conso_per_match": 0.03976955296186045,
      "mean_conso_per_token": 4.751043999999998e-05,
      "mean_win_prob": 0.4660144675996289,
      "win_rate": 0.5449418604651162,
      "useful": 44,
      "creative": 11,
      "complete": 18,
      "clear_formatting": 57,
      "incorrect": 15,
      "superficial": 13,
      "instructions_not_followed": 4,
      "total_prefs": 162,
      "positive_prefs_ratio": 0.8024691358024691
    },
    {
      "model_name": "llama-3.1-70b",
      "median": 976.6167498506961,
      "p2.5": 967.5806245664164,
      "p97.5": 985.0082477637961,
      "rank": 53,
      "rank_p2.5": 50,
      "rank_p97.5": 58,
      "total_output_tokens": 4057254,
      "conso_all_conv": 50.58881819160004,
      "n_match": 5583,
      "mean_conso_per_match": 0.009061224823858148,
      "mean_conso_per_token": 1.2468733333333343e-05,
      "mean_win_prob": 0.4656836180856821,
      "win_rate": 0.530445996775927,
      "useful": 1532,
      "creative": 365,
      "complete": 1047,
      "clear_formatting": 1305,
      "incorrect": 463,
      "superficial": 621,
      "instructions_not_followed": 177,
      "total_prefs": 5510,
      "positive_prefs_ratio": 0.7711433756805808
    },
    {
      "model_name": "claude-3-5-sonnet-v2",
      "median": 975.9012889370675,
      "p2.5": 967.7612048292073,
      "p97.5": 985.0025298289383,
      "rank": 54,
      "rank_p2.5": 49,
      "rank_p97.5": 58,
      "total_output_tokens": 3224219,
      "conso_all_conv": 282.0713150900388,
      "n_match": 5683,
      "mean_conso_per_match": 0.049634227536519235,
      "mean_conso_per_token": 8.748515999999963e-05,
      "mean_win_prob": 0.46469989826840236,
      "win_rate": 0.49210804152736226,
      "useful": 1301,
      "creative": 291,
      "complete": 721,
      "clear_formatting": 905,
      "incorrect": 250,
      "superficial": 606,
      "instructions_not_followed": 94,
      "total_prefs": 4168,
      "positive_prefs_ratio": 0.7720729366602687
    },
    {
      "model_name": "phi-4",
      "median": 972.3927540410971,
      "p2.5": 965.4936468572548,
      "p97.5": 979.3687582378553,
      "rank": 55,
      "rank_p2.5": 52,
      "rank_p97.5": 59,
      "total_output_tokens": 6999198,
      "conso_all_conv": 32.26546287624011,
      "n_match": 8355,
      "mean_conso_per_match": 0.0038618148265996536,
      "mean_conso_per_token": 4.609880000000015e-06,
      "mean_win_prob": 0.45988028804212167,
      "win_rate": 0.4790687096001915,
      "useful": 1560,
      "creative": 319,
      "complete": 1125,
      "clear_formatting": 1265,
      "incorrect": 644,
      "superficial": 701,
      "instructions_not_followed": 225,
      "total_prefs": 5839,
      "positive_prefs_ratio": 0.7311183421818804
    },
    {
      "model_name": "ministral-8b-instruct-2410",
      "median": 968.1516855712291,
      "p2.5": 961.453627958586,
      "p97.5": 975.1653482027714,
      "rank": 56,
      "rank_p2.5": 54,
      "rank_p97.5": 60,
      "total_output_tokens": 7488476,
      "conso_all_conv": 28.215529181359923,
      "n_match": 9278,
      "mean_conso_per_match": 0.0030411219208191335,
      "mean_conso_per_token": 3.7678599999999895e-06,
      "mean_win_prob": 0.45406513318009256,
      "win_rate": 0.47576819407008086,
      "useful": 1796,
      "creative": 412,
      "complete": 1332,
      "clear_formatting": 1695,
      "incorrect": 876,
      "superficial": 927,
      "instructions_not_followed": 274,
      "total_prefs": 7312,
      "positive_prefs_ratio": 0.7159463894967177
    },
    {
      "model_name": "qwen-3-8b",
      "median": 967.9561583110471,
      "p2.5": 920.0293418333697,
      "p97.5": 1019.1529949489235,
      "rank": 57,
      "rank_p2.5": 37,
      "rank_p97.5": 70,
      "total_output_tokens": 265806,
      "conso_all_conv": 1.0015197951599997,
      "n_match": 142,
      "mean_conso_per_match": 0.007052956303943659,
      "mean_conso_per_token": 3.767859999999999e-06,
      "mean_win_prob": 0.45379734029991936,
      "win_rate": 0.45935714285714285,
      "useful": 7,
      "creative": 0,
      "complete": 6,
      "clear_formatting": 6,
      "incorrect": 1,
      "superficial": 1,
      "instructions_not_followed": 2,
      "total_prefs": 23,
      "positive_prefs_ratio": 0.8260869565217391
    },
    {
      "model_name": "gpt-4o-2024-08-06",
      "median": 966.3657113812874,
      "p2.5": 957.8476470466009,
      "p97.5": 975.514288582627,
      "rank": 58,
      "rank_p2.5": 54,
      "rank_p97.5": 62,
      "total_output_tokens": 3903917,
      "conso_all_conv": 341.53480337171897,
      "n_match": 5896,
      "mean_conso_per_match": 0.057926527030481505,
      "mean_conso_per_token": 8.748515999999973e-05,
      "mean_win_prob": 0.45162012715474126,
      "win_rate": 0.48863297150610585,
      "useful": 1230,
      "creative": 243,
      "complete": 593,
      "clear_formatting": 1002,
      "incorrect": 275,
      "superficial": 590,
      "instructions_not_followed": 115,
      "total_prefs": 4048,
      "positive_prefs_ratio": 0.7579051383399209
    },
    {
      "model_name": "qwen2.5-32b-instruct",
      "median": 964.7112004298588,
      "p2.5": 908.4456094701044,
      "p97.5": 1023.1470396739749,
      "rank": 59,
      "rank_p2.5": 36,
      "rank_p97.5": 71,
      "total_output_tokens": 75812,
      "conso_all_conv": 0.5409898832799998,
      "n_match": 142,
      "mean_conso_per_match": 0.0038097879104225336,
      "mean_conso_per_token": 7.135939999999997e-06,
      "mean_win_prob": 0.44935726275682814,
      "win_rate": 0.5557042253521126,
      "useful": 52,
      "creative": 16,
      "complete": 43,
      "clear_formatting": 57,
      "incorrect": 13,
      "superficial": 21,
      "instructions_not_followed": 15,
      "total_prefs": 217,
      "positive_prefs_ratio": 0.7741935483870968
    },
    {
      "model_name": "Apertus-8B-Instruct-2509",
      "median": 963.860659810257,
      "p2.5": 910.3610551315488,
      "p97.5": 1020.0680884130176,
      "rank": 60,
      "rank_p2.5": 37,
      "rank_p97.5": 70,
      "total_output_tokens": 52304,
      "conso_all_conv": 0.19707414944000004,
      "n_match": 86,
      "mean_conso_per_match": 0.002291559877209303,
      "mean_conso_per_token": 3.767860000000001e-06,
      "mean_win_prob": 0.4481948237983913,
      "win_rate": 0.46869047619047627,
      "useful": 2,
      "creative": 0,
      "complete": 3,
      "clear_formatting": 2,
      "incorrect": 3,
      "superficial": 5,
      "instructions_not_followed": 0,
      "total_prefs": 15,
      "positive_prefs_ratio": 0.4666666666666667
    },
    {
      "model_name": "llama-3.1-405b",
      "median": 961.8425812433774,
      "p2.5": 955.4483572718964,
      "p97.5": 968.3006913936042,
      "rank": 61,
      "rank_p2.5": 57,
      "rank_p97.5": 63,
      "total_output_tokens": 10383810,
      "conso_all_conv": 2470.579070314012,
      "n_match": 9973,
      "mean_conso_per_match": 0.24772676930853424,
      "mean_conso_per_token": 0.0002379260666666678,
      "mean_win_prob": 0.4454390685427613,
      "win_rate": 0.4950747166783673,
      "useful": 2224,
      "creative": 556,
      "complete": 1579,
      "clear_formatting": 1788,
      "incorrect": 947,
      "superficial": 890,
      "instructions_not_followed": 437,
      "total_prefs": 8421,
      "positive_prefs_ratio": 0.7299608122550766
    },
    {
      "model_name": "deepseek-r1-distill-llama-70b",
      "median": 957.954643681275,
      "p2.5": 946.1166577290973,
      "p97.5": 969.1456150500622,
      "rank": 62,
      "rank_p2.5": 57,
      "rank_p97.5": 65,
      "total_output_tokens": 2499440,
      "conso_all_conv": 31.164850842666663,
      "n_match": 2721,
      "mean_conso_per_match": 0.011453454921964963,
      "mean_conso_per_token": 1.2468733333333331e-05,
      "mean_win_prob": 0.44013981979889816,
      "win_rate": 0.44303420375137914,
      "useful": 483,
      "creative": 128,
      "complete": 348,
      "clear_formatting": 360,
      "incorrect": 178,
      "superficial": 328,
      "instructions_not_followed": 119,
      "total_prefs": 1944,
      "positive_prefs_ratio": 0.6784979423868313
    },
    {
      "model_name": "gemma-2-9b-it",
      "median": 957.0144996911033,
      "p2.5": 947.4212088823627,
      "p97.5": 966.682336920708,
      "rank": 63,
      "rank_p2.5": 58,
      "rank_p97.5": 65,
      "total_output_tokens": 3108609,
      "conso_all_conv": 12.149055331770018,
      "n_match": 5115,
      "mean_conso_per_match": 0.0023751818830439917,
      "mean_conso_per_token": 3.908196666666672e-06,
      "mean_win_prob": 0.4388604518815837,
      "win_rate": 0.5068660801564027,
      "useful": 1250,
      "creative": 403,
      "complete": 771,
      "clear_formatting": 1197,
      "incorrect": 472,
      "superficial": 595,
      "instructions_not_followed": 177,
      "total_prefs": 4865,
      "positive_prefs_ratio": 0.7442959917780062
    },
    {
      "model_name": "qwq-32b",
      "median": 956.8988898259602,
      "p2.5": 941.4142884036539,
      "p97.5": 972.0214074379812,
      "rank": 64,
      "rank_p2.5": 56,
      "rank_p97.5": 66,
      "total_output_tokens": 1895013,
      "conso_all_conv": 13.522699067219994,
      "n_match": 1566,
      "mean_conso_per_match": 0.008635184589540226,
      "mean_conso_per_token": 7.135939999999997e-06,
      "mean_win_prob": 0.4387031843935816,
      "win_rate": 0.4485997442455244,
      "useful": 291,
      "creative": 139,
      "complete": 343,
      "clear_formatting": 233,
      "incorrect": 140,
      "superficial": 105,
      "instructions_not_followed": 92,
      "total_prefs": 1343,
      "positive_prefs_ratio": 0.7490692479523455
    },
    {
      "model_name": "gpt-5-nano",
      "median": 948.5808238582335,
      "p2.5": 923.9939078678879,
      "p97.5": 973.8407988959997,
      "rank": 65,
      "rank_p2.5": 54,
      "rank_p97.5": 70,
      "total_output_tokens": 414724,
      "conso_all_conv": 1.7372249218800022,
      "n_match": 524,
      "mean_conso_per_match": 0.003315314736412218,
      "mean_conso_per_token": 4.188870000000005e-06,
      "mean_win_prob": 0.42742256947051344,
      "win_rate": 0.3965648854961832,
      "useful": 13,
      "creative": 2,
      "complete": 14,
      "clear_formatting": 9,
      "incorrect": 5,
      "superficial": 9,
      "instructions_not_followed": 8,
      "total_prefs": 60,
      "positive_prefs_ratio": 0.6333333333333333
    },
    {
      "model_name": "hermes-3-llama-3.1-405b",
      "median": 946.7400858175397,
      "p2.5": 939.0349229990242,
      "p97.5": 954.4688850288734,
      "rank": 66,
      "rank_p2.5": 62,
      "rank_p97.5": 66,
      "total_output_tokens": 4092822,
      "conso_all_conv": 973.7890400268014,
      "n_match": 6735,
      "mean_conso_per_match": 0.14458634595795122,
      "mean_conso_per_token": 0.00023792606666666702,
      "mean_win_prob": 0.42493606609613704,
      "win_rate": 0.46634743875278395,
      "useful": 1450,
      "creative": 285,
      "complete": 830,
      "clear_formatting": 1109,
      "incorrect": 426,
      "superficial": 753,
      "instructions_not_followed": 184,
      "total_prefs": 5037,
      "positive_prefs_ratio": 0.7294024220766329
    },
    {
      "model_name": "c4ai-command-r-08-2024",
      "median": 934.5614079039683,
      "p2.5": 926.307482564669,
      "p97.5": 943.4232596718177,
      "rank": 67,
      "rank_p2.5": 65,
      "rank_p97.5": 69,
      "total_output_tokens": 4319206,
      "conso_all_conv": 32.640023781700094,
      "n_match": 5959,
      "mean_conso_per_match": 0.005477433089729836,
      "mean_conso_per_token": 7.556950000000022e-06,
      "mean_win_prob": 0.4085859336735136,
      "win_rate": 0.42968786709179396,
      "useful": 1075,
      "creative": 255,
      "complete": 843,
      "clear_formatting": 796,
      "incorrect": 471,
      "superficial": 660,
      "instructions_not_followed": 163,
      "total_prefs": 4263,
      "positive_prefs_ratio": 0.6964578935022285
    },
    {
      "model_name": "qwen2.5-coder-32b-instruct",
      "median": 931.1064412787455,
      "p2.5": 923.4861805091235,
      "p97.5": 938.9385980284532,
      "rank": 68,
      "rank_p2.5": 66,
      "rank_p97.5": 70,
      "total_output_tokens": 6149486,
      "conso_all_conv": 43.88236312684005,
      "n_match": 7299,
      "mean_conso_per_match": 0.00601210619630635,
      "mean_conso_per_token": 7.135940000000008e-06,
      "mean_win_prob": 0.40398226841902285,
      "win_rate": 0.43789423208658723,
      "useful": 1379,
      "creative": 293,
      "complete": 923,
      "clear_formatting": 1142,
      "incorrect": 790,
      "superficial": 742,
      "instructions_not_followed": 234,
      "total_prefs": 5503,
      "positive_prefs_ratio": 0.6790841359258586
    },
    {
      "model_name": "qwen2.5-7b-instruct",
      "median": 930.2032679986778,
      "p2.5": 911.8371322766343,
      "p97.5": 947.9086389743937,
      "rank": 69,
      "rank_p2.5": 64,
      "rank_p97.5": 71,
      "total_output_tokens": 1186919,
      "conso_all_conv": 4.3055763672766725,
      "n_match": 1417,
      "mean_conso_per_match": 0.003038515432093629,
      "mean_conso_per_token": 3.627523333333338e-06,
      "mean_win_prob": 0.4027815239589935,
      "win_rate": 0.49383909668313336,
      "useful": 402,
      "creative": 104,
      "complete": 284,
      "clear_formatting": 380,
      "incorrect": 231,
      "superficial": 203,
      "instructions_not_followed": 88,
      "total_prefs": 1692,
      "positive_prefs_ratio": 0.6914893617021277
    },
    {
      "model_name": "llama-3.1-8b",
      "median": 928.0381095889402,
      "p2.5": 920.693891928848,
      "p97.5": 935.3693467582158,
      "rank": 70,
      "rank_p2.5": 66,
      "rank_p97.5": 70,
      "total_output_tokens": 6093696,
      "conso_all_conv": 22.960193410559935,
      "n_match": 8402,
      "mean_conso_per_match": 0.00273270571418233,
      "mean_conso_per_token": 3.767859999999989e-06,
      "mean_win_prob": 0.39990770499016887,
      "win_rate": 0.4417390786811094,
      "useful": 1481,
      "creative": 361,
      "complete": 962,
      "clear_formatting": 1115,
      "incorrect": 953,
      "superficial": 928,
      "instructions_not_followed": 384,
      "total_prefs": 6184,
      "positive_prefs_ratio": 0.633732212160414
    },
    {
      "model_name": "hermes-4-70b",
      "median": 899.1847077347403,
      "p2.5": 870.7146742651807,
      "p97.5": 925.9765902402896,
      "rank": 71,
      "rank_p2.5": 70,
      "rank_p97.5": 73,
      "total_output_tokens": 218566,
      "conso_all_conv": 2.725241169733333,
      "n_match": 478,
      "mean_conso_per_match": 0.005701341359274755,
      "mean_conso_per_token": 1.2468733333333333e-05,
      "mean_win_prob": 0.3623199116191135,
      "win_rate": 0.35016806722689076,
      "useful": 13,
      "creative": 6,
      "complete": 4,
      "clear_formatting": 8,
      "incorrect": 8,
      "superficial": 12,
      "instructions_not_followed": 5,
      "total_prefs": 56,
      "positive_prefs_ratio": 0.5535714285714286
    },
    {
      "model_name": "mixtral-8x7b-instruct-v0.1",
      "median": 887.8765837073577,
      "p2.5": 874.367218732117,
      "p97.5": 901.8278538338998,
      "rank": 72,
      "rank_p2.5": 71,
      "rank_p97.5": 73,
      "total_output_tokens": 1575791,
      "conso_all_conv": 7.2642074150800156,
      "n_match": 2560,
      "mean_conso_per_match": 0.002837581021515631,
      "mean_conso_per_token": 4.60988000000001e-06,
      "mean_win_prob": 0.3479968510057423,
      "win_rate": 0.43488671874999996,
      "useful": 727,
      "creative": 164,
      "complete": 375,
      "clear_formatting": 503,
      "incorrect": 256,
      "superficial": 389,
      "instructions_not_followed": 159,
      "total_prefs": 2573,
      "positive_prefs_ratio": 0.687524290711232
    },
    {
      "model_name": "lfm-40b",
      "median": 886.5409894182878,
      "p2.5": 875.6026976437395,
      "p97.5": 897.7181509240683,
      "rank": 73,
      "rank_p2.5": 71,
      "rank_p97.5": 73,
      "total_output_tokens": 2000824,
      "conso_all_conv": 16.524071780533326,
      "n_match": 3578,
      "mean_conso_per_match": 0.004618242532289918,
      "mean_conso_per_token": 8.25863333333333e-06,
      "mean_win_prob": 0.3463219869858048,
      "win_rate": 0.416296813862493,
      "useful": 841,
      "creative": 166,
      "complete": 419,
      "clear_formatting": 647,
      "incorrect": 357,
      "superficial": 572,
      "instructions_not_followed": 121,
      "total_prefs": 3123,
      "positive_prefs_ratio": 0.6637848222862632
    },
    {
      "model_name": "phi-3.5-mini-instruct",
      "median": 864.5438116063076,
      "p2.5": 849.2587255205209,
      "p97.5": 878.1455533195822,
      "rank": 74,
      "rank_p2.5": 73,
      "rank_p97.5": 75,
      "total_output_tokens": 2149046,
      "conso_all_conv": 6.589354700793317,
      "n_match": 2535,
      "mean_conso_per_match": 0.0025993509667823736,
      "mean_conso_per_token": 3.0661766666666592e-06,
      "mean_win_prob": 0.319285511292743,
      "win_rate": 0.4021104536489152,
      "useful": 636,
      "creative": 226,
      "complete": 477,
      "clear_formatting": 533,
      "incorrect": 428,
      "superficial": 449,
      "instructions_not_followed": 300,
      "total_prefs": 3049,
      "positive_prefs_ratio": 0.6139717940308298
    },
    {
      "model_name": "mistral-nemo-2407",
      "median": 855.5984479903573,
      "p2.5": 846.1346322521865,
      "p97.5": 864.4024032064071,
      "rank": 75,
      "rank_p2.5": 74,
      "rank_p97.5": 76,
      "total_output_tokens": 3305342,
      "conso_all_conv": 14.309508622013313,
      "n_match": 6251,
      "mean_conso_per_match": 0.0022891551147037775,
      "mean_conso_per_token": 4.329206666666661e-06,
      "mean_win_prob": 0.30860368652407366,
      "win_rate": 0.37482482802751566,
      "useful": 1413,
      "creative": 225,
      "complete": 661,
      "clear_formatting": 900,
      "incorrect": 638,
      "superficial": 1088,
      "instructions_not_followed": 292,
      "total_prefs": 5217,
      "positive_prefs_ratio": 0.6131876557408472
    },
    {
      "model_name": "mixtral-8x22b-instruct-v0.1",
      "median": 845.1138308444449,
      "p2.5": 835.8689528369678,
      "p97.5": 854.42353747617,
      "rank": 76,
      "rank_p2.5": 75,
      "rank_p97.5": 77,
      "total_output_tokens": 3041056,
      "conso_all_conv": 53.644106197760124,
      "n_match": 5455,
      "mean_conso_per_match": 0.009833933308480316,
      "mean_conso_per_token": 1.7639960000000042e-05,
      "mean_win_prob": 0.2963285872318879,
      "win_rate": 0.3671035747021082,
      "useful": 1117,
      "creative": 203,
      "complete": 516,
      "clear_formatting": 702,
      "incorrect": 535,
      "superficial": 934,
      "instructions_not_followed": 276,
      "total_prefs": 4283,
      "positive_prefs_ratio": 0.5925752976885361
    },
    {
      "model_name": "chocolatine-2-14b-instruct-v2.0.3-q8",
      "median": 823.7259919292206,
      "p2.5": 807.2064915801914,
      "p97.5": 839.3111195736451,
      "rank": 77,
      "rank_p2.5": 77,
      "rank_p97.5": 78,
      "total_output_tokens": 533384,
      "conso_all_conv": 1.934862905626671,
      "n_match": 1796,
      "mean_conso_per_match": 0.0010773178761841152,
      "mean_conso_per_token": 3.6275233333333416e-06,
      "mean_win_prob": 0.27214774859609736,
      "win_rate": 0.33173162583518934,
      "useful": 280,
      "creative": 37,
      "complete": 100,
      "clear_formatting": 199,
      "incorrect": 161,
      "superficial": 370,
      "instructions_not_followed": 50,
      "total_prefs": 1197,
      "positive_prefs_ratio": 0.5146198830409356
    },
    {
      "model_name": "Yi-1.5-9B-Chat",
      "median": 767.4347993725305,
      "p2.5": 671.9318062599262,
      "p97.5": 850.356896293908,
      "rank": 78,
      "rank_p2.5": 76,
      "rank_p97.5": 80,
      "total_output_tokens": 47531,
      "conso_all_conv": 0.1857604957633333,
      "n_match": 65,
      "mean_conso_per_match": 0.0028578537809743586,
      "mean_conso_per_token": 3.908196666666666e-06,
      "mean_win_prob": 0.21441748321718868,
      "win_rate": 0.326,
      "useful": 16,
      "creative": 5,
      "complete": 14,
      "clear_formatting": 19,
      "incorrect": 12,
      "superficial": 17,
      "instructions_not_followed": 14,
      "total_prefs": 97,
      "positive_prefs_ratio": 0.5567010309278351
    },
    {
      "model_name": "chocolatine-14b-instruct-dpo-v1.2-q4",
      "median": 750.5673999976505,
      "p2.5": 706.1724869819025,
      "p97.5": 795.5705048204945,
      "rank": 79,
      "rank_p2.5": 78,
      "rank_p97.5": 80,
      "total_output_tokens": 131187,
      "conso_all_conv": 0.6047563275600003,
      "n_match": 309,
      "mean_conso_per_match": 0.001957140218640778,
      "mean_conso_per_token": 4.6098800000000025e-06,
      "mean_win_prob": 0.1988579534486402,
      "win_rate": 0.2402265372168285,
      "useful": 83,
      "creative": 17,
      "complete": 39,
      "clear_formatting": 43,
      "incorrect": 52,
      "superficial": 107,
      "instructions_not_followed": 50,
      "total_prefs": 391,
      "positive_prefs_ratio": 0.46547314578005117
    },
    {
      "model_name": "qwen2-7b-instruct",
      "median": 733.1406447316264,
      "p2.5": 629.4283268318086,
      "p97.5": 812.8356203502497,
      "rank": 80,
      "rank_p2.5": 78,
      "rank_p97.5": 80,
      "total_output_tokens": 43550,
      "conso_all_conv": 0.15797864116666668,
      "n_match": 80,
      "mean_conso_per_match": 0.0019747330145833335,
      "mean_conso_per_token": 3.6275233333333336e-06,
      "mean_win_prob": 0.18363474147296793,
      "win_rate": 0.2525,
      "useful": 19,
      "creative": 4,
      "complete": 12,
      "clear_formatting": 22,
      "incorrect": 11,
      "superficial": 14,
      "instructions_not_followed": 7,
      "total_prefs": 89,
      "positive_prefs_ratio": 0.6404494382022472
    }
  ]
}