[
  {
    "model_name": "gemini-2.5-flash",
    "median": 1134.2560275339354,
    "p2.5": 1038.3917449863304,
    "p97.5": 1233.615715314911,
    "rank": 3,
    "rank_p2.5": 1,
    "rank_p97.5": 28,
    "total_output_tokens": 617870.0,
    "conso_all_conv": 7.704056264666665,
    "n_match": 812,
    "mean_conso_per_match": 0.00948775402052545,
    "mean_conso_per_token": 0.000012468733333333331
  },
  {
    "model_name": "gemini-2.0-flash-exp",
    "median": 1123.991117814709,
    "p2.5": 1029.9288754927113,
    "p97.5": 1221.5048163882084,
    "rank": 4,
    "rank_p2.5": 1,
    "rank_p97.5": 31,
    "total_output_tokens": 3936799.0,
    "conso_all_conv": 32.5125794480333,
    "n_match": 2816,
    "mean_conso_per_match": 0.011545660315352735,
    "mean_conso_per_token": 8.258633333333324e-6
  },
  {
    "model_name": "gemini-2.0-flash-001",
    "median": 1108.3366709697293,
    "p2.5": 1004.5485809439239,
    "p97.5": 1204.3643641163785,
    "rank": 5,
    "rank_p2.5": 1,
    "rank_p97.5": 40,
    "total_output_tokens": 8359986.0,
    "conso_all_conv": 69.04205904580003,
    "n_match": 5903,
    "mean_conso_per_match": 0.011696096738234801,
    "mean_conso_per_token": 8.258633333333338e-6
  },
  {
    "model_name": "gemma-3-27b",
    "median": 1108.1798634830848,
    "p2.5": 1010.8602564455514,
    "p97.5": 1209.4336309597215,
    "rank": 6,
    "rank_p2.5": 1,
    "rank_p97.5": 37,
    "total_output_tokens": 6498374.0,
    "conso_all_conv": 41.81220623199328,
    "n_match": 4859,
    "mean_conso_per_match": 0.008605105213417015,
    "mean_conso_per_token": 6.434256666666659e-6
  },
  {
    "model_name": "deepseek-v3-0324",
    "median": 1103.8817328059808,
    "p2.5": 1003.6474499130935,
    "p97.5": 1200.0921954992068,
    "rank": 7,
    "rank_p2.5": 1,
    "rank_p97.5": 39,
    "total_output_tokens": 4428337.0,
    "conso_all_conv": 208.2458243943793,
    "n_match": 4832,
    "mean_conso_per_match": 0.0430972318696977,
    "mean_conso_per_token": 0.00004702573999999984
  },
  {
    "model_name": "glm-4.5",
    "median": 1098.9761883726974,
    "p2.5": 1010.7370049079552,
    "p97.5": 1189.1845332086953,
    "rank": 8,
    "rank_p2.5": 2,
    "rank_p97.5": 38,
    "total_output_tokens": 122648.0,
    "conso_all_conv": 19.304065444399992,
    "n_match": 127,
    "mean_conso_per_match": 0.15200051531023615,
    "mean_conso_per_token": 0.00015739404999999993
  },
  {
    "model_name": "deepseek-v3-chat",
    "median": 1096.0289063734597,
    "p2.5": 992.3826278814518,
    "p97.5": 1181.9940146852387,
    "rank": 9,
    "rank_p2.5": 2,
    "rank_p97.5": 44,
    "total_output_tokens": 5638296.0,
    "conso_all_conv": 265.145041739039,
    "n_match": 5394,
    "mean_conso_per_match": 0.04915555093419337,
    "mean_conso_per_token": 0.000047025739999999826
  },
  {
    "model_name": "gpt-oss-120b",
    "median": 1089.0402126142621,
    "p2.5": 985.7731768101439,
    "p97.5": 1186.1695056236224,
    "rank": 10,
    "rank_p2.5": 2,
    "rank_p97.5": 45,
    "total_output_tokens": 948315.0,
    "conso_all_conv": 3.1738680577500005,
    "n_match": 842,
    "mean_conso_per_match": 0.00376943949851544,
    "mean_conso_per_token": 3.3468500000000004e-6
  },
  {
    "model_name": "gemma-3-12b",
    "median": 1085.3262163360941,
    "p2.5": 980.5469768250484,
    "p97.5": 1178.209230373332,
    "rank": 11,
    "rank_p2.5": 2,
    "rank_p97.5": 48,
    "total_output_tokens": 5733918.0,
    "conso_all_conv": 24.823316031720033,
    "n_match": 4522,
    "mean_conso_per_match": 0.005489455115373736,
    "mean_conso_per_token": 4.329206666666673e-6
  },
  {
    "model_name": "command-a",
    "median": 1074.7865679032034,
    "p2.5": 977.082942458762,
    "p97.5": 1173.2576959551754,
    "rank": 12,
    "rank_p2.5": 2,
    "rank_p97.5": 49,
    "total_output_tokens": 4137991.0,
    "conso_all_conv": 75.40469272383673,
    "n_match": 4415,
    "mean_conso_per_match": 0.01707920559996302,
    "mean_conso_per_token": 0.000018222536666666682
  },
  {
    "model_name": "grok-3-mini-beta",
    "median": 1070.6129072916326,
    "p2.5": 973.946063758547,
    "p97.5": 1169.1418335537087,
    "rank": 13,
    "rank_p2.5": 2,
    "rank_p97.5": 50,
    "total_output_tokens": 3468359.0,
    "conso_all_conv": 213.04395157500016,
    "n_match": 1572,
    "mean_conso_per_match": 0.13552414222328255,
    "mean_conso_per_token": 0.00006142500000000004
  },
  {
    "model_name": "gemini-1.5-pro-001",
    "median": 1068.961331093206,
    "p2.5": 952.9995099865441,
    "p97.5": 1176.5921909673207,
    "rank": 15,
    "rank_p2.5": 2,
    "rank_p97.5": 53,
    "total_output_tokens": 1731076.0,
    "conso_all_conv": 229.93791835866668,
    "n_match": 2360,
    "mean_conso_per_match": 0.09743132133841809,
    "mean_conso_per_token": 0.00013282947620940193
  },
  {
    "model_name": "magistral-small-2506",
    "median": 1066.0202798398432,
    "p2.5": 969.8244324670395,
    "p97.5": 1161.1655511487027,
    "rank": 16,
    "rank_p2.5": 3,
    "rank_p97.5": 49,
    "total_output_tokens": 334874.0,
    "conso_all_conv": 2.0136799642533347,
    "n_match": 1037,
    "mean_conso_per_match": 0.0019418321738219235,
    "mean_conso_per_token": 6.013246666666671e-6
  },
  {
    "model_name": "claude-4-sonnet",
    "median": 1062.6430364273533,
    "p2.5": 965.8892745265176,
    "p97.5": 1157.9642959857642,
    "rank": 17,
    "rank_p2.5": 3,
    "rank_p97.5": 51,
    "total_output_tokens": 385602.0,
    "conso_all_conv": 23.68560284999998,
    "n_match": 1092,
    "mean_conso_per_match": 0.021690112499999983,
    "mean_conso_per_token": 0.00006142499999999995
  },
  {
    "model_name": "claude-3-7-sonnet",
    "median": 1060.7500504957798,
    "p2.5": 959.1969951302129,
    "p97.5": 1159.681277510276,
    "rank": 18,
    "rank_p2.5": 3,
    "rank_p97.5": 52,
    "total_output_tokens": 3546728.0,
    "conso_all_conv": 476.1074466280003,
    "n_match": 3909,
    "mean_conso_per_match": 0.12179776071322596,
    "mean_conso_per_token": 0.00013423850000000007
  },
  {
    "model_name": "gemma-3-4b",
    "median": 1056.5902821427158,
    "p2.5": 957.5580010061709,
    "p97.5": 1155.6005222486222,
    "rank": 20,
    "rank_p2.5": 4,
    "rank_p97.5": 54,
    "total_output_tokens": 6678174.0,
    "conso_all_conv": 21.413653973319963,
    "n_match": 5382,
    "mean_conso_per_match": 0.003978753989840201,
    "mean_conso_per_token": 3.206513333333328e-6
  },
  {
    "model_name": "llama-3.1-nemotron-70b-instruct",
    "median": 1056.045254659348,
    "p2.5": 961.2067744662361,
    "p97.5": 1146.4620996241206,
    "rank": 21,
    "rank_p2.5": 5,
    "rank_p97.5": 53,
    "total_output_tokens": 7403970.0,
    "conso_all_conv": 92.31812753799976,
    "n_match": 6838,
    "mean_conso_per_match": 0.013500749859315554,
    "mean_conso_per_token": 0.000012468733333333301
  },
  {
    "model_name": "qwen3-32b",
    "median": 1051.1159868002926,
    "p2.5": 960.4805467266111,
    "p97.5": 1141.0773900560146,
    "rank": 22,
    "rank_p2.5": 5,
    "rank_p97.5": 53,
    "total_output_tokens": 1412357.0,
    "conso_all_conv": 10.078494810579992,
    "n_match": 748,
    "mean_conso_per_match": 0.013473923543556138,
    "mean_conso_per_token": 7.135939999999994e-6
  },
  {
    "model_name": "kimi-k2",
    "median": 1050.6900358163211,
    "p2.5": 945.2862803309774,
    "p97.5": 1143.913766162098,
    "rank": 23,
    "rank_p2.5": 5,
    "rank_p97.5": 56,
    "total_output_tokens": 105815.0,
    "conso_all_conv": 6.040715928799997,
    "n_match": 154,
    "mean_conso_per_match": 0.039225428109090896,
    "mean_conso_per_token": 0.00005708751999999997
  },
  {
    "model_name": "gpt-4.1-mini",
    "median": 1044.5825786044109,
    "p2.5": 946.0792106131452,
    "p97.5": 1146.4381043067542,
    "rank": 24,
    "rank_p2.5": 5,
    "rank_p97.5": 56,
    "total_output_tokens": 4581959.0,
    "conso_all_conv": 57.13122491526673,
    "n_match": 5695,
    "mean_conso_per_match": 0.010031821758606976,
    "mean_conso_per_token": 0.000012468733333333347
  },
  {
    "model_name": "deepseek-r1",
    "median": 1035.7167174694478,
    "p2.5": 940.4766199733144,
    "p97.5": 1141.156320008351,
    "rank": 26,
    "rank_p2.5": 6,
    "rank_p97.5": 57,
    "total_output_tokens": 3662507.0,
    "conso_all_conv": 172.23210193018028,
    "n_match": 3799,
    "mean_conso_per_match": 0.04533616792055285,
    "mean_conso_per_token": 0.00004702574000000008
  },
  {
    "model_name": "mistral-large-2411",
    "median": 1033.2811890147887,
    "p2.5": 936.886666215729,
    "p97.5": 1127.5919715999491,
    "rank": 27,
    "rank_p2.5": 6,
    "rank_p97.5": 58,
    "total_output_tokens": 7677266.0,
    "conso_all_conv": 152.82808421939282,
    "n_match": 8880,
    "mean_conso_per_match": 0.01721036984452622,
    "mean_conso_per_token": 0.0000199065766666666
  },
  {
    "model_name": "gpt-oss-20b",
    "median": 1032.8873820192225,
    "p2.5": 934.8151638237058,
    "p97.5": 1129.4614731904467,
    "rank": 28,
    "rank_p2.5": 6,
    "rank_p97.5": 58,
    "total_output_tokens": 537902.0,
    "conso_all_conv": 1.6493025613533336,
    "n_match": 1085,
    "mean_conso_per_match": 0.0015200945265929342,
    "mean_conso_per_token": 3.0661766666666673e-6
  },
  {
    "model_name": "gemini-1.5-pro-002",
    "median": 1029.95532522158,
    "p2.5": 937.9500910899158,
    "p97.5": 1135.3023151164584,
    "rank": 30,
    "rank_p2.5": 6,
    "rank_p97.5": 58,
    "total_output_tokens": 4303147.0,
    "conso_all_conv": 576.9527534425323,
    "n_match": 5035,
    "mean_conso_per_match": 0.11458843166683859,
    "mean_conso_per_token": 0.0001340769333333331
  },
  {
    "model_name": "llama-4-scout",
    "median": 1023.8740042117446,
    "p2.5": 929.5042202066314,
    "p97.5": 1112.2602418293409,
    "rank": 32,
    "rank_p2.5": 8,
    "rank_p97.5": 59,
    "total_output_tokens": 2450373.0,
    "conso_all_conv": 12.327557021970003,
    "n_match": 3273,
    "mean_conso_per_match": 0.003766439664518791,
    "mean_conso_per_token": 5.030890000000001e-6
  },
  {
    "model_name": "gemma-3n-e4b-it",
    "median": 1018.6406604056078,
    "p2.5": 925.5929553557946,
    "p97.5": 1124.9254438659093,
    "rank": 34,
    "rank_p2.5": 7,
    "rank_p97.5": 60,
    "total_output_tokens": 360025.0,
    "conso_all_conv": 1.1544249628333325,
    "n_match": 1087,
    "mean_conso_per_match": 0.0010620284846672792,
    "mean_conso_per_token": 3.206513333333331e-6
  },
  {
    "model_name": "mistral-small-3.1-24b",
    "median": 1018.0532525235893,
    "p2.5": 916.4081545204865,
    "p97.5": 1113.617779592481,
    "rank": 35,
    "rank_p2.5": 8,
    "rank_p97.5": 62,
    "total_output_tokens": 4470466.0,
    "conso_all_conv": 26.882014772946675,
    "n_match": 5104,
    "mean_conso_per_match": 0.005266852424166669,
    "mean_conso_per_token": 6.013246666666668e-6
  },
  {
    "model_name": "o4-mini",
    "median": 1015.6645977918304,
    "p2.5": 919.9546737747045,
    "p97.5": 1107.651550389574,
    "rank": 36,
    "rank_p2.5": 9,
    "rank_p97.5": 61,
    "total_output_tokens": 2288087.0,
    "conso_all_conv": 140.5457439749998,
    "n_match": 2088,
    "mean_conso_per_match": 0.06731118006465507,
    "mean_conso_per_token": 0.00006142499999999991
  },
  {
    "model_name": "gemma-2-27b-it-q8",
    "median": 1011.8163840102494,
    "p2.5": 892.97538893907,
    "p97.5": 1124.440293668381,
    "rank": 37,
    "rank_p2.5": 7,
    "rank_p97.5": 65,
    "total_output_tokens": 449540.0,
    "conso_all_conv": 2.892455741933333,
    "n_match": 762,
    "mean_conso_per_match": 0.0037958736770778647,
    "mean_conso_per_token": 6.434256666666666e-6
  },
  {
    "model_name": "mistral-saba",
    "median": 1002.4106858387034,
    "p2.5": 908.3359827727625,
    "p97.5": 1100.2896245946924,
    "rank": 38,
    "rank_p2.5": 11,
    "rank_p97.5": 63,
    "total_output_tokens": 3043927.0,
    "conso_all_conv": 18.30388388632673,
    "n_match": 3572,
    "mean_conso_per_match": 0.005124267605354628,
    "mean_conso_per_token": 6.013246666666688e-6
  },
  {
    "model_name": "qwen3-30b-a3b",
    "median": 1000.1145648428571,
    "p2.5": 901.8412851241953,
    "p97.5": 1100.53677685666,
    "rank": 39,
    "rank_p2.5": 11,
    "rank_p97.5": 64,
    "total_output_tokens": 134107.0,
    "conso_all_conv": 0.41119575423666666,
    "n_match": 416,
    "mean_conso_per_match": 0.0009884513322996795,
    "mean_conso_per_token": 3.0661766666666664e-6
  },
  {
    "model_name": "aya-expanse-32b",
    "median": 996.052569765062,
    "p2.5": 907.3757098028257,
    "p97.5": 1089.8058864861043,
    "rank": 40,
    "rank_p2.5": 13,
    "rank_p97.5": 63,
    "total_output_tokens": 2836974.0,
    "conso_all_conv": 20.244476245560026,
    "n_match": 3552,
    "mean_conso_per_match": 0.005699458402466224,
    "mean_conso_per_token": 7.135940000000009e-6
  },
  {
    "model_name": "o3-mini",
    "median": 994.5363803805249,
    "p2.5": 897.6506948038718,
    "p97.5": 1094.8201253770421,
    "rank": 42,
    "rank_p2.5": 12,
    "rank_p97.5": 64,
    "total_output_tokens": 1655945.0,
    "conso_all_conv": 101.71642162499995,
    "n_match": 1620,
    "mean_conso_per_match": 0.0627879145833333,
    "mean_conso_per_token": 0.00006142499999999998
  },
  {
    "model_name": "mistral-small-24b-instruct-2501",
    "median": 992.1179830936155,
    "p2.5": 893.8172010056147,
    "p97.5": 1089.8376111291764,
    "rank": 43,
    "rank_p2.5": 13,
    "rank_p97.5": 65,
    "total_output_tokens": 2818040.0,
    "conso_all_conv": 16.94556963653333,
    "n_match": 3319,
    "mean_conso_per_match": 0.0051056250787988346,
    "mean_conso_per_token": 6.013246666666666e-6
  },
  {
    "model_name": "llama-3.3-70b",
    "median": 990.7116044968982,
    "p2.5": 897.667528544176,
    "p97.5": 1093.0396865437747,
    "rank": 44,
    "rank_p2.5": 12,
    "rank_p97.5": 65,
    "total_output_tokens": 5635427.0,
    "conso_all_conv": 70.26663648246684,
    "n_match": 6738,
    "mean_conso_per_match": 0.010428411469644825,
    "mean_conso_per_token": 0.000012468733333333364
  },
  {
    "model_name": "gpt-4o-mini-2024-07-18",
    "median": 989.9788393728168,
    "p2.5": 887.4926116387802,
    "p97.5": 1090.243490327086,
    "rank": 45,
    "rank_p2.5": 14,
    "rank_p97.5": 65,
    "total_output_tokens": 5207480.0,
    "conso_all_conv": 39.34466317595004,
    "n_match": 6994,
    "mean_conso_per_match": 0.005625488014862745,
    "mean_conso_per_token": 7.555413208682518e-6
  },
  {
    "model_name": "gpt-4.1-nano",
    "median": 981.5841572335778,
    "p2.5": 887.5700915630947,
    "p97.5": 1089.5864355551003,
    "rank": 46,
    "rank_p2.5": 13,
    "rank_p97.5": 65,
    "total_output_tokens": 2762342.0,
    "conso_all_conv": 20.874880376899995,
    "n_match": 4300,
    "mean_conso_per_match": 0.0048546233434651155,
    "mean_conso_per_token": 7.556949999999998e-6
  },
  {
    "model_name": "llama-3.1-70b",
    "median": 981.3189872387238,
    "p2.5": 878.7862124572115,
    "p97.5": 1093.1099219385198,
    "rank": 47,
    "rank_p2.5": 13,
    "rank_p97.5": 66,
    "total_output_tokens": 4057254.0,
    "conso_all_conv": 50.588818191600005,
    "n_match": 5584,
    "mean_conso_per_match": 0.009059602111676219,
    "mean_conso_per_token": 0.000012468733333333335
  },
  {
    "model_name": "jamba-1.5-large",
    "median": 980.3806564841325,
    "p2.5": 873.2053884579585,
    "p97.5": 1087.9188885640874,
    "rank": 48,
    "rank_p2.5": 14,
    "rank_p97.5": 67,
    "total_output_tokens": 143976.0,
    "conso_all_conv": 6.840363109439999,
    "n_match": 172,
    "mean_conso_per_match": 0.03976955296186046,
    "mean_conso_per_token": 0.000047510439999999994
  },
  {
    "model_name": "aya-expanse-8b",
    "median": 979.6577797363311,
    "p2.5": 883.1637041240477,
    "p97.5": 1081.420574501269,
    "rank": 49,
    "rank_p2.5": 16,
    "rank_p97.5": 66,
    "total_output_tokens": 1057810.0,
    "conso_all_conv": 3.985679986599994,
    "n_match": 1302,
    "mean_conso_per_match": 0.003061198146390164,
    "mean_conso_per_token": 3.767859999999994e-6
  },
  {
    "model_name": "claude-3-5-sonnet-v2",
    "median": 978.9122934118849,
    "p2.5": 880.5638280397347,
    "p97.5": 1084.5227867311137,
    "rank": 50,
    "rank_p2.5": 15,
    "rank_p97.5": 66,
    "total_output_tokens": 3224219.0,
    "conso_all_conv": 432.81432223150125,
    "n_match": 5685,
    "mean_conso_per_match": 0.07613268640835553,
    "mean_conso_per_token": 0.0001342385000000004
  },
  {
    "model_name": "phi-4",
    "median": 974.9235476534786,
    "p2.5": 879.7100947516224,
    "p97.5": 1081.8506964468315,
    "rank": 52,
    "rank_p2.5": 14,
    "rank_p97.5": 66,
    "total_output_tokens": 6547451.0,
    "conso_all_conv": 30.182963415880067,
    "n_match": 8003,
    "mean_conso_per_match": 0.0037714561309359074,
    "mean_conso_per_token": 4.60988000000001e-6
  },
  {
    "model_name": "ministral-8b-instruct-2410",
    "median": 973.7676977012246,
    "p2.5": 872.321081472326,
    "p97.5": 1069.2281876067302,
    "rank": 53,
    "rank_p2.5": 19,
    "rank_p97.5": 67,
    "total_output_tokens": 7488476.0,
    "conso_all_conv": 28.21552918135988,
    "n_match": 9388,
    "mean_conso_per_match": 0.0030054888348274265,
    "mean_conso_per_token": 3.767859999999984e-6
  },
  {
    "model_name": "gpt-4o-2024-08-06",
    "median": 972.7782683939039,
    "p2.5": 874.4055109410259,
    "p97.5": 1069.900292550577,
    "rank": 54,
    "rank_p2.5": 18,
    "rank_p97.5": 67,
    "total_output_tokens": 3903917.0,
    "conso_all_conv": 239.79810172500032,
    "n_match": 5900,
    "mean_conso_per_match": 0.0406437460550848,
    "mean_conso_per_token": 0.00006142500000000008
  },
  {
    "model_name": "qwen2.5-32b-instruct",
    "median": 972.4513192789418,
    "p2.5": 853.7315261950562,
    "p97.5": 1081.2886973909988,
    "rank": 55,
    "rank_p2.5": 14,
    "rank_p97.5": 68,
    "total_output_tokens": 75812.0,
    "conso_all_conv": 0.5310851985599998,
    "n_match": 142,
    "mean_conso_per_match": 0.0037400366095774636,
    "mean_conso_per_token": 7.0052920192054e-6
  },
  {
    "model_name": "llama-3.1-405b",
    "median": 963.9360235016366,
    "p2.5": 866.5590315537745,
    "p97.5": 1067.3892351613028,
    "rank": 56,
    "rank_p2.5": 19,
    "rank_p97.5": 67,
    "total_output_tokens": 10356576.0,
    "conso_all_conv": 2464.0993918144186,
    "n_match": 10102,
    "mean_conso_per_match": 0.24392193543995433,
    "mean_conso_per_token": 0.00023792606666666845
  },
  {
    "model_name": "gemma-2-9b-it",
    "median": 963.9188073277564,
    "p2.5": 862.4200351413148,
    "p97.5": 1056.6848369269992,
    "rank": 57,
    "rank_p2.5": 23,
    "rank_p97.5": 68,
    "total_output_tokens": 3108609.0,
    "conso_all_conv": 12.13237905659333,
    "n_match": 5116,
    "mean_conso_per_match": 0.0023714579860424803,
    "mean_conso_per_token": 3.902832120923966e-6
  },
  {
    "model_name": "deepseek-r1-distill-llama-70b",
    "median": 959.2874827181015,
    "p2.5": 862.9583750261563,
    "p97.5": 1054.4991417623144,
    "rank": 58,
    "rank_p2.5": 23,
    "rank_p97.5": 68,
    "total_output_tokens": 2339110.0,
    "conso_all_conv": 29.16573882733335,
    "n_match": 2559,
    "mean_conso_per_match": 0.011397318807086108,
    "mean_conso_per_token": 0.00001246873333333334
  },
  {
    "model_name": "qwq-32b",
    "median": 957.5551350928205,
    "p2.5": 859.2382623260685,
    "p97.5": 1066.5643381727434,
    "rank": 59,
    "rank_p2.5": 20,
    "rank_p97.5": 68,
    "total_output_tokens": 1895013.0,
    "conso_all_conv": 13.522699067219976,
    "n_match": 1596,
    "mean_conso_per_match": 0.008472869089736827,
    "mean_conso_per_token": 7.135939999999987e-6
  },
  {
    "model_name": "hermes-3-llama-3.1-405b",
    "median": 947.574334612726,
    "p2.5": 849.4849921084984,
    "p97.5": 1047.715359782926,
    "rank": 60,
    "rank_p2.5": 25,
    "rank_p97.5": 69,
    "total_output_tokens": 4093318.0,
    "conso_all_conv": 973.907051355869,
    "n_match": 6782,
    "mean_conso_per_match": 0.1436017474721128,
    "mean_conso_per_token": 0.00023792606666666723
  },
  {
    "model_name": "c4ai-command-r-08-2024",
    "median": 935.4568573247941,
    "p2.5": 846.7160196058447,
    "p97.5": 1038.6521035801475,
    "rank": 61,
    "rank_p2.5": 27,
    "rank_p97.5": 69,
    "total_output_tokens": 4319206.0,
    "conso_all_conv": 32.64002378170007,
    "n_match": 5999,
    "mean_conso_per_match": 0.005440910782080359,
    "mean_conso_per_token": 7.556950000000017e-6
  },
  {
    "model_name": "qwen2.5-7b-instruct",
    "median": 933.0885044754662,
    "p2.5": 827.7787924868439,
    "p97.5": 1045.36200764538,
    "rank": 62,
    "rank_p2.5": 26,
    "rank_p97.5": 70,
    "total_output_tokens": 1186919.0,
    "conso_all_conv": 4.305576367276666,
    "n_match": 1420,
    "mean_conso_per_match": 0.003032096033293427,
    "mean_conso_per_token": 3.627523333333333e-6
  },
  {
    "model_name": "qwen2.5-coder-32b-instruct",
    "median": 931.9535682877327,
    "p2.5": 841.7826838402167,
    "p97.5": 1030.57171309256,
    "rank": 63,
    "rank_p2.5": 30,
    "rank_p97.5": 69,
    "total_output_tokens": 6149486.0,
    "conso_all_conv": 43.882363126840055,
    "n_match": 7330,
    "mean_conso_per_match": 0.005986679826308329,
    "mean_conso_per_token": 7.135940000000009e-6
  },
  {
    "model_name": "llama-3.1-8b",
    "median": 926.9880865731745,
    "p2.5": 833.9197162283431,
    "p97.5": 1032.3253855029348,
    "rank": 64,
    "rank_p2.5": 30,
    "rank_p97.5": 70,
    "total_output_tokens": 5670436.0,
    "conso_all_conv": 21.365408986959896,
    "n_match": 8257,
    "mean_conso_per_match": 0.0025875510460167004,
    "mean_conso_per_token": 3.7678599999999815e-6
  },
  {
    "model_name": "mixtral-8x7b-instruct-v0.1",
    "median": 890.4069585071875,
    "p2.5": 785.2816298692917,
    "p97.5": 1008.8304831157745,
    "rank": 66,
    "rank_p2.5": 38,
    "rank_p97.5": 72,
    "total_output_tokens": 1575791.0,
    "conso_all_conv": 7.264207415080009,
    "n_match": 2560,
    "mean_conso_per_match": 0.0028375810215156287,
    "mean_conso_per_token": 4.609880000000006e-6
  },
  {
    "model_name": "lfm-40b",
    "median": 883.9994707655526,
    "p2.5": 775.6228526450049,
    "p97.5": 995.4958901644612,
    "rank": 67,
    "rank_p2.5": 41,
    "rank_p97.5": 72,
    "total_output_tokens": 2000824.0,
    "conso_all_conv": 16.524071780533333,
    "n_match": 3578,
    "mean_conso_per_match": 0.0046182425322899194,
    "mean_conso_per_token": 8.258633333333333e-6
  },
  {
    "model_name": "phi-3.5-mini-instruct",
    "median": 867.3489822332846,
    "p2.5": 747.0708936499982,
    "p97.5": 977.7974012170556,
    "rank": 68,
    "rank_p2.5": 47,
    "rank_p97.5": 73,
    "total_output_tokens": 2149046.0,
    "conso_all_conv": 6.58935470079332,
    "n_match": 2535,
    "mean_conso_per_match": 0.002599350966782375,
    "mean_conso_per_token": 3.0661766666666605e-6
  },
  {
    "model_name": "mistral-nemo-2407",
    "median": 854.3108591526774,
    "p2.5": 753.2739117522591,
    "p97.5": 961.2239541808034,
    "rank": 69,
    "rank_p2.5": 51,
    "rank_p97.5": 73,
    "total_output_tokens": 3305342.0,
    "conso_all_conv": 14.309508622013324,
    "n_match": 6253,
    "mean_conso_per_match": 0.0022884229365126058,
    "mean_conso_per_token": 4.3292066666666635e-6
  },
  {
    "model_name": "mixtral-8x22b-instruct-v0.1",
    "median": 839.8107255212117,
    "p2.5": 742.574422786857,
    "p97.5": 940.5416339610649,
    "rank": 70,
    "rank_p2.5": 57,
    "rank_p97.5": 73,
    "total_output_tokens": 3041056.0,
    "conso_all_conv": 53.624913921280175,
    "n_match": 5458,
    "mean_conso_per_match": 0.009825011711484092,
    "mean_conso_per_token": 0.00001763364894341971
  },
  {
    "model_name": "chocolatine-2-14b-instruct-v2.0.3-q8",
    "median": 821.3573859298085,
    "p2.5": 722.1186771887129,
    "p97.5": 925.2901959902607,
    "rank": 71,
    "rank_p2.5": 60,
    "rank_p97.5": 74,
    "total_output_tokens": 533384.0,
    "conso_all_conv": 1.9348629056266684,
    "n_match": 1796,
    "mean_conso_per_match": 0.0010773178761841137,
    "mean_conso_per_token": 3.6275233333333365e-6
  },
  {
    "model_name": "Yi-1.5-9B-Chat",
    "median": 784.41651119934,
    "p2.5": 671.2952396310106,
    "p97.5": 892.4355836498457,
    "rank": 72,
    "rank_p2.5": 65,
    "rank_p97.5": 74,
    "total_output_tokens": 47531.0,
    "conso_all_conv": 0.18274336793666668,
    "n_match": 65,
    "mean_conso_per_match": 0.002811436429794872,
    "mean_conso_per_token": 3.844719613234872e-6
  },
  {
    "model_name": "chocolatine-14b-instruct-dpo-v1.2-q4",
    "median": 749.6681720029021,
    "p2.5": 634.4038286870278,
    "p97.5": 875.6124619167322,
    "rank": 73,
    "rank_p2.5": 66,
    "rank_p97.5": 74,
    "total_output_tokens": 131187.0,
    "conso_all_conv": 0.6022485528400002,
    "n_match": 309,
    "mean_conso_per_match": 0.0019490244428478972,
    "mean_conso_per_token": 4.59076396929574e-6
  },
  {
    "model_name": "qwen2-7b-instruct",
    "median": 742.3669108014093,
    "p2.5": 626.3309490688346,
    "p97.5": 860.3660147907658,
    "rank": 74,
    "rank_p2.5": 68,
    "rank_p97.5": 74,
    "total_output_tokens": 43550.0,
    "conso_all_conv": 0.15307785714333336,
    "n_match": 80,
    "mean_conso_per_match": 0.001913473214291667,
    "mean_conso_per_token": 3.5149909791810184e-6
  }
]
