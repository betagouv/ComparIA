{
  "timestamp": 1769488026.0,
  "models": [
    {
      "model_name": "mistral-medium-3.1",
      "median": 1136.8853567890883,
      "p2.5": 1097.3987400412177,
      "p97.5": 1183.1371214517517,
      "rank": 1,
      "rank_p2.5": 1,
      "rank_p97.5": 8,
      "total_output_tokens": 353926,
      "conso_all_conv": 0.0,
      "n_match": 191,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.6802435007978013,
      "win_rate": 0.5832258064516129,
      "useful": 5,
      "creative": 3,
      "complete": 12,
      "clear_formatting": 8,
      "incorrect": 4,
      "superficial": 1,
      "instructions_not_followed": 0,
      "total_prefs": 33,
      "positive_prefs_ratio": 0.8484848484848485
    },
    {
      "model_name": "gemini-3-flash-preview",
      "median": 1124.1981954717148,
      "p2.5": 1103.670275528673,
      "p97.5": 1147.0557805322449,
      "rank": 2,
      "rank_p2.5": 1,
      "rank_p97.5": 6,
      "total_output_tokens": 640296,
      "conso_all_conv": 56.01639800735999,
      "n_match": 651,
      "mean_conso_per_match": 0.08604669432774192,
      "mean_conso_per_token": 8.748515999999998e-05,
      "mean_win_prob": 0.6645617913372063,
      "win_rate": 0.5824731182795699,
      "useful": 143,
      "creative": 45,
      "complete": 135,
      "clear_formatting": 115,
      "incorrect": 35,
      "superficial": 31,
      "instructions_not_followed": 12,
      "total_prefs": 516,
      "positive_prefs_ratio": 0.8488372093023255
    },
    {
      "model_name": "mistral-large-2512",
      "median": 1120.6455043146739,
      "p2.5": 1108.5335359956077,
      "p97.5": 1133.49052607129,
      "rank": 3,
      "rank_p2.5": 1,
      "rank_p97.5": 5,
      "total_output_tokens": 4786939,
      "conso_all_conv": 241.23214231697997,
      "n_match": 2216,
      "mean_conso_per_match": 0.10885926999863717,
      "mean_conso_per_token": 5.039381999999999e-05,
      "mean_win_prob": 0.6601080046824633,
      "win_rate": 0.5707581227436823,
      "useful": 560,
      "creative": 137,
      "complete": 516,
      "clear_formatting": 413,
      "incorrect": 97,
      "superficial": 88,
      "instructions_not_followed": 72,
      "total_prefs": 1883,
      "positive_prefs_ratio": 0.8635156664896442
    },
    {
      "model_name": "mistral-medium-2508",
      "median": 1117.5926333970544,
      "p2.5": 1109.7898677180483,
      "p97.5": 1125.4715879043567,
      "rank": 4,
      "rank_p2.5": 2,
      "rank_p97.5": 5,
      "total_output_tokens": 8957999,
      "conso_all_conv": 178.32309387342335,
      "n_match": 5837,
      "mean_conso_per_match": 0.030550470082820514,
      "mean_conso_per_token": 1.9906576666666667e-05,
      "mean_win_prob": 0.6562598155346869,
      "win_rate": 0.5845202193283071,
      "useful": 745,
      "creative": 191,
      "complete": 713,
      "clear_formatting": 571,
      "incorrect": 162,
      "superficial": 131,
      "instructions_not_followed": 73,
      "total_prefs": 2586,
      "positive_prefs_ratio": 0.8584686774941995
    },
    {
      "model_name": "gemini-2.5-flash",
      "median": 1105.0259751608187,
      "p2.5": 1096.3592970475563,
      "p97.5": 1113.6446967809036,
      "rank": 5,
      "rank_p2.5": 4,
      "rank_p97.5": 8,
      "total_output_tokens": 5790557,
      "conso_all_conv": 506.5878056341199,
      "n_match": 4429,
      "mean_conso_per_match": 0.11437972581488369,
      "mean_conso_per_token": 8.748515999999998e-05,
      "mean_win_prob": 0.6402238978033056,
      "win_rate": 0.578116956423572,
      "useful": 542,
      "creative": 173,
      "complete": 599,
      "clear_formatting": 451,
      "incorrect": 132,
      "superficial": 113,
      "instructions_not_followed": 42,
      "total_prefs": 2052,
      "positive_prefs_ratio": 0.8601364522417154
    },
    {
      "model_name": "gemini-3-pro-preview",
      "median": 1103.7667677929935,
      "p2.5": 1091.332578555651,
      "p97.5": 1116.003571821986,
      "rank": 6,
      "rank_p2.5": 4,
      "rank_p97.5": 9,
      "total_output_tokens": 4264534,
      "conso_all_conv": 229.26945045459996,
      "n_match": 2475,
      "mean_conso_per_match": 0.09263412139579796,
      "mean_conso_per_token": 5.376189999999999e-05,
      "mean_win_prob": 0.6386004462995448,
      "win_rate": 0.5569090909090909,
      "useful": 512,
      "creative": 156,
      "complete": 478,
      "clear_formatting": 353,
      "incorrect": 69,
      "superficial": 94,
      "instructions_not_followed": 50,
      "total_prefs": 1712,
      "positive_prefs_ratio": 0.8755841121495327
    },
    {
      "model_name": "qwen3-max-2025-09-23",
      "median": 1102.7815855821661,
      "p2.5": 1092.201273862567,
      "p97.5": 1113.5825316041912,
      "rank": 7,
      "rank_p2.5": 4,
      "rank_p97.5": 9,
      "total_output_tokens": 3189223,
      "conso_all_conv": 182.06483179695994,
      "n_match": 2852,
      "mean_conso_per_match": 0.0638375988067882,
      "mean_conso_per_token": 5.708751999999998e-05,
      "mean_win_prob": 0.6373282578576308,
      "win_rate": 0.578716239915819,
      "useful": 347,
      "creative": 114,
      "complete": 319,
      "clear_formatting": 308,
      "incorrect": 119,
      "superficial": 85,
      "instructions_not_followed": 41,
      "total_prefs": 1333,
      "positive_prefs_ratio": 0.8162040510127532
    },
    {
      "model_name": "gemini-2.0-flash",
      "median": 1099.4923705700032,
      "p2.5": 1092.3169457023073,
      "p97.5": 1106.8548859094212,
      "rank": 8,
      "rank_p2.5": 5,
      "rank_p97.5": 9,
      "total_output_tokens": 12296785,
      "conso_all_conv": 1075.7862032105998,
      "n_match": 8684,
      "mean_conso_per_match": 0.12388141446460153,
      "mean_conso_per_token": 8.748515999999998e-05,
      "mean_win_prob": 0.6330681261716332,
      "win_rate": 0.6317699216950714,
      "useful": 2128,
      "creative": 677,
      "complete": 2179,
      "clear_formatting": 1909,
      "incorrect": 376,
      "superficial": 397,
      "instructions_not_followed": 112,
      "total_prefs": 7778,
      "positive_prefs_ratio": 0.8862175366418102
    },
    {
      "model_name": "deepseek-v3-0324",
      "median": 1091.8623519456096,
      "p2.5": 1082.6259080799025,
      "p97.5": 1101.2423927611133,
      "rank": 9,
      "rank_p2.5": 7,
      "rank_p97.5": 12,
      "total_output_tokens": 4435392,
      "conso_all_conv": 208.57759099007998,
      "n_match": 4385,
      "mean_conso_per_match": 0.04756615529990422,
      "mean_conso_per_token": 4.7025739999999995e-05,
      "mean_win_prob": 0.6231132661156734,
      "win_rate": 0.5851128848346637,
      "useful": 1141,
      "creative": 336,
      "complete": 1012,
      "clear_formatting": 1043,
      "incorrect": 230,
      "superficial": 288,
      "instructions_not_followed": 79,
      "total_prefs": 4129,
      "positive_prefs_ratio": 0.8554129329135384
    },
    {
      "model_name": "magistral-medium",
      "median": 1089.27494211612,
      "p2.5": 1077.845802959409,
      "p97.5": 1101.643129593578,
      "rank": 10,
      "rank_p2.5": 7,
      "rank_p97.5": 14,
      "total_output_tokens": 2039837,
      "conso_all_conv": 40.60617162800334,
      "n_match": 2207,
      "mean_conso_per_match": 0.01839880907476363,
      "mean_conso_per_token": 1.9906576666666667e-05,
      "mean_win_prob": 0.6197154055144258,
      "win_rate": 0.5809968282736747,
      "useful": 146,
      "creative": 41,
      "complete": 150,
      "clear_formatting": 104,
      "incorrect": 50,
      "superficial": 28,
      "instructions_not_followed": 3,
      "total_prefs": 522,
      "positive_prefs_ratio": 0.8448275862068966
    },
    {
      "model_name": "gemma-3-27b",
      "median": 1083.073644194183,
      "p2.5": 1076.3469225401782,
      "p97.5": 1088.9893867916267,
      "rank": 11,
      "rank_p2.5": 10,
      "rank_p97.5": 16,
      "total_output_tokens": 10789878,
      "conso_all_conv": 69.42484445402,
      "n_match": 8066,
      "mean_conso_per_match": 0.008607097006449294,
      "mean_conso_per_token": 6.434256666666667e-06,
      "mean_win_prob": 0.6115286426167124,
      "win_rate": 0.5720505826927845,
      "useful": 1532,
      "creative": 511,
      "complete": 1698,
      "clear_formatting": 1248,
      "incorrect": 418,
      "superficial": 297,
      "instructions_not_followed": 146,
      "total_prefs": 5850,
      "positive_prefs_ratio": 0.8528205128205129
    },
    {
      "model_name": "deepseek-chat-v3.1",
      "median": 1081.6346809640513,
      "p2.5": 1068.5578925262657,
      "p97.5": 1094.114601356239,
      "rank": 12,
      "rank_p2.5": 9,
      "rank_p97.5": 19,
      "total_output_tokens": 2795086,
      "conso_all_conv": 131.44098751363998,
      "n_match": 2016,
      "mean_conso_per_match": 0.06519890253652777,
      "mean_conso_per_token": 4.7025739999999995e-05,
      "mean_win_prob": 0.6096206023679359,
      "win_rate": 0.5316617063492063,
      "useful": 274,
      "creative": 93,
      "complete": 244,
      "clear_formatting": 225,
      "incorrect": 74,
      "superficial": 73,
      "instructions_not_followed": 44,
      "total_prefs": 1027,
      "positive_prefs_ratio": 0.8140214216163584
    },
    {
      "model_name": "deepseek-v3-chat",
      "median": 1078.5623675775928,
      "p2.5": 1068.9641417960524,
      "p97.5": 1086.7818617032995,
      "rank": 13,
      "rank_p2.5": 11,
      "rank_p97.5": 20,
      "total_output_tokens": 5638296,
      "conso_all_conv": 265.14504173904,
      "n_match": 5388,
      "mean_conso_per_match": 0.049210289855055676,
      "mean_conso_per_token": 4.7025739999999995e-05,
      "mean_win_prob": 0.6055366472572501,
      "win_rate": 0.6141481069042317,
      "useful": 1330,
      "creative": 390,
      "complete": 1245,
      "clear_formatting": 1399,
      "incorrect": 314,
      "superficial": 285,
      "instructions_not_followed": 81,
      "total_prefs": 5044,
      "positive_prefs_ratio": 0.8651863600317209
    },
    {
      "model_name": "gpt-5.2",
      "median": 1077.4984903022787,
      "p2.5": 1063.9179426542241,
      "p97.5": 1089.9491956626175,
      "rank": 14,
      "rank_p2.5": 10,
      "rank_p97.5": 22,
      "total_output_tokens": 2018694,
      "conso_all_conv": 95.90904016535997,
      "n_match": 1783,
      "mean_conso_per_match": 0.053790824545911366,
      "mean_conso_per_token": 4.751043999999999e-05,
      "mean_win_prob": 0.6041193176587559,
      "win_rate": 0.5219629837352776,
      "useful": 374,
      "creative": 88,
      "complete": 293,
      "clear_formatting": 281,
      "incorrect": 54,
      "superficial": 123,
      "instructions_not_followed": 45,
      "total_prefs": 1258,
      "positive_prefs_ratio": 0.8235294117647058
    },
    {
      "model_name": "grok-4.1-fast",
      "median": 1076.5887321540267,
      "p2.5": 1063.0020212546488,
      "p97.5": 1088.9684309869153,
      "rank": 15,
      "rank_p2.5": 10,
      "rank_p97.5": 23,
      "total_output_tokens": 2212092,
      "conso_all_conv": 564.3859488337199,
      "n_match": 1963,
      "mean_conso_per_match": 0.28751194540688735,
      "mean_conso_per_token": 0.0002551367433333333,
      "mean_win_prob": 0.6029060545671084,
      "win_rate": 0.5402649006622516,
      "useful": 375,
      "creative": 143,
      "complete": 306,
      "clear_formatting": 267,
      "incorrect": 99,
      "superficial": 99,
      "instructions_not_followed": 42,
      "total_prefs": 1331,
      "positive_prefs_ratio": 0.8196844477836214
    },
    {
      "model_name": "claude-4-5-sonnet",
      "median": 1073.9587460429436,
      "p2.5": 1066.5476607974383,
      "p97.5": 1081.8995023837929,
      "rank": 16,
      "rank_p2.5": 12,
      "rank_p97.5": 21,
      "total_output_tokens": 6098686,
      "conso_all_conv": 533.5445204997599,
      "n_match": 5706,
      "mean_conso_per_match": 0.09350587460563616,
      "mean_conso_per_token": 8.748515999999998e-05,
      "mean_win_prob": 0.5993922929103271,
      "win_rate": 0.5386890991938311,
      "useful": 1067,
      "creative": 489,
      "complete": 812,
      "clear_formatting": 548,
      "incorrect": 139,
      "superficial": 212,
      "instructions_not_followed": 82,
      "total_prefs": 3349,
      "positive_prefs_ratio": 0.8707076739325171
    },
    {
      "model_name": "DeepSeek-V3.2",
      "median": 1072.4017444489148,
      "p2.5": 1057.7891969555694,
      "p97.5": 1088.1393230188091,
      "rank": 17,
      "rank_p2.5": 10,
      "rank_p97.5": 26,
      "total_output_tokens": 1432989,
      "conso_all_conv": 67.38736813685999,
      "n_match": 1296,
      "mean_conso_per_match": 0.05199642603152777,
      "mean_conso_per_token": 4.7025739999999995e-05,
      "mean_win_prob": 0.5973077070083498,
      "win_rate": 0.5447067901234568,
      "useful": 329,
      "creative": 171,
      "complete": 328,
      "clear_formatting": 237,
      "incorrect": 91,
      "superficial": 89,
      "instructions_not_followed": 47,
      "total_prefs": 1292,
      "positive_prefs_ratio": 0.8243034055727554
    },
    {
      "model_name": "glm-4.5",
      "median": 1071.8688228668893,
      "p2.5": 1060.1979397773357,
      "p97.5": 1084.9951281805538,
      "rank": 18,
      "rank_p2.5": 11,
      "rank_p97.5": 25,
      "total_output_tokens": 5128869,
      "conso_all_conv": 109.79790435558,
      "n_match": 2178,
      "mean_conso_per_match": 0.050412260952975206,
      "mean_conso_per_token": 2.140782e-05,
      "mean_win_prob": 0.5965934755223276,
      "win_rate": 0.5414882866329811,
      "useful": 227,
      "creative": 75,
      "complete": 282,
      "clear_formatting": 209,
      "incorrect": 48,
      "superficial": 57,
      "instructions_not_followed": 33,
      "total_prefs": 931,
      "positive_prefs_ratio": 0.8517722878625135
    },
    {
      "model_name": "gpt-5.1",
      "median": 1071.7384878996527,
      "p2.5": 1060.838772719542,
      "p97.5": 1083.6578825942206,
      "rank": 19,
      "rank_p2.5": 12,
      "rank_p97.5": 25,
      "total_output_tokens": 3204901,
      "conso_all_conv": 152.26625666643997,
      "n_match": 2666,
      "mean_conso_per_match": 0.05711412478111027,
      "mean_conso_per_token": 4.7510439999999994e-05,
      "mean_win_prob": 0.5964187419659115,
      "win_rate": 0.5288709677419355,
      "useful": 388,
      "creative": 111,
      "complete": 381,
      "clear_formatting": 318,
      "incorrect": 60,
      "superficial": 111,
      "instructions_not_followed": 46,
      "total_prefs": 1415,
      "positive_prefs_ratio": 0.846643109540636
    },
    {
      "model_name": "gpt-oss-120b",
      "median": 1065.0011883898223,
      "p2.5": 1052.0097950229901,
      "p97.5": 1077.944063085501,
      "rank": 20,
      "rank_p2.5": 14,
      "rank_p97.5": 30,
      "total_output_tokens": 4400470,
      "conso_all_conv": 14.727713019500001,
      "n_match": 1868,
      "mean_conso_per_match": 0.007884214678533192,
      "mean_conso_per_token": 3.3468500000000004e-06,
      "mean_win_prob": 0.5873573376283776,
      "win_rate": 0.5230690948044993,
      "useful": 274,
      "creative": 96,
      "complete": 371,
      "clear_formatting": 250,
      "incorrect": 107,
      "superficial": 75,
      "instructions_not_followed": 59,
      "total_prefs": 1232,
      "positive_prefs_ratio": 0.8043831168831169
    },
    {
      "model_name": "gemma-3-12b",
      "median": 1064.0633367741577,
      "p2.5": 1057.4052927853484,
      "p97.5": 1070.6001329536275,
      "rank": 21,
      "rank_p2.5": 18,
      "rank_p97.5": 27,
      "total_output_tokens": 10080290,
      "conso_all_conv": 43.639658669933326,
      "n_match": 7796,
      "mean_conso_per_match": 0.005597698649298785,
      "mean_conso_per_token": 4.329206666666666e-06,
      "mean_win_prob": 0.5860916159139896,
      "win_rate": 0.5560915854284249,
      "useful": 1330,
      "creative": 393,
      "complete": 1475,
      "clear_formatting": 1126,
      "incorrect": 456,
      "superficial": 340,
      "instructions_not_followed": 200,
      "total_prefs": 5320,
      "positive_prefs_ratio": 0.812781954887218
    },
    {
      "model_name": "claude-4-sonnet",
      "median": 1062.9607019622022,
      "p2.5": 1050.8898873528015,
      "p97.5": 1073.6876825507568,
      "rank": 22,
      "rank_p2.5": 16,
      "rank_p97.5": 30,
      "total_output_tokens": 1853912,
      "conso_all_conv": 162.18978794591996,
      "n_match": 2540,
      "mean_conso_per_match": 0.06385424722280314,
      "mean_conso_per_token": 8.748515999999998e-05,
      "mean_win_prob": 0.5846022046494592,
      "win_rate": 0.5355651831429696,
      "useful": 234,
      "creative": 62,
      "complete": 198,
      "clear_formatting": 215,
      "incorrect": 41,
      "superficial": 64,
      "instructions_not_followed": 20,
      "total_prefs": 834,
      "positive_prefs_ratio": 0.8501199040767387
    },
    {
      "model_name": "kimi-k2-thinking",
      "median": 1062.7943915374012,
      "p2.5": 1043.6654854729181,
      "p97.5": 1082.7580940374637,
      "rank": 23,
      "rank_p2.5": 12,
      "rank_p97.5": 33,
      "total_output_tokens": 1446271,
      "conso_all_conv": 82.56402463791997,
      "n_match": 871,
      "mean_conso_per_match": 0.09479222116867965,
      "mean_conso_per_token": 5.708751999999998e-05,
      "mean_win_prob": 0.5843774363499111,
      "win_rate": 0.5373708381171068,
      "useful": 168,
      "creative": 32,
      "complete": 167,
      "clear_formatting": 121,
      "incorrect": 47,
      "superficial": 56,
      "instructions_not_followed": 36,
      "total_prefs": 627,
      "positive_prefs_ratio": 0.7783094098883573
    },
    {
      "model_name": "grok-4-fast",
      "median": 1062.677569759866,
      "p2.5": 1052.4759994770486,
      "p97.5": 1075.1897092233444,
      "rank": 24,
      "rank_p2.5": 16,
      "rank_p97.5": 29,
      "total_output_tokens": 3521762,
      "conso_all_conv": 898.5308874750866,
      "n_match": 2623,
      "mean_conso_per_match": 0.34255847787841653,
      "mean_conso_per_token": 0.0002551367433333333,
      "mean_win_prob": 0.5842195331607049,
      "win_rate": 0.5293971766501335,
      "useful": 228,
      "creative": 53,
      "complete": 176,
      "clear_formatting": 137,
      "incorrect": 61,
      "superficial": 52,
      "instructions_not_followed": 20,
      "total_prefs": 727,
      "positive_prefs_ratio": 0.8170563961485557
    },
    {
      "model_name": "grok-3-mini-beta",
      "median": 1059.818877289063,
      "p2.5": 1045.0700566279822,
      "p97.5": 1076.887285563348,
      "rank": 25,
      "rank_p2.5": 15,
      "rank_p97.5": 33,
      "total_output_tokens": 3474752,
      "conso_all_conv": 39.83854131029333,
      "n_match": 1537,
      "mean_conso_per_match": 0.02591967554345695,
      "mean_conso_per_token": 1.1465146666666665e-05,
      "mean_win_prob": 0.5803508234220015,
      "win_rate": 0.5305338541666668,
      "useful": 404,
      "creative": 102,
      "complete": 350,
      "clear_formatting": 320,
      "incorrect": 102,
      "superficial": 106,
      "instructions_not_followed": 47,
      "total_prefs": 1431,
      "positive_prefs_ratio": 0.8218029350104822
    },
    {
      "model_name": "mistral-small-2506",
      "median": 1059.6818556759972,
      "p2.5": 1050.3482529271307,
      "p97.5": 1068.2621491005339,
      "rank": 26,
      "rank_p2.5": 20,
      "rank_p97.5": 30,
      "total_output_tokens": 3853836,
      "conso_all_conv": 23.174066480879997,
      "n_match": 4752,
      "mean_conso_per_match": 0.004876697491767676,
      "mean_conso_per_token": 6.013246666666666e-06,
      "mean_win_prob": 0.5801651656735431,
      "win_rate": 0.5266603535353536,
      "useful": 535,
      "creative": 136,
      "complete": 441,
      "clear_formatting": 424,
      "incorrect": 196,
      "superficial": 174,
      "instructions_not_followed": 53,
      "total_prefs": 1959,
      "positive_prefs_ratio": 0.7840735068912711
    },
    {
      "model_name": "kimi-k2",
      "median": 1057.461272872294,
      "p2.5": 1041.9239860703165,
      "p97.5": 1073.0856693618584,
      "rank": 27,
      "rank_p2.5": 17,
      "rank_p97.5": 34,
      "total_output_tokens": 1643414,
      "conso_all_conv": 93.81842959327997,
      "n_match": 1332,
      "mean_conso_per_match": 0.0704342564514114,
      "mean_conso_per_token": 5.7087519999999986e-05,
      "mean_win_prob": 0.5771536046889836,
      "win_rate": 0.5049284099472494,
      "useful": 307,
      "creative": 79,
      "complete": 188,
      "clear_formatting": 174,
      "incorrect": 64,
      "superficial": 82,
      "instructions_not_followed": 19,
      "total_prefs": 913,
      "positive_prefs_ratio": 0.8192771084337349
    },
    {
      "model_name": "command-a",
      "median": 1055.3033268516172,
      "p2.5": 1048.3071574577348,
      "p97.5": 1061.7810301422232,
      "rank": 28,
      "rank_p2.5": 24,
      "rank_p97.5": 32,
      "total_output_tokens": 7263914,
      "conso_all_conv": 132.36693920851334,
      "n_match": 7493,
      "mean_conso_per_match": 0.017665412946551894,
      "mean_conso_per_token": 1.822253666666667e-05,
      "mean_win_prob": 0.5742221131697753,
      "win_rate": 0.5449646336580809,
      "useful": 1453,
      "creative": 346,
      "complete": 1311,
      "clear_formatting": 1216,
      "incorrect": 348,
      "superficial": 392,
      "instructions_not_followed": 132,
      "total_prefs": 5198,
      "positive_prefs_ratio": 0.8322431704501732
    },
    {
      "model_name": "deepseek-r1-0528",
      "median": 1054.0865951933506,
      "p2.5": 1041.5441775399984,
      "p97.5": 1068.8210001527316,
      "rank": 29,
      "rank_p2.5": 20,
      "rank_p97.5": 34,
      "total_output_tokens": 2968759,
      "conso_all_conv": 139.60808885666,
      "n_match": 1614,
      "mean_conso_per_match": 0.08649819631763321,
      "mean_conso_per_token": 4.702574e-05,
      "mean_win_prob": 0.5725671793802569,
      "win_rate": 0.5251301115241636,
      "useful": 215,
      "creative": 67,
      "complete": 187,
      "clear_formatting": 135,
      "incorrect": 57,
      "superficial": 63,
      "instructions_not_followed": 32,
      "total_prefs": 756,
      "positive_prefs_ratio": 0.798941798941799
    },
    {
      "model_name": "Qwen3-Coder-480B-A35B-Instruct",
      "median": 1049.8672943621427,
      "p2.5": 1033.928245909635,
      "p97.5": 1065.671778206012,
      "rank": 30,
      "rank_p2.5": 21,
      "rank_p97.5": 37,
      "total_output_tokens": 1131257,
      "conso_all_conv": 34.19541034459999,
      "n_match": 1119,
      "mean_conso_per_match": 0.03055890111224307,
      "mean_conso_per_token": 3.0227799999999992e-05,
      "mean_win_prob": 0.5668174223080993,
      "win_rate": 0.5335004476275739,
      "useful": 194,
      "creative": 50,
      "complete": 128,
      "clear_formatting": 144,
      "incorrect": 50,
      "superficial": 69,
      "instructions_not_followed": 26,
      "total_prefs": 661,
      "positive_prefs_ratio": 0.7806354009077155
    },
    {
      "model_name": "claude-3-7-sonnet",
      "median": 1048.6408239734747,
      "p2.5": 1039.0258181209906,
      "p97.5": 1058.1694405099704,
      "rank": 31,
      "rank_p2.5": 26,
      "rank_p97.5": 35,
      "total_output_tokens": 3546728,
      "conso_all_conv": 310.2860665564799,
      "n_match": 3907,
      "mean_conso_per_match": 0.07941798478538006,
      "mean_conso_per_token": 8.748515999999998e-05,
      "mean_win_prob": 0.5651430484108177,
      "win_rate": 0.524225748656258,
      "useful": 1003,
      "creative": 230,
      "complete": 774,
      "clear_formatting": 822,
      "incorrect": 140,
      "superficial": 318,
      "instructions_not_followed": 46,
      "total_prefs": 3333,
      "positive_prefs_ratio": 0.8487848784878488
    },
    {
      "model_name": "magistral-small-2506",
      "median": 1048.314918340033,
      "p2.5": 1038.6610783738988,
      "p97.5": 1059.3528190534998,
      "rank": 32,
      "rank_p2.5": 26,
      "rank_p97.5": 35,
      "total_output_tokens": 2445603,
      "conso_all_conv": 14.706014087739998,
      "n_match": 3147,
      "mean_conso_per_match": 0.0046730264022052746,
      "mean_conso_per_token": 6.013246666666666e-06,
      "mean_win_prob": 0.5646979028521918,
      "win_rate": 0.52184361093452,
      "useful": 248,
      "creative": 53,
      "complete": 198,
      "clear_formatting": 181,
      "incorrect": 88,
      "superficial": 84,
      "instructions_not_followed": 32,
      "total_prefs": 884,
      "positive_prefs_ratio": 0.7692307692307693
    },
    {
      "model_name": "glm-4.7",
      "median": 1046.522220475369,
      "p2.5": 1019.0773211355399,
      "p97.5": 1074.0198589627162,
      "rank": 33,
      "rank_p2.5": 16,
      "rank_p97.5": 41,
      "total_output_tokens": 1034858,
      "conso_all_conv": 22.154053789560002,
      "n_match": 420,
      "mean_conso_per_match": 0.052747747118,
      "mean_conso_per_token": 2.1407820000000003e-05,
      "mean_win_prob": 0.5622476944384343,
      "win_rate": 0.497,
      "useful": 76,
      "creative": 27,
      "complete": 82,
      "clear_formatting": 66,
      "incorrect": 22,
      "superficial": 25,
      "instructions_not_followed": 15,
      "total_prefs": 313,
      "positive_prefs_ratio": 0.8019169329073482
    },
    {
      "model_name": "llama-3.1-nemotron-70b-instruct",
      "median": 1043.5323878782992,
      "p2.5": 1036.3199446904944,
      "p97.5": 1050.878274577678,
      "rank": 34,
      "rank_p2.5": 30,
      "rank_p97.5": 36,
      "total_output_tokens": 7426282,
      "conso_all_conv": 92.59632991613334,
      "n_match": 6709,
      "mean_conso_per_match": 0.01380180800657823,
      "mean_conso_per_token": 1.2468733333333335e-05,
      "mean_win_prob": 0.5581554441201362,
      "win_rate": 0.5452863107664778,
      "useful": 1544,
      "creative": 487,
      "complete": 1473,
      "clear_formatting": 1431,
      "incorrect": 381,
      "superficial": 395,
      "instructions_not_followed": 136,
      "total_prefs": 5847,
      "positive_prefs_ratio": 0.8440225756798359
    },
    {
      "model_name": "glm-4.6",
      "median": 1041.1134147877233,
      "p2.5": 1030.4477257666524,
      "p97.5": 1053.3486587122952,
      "rank": 35,
      "rank_p2.5": 29,
      "rank_p97.5": 38,
      "total_output_tokens": 6675805,
      "conso_all_conv": 142.9144317951,
      "n_match": 2427,
      "mean_conso_per_match": 0.058885221176390605,
      "mean_conso_per_token": 2.140782e-05,
      "mean_win_prob": 0.5548395099451212,
      "win_rate": 0.501516275236918,
      "useful": 288,
      "creative": 108,
      "complete": 324,
      "clear_formatting": 223,
      "incorrect": 87,
      "superficial": 86,
      "instructions_not_followed": 54,
      "total_prefs": 1170,
      "positive_prefs_ratio": 0.805982905982906
    },
    {
      "model_name": "gemma-3-4b",
      "median": 1035.6124391267517,
      "p2.5": 1029.832040078254,
      "p97.5": 1042.3479831768836,
      "rank": 36,
      "rank_p2.5": 34,
      "rank_p97.5": 38,
      "total_output_tokens": 10890335,
      "conso_all_conv": 34.92000438196667,
      "n_match": 8861,
      "mean_conso_per_match": 0.0039408649567731265,
      "mean_conso_per_token": 3.206513333333334e-06,
      "mean_win_prob": 0.5472835493330679,
      "win_rate": 0.5128111951247039,
      "useful": 1347,
      "creative": 402,
      "complete": 1457,
      "clear_formatting": 1173,
      "incorrect": 699,
      "superficial": 357,
      "instructions_not_followed": 246,
      "total_prefs": 5681,
      "positive_prefs_ratio": 0.7708149973596198
    },
    {
      "model_name": "gpt-4.1-mini",
      "median": 1031.2698577780436,
      "p2.5": 1023.8244389938403,
      "p97.5": 1038.362122562537,
      "rank": 37,
      "rank_p2.5": 35,
      "rank_p97.5": 40,
      "total_output_tokens": 5550374,
      "conso_all_conv": 73.10073823583333,
      "n_match": 7173,
      "mean_conso_per_match": 0.010191096923997398,
      "mean_conso_per_token": 1.3170416666666667e-05,
      "mean_win_prob": 0.5413055141479137,
      "win_rate": 0.5152977269557941,
      "useful": 1227,
      "creative": 286,
      "complete": 945,
      "clear_formatting": 1010,
      "incorrect": 244,
      "superficial": 455,
      "instructions_not_followed": 97,
      "total_prefs": 4264,
      "positive_prefs_ratio": 0.8133208255159474
    },
    {
      "model_name": "gemma-3n-e4b-it",
      "median": 1030.8423280994205,
      "p2.5": 1021.2826077308912,
      "p97.5": 1039.722811152783,
      "rank": 38,
      "rank_p2.5": 34,
      "rank_p97.5": 41,
      "total_output_tokens": 4733622,
      "conso_all_conv": 15.17842205796,
      "n_match": 4176,
      "mean_conso_per_match": 0.00363467961158046,
      "mean_conso_per_token": 3.2065133333333334e-06,
      "mean_win_prob": 0.5407164118920295,
      "win_rate": 0.49403735632183904,
      "useful": 426,
      "creative": 137,
      "complete": 417,
      "clear_formatting": 353,
      "incorrect": 209,
      "superficial": 167,
      "instructions_not_followed": 92,
      "total_prefs": 1801,
      "positive_prefs_ratio": 0.7401443642420877
    },
    {
      "model_name": "gemini-1.5-pro",
      "median": 1030.1194434755532,
      "p2.5": 1022.4601983809843,
      "p97.5": 1037.8932812975106,
      "rank": 39,
      "rank_p2.5": 35,
      "rank_p97.5": 41,
      "total_output_tokens": 6034223,
      "conso_all_conv": 1011.3126436118333,
      "n_match": 7387,
      "mean_conso_per_match": 0.13690437845022788,
      "mean_conso_per_token": 0.00016759616666666666,
      "mean_win_prob": 0.5397201200029579,
      "win_rate": 0.5830743197509137,
      "useful": 2118,
      "creative": 683,
      "complete": 1630,
      "clear_formatting": 1959,
      "incorrect": 461,
      "superficial": 655,
      "instructions_not_followed": 202,
      "total_prefs": 7708,
      "positive_prefs_ratio": 0.8290088220031137
    },
    {
      "model_name": "deepseek-r1",
      "median": 1024.4446948414336,
      "p2.5": 1014.2457120005711,
      "p97.5": 1034.7212149935986,
      "rank": 40,
      "rank_p2.5": 36,
      "rank_p97.5": 44,
      "total_output_tokens": 3693582,
      "conso_all_conv": 173.69342680068,
      "n_match": 3510,
      "mean_conso_per_match": 0.04948530678082051,
      "mean_conso_per_token": 4.7025739999999995e-05,
      "mean_win_prob": 0.5318905738874531,
      "win_rate": 0.5313019943019943,
      "useful": 826,
      "creative": 284,
      "complete": 783,
      "clear_formatting": 667,
      "incorrect": 171,
      "superficial": 207,
      "instructions_not_followed": 112,
      "total_prefs": 3050,
      "positive_prefs_ratio": 0.839344262295082
    },
    {
      "model_name": "qwen3-32b",
      "median": 1018.3031744392283,
      "p2.5": 1005.8391360251895,
      "p97.5": 1031.1204465608093,
      "rank": 41,
      "rank_p2.5": 38,
      "rank_p97.5": 49,
      "total_output_tokens": 3842778,
      "conso_all_conv": 27.42183324131999,
      "n_match": 1905,
      "mean_conso_per_match": 0.014394663118803145,
      "mean_conso_per_token": 7.1359399999999974e-06,
      "mean_win_prob": 0.523403026420265,
      "win_rate": 0.5019831667543398,
      "useful": 438,
      "creative": 127,
      "complete": 359,
      "clear_formatting": 276,
      "incorrect": 171,
      "superficial": 145,
      "instructions_not_followed": 79,
      "total_prefs": 1595,
      "positive_prefs_ratio": 0.7523510971786834
    },
    {
      "model_name": "mistral-large-2411",
      "median": 1017.8794714543881,
      "p2.5": 1011.5454762561113,
      "p97.5": 1024.6478050976532,
      "rank": 42,
      "rank_p2.5": 40,
      "rank_p97.5": 46,
      "total_output_tokens": 7677266,
      "conso_all_conv": 152.82808421939336,
      "n_match": 8829,
      "mean_conso_per_match": 0.017309784145361124,
      "mean_conso_per_token": 1.990657666666667e-05,
      "mean_win_prob": 0.5228170484784175,
      "win_rate": 0.527441386340469,
      "useful": 1898,
      "creative": 355,
      "complete": 1451,
      "clear_formatting": 1608,
      "incorrect": 393,
      "superficial": 666,
      "instructions_not_followed": 140,
      "total_prefs": 6511,
      "positive_prefs_ratio": 0.8158500998310552
    },
    {
      "model_name": "mistral-saba",
      "median": 1014.1997857094951,
      "p2.5": 1006.2767797881493,
      "p97.5": 1022.3553911018319,
      "rank": 43,
      "rank_p2.5": 41,
      "rank_p97.5": 49,
      "total_output_tokens": 4349650,
      "conso_all_conv": 26.155518363666665,
      "n_match": 4934,
      "mean_conso_per_match": 0.005301077901026888,
      "mean_conso_per_token": 6.0132466666666666e-06,
      "mean_win_prob": 0.5177262937335063,
      "win_rate": 0.48257855260490573,
      "useful": 745,
      "creative": 170,
      "complete": 587,
      "clear_formatting": 586,
      "incorrect": 241,
      "superficial": 337,
      "instructions_not_followed": 113,
      "total_prefs": 2779,
      "positive_prefs_ratio": 0.751349406261245
    },
    {
      "model_name": "llama-maverick",
      "median": 1012.4971481986399,
      "p2.5": 1002.5511799128594,
      "p97.5": 1022.4892702877548,
      "rank": 44,
      "rank_p2.5": 41,
      "rank_p97.5": 50,
      "total_output_tokens": 2658735,
      "conso_all_conv": 40.127409972449996,
      "n_match": 3383,
      "mean_conso_per_match": 0.011861486837851019,
      "mean_conso_per_token": 1.5092669999999998e-05,
      "mean_win_prob": 0.5153698355260665,
      "win_rate": 0.4775879396984925,
      "useful": 350,
      "creative": 67,
      "complete": 245,
      "clear_formatting": 234,
      "incorrect": 103,
      "superficial": 189,
      "instructions_not_followed": 57,
      "total_prefs": 1245,
      "positive_prefs_ratio": 0.7196787148594378
    },
    {
      "model_name": "gpt-oss-20b",
      "median": 1011.7594401498258,
      "p2.5": 1000.318364356267,
      "p97.5": 1024.3219839453532,
      "rank": 45,
      "rank_p2.5": 40,
      "rank_p97.5": 51,
      "total_output_tokens": 3658487,
      "conso_all_conv": 11.217567474703333,
      "n_match": 2169,
      "mean_conso_per_match": 0.005171769236838789,
      "mean_conso_per_token": 3.066176666666667e-06,
      "mean_win_prob": 0.5143487040259033,
      "win_rate": 0.45893911439114393,
      "useful": 243,
      "creative": 83,
      "complete": 230,
      "clear_formatting": 203,
      "incorrect": 122,
      "superficial": 114,
      "instructions_not_followed": 68,
      "total_prefs": 1063,
      "positive_prefs_ratio": 0.7140169332079022
    },
    {
      "model_name": "gpt-5-mini",
      "median": 1010.7758564437518,
      "p2.5": 1000.7744679653886,
      "p97.5": 1020.5579023981417,
      "rank": 46,
      "rank_p2.5": 41,
      "rank_p97.5": 51,
      "total_output_tokens": 4318175,
      "conso_all_conv": 39.904211993249994,
      "n_match": 3712,
      "mean_conso_per_match": 0.010750057110250536,
      "mean_conso_per_token": 9.24099e-06,
      "mean_win_prob": 0.5129871203813897,
      "win_rate": 0.4687388843977365,
      "useful": 363,
      "creative": 89,
      "complete": 367,
      "clear_formatting": 220,
      "incorrect": 84,
      "superficial": 146,
      "instructions_not_followed": 98,
      "total_prefs": 1367,
      "positive_prefs_ratio": 0.7600585223116313
    },
    {
      "model_name": "llama-4-scout",
      "median": 1009.5225507568304,
      "p2.5": 1002.8172919424958,
      "p97.5": 1016.8856834141377,
      "rank": 47,
      "rank_p2.5": 43,
      "rank_p97.5": 50,
      "total_output_tokens": 4892081,
      "conso_all_conv": 24.611521382089997,
      "n_match": 6149,
      "mean_conso_per_match": 0.0040025242124068945,
      "mean_conso_per_token": 5.03089e-06,
      "mean_win_prob": 0.51125200002953,
      "win_rate": 0.48678972190600095,
      "useful": 931,
      "creative": 208,
      "complete": 787,
      "clear_formatting": 747,
      "incorrect": 323,
      "superficial": 457,
      "instructions_not_followed": 123,
      "total_prefs": 3576,
      "positive_prefs_ratio": 0.74748322147651
    },
    {
      "model_name": "mistral-small-3.1-24b",
      "median": 1004.5325241469238,
      "p2.5": 996.1500127385203,
      "p97.5": 1013.4793974906233,
      "rank": 48,
      "rank_p2.5": 45,
      "rank_p97.5": 53,
      "total_output_tokens": 4470466,
      "conso_all_conv": 26.882014772946665,
      "n_match": 5079,
      "mean_conso_per_match": 0.005292777076776268,
      "mean_conso_per_token": 6.0132466666666666e-06,
      "mean_win_prob": 0.5043426283031475,
      "win_rate": 0.4945107304587517,
      "useful": 1108,
      "creative": 247,
      "complete": 791,
      "clear_formatting": 916,
      "incorrect": 268,
      "superficial": 430,
      "instructions_not_followed": 130,
      "total_prefs": 3890,
      "positive_prefs_ratio": 0.787146529562982
    },
    {
      "model_name": "o4-mini",
      "median": 1002.6182164334068,
      "p2.5": 991.6247975009478,
      "p97.5": 1013.8189696631265,
      "rank": 49,
      "rank_p2.5": 44,
      "rank_p97.5": 54,
      "total_output_tokens": 2940457,
      "conso_all_conv": 15.205769650586666,
      "n_match": 2830,
      "mean_conso_per_match": 0.005373063480772673,
      "mean_conso_per_token": 5.171226666666666e-06,
      "mean_win_prob": 0.5016919435195798,
      "win_rate": 0.4738494167550371,
      "useful": 527,
      "creative": 111,
      "complete": 374,
      "clear_formatting": 286,
      "incorrect": 133,
      "superficial": 210,
      "instructions_not_followed": 45,
      "total_prefs": 1686,
      "positive_prefs_ratio": 0.7698695136417556
    },
    {
      "model_name": "gemma-2-27b-it-q8",
      "median": 1000.2908451219334,
      "p2.5": 977.2799558861243,
      "p97.5": 1025.936209725001,
      "rank": 50,
      "rank_p2.5": 40,
      "rank_p97.5": 62,
      "total_output_tokens": 449540,
      "conso_all_conv": 2.8924557419333334,
      "n_match": 762,
      "mean_conso_per_match": 0.0037958736770778655,
      "mean_conso_per_token": 6.434256666666667e-06,
      "mean_win_prob": 0.49846955830892076,
      "win_rate": 0.5826115485564304,
      "useful": 318,
      "creative": 97,
      "complete": 178,
      "clear_formatting": 305,
      "incorrect": 63,
      "superficial": 91,
      "instructions_not_followed": 29,
      "total_prefs": 1081,
      "positive_prefs_ratio": 0.8307123034227567
    },
    {
      "model_name": "gpt-5",
      "median": 999.1969919095816,
      "p2.5": 989.394922106717,
      "p97.5": 1008.3868888147997,
      "rank": 51,
      "rank_p2.5": 47,
      "rank_p97.5": 55,
      "total_output_tokens": 4019540,
      "conso_all_conv": 190.97011399759995,
      "n_match": 3843,
      "mean_conso_per_match": 0.0496929778812386,
      "mean_conso_per_token": 4.751043999999999e-05,
      "mean_win_prob": 0.49695521685767907,
      "win_rate": 0.45334721499219155,
      "useful": 144,
      "creative": 54,
      "complete": 158,
      "clear_formatting": 68,
      "incorrect": 29,
      "superficial": 57,
      "instructions_not_followed": 32,
      "total_prefs": 542,
      "positive_prefs_ratio": 0.7822878228782287
    },
    {
      "model_name": "EuroLLM-22B-Instruct-2512",
      "median": 997.4170772804953,
      "p2.5": 962.3169537885988,
      "p97.5": 1032.690611573234,
      "rank": 52,
      "rank_p2.5": 37,
      "rank_p97.5": 69,
      "total_output_tokens": 192139,
      "conso_all_conv": 1.1014509076933332,
      "n_match": 254,
      "mean_conso_per_match": 0.004336420896430446,
      "mean_conso_per_token": 5.7325733333333326e-06,
      "mean_win_prob": 0.49449139797752767,
      "win_rate": 0.419484126984127,
      "useful": 74,
      "creative": 17,
      "complete": 46,
      "clear_formatting": 54,
      "incorrect": 15,
      "superficial": 25,
      "instructions_not_followed": 10,
      "total_prefs": 241,
      "positive_prefs_ratio": 0.7925311203319502
    },
    {
      "model_name": "lfm2-8b-a1b",
      "median": 996.8270464984205,
      "p2.5": 982.6095816374128,
      "p97.5": 1009.9371558895855,
      "rank": 53,
      "rank_p2.5": 46,
      "rank_p97.5": 59,
      "total_output_tokens": 1465418,
      "conso_all_conv": 4.081926723726667,
      "n_match": 1907,
      "mean_conso_per_match": 0.002140496446631708,
      "mean_conso_per_token": 2.7855033333333337e-06,
      "mean_win_prob": 0.49367475884329776,
      "win_rate": 0.4640115364446775,
      "useful": 232,
      "creative": 41,
      "complete": 158,
      "clear_formatting": 193,
      "incorrect": 155,
      "superficial": 150,
      "instructions_not_followed": 70,
      "total_prefs": 999,
      "positive_prefs_ratio": 0.6246246246246246
    },
    {
      "model_name": "aya-expanse-32b",
      "median": 990.628530720117,
      "p2.5": 982.0764158394135,
      "p97.5": 998.7153322406944,
      "rank": 54,
      "rank_p2.5": 51,
      "rank_p97.5": 60,
      "total_output_tokens": 4082212,
      "conso_all_conv": 29.130419899279993,
      "n_match": 5113,
      "mean_conso_per_match": 0.005697324447345979,
      "mean_conso_per_token": 7.135939999999998e-06,
      "mean_win_prob": 0.48509989102912404,
      "win_rate": 0.46256796401329947,
      "useful": 722,
      "creative": 142,
      "complete": 527,
      "clear_formatting": 513,
      "incorrect": 277,
      "superficial": 353,
      "instructions_not_followed": 109,
      "total_prefs": 2643,
      "positive_prefs_ratio": 0.7203934922436626
    },
    {
      "model_name": "qwen3-30b-a3b",
      "median": 987.8470735133506,
      "p2.5": 977.0810208728981,
      "p97.5": 998.2198155782856,
      "rank": 55,
      "rank_p2.5": 52,
      "rank_p97.5": 62,
      "total_output_tokens": 5797968,
      "conso_all_conv": 17.77759419568,
      "n_match": 3337,
      "mean_conso_per_match": 0.005327418098795325,
      "mean_conso_per_token": 3.0661766666666664e-06,
      "mean_win_prob": 0.48125541854162907,
      "win_rate": 0.4606205035971223,
      "useful": 281,
      "creative": 72,
      "complete": 298,
      "clear_formatting": 224,
      "incorrect": 188,
      "superficial": 155,
      "instructions_not_followed": 76,
      "total_prefs": 1294,
      "positive_prefs_ratio": 0.6761978361669243
    },
    {
      "model_name": "qwen-3-8b",
      "median": 987.1543403969349,
      "p2.5": 976.2650364906897,
      "p97.5": 998.0914012870919,
      "rank": 56,
      "rank_p2.5": 51,
      "rank_p97.5": 63,
      "total_output_tokens": 5563742,
      "conso_all_conv": 20.96340093212,
      "n_match": 2776,
      "mean_conso_per_match": 0.007551657396296829,
      "mean_conso_per_token": 3.7678599999999997e-06,
      "mean_win_prob": 0.4802983346485039,
      "win_rate": 0.43244596541786745,
      "useful": 246,
      "creative": 73,
      "complete": 262,
      "clear_formatting": 182,
      "incorrect": 184,
      "superficial": 111,
      "instructions_not_followed": 74,
      "total_prefs": 1132,
      "positive_prefs_ratio": 0.6740282685512368
    },
    {
      "model_name": "llama-3.3-70b",
      "median": 985.8318560600954,
      "p2.5": 979.6395474611442,
      "p97.5": 991.853498686917,
      "rank": 57,
      "rank_p2.5": 54,
      "rank_p97.5": 62,
      "total_output_tokens": 7716623,
      "conso_all_conv": 96.21651442086667,
      "n_match": 9454,
      "mean_conso_per_match": 0.010177333871468868,
      "mean_conso_per_token": 1.2468733333333335e-05,
      "mean_win_prob": 0.47847166537734503,
      "win_rate": 0.47380262322826316,
      "useful": 1581,
      "creative": 326,
      "complete": 1228,
      "clear_formatting": 1180,
      "incorrect": 517,
      "superficial": 747,
      "instructions_not_followed": 175,
      "total_prefs": 5754,
      "positive_prefs_ratio": 0.7499131039277025
    },
    {
      "model_name": "mistral-small-24b-instruct-2501",
      "median": 984.5070315879173,
      "p2.5": 974.1766654461414,
      "p97.5": 995.5365781787193,
      "rank": 58,
      "rank_p2.5": 52,
      "rank_p97.5": 64,
      "total_output_tokens": 2818040,
      "conso_all_conv": 16.94556963653333,
      "n_match": 3318,
      "mean_conso_per_match": 0.005107163844645368,
      "mean_conso_per_token": 6.013246666666666e-06,
      "mean_win_prob": 0.47664243725867267,
      "win_rate": 0.4952350813743219,
      "useful": 745,
      "creative": 155,
      "complete": 536,
      "clear_formatting": 656,
      "incorrect": 204,
      "superficial": 307,
      "instructions_not_followed": 71,
      "total_prefs": 2674,
      "positive_prefs_ratio": 0.7823485415108452
    },
    {
      "model_name": "o3-mini",
      "median": 980.9816365711731,
      "p2.5": 966.3615150267133,
      "p97.5": 995.5464802986476,
      "rank": 59,
      "rank_p2.5": 52,
      "rank_p97.5": 67,
      "total_output_tokens": 1655945,
      "conso_all_conv": 8.563266942533334,
      "n_match": 1619,
      "mean_conso_per_match": 0.005289232206629607,
      "mean_conso_per_token": 5.171226666666667e-06,
      "mean_win_prob": 0.4717784406109374,
      "win_rate": 0.51142063001853,
      "useful": 350,
      "creative": 85,
      "complete": 254,
      "clear_formatting": 230,
      "incorrect": 49,
      "superficial": 133,
      "instructions_not_followed": 28,
      "total_prefs": 1129,
      "positive_prefs_ratio": 0.8139946855624446
    },
    {
      "model_name": "gpt-4o-mini-2024-07-18",
      "median": 980.4624152475806,
      "p2.5": 973.0806052544932,
      "p97.5": 988.1195970602953,
      "rank": 60,
      "rank_p2.5": 56,
      "rank_p97.5": 65,
      "total_output_tokens": 5207480,
      "conso_all_conv": 26.929059442133333,
      "n_match": 6990,
      "mean_conso_per_match": 0.0038525120804196473,
      "mean_conso_per_token": 5.171226666666666e-06,
      "mean_win_prob": 0.4710625525223503,
      "win_rate": 0.49947067238912735,
      "useful": 1491,
      "creative": 319,
      "complete": 856,
      "clear_formatting": 1282,
      "incorrect": 369,
      "superficial": 599,
      "instructions_not_followed": 110,
      "total_prefs": 5026,
      "positive_prefs_ratio": 0.7855153203342619
    },
    {
      "model_name": "gpt-4.1-nano",
      "median": 977.3009090559875,
      "p2.5": 969.608671123157,
      "p97.5": 984.4936590535859,
      "rank": 61,
      "rank_p2.5": 58,
      "rank_p97.5": 67,
      "total_output_tokens": 3563423,
      "conso_all_conv": 20.927662570929996,
      "n_match": 5717,
      "mean_conso_per_match": 0.003660602163884904,
      "mean_conso_per_token": 5.872909999999999e-06,
      "mean_win_prob": 0.46670650496723026,
      "win_rate": 0.46743047052649994,
      "useful": 928,
      "creative": 159,
      "complete": 529,
      "clear_formatting": 649,
      "incorrect": 276,
      "superficial": 448,
      "instructions_not_followed": 103,
      "total_prefs": 3092,
      "positive_prefs_ratio": 0.732535575679172
    },
    {
      "model_name": "Apertus-70B-Instruct-2509",
      "median": 977.2495806909546,
      "p2.5": 964.918841384824,
      "p97.5": 989.1331949241667,
      "rank": 62,
      "rank_p2.5": 56,
      "rank_p97.5": 69,
      "total_output_tokens": 2056962,
      "conso_all_conv": 25.6477106548,
      "n_match": 2107,
      "mean_conso_per_match": 0.012172620149406739,
      "mean_conso_per_token": 1.2468733333333333e-05,
      "mean_win_prob": 0.4666358265452233,
      "win_rate": 0.4118841955386806,
      "useful": 206,
      "creative": 41,
      "complete": 136,
      "clear_formatting": 122,
      "incorrect": 108,
      "superficial": 134,
      "instructions_not_followed": 67,
      "total_prefs": 814,
      "positive_prefs_ratio": 0.6203931203931204
    },
    {
      "model_name": "minimax-m2",
      "median": 973.7681447604114,
      "p2.5": 960.4975483793612,
      "p97.5": 987.6574156544013,
      "rank": 63,
      "rank_p2.5": 56,
      "rank_p97.5": 71,
      "total_output_tokens": 3184435,
      "conso_all_conv": 25.784582490666665,
      "n_match": 1763,
      "mean_conso_per_match": 0.014625401299300433,
      "mean_conso_per_token": 8.097066666666666e-06,
      "mean_win_prob": 0.4618454749310405,
      "win_rate": 0.4338287010777085,
      "useful": 218,
      "creative": 53,
      "complete": 179,
      "clear_formatting": 126,
      "incorrect": 91,
      "superficial": 103,
      "instructions_not_followed": 53,
      "total_prefs": 823,
      "positive_prefs_ratio": 0.6998784933171325
    },
    {
      "model_name": "jamba-1.5-large",
      "median": 972.4579575199238,
      "p2.5": 926.668140169913,
      "p97.5": 1014.8591483344643,
      "rank": 64,
      "rank_p2.5": 44,
      "rank_p97.5": 81,
      "total_output_tokens": 143976,
      "conso_all_conv": 6.840363109439998,
      "n_match": 172,
      "mean_conso_per_match": 0.03976955296186046,
      "mean_conso_per_token": 4.751043999999999e-05,
      "mean_win_prob": 0.4600445997642982,
      "win_rate": 0.5449418604651162,
      "useful": 44,
      "creative": 11,
      "complete": 18,
      "clear_formatting": 57,
      "incorrect": 15,
      "superficial": 13,
      "instructions_not_followed": 4,
      "total_prefs": 162,
      "positive_prefs_ratio": 0.8024691358024691
    },
    {
      "model_name": "aya-expanse-8b",
      "median": 972.2192273732134,
      "p2.5": 956.0618184098129,
      "p97.5": 988.6321284490007,
      "rank": 65,
      "rank_p2.5": 56,
      "rank_p97.5": 72,
      "total_output_tokens": 1057810,
      "conso_all_conv": 3.9856799865999997,
      "n_match": 1302,
      "mean_conso_per_match": 0.003061198146390169,
      "mean_conso_per_token": 3.7678599999999997e-06,
      "mean_win_prob": 0.4597165791361126,
      "win_rate": 0.5014285714285714,
      "useful": 243,
      "creative": 55,
      "complete": 133,
      "clear_formatting": 223,
      "incorrect": 149,
      "superficial": 104,
      "instructions_not_followed": 31,
      "total_prefs": 938,
      "positive_prefs_ratio": 0.697228144989339
    },
    {
      "model_name": "llama-3.1-70b",
      "median": 971.4188673555182,
      "p2.5": 962.2539372254712,
      "p97.5": 979.6655763394734,
      "rank": 66,
      "rank_p2.5": 61,
      "rank_p97.5": 70,
      "total_output_tokens": 4057254,
      "conso_all_conv": 50.588818191600005,
      "n_match": 5583,
      "mean_conso_per_match": 0.009061224823858141,
      "mean_conso_per_token": 1.2468733333333335e-05,
      "mean_win_prob": 0.45861713828707984,
      "win_rate": 0.530445996775927,
      "useful": 1532,
      "creative": 365,
      "complete": 1047,
      "clear_formatting": 1305,
      "incorrect": 463,
      "superficial": 621,
      "instructions_not_followed": 177,
      "total_prefs": 5510,
      "positive_prefs_ratio": 0.7711433756805808
    },
    {
      "model_name": "claude-3-5-sonnet-v2",
      "median": 970.1925668462976,
      "p2.5": 961.8870556144376,
      "p97.5": 978.4716501663481,
      "rank": 67,
      "rank_p2.5": 62,
      "rank_p97.5": 70,
      "total_output_tokens": 3224219,
      "conso_all_conv": 282.07131509003995,
      "n_match": 5683,
      "mean_conso_per_match": 0.049634227536519436,
      "mean_conso_per_token": 8.748515999999998e-05,
      "mean_win_prob": 0.4569334210568974,
      "win_rate": 0.4921080415273623,
      "useful": 1301,
      "creative": 291,
      "complete": 721,
      "clear_formatting": 905,
      "incorrect": 250,
      "superficial": 606,
      "instructions_not_followed": 94,
      "total_prefs": 4168,
      "positive_prefs_ratio": 0.7720729366602687
    },
    {
      "model_name": "phi-4",
      "median": 965.8752119815938,
      "p2.5": 960.0667083387409,
      "p97.5": 971.900896040392,
      "rank": 68,
      "rank_p2.5": 65,
      "rank_p97.5": 71,
      "total_output_tokens": 8226489,
      "conso_all_conv": 37.92312711132,
      "n_match": 9968,
      "mean_conso_per_match": 0.003804487069755217,
      "mean_conso_per_token": 4.60988e-06,
      "mean_win_prob": 0.45101415659935146,
      "win_rate": 0.46780074245008524,
      "useful": 1626,
      "creative": 336,
      "complete": 1193,
      "clear_formatting": 1311,
      "incorrect": 731,
      "superficial": 760,
      "instructions_not_followed": 253,
      "total_prefs": 6210,
      "positive_prefs_ratio": 0.7191626409017713
    },
    {
      "model_name": "ministral-8b-instruct-2410",
      "median": 962.1536064082668,
      "p2.5": 955.5953408962438,
      "p97.5": 968.800499813682,
      "rank": 69,
      "rank_p2.5": 66,
      "rank_p97.5": 72,
      "total_output_tokens": 7488476,
      "conso_all_conv": 28.215529181359997,
      "n_match": 9278,
      "mean_conso_per_match": 0.003041121920819142,
      "mean_conso_per_token": 3.7678599999999997e-06,
      "mean_win_prob": 0.44592318016451804,
      "win_rate": 0.47576819407008086,
      "useful": 1796,
      "creative": 412,
      "complete": 1332,
      "clear_formatting": 1695,
      "incorrect": 876,
      "superficial": 927,
      "instructions_not_followed": 274,
      "total_prefs": 7312,
      "positive_prefs_ratio": 0.7159463894967177
    },
    {
      "model_name": "gpt-4o-2024-08-06",
      "median": 961.1871906239711,
      "p2.5": 952.1742988906973,
      "p97.5": 969.7649708474723,
      "rank": 70,
      "rank_p2.5": 66,
      "rank_p97.5": 74,
      "total_output_tokens": 3903917,
      "conso_all_conv": 341.53480337171993,
      "n_match": 5896,
      "mean_conso_per_match": 0.05792652703048167,
      "mean_conso_per_token": 8.748515999999998e-05,
      "mean_win_prob": 0.4446030395867616,
      "win_rate": 0.48863297150610585,
      "useful": 1230,
      "creative": 243,
      "complete": 593,
      "clear_formatting": 1002,
      "incorrect": 275,
      "superficial": 590,
      "instructions_not_followed": 115,
      "total_prefs": 4048,
      "positive_prefs_ratio": 0.7579051383399209
    },
    {
      "model_name": "Apertus-8B-Instruct-2509",
      "median": 960.0324252981634,
      "p2.5": 904.539624073799,
      "p97.5": 1013.5611888868611,
      "rank": 71,
      "rank_p2.5": 45,
      "rank_p97.5": 83,
      "total_output_tokens": 52304,
      "conso_all_conv": 0.19707414943999998,
      "n_match": 86,
      "mean_conso_per_match": 0.002291559877209302,
      "mean_conso_per_token": 3.7678599999999997e-06,
      "mean_win_prob": 0.4430266660493022,
      "win_rate": 0.46880952380952384,
      "useful": 2,
      "creative": 0,
      "complete": 3,
      "clear_formatting": 2,
      "incorrect": 3,
      "superficial": 5,
      "instructions_not_followed": 0,
      "total_prefs": 15,
      "positive_prefs_ratio": 0.4666666666666667
    },
    {
      "model_name": "qwen2.5-32b-instruct",
      "median": 956.3236394690182,
      "p2.5": 904.0571866608016,
      "p97.5": 1013.3784692884396,
      "rank": 72,
      "rank_p2.5": 44,
      "rank_p97.5": 83,
      "total_output_tokens": 75812,
      "conso_all_conv": 0.5409898832799999,
      "n_match": 142,
      "mean_conso_per_match": 0.003809787910422534,
      "mean_conso_per_token": 7.135939999999998e-06,
      "mean_win_prob": 0.43797189480634385,
      "win_rate": 0.5557042253521126,
      "useful": 52,
      "creative": 16,
      "complete": 43,
      "clear_formatting": 57,
      "incorrect": 13,
      "superficial": 21,
      "instructions_not_followed": 15,
      "total_prefs": 217,
      "positive_prefs_ratio": 0.7741935483870968
    },
    {
      "model_name": "llama-3.1-405b",
      "median": 955.7198729007441,
      "p2.5": 948.9548283567732,
      "p97.5": 962.6296556443101,
      "rank": 73,
      "rank_p2.5": 69,
      "rank_p97.5": 75,
      "total_output_tokens": 10383810,
      "conso_all_conv": 2470.579070314,
      "n_match": 9973,
      "mean_conso_per_match": 0.24772676930853305,
      "mean_conso_per_token": 0.00023792606666666667,
      "mean_win_prob": 0.4371502244185798,
      "win_rate": 0.4950747166783673,
      "useful": 2224,
      "creative": 556,
      "complete": 1579,
      "clear_formatting": 1788,
      "incorrect": 947,
      "superficial": 890,
      "instructions_not_followed": 437,
      "total_prefs": 8421,
      "positive_prefs_ratio": 0.7299608122550766
    },
    {
      "model_name": "gemma-2-9b-it",
      "median": 951.5120703755435,
      "p2.5": 942.1376455971877,
      "p97.5": 960.9210966803771,
      "rank": 74,
      "rank_p2.5": 70,
      "rank_p97.5": 77,
      "total_output_tokens": 3108609,
      "conso_all_conv": 12.149055331769999,
      "n_match": 5115,
      "mean_conso_per_match": 0.002375181883043988,
      "mean_conso_per_token": 3.908196666666666e-06,
      "mean_win_prob": 0.43143376714457565,
      "win_rate": 0.5068660801564027,
      "useful": 1250,
      "creative": 403,
      "complete": 771,
      "clear_formatting": 1197,
      "incorrect": 472,
      "superficial": 595,
      "instructions_not_followed": 177,
      "total_prefs": 4865,
      "positive_prefs_ratio": 0.7442959917780062
    },
    {
      "model_name": "gpt-5-nano",
      "median": 948.0231362977216,
      "p2.5": 937.6265300451718,
      "p97.5": 958.848791109012,
      "rank": 75,
      "rank_p2.5": 71,
      "rank_p97.5": 78,
      "total_output_tokens": 3186974,
      "conso_all_conv": 13.349819779379999,
      "n_match": 3055,
      "mean_conso_per_match": 0.0043698264416955806,
      "mean_conso_per_token": 4.188869999999999e-06,
      "mean_win_prob": 0.42670782827312054,
      "win_rate": 0.40083142389525367,
      "useful": 232,
      "creative": 56,
      "complete": 228,
      "clear_formatting": 155,
      "incorrect": 115,
      "superficial": 138,
      "instructions_not_followed": 137,
      "total_prefs": 1061,
      "positive_prefs_ratio": 0.6324222431668237
    },
    {
      "model_name": "qwq-32b",
      "median": 947.214690025683,
      "p2.5": 932.022986559223,
      "p97.5": 963.4931979087197,
      "rank": 76,
      "rank_p2.5": 70,
      "rank_p97.5": 80,
      "total_output_tokens": 1895013,
      "conso_all_conv": 13.522699067219996,
      "n_match": 1566,
      "mean_conso_per_match": 0.008635184589540228,
      "mean_conso_per_token": 7.135939999999998e-06,
      "mean_win_prob": 0.4256146358234883,
      "win_rate": 0.4485997442455243,
      "useful": 291,
      "creative": 139,
      "complete": 343,
      "clear_formatting": 233,
      "incorrect": 140,
      "superficial": 105,
      "instructions_not_followed": 92,
      "total_prefs": 1343,
      "positive_prefs_ratio": 0.7490692479523455
    },
    {
      "model_name": "deepseek-r1-distill-llama-70b",
      "median": 943.890806972071,
      "p2.5": 933.5554585232039,
      "p97.5": 954.8418886338616,
      "rank": 77,
      "rank_p2.5": 72,
      "rank_p97.5": 79,
      "total_output_tokens": 2863519,
      "conso_all_conv": 35.70445480593334,
      "n_match": 2981,
      "mean_conso_per_match": 0.011977341431041039,
      "mean_conso_per_token": 1.2468733333333335e-05,
      "mean_win_prob": 0.4211278179681587,
      "win_rate": 0.4397953706809795,
      "useful": 489,
      "creative": 130,
      "complete": 355,
      "clear_formatting": 363,
      "incorrect": 190,
      "superficial": 342,
      "instructions_not_followed": 126,
      "total_prefs": 1995,
      "positive_prefs_ratio": 0.6701754385964912
    },
    {
      "model_name": "hermes-3-llama-3.1-405b",
      "median": 940.1577661303793,
      "p2.5": 932.9852408861709,
      "p97.5": 947.6963525232048,
      "rank": 78,
      "rank_p2.5": 74,
      "rank_p97.5": 79,
      "total_output_tokens": 4092822,
      "conso_all_conv": 973.7890400268,
      "n_match": 6735,
      "mean_conso_per_match": 0.144586345957951,
      "mean_conso_per_token": 0.00023792606666666667,
      "mean_win_prob": 0.4161042345796578,
      "win_rate": 0.46634743875278395,
      "useful": 1450,
      "creative": 285,
      "complete": 830,
      "clear_formatting": 1109,
      "incorrect": 426,
      "superficial": 753,
      "instructions_not_followed": 184,
      "total_prefs": 5037,
      "positive_prefs_ratio": 0.7294024220766329
    },
    {
      "model_name": "hermes-4-70b",
      "median": 934.4082914439418,
      "p2.5": 922.2053083834113,
      "p97.5": 945.9587598930888,
      "rank": 79,
      "rank_p2.5": 75,
      "rank_p97.5": 83,
      "total_output_tokens": 1303185,
      "conso_all_conv": 16.249066249000002,
      "n_match": 2809,
      "mean_conso_per_match": 0.005784644446066216,
      "mean_conso_per_token": 1.2468733333333335e-05,
      "mean_win_prob": 0.40840134196626643,
      "win_rate": 0.3727344028520499,
      "useful": 242,
      "creative": 43,
      "complete": 106,
      "clear_formatting": 146,
      "incorrect": 133,
      "superficial": 213,
      "instructions_not_followed": 91,
      "total_prefs": 974,
      "positive_prefs_ratio": 0.5513347022587269
    },
    {
      "model_name": "llama-3.1-8b",
      "median": 932.1014132357332,
      "p2.5": 926.2940901695346,
      "p97.5": 938.3323642554968,
      "rank": 80,
      "rank_p2.5": 77,
      "rank_p97.5": 82,
      "total_output_tokens": 7372632,
      "conso_all_conv": 27.779045207519996,
      "n_match": 10444,
      "mean_conso_per_match": 0.002659809001103025,
      "mean_conso_per_token": 3.7678599999999993e-06,
      "mean_win_prob": 0.405322988048665,
      "win_rate": 0.4424234009957871,
      "useful": 1540,
      "creative": 373,
      "complete": 1014,
      "clear_formatting": 1159,
      "incorrect": 1043,
      "superficial": 978,
      "instructions_not_followed": 404,
      "total_prefs": 6511,
      "positive_prefs_ratio": 0.6275533712179389
    },
    {
      "model_name": "c4ai-command-r-08-2024",
      "median": 928.1723741130619,
      "p2.5": 920.4351721110385,
      "p97.5": 936.2497851777385,
      "rank": 81,
      "rank_p2.5": 78,
      "rank_p97.5": 83,
      "total_output_tokens": 4319206,
      "conso_all_conv": 32.640023781699995,
      "n_match": 5959,
      "mean_conso_per_match": 0.005477433089729819,
      "mean_conso_per_token": 7.556949999999999e-06,
      "mean_win_prob": 0.400097034027319,
      "win_rate": 0.42968786709179396,
      "useful": 1075,
      "creative": 255,
      "complete": 843,
      "clear_formatting": 796,
      "incorrect": 471,
      "superficial": 660,
      "instructions_not_followed": 163,
      "total_prefs": 4263,
      "positive_prefs_ratio": 0.6964578935022285
    },
    {
      "model_name": "qwen2.5-7b-instruct",
      "median": 925.0309906766589,
      "p2.5": 907.0975125120026,
      "p97.5": 943.3664361992691,
      "rank": 82,
      "rank_p2.5": 76,
      "rank_p97.5": 83,
      "total_output_tokens": 1186919,
      "conso_all_conv": 4.305576367276667,
      "n_match": 1417,
      "mean_conso_per_match": 0.0030385154320936255,
      "mean_conso_per_token": 3.6275233333333336e-06,
      "mean_win_prob": 0.3959347678996002,
      "win_rate": 0.49383909668313336,
      "useful": 402,
      "creative": 104,
      "complete": 284,
      "clear_formatting": 380,
      "incorrect": 231,
      "superficial": 203,
      "instructions_not_followed": 88,
      "total_prefs": 1692,
      "positive_prefs_ratio": 0.6914893617021277
    },
    {
      "model_name": "qwen2.5-coder-32b-instruct",
      "median": 924.5679212826558,
      "p2.5": 917.0873836532928,
      "p97.5": 932.2026812490321,
      "rank": 83,
      "rank_p2.5": 79,
      "rank_p97.5": 83,
      "total_output_tokens": 6149486,
      "conso_all_conv": 43.882363126839984,
      "n_match": 7299,
      "mean_conso_per_match": 0.006012106196306341,
      "mean_conso_per_token": 7.1359399999999974e-06,
      "mean_win_prob": 0.3953224509075499,
      "win_rate": 0.43789423208658723,
      "useful": 1379,
      "creative": 293,
      "complete": 923,
      "clear_formatting": 1142,
      "incorrect": 790,
      "superficial": 742,
      "instructions_not_followed": 234,
      "total_prefs": 5503,
      "positive_prefs_ratio": 0.6790841359258586
    },
    {
      "model_name": "mixtral-8x7b-instruct-v0.1",
      "median": 882.689046319628,
      "p2.5": 868.837282212916,
      "p97.5": 896.1229966853085,
      "rank": 84,
      "rank_p2.5": 84,
      "rank_p97.5": 86,
      "total_output_tokens": 1575791,
      "conso_all_conv": 7.2642074150800005,
      "n_match": 2560,
      "mean_conso_per_match": 0.0028375810215156253,
      "mean_conso_per_token": 4.60988e-06,
      "mean_win_prob": 0.34147230645609067,
      "win_rate": 0.43488671874999996,
      "useful": 727,
      "creative": 164,
      "complete": 375,
      "clear_formatting": 503,
      "incorrect": 256,
      "superficial": 389,
      "instructions_not_followed": 159,
      "total_prefs": 2573,
      "positive_prefs_ratio": 0.687524290711232
    },
    {
      "model_name": "lfm-40b",
      "median": 880.5006765040507,
      "p2.5": 869.09754117585,
      "p97.5": 891.3765019085849,
      "rank": 85,
      "rank_p2.5": 84,
      "rank_p97.5": 86,
      "total_output_tokens": 2000824,
      "conso_all_conv": 8.661980599626665,
      "n_match": 3578,
      "mean_conso_per_match": 0.0024209001116899565,
      "mean_conso_per_token": 4.329206666666666e-06,
      "mean_win_prob": 0.3387517352980045,
      "win_rate": 0.416296813862493,
      "useful": 841,
      "creative": 166,
      "complete": 419,
      "clear_formatting": 647,
      "incorrect": 357,
      "superficial": 572,
      "instructions_not_followed": 121,
      "total_prefs": 3123,
      "positive_prefs_ratio": 0.6637848222862632
    },
    {
      "model_name": "olmo-3-32b-think",
      "median": 877.7712507390677,
      "p2.5": 853.9078806995676,
      "p97.5": 900.1917916630983,
      "rank": 86,
      "rank_p2.5": 84,
      "rank_p97.5": 87,
      "total_output_tokens": 1738949,
      "conso_all_conv": 12.409035727059996,
      "n_match": 751,
      "mean_conso_per_match": 0.016523349836298263,
      "mean_conso_per_token": 7.1359399999999974e-06,
      "mean_win_prob": 0.33537291495874644,
      "win_rate": 0.3532356857523303,
      "useful": 70,
      "creative": 22,
      "complete": 63,
      "clear_formatting": 33,
      "incorrect": 75,
      "superficial": 56,
      "instructions_not_followed": 62,
      "total_prefs": 381,
      "positive_prefs_ratio": 0.49343832020997375
    },
    {
      "model_name": "phi-3.5-mini-instruct",
      "median": 859.5075317269946,
      "p2.5": 846.1016067302498,
      "p97.5": 872.3214166842588,
      "rank": 87,
      "rank_p2.5": 86,
      "rank_p97.5": 88,
      "total_output_tokens": 2149046,
      "conso_all_conv": 6.589354700793333,
      "n_match": 2535,
      "mean_conso_per_match": 0.0025993509667823797,
      "mean_conso_per_token": 3.0661766666666664e-06,
      "mean_win_prob": 0.31319216099271757,
      "win_rate": 0.4021104536489152,
      "useful": 636,
      "creative": 226,
      "complete": 477,
      "clear_formatting": 533,
      "incorrect": 428,
      "superficial": 449,
      "instructions_not_followed": 300,
      "total_prefs": 3049,
      "positive_prefs_ratio": 0.6139717940308298
    },
    {
      "model_name": "mistral-nemo-2407",
      "median": 850.167696989109,
      "p2.5": 842.029898930688,
      "p97.5": 859.0533326728812,
      "rank": 88,
      "rank_p2.5": 87,
      "rank_p97.5": 89,
      "total_output_tokens": 3305342,
      "conso_all_conv": 14.30950862201333,
      "n_match": 6251,
      "mean_conso_per_match": 0.0022891551147037805,
      "mean_conso_per_token": 4.329206666666666e-06,
      "mean_win_prob": 0.3021513534733929,
      "win_rate": 0.37482482802751566,
      "useful": 1413,
      "creative": 225,
      "complete": 661,
      "clear_formatting": 900,
      "incorrect": 638,
      "superficial": 1088,
      "instructions_not_followed": 292,
      "total_prefs": 5217,
      "positive_prefs_ratio": 0.6131876557408472
    },
    {
      "model_name": "mixtral-8x22b-instruct-v0.1",
      "median": 839.778694831218,
      "p2.5": 830.9676283496241,
      "p97.5": 848.2150316301843,
      "rank": 89,
      "rank_p2.5": 88,
      "rank_p97.5": 90,
      "total_output_tokens": 3041056,
      "conso_all_conv": 53.644106197759996,
      "n_match": 5455,
      "mean_conso_per_match": 0.009833933308480293,
      "mean_conso_per_token": 1.7639959999999998e-05,
      "mean_win_prob": 0.2901231918216952,
      "win_rate": 0.36710357470210814,
      "useful": 1117,
      "creative": 203,
      "complete": 516,
      "clear_formatting": 702,
      "incorrect": 535,
      "superficial": 934,
      "instructions_not_followed": 276,
      "total_prefs": 4283,
      "positive_prefs_ratio": 0.5925752976885361
    },
    {
      "model_name": "chocolatine-2-14b-instruct-v2.0.3-q8",
      "median": 817.1766927615588,
      "p2.5": 800.7961234115579,
      "p97.5": 832.3597889090931,
      "rank": 90,
      "rank_p2.5": 90,
      "rank_p97.5": 91,
      "total_output_tokens": 533384,
      "conso_all_conv": 1.9348629056266669,
      "n_match": 1796,
      "mean_conso_per_match": 0.0010773178761841128,
      "mean_conso_per_token": 3.6275233333333336e-06,
      "mean_win_prob": 0.2649180311939552,
      "win_rate": 0.3317316258351893,
      "useful": 280,
      "creative": 37,
      "complete": 100,
      "clear_formatting": 199,
      "incorrect": 161,
      "superficial": 370,
      "instructions_not_followed": 50,
      "total_prefs": 1197,
      "positive_prefs_ratio": 0.5146198830409356
    },
    {
      "model_name": "Yi-1.5-9B-Chat",
      "median": 763.0785037937003,
      "p2.5": 664.0286058134907,
      "p97.5": 852.4399807031193,
      "rank": 91,
      "rank_p2.5": 88,
      "rank_p97.5": 93,
      "total_output_tokens": 47531,
      "conso_all_conv": 0.1857604957633333,
      "n_match": 65,
      "mean_conso_per_match": 0.0028578537809743586,
      "mean_conso_per_token": 3.908196666666666e-06,
      "mean_win_prob": 0.21028866114872546,
      "win_rate": 0.32599999999999996,
      "useful": 16,
      "creative": 5,
      "complete": 14,
      "clear_formatting": 19,
      "incorrect": 12,
      "superficial": 17,
      "instructions_not_followed": 14,
      "total_prefs": 97,
      "positive_prefs_ratio": 0.5567010309278351
    },
    {
      "model_name": "chocolatine-14b-instruct-dpo-v1.2-q4",
      "median": 748.951977892285,
      "p2.5": 699.3025120800141,
      "p97.5": 789.2468241091556,
      "rank": 92,
      "rank_p2.5": 91,
      "rank_p97.5": 93,
      "total_output_tokens": 131187,
      "conso_all_conv": 0.6047563275600001,
      "n_match": 309,
      "mean_conso_per_match": 0.001957140218640777,
      "mean_conso_per_token": 4.609880000000001e-06,
      "mean_win_prob": 0.1973936366074995,
      "win_rate": 0.2402265372168285,
      "useful": 83,
      "creative": 17,
      "complete": 39,
      "clear_formatting": 43,
      "incorrect": 52,
      "superficial": 107,
      "instructions_not_followed": 50,
      "total_prefs": 391,
      "positive_prefs_ratio": 0.46547314578005117
    },
    {
      "model_name": "qwen2-7b-instruct",
      "median": 725.6507160342635,
      "p2.5": 616.0565971727976,
      "p97.5": 803.9810393526626,
      "rank": 93,
      "rank_p2.5": 91,
      "rank_p97.5": 93,
      "total_output_tokens": 43550,
      "conso_all_conv": 0.15797864116666668,
      "n_match": 80,
      "mean_conso_per_match": 0.0019747330145833335,
      "mean_conso_per_token": 3.6275233333333336e-06,
      "mean_win_prob": 0.1773719633399619,
      "win_rate": 0.2525,
      "useful": 19,
      "creative": 4,
      "complete": 12,
      "clear_formatting": 22,
      "incorrect": 11,
      "superficial": 14,
      "instructions_not_followed": 7,
      "total_prefs": 89,
      "positive_prefs_ratio": 0.6404494382022472
    }
  ]
}
