{
  "timestamp": 1768886256.0,
  "models": [
    {
      "model_name": "mistral-medium-3.1",
      "median": 1136.3417048523174,
      "p2.5": 1097.9840921068849,
      "p97.5": 1178.316630202692,
      "rank": 1,
      "rank_p2.5": 1,
      "rank_p97.5": 8,
      "total_output_tokens": 353926,
      "conso_all_conv": 0.0,
      "n_match": 191,
      "mean_conso_per_match": 0.0,
      "mean_conso_per_token": 0.0,
      "mean_win_prob": 0.6796186981311356,
      "win_rate": 0.5832258064516129,
      "useful": 5,
      "creative": 3,
      "complete": 12,
      "clear_formatting": 8,
      "incorrect": 4,
      "superficial": 1,
      "instructions_not_followed": 0,
      "total_prefs": 33,
      "positive_prefs_ratio": 0.8484848484848485
    },
    {
      "model_name": "gemini-3-flash-preview",
      "median": 1131.0993868269288,
      "p2.5": 1101.0921005069417,
      "p97.5": 1159.0338069149655,
      "rank": 2,
      "rank_p2.5": 1,
      "rank_p97.5": 7,
      "total_output_tokens": 375370,
      "conso_all_conv": 32.83930450919999,
      "n_match": 403,
      "mean_conso_per_match": 0.08148710796327541,
      "mean_conso_per_token": 8.748515999999998e-05,
      "mean_win_prob": 0.673175186123537,
      "win_rate": 0.6028287841191067,
      "useful": 81,
      "creative": 29,
      "complete": 92,
      "clear_formatting": 72,
      "incorrect": 24,
      "superficial": 18,
      "instructions_not_followed": 6,
      "total_prefs": 322,
      "positive_prefs_ratio": 0.8509316770186336
    },
    {
      "model_name": "mistral-large-2512",
      "median": 1118.9684250859273,
      "p2.5": 1106.3888859744168,
      "p97.5": 1131.840853673345,
      "rank": 3,
      "rank_p2.5": 1,
      "rank_p97.5": 5,
      "total_output_tokens": 3979927,
      "conso_all_conv": 200.56372485113997,
      "n_match": 1777,
      "mean_conso_per_match": 0.11286647431127741,
      "mean_conso_per_token": 5.039381999999999e-05,
      "mean_win_prob": 0.6580337185026073,
      "win_rate": 0.5672312886888013,
      "useful": 438,
      "creative": 115,
      "complete": 422,
      "clear_formatting": 351,
      "incorrect": 83,
      "superficial": 69,
      "instructions_not_followed": 67,
      "total_prefs": 1545,
      "positive_prefs_ratio": 0.858252427184466
    },
    {
      "model_name": "mistral-medium-2508",
      "median": 1115.8752010535256,
      "p2.5": 1108.4126567964906,
      "p97.5": 1124.3299162112876,
      "rank": 4,
      "rank_p2.5": 2,
      "rank_p97.5": 5,
      "total_output_tokens": 8556754,
      "conso_all_conv": 170.33567951880667,
      "n_match": 5615,
      "mean_conso_per_match": 0.03033582894368774,
      "mean_conso_per_token": 1.9906576666666667e-05,
      "mean_win_prob": 0.6541234060020653,
      "win_rate": 0.5848895618097614,
      "useful": 698,
      "creative": 176,
      "complete": 657,
      "clear_formatting": 532,
      "incorrect": 154,
      "superficial": 125,
      "instructions_not_followed": 70,
      "total_prefs": 2412,
      "positive_prefs_ratio": 0.8553067993366501
    },
    {
      "model_name": "gemini-3-pro-preview",
      "median": 1106.4886565168486,
      "p2.5": 1095.0128435071342,
      "p97.5": 1118.81376452615,
      "rank": 5,
      "rank_p2.5": 3,
      "rank_p97.5": 8,
      "total_output_tokens": 3845872,
      "conso_all_conv": 206.76138587679998,
      "n_match": 2229,
      "mean_conso_per_match": 0.09275970653961417,
      "mean_conso_per_token": 5.376189999999999e-05,
      "mean_win_prob": 0.6421411137356045,
      "win_rate": 0.5612651413189771,
      "useful": 445,
      "creative": 140,
      "complete": 413,
      "clear_formatting": 314,
      "incorrect": 58,
      "superficial": 81,
      "instructions_not_followed": 42,
      "total_prefs": 1493,
      "positive_prefs_ratio": 0.8787675820495646
    },
    {
      "model_name": "gemini-2.5-flash",
      "median": 1104.398836092235,
      "p2.5": 1094.9524553227575,
      "p97.5": 1113.6632791766492,
      "rank": 6,
      "rank_p2.5": 4,
      "rank_p97.5": 8,
      "total_output_tokens": 5529185,
      "conso_all_conv": 483.7216343945999,
      "n_match": 4201,
      "mean_conso_per_match": 0.11514440237910019,
      "mean_conso_per_token": 8.748515999999998e-05,
      "mean_win_prob": 0.6394504324653519,
      "win_rate": 0.5805474886931683,
      "useful": 493,
      "creative": 159,
      "complete": 548,
      "clear_formatting": 424,
      "incorrect": 120,
      "superficial": 107,
      "instructions_not_followed": 37,
      "total_prefs": 1888,
      "positive_prefs_ratio": 0.8601694915254238
    },
    {
      "model_name": "qwen3-max-2025-09-23",
      "median": 1101.7445220538036,
      "p2.5": 1090.2857322981336,
      "p97.5": 1112.8419637972227,
      "rank": 7,
      "rank_p2.5": 4,
      "rank_p97.5": 10,
      "total_output_tokens": 2964523,
      "conso_all_conv": 169.23726605295994,
      "n_match": 2648,
      "mean_conso_per_match": 0.06391135424960723,
      "mean_conso_per_token": 5.708751999999998e-05,
      "mean_win_prob": 0.6360213580712824,
      "win_rate": 0.5793993199848886,
      "useful": 304,
      "creative": 90,
      "complete": 281,
      "clear_formatting": 270,
      "incorrect": 108,
      "superficial": 67,
      "instructions_not_followed": 36,
      "total_prefs": 1156,
      "positive_prefs_ratio": 0.8174740484429066
    },
    {
      "model_name": "gemini-2.0-flash",
      "median": 1100.0007496479952,
      "p2.5": 1093.3677220982595,
      "p97.5": 1106.617727558397,
      "rank": 8,
      "rank_p2.5": 5,
      "rank_p97.5": 9,
      "total_output_tokens": 12296785,
      "conso_all_conv": 1075.7862032105998,
      "n_match": 8684,
      "mean_conso_per_match": 0.12388141446460153,
      "mean_conso_per_token": 8.748515999999998e-05,
      "mean_win_prob": 0.633761666052422,
      "win_rate": 0.6317699216950714,
      "useful": 2128,
      "creative": 677,
      "complete": 2179,
      "clear_formatting": 1909,
      "incorrect": 376,
      "superficial": 397,
      "instructions_not_followed": 112,
      "total_prefs": 7778,
      "positive_prefs_ratio": 0.8862175366418102
    },
    {
      "model_name": "deepseek-v3-0324",
      "median": 1092.1071919226324,
      "p2.5": 1083.6626876696782,
      "p97.5": 1100.553953964512,
      "rank": 9,
      "rank_p2.5": 7,
      "rank_p97.5": 12,
      "total_output_tokens": 4435392,
      "conso_all_conv": 208.57759099007998,
      "n_match": 4385,
      "mean_conso_per_match": 0.04756615529990422,
      "mean_conso_per_token": 4.7025739999999995e-05,
      "mean_win_prob": 0.6234663676683626,
      "win_rate": 0.5851128848346637,
      "useful": 1141,
      "creative": 336,
      "complete": 1012,
      "clear_formatting": 1043,
      "incorrect": 230,
      "superficial": 288,
      "instructions_not_followed": 79,
      "total_prefs": 4129,
      "positive_prefs_ratio": 0.8554129329135384
    },
    {
      "model_name": "magistral-medium",
      "median": 1089.4858595439696,
      "p2.5": 1077.5371786563228,
      "p97.5": 1101.402709845488,
      "rank": 10,
      "rank_p2.5": 7,
      "rank_p97.5": 14,
      "total_output_tokens": 2039837,
      "conso_all_conv": 40.60617162800334,
      "n_match": 2207,
      "mean_conso_per_match": 0.01839880907476363,
      "mean_conso_per_token": 1.9906576666666667e-05,
      "mean_win_prob": 0.6200243331554058,
      "win_rate": 0.5809968282736747,
      "useful": 146,
      "creative": 41,
      "complete": 150,
      "clear_formatting": 104,
      "incorrect": 50,
      "superficial": 28,
      "instructions_not_followed": 3,
      "total_prefs": 522,
      "positive_prefs_ratio": 0.8448275862068966
    },
    {
      "model_name": "gemma-3-27b",
      "median": 1082.7457902311562,
      "p2.5": 1076.101532348681,
      "p97.5": 1089.6473838312477,
      "rank": 11,
      "rank_p2.5": 10,
      "rank_p97.5": 16,
      "total_output_tokens": 10564130,
      "conso_all_conv": 67.97232388003333,
      "n_match": 7884,
      "mean_conso_per_match": 0.008621553003555724,
      "mean_conso_per_token": 6.434256666666666e-06,
      "mean_win_prob": 0.6111241206287387,
      "win_rate": 0.5728272450532724,
      "useful": 1487,
      "creative": 501,
      "complete": 1650,
      "clear_formatting": 1213,
      "incorrect": 409,
      "superficial": 288,
      "instructions_not_followed": 145,
      "total_prefs": 5693,
      "positive_prefs_ratio": 0.8520990690321447
    },
    {
      "model_name": "gpt-5.2",
      "median": 1080.5580061765213,
      "p2.5": 1066.5782358525532,
      "p97.5": 1095.1217475056287,
      "rank": 12,
      "rank_p2.5": 9,
      "rank_p97.5": 21,
      "total_output_tokens": 1609934,
      "conso_all_conv": 76.48867271095997,
      "n_match": 1416,
      "mean_conso_per_match": 0.054017424230903936,
      "mean_conso_per_token": 4.751043999999999e-05,
      "mean_win_prob": 0.6082203505042751,
      "win_rate": 0.523502824858757,
      "useful": 297,
      "creative": 63,
      "complete": 230,
      "clear_formatting": 217,
      "incorrect": 38,
      "superficial": 90,
      "instructions_not_followed": 39,
      "total_prefs": 974,
      "positive_prefs_ratio": 0.8285420944558521
    },
    {
      "model_name": "deepseek-v3-chat",
      "median": 1078.610474040367,
      "p2.5": 1069.5052939973389,
      "p97.5": 1088.0113552152422,
      "rank": 13,
      "rank_p2.5": 10,
      "rank_p97.5": 19,
      "total_output_tokens": 5638296,
      "conso_all_conv": 265.14504173904,
      "n_match": 5388,
      "mean_conso_per_match": 0.049210289855055676,
      "mean_conso_per_token": 4.7025739999999995e-05,
      "mean_win_prob": 0.6056296000305867,
      "win_rate": 0.6141481069042317,
      "useful": 1330,
      "creative": 390,
      "complete": 1245,
      "clear_formatting": 1399,
      "incorrect": 314,
      "superficial": 285,
      "instructions_not_followed": 81,
      "total_prefs": 5044,
      "positive_prefs_ratio": 0.8651863600317209
    },
    {
      "model_name": "deepseek-chat-v3.1",
      "median": 1077.5705547661,
      "p2.5": 1064.3849961241613,
      "p97.5": 1090.778741334898,
      "rank": 14,
      "rank_p2.5": 10,
      "rank_p97.5": 22,
      "total_output_tokens": 2506643,
      "conso_all_conv": 117.87674199082,
      "n_match": 1785,
      "mean_conso_per_match": 0.06603739047104762,
      "mean_conso_per_token": 4.7025739999999995e-05,
      "mean_win_prob": 0.6042440097383502,
      "win_rate": 0.5241512605042017,
      "useful": 226,
      "creative": 77,
      "complete": 201,
      "clear_formatting": 177,
      "incorrect": 64,
      "superficial": 55,
      "instructions_not_followed": 31,
      "total_prefs": 831,
      "positive_prefs_ratio": 0.8194945848375451
    },
    {
      "model_name": "grok-4.1-fast",
      "median": 1076.8344656194186,
      "p2.5": 1061.9369172887866,
      "p97.5": 1089.8114499437277,
      "rank": 15,
      "rank_p2.5": 10,
      "rank_p97.5": 23,
      "total_output_tokens": 1918308,
      "conso_all_conv": 489.43085583027994,
      "n_match": 1706,
      "mean_conso_per_match": 0.28688795769652986,
      "mean_conso_per_token": 0.0002551367433333333,
      "mean_win_prob": 0.6032623261621695,
      "win_rate": 0.5481946072684643,
      "useful": 302,
      "creative": 127,
      "complete": 254,
      "clear_formatting": 225,
      "incorrect": 84,
      "superficial": 80,
      "instructions_not_followed": 33,
      "total_prefs": 1105,
      "positive_prefs_ratio": 0.8217194570135746
    },
    {
      "model_name": "claude-4-5-sonnet",
      "median": 1072.8246688129248,
      "p2.5": 1064.8324747709455,
      "p97.5": 1080.9631365406883,
      "rank": 16,
      "rank_p2.5": 13,
      "rank_p97.5": 22,
      "total_output_tokens": 5768825,
      "conso_all_conv": 504.68657813699986,
      "n_match": 5354,
      "mean_conso_per_match": 0.09426346248356367,
      "mean_conso_per_token": 8.748515999999998e-05,
      "mean_win_prob": 0.5979016444464323,
      "win_rate": 0.5368827045199851,
      "useful": 904,
      "creative": 391,
      "complete": 706,
      "clear_formatting": 490,
      "incorrect": 130,
      "superficial": 187,
      "instructions_not_followed": 77,
      "total_prefs": 2885,
      "positive_prefs_ratio": 0.8634315424610052
    },
    {
      "model_name": "DeepSeek-V3.2",
      "median": 1072.5468342012955,
      "p2.5": 1056.3792222903087,
      "p97.5": 1090.6716569028465,
      "rank": 17,
      "rank_p2.5": 10,
      "rank_p97.5": 27,
      "total_output_tokens": 1211237,
      "conso_all_conv": 56.95931624038,
      "n_match": 1054,
      "mean_conso_per_match": 0.054041097002258065,
      "mean_conso_per_token": 4.7025739999999995e-05,
      "mean_win_prob": 0.5975294107870714,
      "win_rate": 0.539146110056926,
      "useful": 269,
      "creative": 137,
      "complete": 265,
      "clear_formatting": 186,
      "incorrect": 78,
      "superficial": 68,
      "instructions_not_followed": 36,
      "total_prefs": 1039,
      "positive_prefs_ratio": 0.8248315688161694
    },
    {
      "model_name": "glm-4.5",
      "median": 1071.5894336094539,
      "p2.5": 1059.0831743115648,
      "p97.5": 1083.9884952043906,
      "rank": 18,
      "rank_p2.5": 12,
      "rank_p97.5": 25,
      "total_output_tokens": 5128869,
      "conso_all_conv": 109.79790435558,
      "n_match": 2178,
      "mean_conso_per_match": 0.050412260952975206,
      "mean_conso_per_token": 2.140782e-05,
      "mean_win_prob": 0.5962459436308675,
      "win_rate": 0.5414882866329811,
      "useful": 227,
      "creative": 75,
      "complete": 282,
      "clear_formatting": 209,
      "incorrect": 48,
      "superficial": 57,
      "instructions_not_followed": 33,
      "total_prefs": 931,
      "positive_prefs_ratio": 0.8517722878625135
    },
    {
      "model_name": "gpt-5.1",
      "median": 1070.893932242053,
      "p2.5": 1058.554377132625,
      "p97.5": 1082.8525040508655,
      "rank": 19,
      "rank_p2.5": 12,
      "rank_p97.5": 26,
      "total_output_tokens": 2930696,
      "conso_all_conv": 139.23865646623997,
      "n_match": 2417,
      "mean_conso_per_match": 0.05760804984122465,
      "mean_conso_per_token": 4.7510439999999994e-05,
      "mean_win_prob": 0.5953128268472361,
      "win_rate": 0.5336698386429458,
      "useful": 335,
      "creative": 94,
      "complete": 333,
      "clear_formatting": 272,
      "incorrect": 56,
      "superficial": 94,
      "instructions_not_followed": 41,
      "total_prefs": 1225,
      "positive_prefs_ratio": 0.8440816326530612
    },
    {
      "model_name": "gpt-oss-120b",
      "median": 1068.3061995106573,
      "p2.5": 1054.8638676749456,
      "p97.5": 1082.9602750676468,
      "rank": 20,
      "rank_p2.5": 12,
      "rank_p97.5": 28,
      "total_output_tokens": 3891107,
      "conso_all_conv": 13.022951462950001,
      "n_match": 1629,
      "mean_conso_per_match": 0.007994445342510743,
      "mean_conso_per_token": 3.3468500000000004e-06,
      "mean_win_prob": 0.5918356063955229,
      "win_rate": 0.5262653562653563,
      "useful": 233,
      "creative": 83,
      "complete": 322,
      "clear_formatting": 212,
      "incorrect": 96,
      "superficial": 60,
      "instructions_not_followed": 49,
      "total_prefs": 1055,
      "positive_prefs_ratio": 0.8056872037914692
    },
    {
      "model_name": "gemma-3-12b",
      "median": 1064.366925842643,
      "p2.5": 1057.1702953681643,
      "p97.5": 1071.7209539487717,
      "rank": 21,
      "rank_p2.5": 17,
      "rank_p97.5": 27,
      "total_output_tokens": 9797471,
      "conso_all_conv": 42.415276769673326,
      "n_match": 7558,
      "mean_conso_per_match": 0.005611970993605891,
      "mean_conso_per_token": 4.329206666666666e-06,
      "mean_win_prob": 0.5865265015881653,
      "win_rate": 0.5586080973802593,
      "useful": 1283,
      "creative": 386,
      "complete": 1433,
      "clear_formatting": 1092,
      "incorrect": 439,
      "superficial": 321,
      "instructions_not_followed": 196,
      "total_prefs": 5150,
      "positive_prefs_ratio": 0.814368932038835
    },
    {
      "model_name": "grok-4-fast",
      "median": 1063.058854785343,
      "p2.5": 1051.1802140358664,
      "p97.5": 1074.3767607761074,
      "rank": 22,
      "rank_p2.5": 16,
      "rank_p97.5": 29,
      "total_output_tokens": 3521762,
      "conso_all_conv": 898.5308874750866,
      "n_match": 2623,
      "mean_conso_per_match": 0.34255847787841653,
      "mean_conso_per_token": 0.0002551367433333333,
      "mean_win_prob": 0.5847595187811853,
      "win_rate": 0.5293971766501335,
      "useful": 228,
      "creative": 53,
      "complete": 176,
      "clear_formatting": 137,
      "incorrect": 61,
      "superficial": 52,
      "instructions_not_followed": 20,
      "total_prefs": 727,
      "positive_prefs_ratio": 0.8170563961485557
    },
    {
      "model_name": "claude-4-sonnet",
      "median": 1062.6434292782344,
      "p2.5": 1052.492100010506,
      "p97.5": 1073.9712322858682,
      "rank": 23,
      "rank_p2.5": 16,
      "rank_p97.5": 29,
      "total_output_tokens": 1853912,
      "conso_all_conv": 162.18978794591996,
      "n_match": 2540,
      "mean_conso_per_match": 0.06385424722280314,
      "mean_conso_per_token": 8.748515999999998e-05,
      "mean_win_prob": 0.5841979394726365,
      "win_rate": 0.5355651831429696,
      "useful": 234,
      "creative": 62,
      "complete": 198,
      "clear_formatting": 215,
      "incorrect": 41,
      "superficial": 64,
      "instructions_not_followed": 20,
      "total_prefs": 834,
      "positive_prefs_ratio": 0.8501199040767387
    },
    {
      "model_name": "grok-3-mini-beta",
      "median": 1060.7242755705915,
      "p2.5": 1046.6686234766012,
      "p97.5": 1074.845586004332,
      "rank": 24,
      "rank_p2.5": 16,
      "rank_p97.5": 31,
      "total_output_tokens": 3474752,
      "conso_all_conv": 39.83854131029333,
      "n_match": 1537,
      "mean_conso_per_match": 0.02591967554345695,
      "mean_conso_per_token": 1.1465146666666665e-05,
      "mean_win_prob": 0.5816010813581873,
      "win_rate": 0.5305338541666668,
      "useful": 404,
      "creative": 102,
      "complete": 350,
      "clear_formatting": 320,
      "incorrect": 102,
      "superficial": 106,
      "instructions_not_followed": 47,
      "total_prefs": 1431,
      "positive_prefs_ratio": 0.8218029350104822
    },
    {
      "model_name": "kimi-k2-thinking",
      "median": 1060.3552878642026,
      "p2.5": 1038.5262065622546,
      "p97.5": 1082.193650352635,
      "rank": 25,
      "rank_p2.5": 13,
      "rank_p97.5": 34,
      "total_output_tokens": 1157671,
      "conso_all_conv": 66.08856636591997,
      "n_match": 678,
      "mean_conso_per_match": 0.09747576160165188,
      "mean_conso_per_token": 5.708751999999998e-05,
      "mean_win_prob": 0.5811013277123745,
      "win_rate": 0.5342920353982301,
      "useful": 126,
      "creative": 30,
      "complete": 129,
      "clear_formatting": 92,
      "incorrect": 39,
      "superficial": 48,
      "instructions_not_followed": 29,
      "total_prefs": 493,
      "positive_prefs_ratio": 0.7647058823529411
    },
    {
      "model_name": "mistral-small-2506",
      "median": 1059.9592084017231,
      "p2.5": 1051.3284908088083,
      "p97.5": 1068.8495171152083,
      "rank": 26,
      "rank_p2.5": 20,
      "rank_p97.5": 30,
      "total_output_tokens": 3604985,
      "conso_all_conv": 21.67766403463333,
      "n_match": 4433,
      "mean_conso_per_match": 0.004890066328588615,
      "mean_conso_per_token": 6.013246666666666e-06,
      "mean_win_prob": 0.5805647163202088,
      "win_rate": 0.5294428152492668,
      "useful": 468,
      "creative": 124,
      "complete": 385,
      "clear_formatting": 367,
      "incorrect": 177,
      "superficial": 139,
      "instructions_not_followed": 45,
      "total_prefs": 1705,
      "positive_prefs_ratio": 0.7882697947214077
    },
    {
      "model_name": "deepseek-r1-0528",
      "median": 1056.852144399906,
      "p2.5": 1043.047616463755,
      "p97.5": 1072.4261867285936,
      "rank": 27,
      "rank_p2.5": 17,
      "rank_p97.5": 33,
      "total_output_tokens": 2619487,
      "conso_all_conv": 123.18331459538,
      "n_match": 1412,
      "mean_conso_per_match": 0.08724030778709632,
      "mean_conso_per_token": 4.702574e-05,
      "mean_win_prob": 0.576349450955055,
      "win_rate": 0.5322733711048159,
      "useful": 177,
      "creative": 57,
      "complete": 154,
      "clear_formatting": 117,
      "incorrect": 49,
      "superficial": 52,
      "instructions_not_followed": 25,
      "total_prefs": 631,
      "positive_prefs_ratio": 0.8003169572107766
    },
    {
      "model_name": "command-a",
      "median": 1055.4181630833723,
      "p2.5": 1048.9358103298453,
      "p97.5": 1062.111743010546,
      "rank": 28,
      "rank_p2.5": 23,
      "rank_p97.5": 31,
      "total_output_tokens": 7091558,
      "conso_all_conv": 129.22617567879334,
      "n_match": 7294,
      "mean_conso_per_match": 0.017716777581408466,
      "mean_conso_per_token": 1.822253666666667e-05,
      "mean_win_prob": 0.5744006448837378,
      "win_rate": 0.5459692898272553,
      "useful": 1390,
      "creative": 333,
      "complete": 1264,
      "clear_formatting": 1174,
      "incorrect": 343,
      "superficial": 376,
      "instructions_not_followed": 130,
      "total_prefs": 5010,
      "positive_prefs_ratio": 0.8305389221556886
    },
    {
      "model_name": "kimi-k2",
      "median": 1054.6833739242657,
      "p2.5": 1037.318345848173,
      "p97.5": 1071.3485237355558,
      "rank": 29,
      "rank_p2.5": 17,
      "rank_p97.5": 35,
      "total_output_tokens": 1485794,
      "conso_all_conv": 84.82029469087998,
      "n_match": 1146,
      "mean_conso_per_match": 0.07401421875294936,
      "mean_conso_per_token": 5.7087519999999986e-05,
      "mean_win_prob": 0.5734012564678315,
      "win_rate": 0.5144434706397897,
      "useful": 263,
      "creative": 67,
      "complete": 149,
      "clear_formatting": 144,
      "incorrect": 56,
      "superficial": 70,
      "instructions_not_followed": 15,
      "total_prefs": 764,
      "positive_prefs_ratio": 0.8154450261780105
    },
    {
      "model_name": "Qwen3-Coder-480B-A35B-Instruct",
      "median": 1049.0215148455918,
      "p2.5": 1031.519604474285,
      "p97.5": 1067.1653054044036,
      "rank": 30,
      "rank_p2.5": 20,
      "rank_p97.5": 37,
      "total_output_tokens": 975688,
      "conso_all_conv": 29.492901726399996,
      "n_match": 928,
      "mean_conso_per_match": 0.03178114410172413,
      "mean_conso_per_token": 3.0227799999999995e-05,
      "mean_win_prob": 0.5656833367299694,
      "win_rate": 0.5300431965442765,
      "useful": 146,
      "creative": 40,
      "complete": 98,
      "clear_formatting": 117,
      "incorrect": 37,
      "superficial": 54,
      "instructions_not_followed": 21,
      "total_prefs": 513,
      "positive_prefs_ratio": 0.7816764132553606
    },
    {
      "model_name": "magistral-small-2506",
      "median": 1048.8923445351527,
      "p2.5": 1039.1160386019485,
      "p97.5": 1058.249389623649,
      "rank": 31,
      "rank_p2.5": 26,
      "rank_p97.5": 34,
      "total_output_tokens": 2445603,
      "conso_all_conv": 14.706014087739998,
      "n_match": 3147,
      "mean_conso_per_match": 0.0046730264022052746,
      "mean_conso_per_token": 6.013246666666666e-06,
      "mean_win_prob": 0.565506919253787,
      "win_rate": 0.52184361093452,
      "useful": 248,
      "creative": 53,
      "complete": 198,
      "clear_formatting": 181,
      "incorrect": 88,
      "superficial": 84,
      "instructions_not_followed": 32,
      "total_prefs": 884,
      "positive_prefs_ratio": 0.7692307692307693
    },
    {
      "model_name": "claude-3-7-sonnet",
      "median": 1048.6915459912173,
      "p2.5": 1038.8251105156319,
      "p97.5": 1058.180807391931,
      "rank": 32,
      "rank_p2.5": 26,
      "rank_p97.5": 34,
      "total_output_tokens": 3546728,
      "conso_all_conv": 310.2860665564799,
      "n_match": 3907,
      "mean_conso_per_match": 0.07941798478538006,
      "mean_conso_per_token": 8.748515999999998e-05,
      "mean_win_prob": 0.5652326449421975,
      "win_rate": 0.524225748656258,
      "useful": 1003,
      "creative": 230,
      "complete": 774,
      "clear_formatting": 822,
      "incorrect": 140,
      "superficial": 318,
      "instructions_not_followed": 46,
      "total_prefs": 3333,
      "positive_prefs_ratio": 0.8487848784878488
    },
    {
      "model_name": "llama-3.1-nemotron-70b-instruct",
      "median": 1043.9150592683645,
      "p2.5": 1036.1217893356184,
      "p97.5": 1051.6085349006516,
      "rank": 33,
      "rank_p2.5": 29,
      "rank_p97.5": 35,
      "total_output_tokens": 7426282,
      "conso_all_conv": 92.59632991613334,
      "n_match": 6709,
      "mean_conso_per_match": 0.01380180800657823,
      "mean_conso_per_token": 1.2468733333333335e-05,
      "mean_win_prob": 0.5586983979446976,
      "win_rate": 0.5452863107664778,
      "useful": 1544,
      "creative": 487,
      "complete": 1473,
      "clear_formatting": 1431,
      "incorrect": 381,
      "superficial": 395,
      "instructions_not_followed": 136,
      "total_prefs": 5847,
      "positive_prefs_ratio": 0.8440225756798359
    },
    {
      "model_name": "glm-4.6",
      "median": 1040.4643935994818,
      "p2.5": 1027.9939267047503,
      "p97.5": 1053.0940107296024,
      "rank": 34,
      "rank_p2.5": 29,
      "rank_p97.5": 38,
      "total_output_tokens": 6297696,
      "conso_all_conv": 134.81994238272,
      "n_match": 2266,
      "mean_conso_per_match": 0.05949688542926743,
      "mean_conso_per_token": 2.140782e-05,
      "mean_win_prob": 0.5539667590883812,
      "win_rate": 0.4990291262135922,
      "useful": 249,
      "creative": 94,
      "complete": 280,
      "clear_formatting": 197,
      "incorrect": 71,
      "superficial": 74,
      "instructions_not_followed": 46,
      "total_prefs": 1011,
      "positive_prefs_ratio": 0.811078140454995
    },
    {
      "model_name": "gemma-3-4b",
      "median": 1036.5054541272475,
      "p2.5": 1029.8268973752645,
      "p97.5": 1042.9124321546515,
      "rank": 35,
      "rank_p2.5": 33,
      "rank_p97.5": 38,
      "total_output_tokens": 10578812,
      "conso_all_conv": 33.92110172882667,
      "n_match": 8603,
      "mean_conso_per_match": 0.003942938710778411,
      "mean_conso_per_token": 3.206513333333334e-06,
      "mean_win_prob": 0.5485278358085516,
      "win_rate": 0.5147960013948623,
      "useful": 1303,
      "creative": 391,
      "complete": 1422,
      "clear_formatting": 1140,
      "incorrect": 677,
      "superficial": 337,
      "instructions_not_followed": 241,
      "total_prefs": 5511,
      "positive_prefs_ratio": 0.7722736345490836
    },
    {
      "model_name": "gpt-4.1-mini",
      "median": 1031.1981681474986,
      "p2.5": 1024.2488857161884,
      "p97.5": 1038.411575129714,
      "rank": 36,
      "rank_p2.5": 34,
      "rank_p97.5": 40,
      "total_output_tokens": 5550374,
      "conso_all_conv": 73.10073823583333,
      "n_match": 7173,
      "mean_conso_per_match": 0.010191096923997398,
      "mean_conso_per_token": 1.3170416666666667e-05,
      "mean_win_prob": 0.5412212451577058,
      "win_rate": 0.5152977269557941,
      "useful": 1227,
      "creative": 286,
      "complete": 945,
      "clear_formatting": 1010,
      "incorrect": 244,
      "superficial": 455,
      "instructions_not_followed": 97,
      "total_prefs": 4264,
      "positive_prefs_ratio": 0.8133208255159474
    },
    {
      "model_name": "gemini-1.5-pro",
      "median": 1030.3619828468663,
      "p2.5": 1023.1359837214284,
      "p97.5": 1038.4374046270898,
      "rank": 37,
      "rank_p2.5": 34,
      "rank_p97.5": 40,
      "total_output_tokens": 6034223,
      "conso_all_conv": 1011.3126436118333,
      "n_match": 7387,
      "mean_conso_per_match": 0.13690437845022788,
      "mean_conso_per_token": 0.00016759616666666666,
      "mean_win_prob": 0.5400686374275403,
      "win_rate": 0.5830743197509137,
      "useful": 2118,
      "creative": 683,
      "complete": 1630,
      "clear_formatting": 1959,
      "incorrect": 461,
      "superficial": 655,
      "instructions_not_followed": 202,
      "total_prefs": 7708,
      "positive_prefs_ratio": 0.8290088220031137
    },
    {
      "model_name": "gemma-3n-e4b-it",
      "median": 1029.48539288394,
      "p2.5": 1020.3421245522081,
      "p97.5": 1038.1205728047266,
      "rank": 38,
      "rank_p2.5": 34,
      "rank_p97.5": 41,
      "total_output_tokens": 4439755,
      "conso_all_conv": 14.236133604233334,
      "n_match": 3938,
      "mean_conso_per_match": 0.003615066938606738,
      "mean_conso_per_token": 3.2065133333333334e-06,
      "mean_win_prob": 0.5388599542139326,
      "win_rate": 0.4928186896901981,
      "useful": 367,
      "creative": 125,
      "complete": 368,
      "clear_formatting": 315,
      "incorrect": 193,
      "superficial": 153,
      "instructions_not_followed": 83,
      "total_prefs": 1604,
      "positive_prefs_ratio": 0.7325436408977556
    },
    {
      "model_name": "deepseek-r1",
      "median": 1025.0651243803609,
      "p2.5": 1014.8519111940177,
      "p97.5": 1034.726120970915,
      "rank": 39,
      "rank_p2.5": 36,
      "rank_p97.5": 43,
      "total_output_tokens": 3693582,
      "conso_all_conv": 173.69342680068,
      "n_match": 3510,
      "mean_conso_per_match": 0.04948530678082051,
      "mean_conso_per_token": 4.7025739999999995e-05,
      "mean_win_prob": 0.5327596127437955,
      "win_rate": 0.5313019943019943,
      "useful": 826,
      "creative": 284,
      "complete": 783,
      "clear_formatting": 667,
      "incorrect": 171,
      "superficial": 207,
      "instructions_not_followed": 112,
      "total_prefs": 3050,
      "positive_prefs_ratio": 0.839344262295082
    },
    {
      "model_name": "qwen3-32b",
      "median": 1020.658332565152,
      "p2.5": 1007.5820543581493,
      "p97.5": 1033.8618374673915,
      "rank": 40,
      "rank_p2.5": 36,
      "rank_p97.5": 48,
      "total_output_tokens": 3466073,
      "conso_all_conv": 24.733688963619993,
      "n_match": 1689,
      "mean_conso_per_match": 0.014643983992670214,
      "mean_conso_per_token": 7.135939999999998e-06,
      "mean_win_prob": 0.5266700398537579,
      "win_rate": 0.5090148367952523,
      "useful": 410,
      "creative": 117,
      "complete": 328,
      "clear_formatting": 257,
      "incorrect": 156,
      "superficial": 128,
      "instructions_not_followed": 75,
      "total_prefs": 1471,
      "positive_prefs_ratio": 0.7559483344663495
    },
    {
      "model_name": "mistral-large-2411",
      "median": 1018.3062850458269,
      "p2.5": 1011.587989187489,
      "p97.5": 1024.7701379666782,
      "rank": 41,
      "rank_p2.5": 39,
      "rank_p97.5": 46,
      "total_output_tokens": 7677266,
      "conso_all_conv": 152.82808421939336,
      "n_match": 8829,
      "mean_conso_per_match": 0.017309784145361124,
      "mean_conso_per_token": 1.990657666666667e-05,
      "mean_win_prob": 0.5234172299735705,
      "win_rate": 0.527441386340469,
      "useful": 1898,
      "creative": 355,
      "complete": 1451,
      "clear_formatting": 1608,
      "incorrect": 393,
      "superficial": 666,
      "instructions_not_followed": 140,
      "total_prefs": 6511,
      "positive_prefs_ratio": 0.8158500998310552
    },
    {
      "model_name": "gpt-oss-20b",
      "median": 1017.4570653701672,
      "p2.5": 1005.1895193585142,
      "p97.5": 1030.6749243220588,
      "rank": 42,
      "rank_p2.5": 38,
      "rank_p97.5": 49,
      "total_output_tokens": 3214051,
      "conso_all_conv": 9.854848181676667,
      "n_match": 1948,
      "mean_conso_per_match": 0.005058956972113279,
      "mean_conso_per_token": 3.066176666666667e-06,
      "mean_win_prob": 0.5222424082765674,
      "win_rate": 0.4692706728299949,
      "useful": 211,
      "creative": 75,
      "complete": 205,
      "clear_formatting": 186,
      "incorrect": 104,
      "superficial": 97,
      "instructions_not_followed": 56,
      "total_prefs": 934,
      "positive_prefs_ratio": 0.7248394004282656
    },
    {
      "model_name": "glm-4.7",
      "median": 1017.3658791330402,
      "p2.5": 980.4869260320432,
      "p97.5": 1052.1861956483704,
      "rank": 43,
      "rank_p2.5": 29,
      "rank_p97.5": 60,
      "total_output_tokens": 563587,
      "conso_all_conv": 12.06516905034,
      "n_match": 239,
      "mean_conso_per_match": 0.05048187887171548,
      "mean_conso_per_token": 2.140782e-05,
      "mean_win_prob": 0.5221162490919808,
      "win_rate": 0.46142259414225945,
      "useful": 35,
      "creative": 14,
      "complete": 39,
      "clear_formatting": 35,
      "incorrect": 18,
      "superficial": 16,
      "instructions_not_followed": 13,
      "total_prefs": 170,
      "positive_prefs_ratio": 0.7235294117647059
    },
    {
      "model_name": "mistral-saba",
      "median": 1014.5092854257869,
      "p2.5": 1006.029315615743,
      "p97.5": 1022.2658480807752,
      "rank": 44,
      "rank_p2.5": 40,
      "rank_p97.5": 48,
      "total_output_tokens": 4349650,
      "conso_all_conv": 26.155518363666665,
      "n_match": 4934,
      "mean_conso_per_match": 0.005301077901026888,
      "mean_conso_per_token": 6.0132466666666666e-06,
      "mean_win_prob": 0.5181630894855058,
      "win_rate": 0.48257855260490573,
      "useful": 745,
      "creative": 170,
      "complete": 587,
      "clear_formatting": 586,
      "incorrect": 241,
      "superficial": 337,
      "instructions_not_followed": 113,
      "total_prefs": 2779,
      "positive_prefs_ratio": 0.751349406261245
    },
    {
      "model_name": "llama-maverick",
      "median": 1012.5405194303282,
      "p2.5": 1001.7683915713392,
      "p97.5": 1022.3966426785697,
      "rank": 45,
      "rank_p2.5": 40,
      "rank_p97.5": 50,
      "total_output_tokens": 2504639,
      "conso_all_conv": 37.80168989613,
      "n_match": 3197,
      "mean_conso_per_match": 0.011824113198664372,
      "mean_conso_per_token": 1.509267e-05,
      "mean_win_prob": 0.5154376346310893,
      "win_rate": 0.47832030028151395,
      "useful": 315,
      "creative": 59,
      "complete": 221,
      "clear_formatting": 206,
      "incorrect": 97,
      "superficial": 167,
      "instructions_not_followed": 52,
      "total_prefs": 1117,
      "positive_prefs_ratio": 0.7170993733213966
    },
    {
      "model_name": "llama-4-scout",
      "median": 1009.2146222478575,
      "p2.5": 1001.4595087304773,
      "p97.5": 1015.993929258901,
      "rank": 46,
      "rank_p2.5": 43,
      "rank_p97.5": 51,
      "total_output_tokens": 4760953,
      "conso_all_conv": 23.951830838169997,
      "n_match": 5971,
      "mean_conso_per_match": 0.004011360046586836,
      "mean_conso_per_token": 5.03089e-06,
      "mean_win_prob": 0.5108321873778869,
      "win_rate": 0.4855066153073187,
      "useful": 894,
      "creative": 200,
      "complete": 758,
      "clear_formatting": 717,
      "incorrect": 316,
      "superficial": 438,
      "instructions_not_followed": 120,
      "total_prefs": 3443,
      "positive_prefs_ratio": 0.7461516119663084
    },
    {
      "model_name": "gpt-5-mini",
      "median": 1008.695952680056,
      "p2.5": 998.7937426670836,
      "p97.5": 1018.5186499298239,
      "rank": 47,
      "rank_p2.5": 42,
      "rank_p97.5": 52,
      "total_output_tokens": 4050672,
      "conso_all_conv": 37.43221944528,
      "n_match": 3455,
      "mean_conso_per_match": 0.010834216916144716,
      "mean_conso_per_token": 9.24099e-06,
      "mean_win_prob": 0.5101138706113768,
      "win_rate": 0.4652345107122177,
      "useful": 319,
      "creative": 82,
      "complete": 336,
      "clear_formatting": 195,
      "incorrect": 79,
      "superficial": 130,
      "instructions_not_followed": 88,
      "total_prefs": 1229,
      "positive_prefs_ratio": 0.758340113913751
    },
    {
      "model_name": "mistral-small-3.1-24b",
      "median": 1004.8344637526056,
      "p2.5": 997.5283146723439,
      "p97.5": 1013.2053762139294,
      "rank": 48,
      "rank_p2.5": 45,
      "rank_p97.5": 53,
      "total_output_tokens": 4470466,
      "conso_all_conv": 26.882014772946665,
      "n_match": 5079,
      "mean_conso_per_match": 0.005292777076776268,
      "mean_conso_per_token": 6.0132466666666666e-06,
      "mean_win_prob": 0.5047655743570576,
      "win_rate": 0.4945107304587517,
      "useful": 1108,
      "creative": 247,
      "complete": 791,
      "clear_formatting": 916,
      "incorrect": 268,
      "superficial": 430,
      "instructions_not_followed": 130,
      "total_prefs": 3890,
      "positive_prefs_ratio": 0.787146529562982
    },
    {
      "model_name": "o4-mini",
      "median": 1002.2546284816822,
      "p2.5": 991.6197299511147,
      "p97.5": 1012.9013613330469,
      "rank": 49,
      "rank_p2.5": 45,
      "rank_p97.5": 54,
      "total_output_tokens": 2940457,
      "conso_all_conv": 15.205769650586666,
      "n_match": 2830,
      "mean_conso_per_match": 0.005373063480772673,
      "mean_conso_per_token": 5.171226666666666e-06,
      "mean_win_prob": 0.5011923719206804,
      "win_rate": 0.4738494167550371,
      "useful": 527,
      "creative": 111,
      "complete": 374,
      "clear_formatting": 286,
      "incorrect": 133,
      "superficial": 210,
      "instructions_not_followed": 45,
      "total_prefs": 1686,
      "positive_prefs_ratio": 0.7698695136417556
    },
    {
      "model_name": "gemma-2-27b-it-q8",
      "median": 1000.2768399712684,
      "p2.5": 975.9897989938095,
      "p97.5": 1023.7039492437291,
      "rank": 50,
      "rank_p2.5": 40,
      "rank_p97.5": 63,
      "total_output_tokens": 449540,
      "conso_all_conv": 2.8924557419333334,
      "n_match": 762,
      "mean_conso_per_match": 0.0037958736770778655,
      "mean_conso_per_token": 6.434256666666667e-06,
      "mean_win_prob": 0.4984532666661402,
      "win_rate": 0.5826115485564304,
      "useful": 318,
      "creative": 97,
      "complete": 178,
      "clear_formatting": 305,
      "incorrect": 63,
      "superficial": 91,
      "instructions_not_followed": 29,
      "total_prefs": 1081,
      "positive_prefs_ratio": 0.8307123034227567
    },
    {
      "model_name": "gpt-5",
      "median": 999.363596923938,
      "p2.5": 989.622944504008,
      "p97.5": 1008.7088850406345,
      "rank": 51,
      "rank_p2.5": 47,
      "rank_p97.5": 55,
      "total_output_tokens": 4019540,
      "conso_all_conv": 190.97011399759995,
      "n_match": 3843,
      "mean_conso_per_match": 0.0496929778812386,
      "mean_conso_per_token": 4.751043999999999e-05,
      "mean_win_prob": 0.4971886021948773,
      "win_rate": 0.45334721499219155,
      "useful": 144,
      "creative": 54,
      "complete": 158,
      "clear_formatting": 68,
      "incorrect": 29,
      "superficial": 57,
      "instructions_not_followed": 32,
      "total_prefs": 542,
      "positive_prefs_ratio": 0.7822878228782287
    },
    {
      "model_name": "EuroLLM-22B-Instruct-2512",
      "median": 997.0852737062537,
      "p2.5": 960.5752775370632,
      "p97.5": 1034.9577845918532,
      "rank": 52,
      "rank_p2.5": 36,
      "rank_p97.5": 70,
      "total_output_tokens": 192139,
      "conso_all_conv": 1.1014509076933332,
      "n_match": 254,
      "mean_conso_per_match": 0.004336420896430446,
      "mean_conso_per_token": 5.7325733333333326e-06,
      "mean_win_prob": 0.49403401239369116,
      "win_rate": 0.419484126984127,
      "useful": 74,
      "creative": 17,
      "complete": 46,
      "clear_formatting": 54,
      "incorrect": 15,
      "superficial": 25,
      "instructions_not_followed": 10,
      "total_prefs": 241,
      "positive_prefs_ratio": 0.7925311203319502
    },
    {
      "model_name": "lfm2-8b-a1b",
      "median": 996.647416780047,
      "p2.5": 982.0136651550408,
      "p97.5": 1011.0284644014938,
      "rank": 53,
      "rank_p2.5": 46,
      "rank_p97.5": 60,
      "total_output_tokens": 1308678,
      "conso_all_conv": 3.64532693126,
      "n_match": 1702,
      "mean_conso_per_match": 0.0021417902063807287,
      "mean_conso_per_token": 2.7855033333333333e-06,
      "mean_win_prob": 0.4934278385346193,
      "win_rate": 0.4563337250293772,
      "useful": 201,
      "creative": 37,
      "complete": 136,
      "clear_formatting": 166,
      "incorrect": 138,
      "superficial": 126,
      "instructions_not_followed": 60,
      "total_prefs": 864,
      "positive_prefs_ratio": 0.625
    },
    {
      "model_name": "aya-expanse-32b",
      "median": 991.1910947395041,
      "p2.5": 982.8199595178106,
      "p97.5": 998.5600373644799,
      "rank": 54,
      "rank_p2.5": 51,
      "rank_p97.5": 60,
      "total_output_tokens": 4082212,
      "conso_all_conv": 29.130419899279993,
      "n_match": 5113,
      "mean_conso_per_match": 0.005697324447345979,
      "mean_conso_per_token": 7.135939999999998e-06,
      "mean_win_prob": 0.4858772861513582,
      "win_rate": 0.46256796401329947,
      "useful": 722,
      "creative": 142,
      "complete": 527,
      "clear_formatting": 513,
      "incorrect": 277,
      "superficial": 353,
      "instructions_not_followed": 109,
      "total_prefs": 2643,
      "positive_prefs_ratio": 0.7203934922436626
    },
    {
      "model_name": "qwen-3-8b",
      "median": 989.2194728691992,
      "p2.5": 977.2067314943608,
      "p97.5": 1001.0657278605617,
      "rank": 55,
      "rank_p2.5": 51,
      "rank_p97.5": 63,
      "total_output_tokens": 5244114,
      "conso_all_conv": 19.759087376039997,
      "n_match": 2580,
      "mean_conso_per_match": 0.007658560998465115,
      "mean_conso_per_token": 3.7678599999999993e-06,
      "mean_win_prob": 0.48315078014791146,
      "win_rate": 0.4352015503875969,
      "useful": 215,
      "creative": 68,
      "complete": 233,
      "clear_formatting": 162,
      "incorrect": 168,
      "superficial": 92,
      "instructions_not_followed": 66,
      "total_prefs": 1004,
      "positive_prefs_ratio": 0.6752988047808764
    },
    {
      "model_name": "qwen3-30b-a3b",
      "median": 987.0406692975203,
      "p2.5": 976.3129150490118,
      "p97.5": 997.5586053934893,
      "rank": 56,
      "rank_p2.5": 52,
      "rank_p97.5": 63,
      "total_output_tokens": 5423645,
      "conso_all_conv": 16.629853747283335,
      "n_match": 3122,
      "mean_conso_per_match": 0.005326666799257955,
      "mean_conso_per_token": 3.066176666666667e-06,
      "mean_win_prob": 0.4801392037086969,
      "win_rate": 0.46096443447612945,
      "useful": 258,
      "creative": 63,
      "complete": 266,
      "clear_formatting": 196,
      "incorrect": 168,
      "superficial": 135,
      "instructions_not_followed": 63,
      "total_prefs": 1149,
      "positive_prefs_ratio": 0.6814621409921671
    },
    {
      "model_name": "llama-3.3-70b",
      "median": 985.9747528619652,
      "p2.5": 979.072533657041,
      "p97.5": 991.8420047534565,
      "rank": 57,
      "rank_p2.5": 54,
      "rank_p97.5": 62,
      "total_output_tokens": 7614801,
      "conso_all_conv": 94.9469230554,
      "n_match": 9284,
      "mean_conso_per_match": 0.01022694130282206,
      "mean_conso_per_token": 1.2468733333333335e-05,
      "mean_win_prob": 0.47866648621678304,
      "win_rate": 0.4745099095217579,
      "useful": 1549,
      "creative": 319,
      "complete": 1207,
      "clear_formatting": 1155,
      "incorrect": 507,
      "superficial": 723,
      "instructions_not_followed": 169,
      "total_prefs": 5629,
      "positive_prefs_ratio": 0.7514656244448392
    },
    {
      "model_name": "mistral-small-24b-instruct-2501",
      "median": 985.379069506308,
      "p2.5": 975.1559022562396,
      "p97.5": 995.3563965340136,
      "rank": 58,
      "rank_p2.5": 52,
      "rank_p97.5": 63,
      "total_output_tokens": 2818040,
      "conso_all_conv": 16.94556963653333,
      "n_match": 3318,
      "mean_conso_per_match": 0.005107163844645368,
      "mean_conso_per_token": 6.013246666666666e-06,
      "mean_win_prob": 0.4778436504553153,
      "win_rate": 0.4952350813743219,
      "useful": 745,
      "creative": 155,
      "complete": 536,
      "clear_formatting": 656,
      "incorrect": 204,
      "superficial": 307,
      "instructions_not_followed": 71,
      "total_prefs": 2674,
      "positive_prefs_ratio": 0.7823485415108452
    },
    {
      "model_name": "o3-mini",
      "median": 981.4926913098273,
      "p2.5": 966.6917218690526,
      "p97.5": 995.7611591512783,
      "rank": 59,
      "rank_p2.5": 53,
      "rank_p97.5": 68,
      "total_output_tokens": 1655945,
      "conso_all_conv": 8.563266942533334,
      "n_match": 1619,
      "mean_conso_per_match": 0.005289232206629607,
      "mean_conso_per_token": 5.171226666666667e-06,
      "mean_win_prob": 0.47247888296939516,
      "win_rate": 0.51142063001853,
      "useful": 350,
      "creative": 85,
      "complete": 254,
      "clear_formatting": 230,
      "incorrect": 49,
      "superficial": 133,
      "instructions_not_followed": 28,
      "total_prefs": 1129,
      "positive_prefs_ratio": 0.8139946855624446
    },
    {
      "model_name": "gpt-4o-mini-2024-07-18",
      "median": 980.9810820875207,
      "p2.5": 973.3728399536376,
      "p97.5": 988.7781809544667,
      "rank": 60,
      "rank_p2.5": 56,
      "rank_p97.5": 65,
      "total_output_tokens": 5207480,
      "conso_all_conv": 26.929059442133333,
      "n_match": 6990,
      "mean_conso_per_match": 0.0038525120804196473,
      "mean_conso_per_token": 5.171226666666666e-06,
      "mean_win_prob": 0.4717731589535421,
      "win_rate": 0.49947067238912735,
      "useful": 1491,
      "creative": 319,
      "complete": 856,
      "clear_formatting": 1282,
      "incorrect": 369,
      "superficial": 599,
      "instructions_not_followed": 110,
      "total_prefs": 5026,
      "positive_prefs_ratio": 0.7855153203342619
    },
    {
      "model_name": "gpt-4.1-nano",
      "median": 977.0576907327647,
      "p2.5": 969.6915308779319,
      "p97.5": 985.4785081129481,
      "rank": 61,
      "rank_p2.5": 57,
      "rank_p97.5": 67,
      "total_output_tokens": 3563423,
      "conso_all_conv": 20.927662570929996,
      "n_match": 5717,
      "mean_conso_per_match": 0.003660602163884904,
      "mean_conso_per_token": 5.872909999999999e-06,
      "mean_win_prob": 0.46636551728728115,
      "win_rate": 0.46743047052649994,
      "useful": 928,
      "creative": 159,
      "complete": 529,
      "clear_formatting": 649,
      "incorrect": 276,
      "superficial": 448,
      "instructions_not_followed": 103,
      "total_prefs": 3092,
      "positive_prefs_ratio": 0.732535575679172
    },
    {
      "model_name": "Apertus-70B-Instruct-2509",
      "median": 976.871030094648,
      "p2.5": 964.2321352988552,
      "p97.5": 989.8187224067748,
      "rank": 62,
      "rank_p2.5": 55,
      "rank_p97.5": 69,
      "total_output_tokens": 2056962,
      "conso_all_conv": 25.6477106548,
      "n_match": 2106,
      "mean_conso_per_match": 0.012178400120987655,
      "mean_conso_per_token": 1.2468733333333333e-05,
      "mean_win_prob": 0.4661084453883024,
      "win_rate": 0.41137226970560303,
      "useful": 206,
      "creative": 41,
      "complete": 136,
      "clear_formatting": 122,
      "incorrect": 108,
      "superficial": 134,
      "instructions_not_followed": 67,
      "total_prefs": 814,
      "positive_prefs_ratio": 0.6203931203931204
    },
    {
      "model_name": "minimax-m2",
      "median": 975.0895845601183,
      "p2.5": 960.245445935748,
      "p97.5": 990.3078502882013,
      "rank": 63,
      "rank_p2.5": 55,
      "rank_p97.5": 71,
      "total_output_tokens": 2857086,
      "conso_all_conv": 23.134015814399998,
      "n_match": 1566,
      "mean_conso_per_match": 0.014772679319540228,
      "mean_conso_per_token": 8.097066666666666e-06,
      "mean_win_prob": 0.46365601058379236,
      "win_rate": 0.43562579821200514,
      "useful": 193,
      "creative": 46,
      "complete": 151,
      "clear_formatting": 108,
      "incorrect": 77,
      "superficial": 92,
      "instructions_not_followed": 46,
      "total_prefs": 713,
      "positive_prefs_ratio": 0.6984572230014026
    },
    {
      "model_name": "jamba-1.5-large",
      "median": 973.0290689144917,
      "p2.5": 928.4537175494206,
      "p97.5": 1018.2281315991596,
      "rank": 64,
      "rank_p2.5": 42,
      "rank_p97.5": 80,
      "total_output_tokens": 143976,
      "conso_all_conv": 6.840363109439998,
      "n_match": 172,
      "mean_conso_per_match": 0.03976955296186046,
      "mean_conso_per_token": 4.751043999999999e-05,
      "mean_win_prob": 0.4608217526761389,
      "win_rate": 0.5449418604651163,
      "useful": 44,
      "creative": 11,
      "complete": 18,
      "clear_formatting": 57,
      "incorrect": 15,
      "superficial": 13,
      "instructions_not_followed": 4,
      "total_prefs": 162,
      "positive_prefs_ratio": 0.8024691358024691
    },
    {
      "model_name": "aya-expanse-8b",
      "median": 972.258265342761,
      "p2.5": 956.8104859176012,
      "p97.5": 987.7149730001724,
      "rank": 65,
      "rank_p2.5": 56,
      "rank_p97.5": 72,
      "total_output_tokens": 1057810,
      "conso_all_conv": 3.9856799865999997,
      "n_match": 1302,
      "mean_conso_per_match": 0.003061198146390169,
      "mean_conso_per_token": 3.7678599999999997e-06,
      "mean_win_prob": 0.4597621885911757,
      "win_rate": 0.5014285714285714,
      "useful": 243,
      "creative": 55,
      "complete": 133,
      "clear_formatting": 223,
      "incorrect": 149,
      "superficial": 104,
      "instructions_not_followed": 31,
      "total_prefs": 938,
      "positive_prefs_ratio": 0.697228144989339
    },
    {
      "model_name": "llama-3.1-70b",
      "median": 971.6386297043077,
      "p2.5": 963.1509285834545,
      "p97.5": 980.3053774970598,
      "rank": 66,
      "rank_p2.5": 61,
      "rank_p97.5": 70,
      "total_output_tokens": 4057254,
      "conso_all_conv": 50.588818191600005,
      "n_match": 5583,
      "mean_conso_per_match": 0.009061224823858141,
      "mean_conso_per_token": 1.2468733333333335e-05,
      "mean_win_prob": 0.45891070269576695,
      "win_rate": 0.530445996775927,
      "useful": 1532,
      "creative": 365,
      "complete": 1047,
      "clear_formatting": 1305,
      "incorrect": 463,
      "superficial": 621,
      "instructions_not_followed": 177,
      "total_prefs": 5510,
      "positive_prefs_ratio": 0.7711433756805808
    },
    {
      "model_name": "claude-3-5-sonnet-v2",
      "median": 970.724826016665,
      "p2.5": 962.3556644615504,
      "p97.5": 979.4289062725001,
      "rank": 67,
      "rank_p2.5": 61,
      "rank_p97.5": 70,
      "total_output_tokens": 3224219,
      "conso_all_conv": 282.07131509003995,
      "n_match": 5683,
      "mean_conso_per_match": 0.049634227536519436,
      "mean_conso_per_token": 8.748515999999998e-05,
      "mean_win_prob": 0.4576554440182713,
      "win_rate": 0.4921080415273623,
      "useful": 1301,
      "creative": 291,
      "complete": 721,
      "clear_formatting": 905,
      "incorrect": 250,
      "superficial": 606,
      "instructions_not_followed": 94,
      "total_prefs": 4168,
      "positive_prefs_ratio": 0.7720729366602687
    },
    {
      "model_name": "phi-4",
      "median": 966.230807006805,
      "p2.5": 959.8132931832162,
      "p97.5": 972.212863963309,
      "rank": 68,
      "rank_p2.5": 65,
      "rank_p97.5": 71,
      "total_output_tokens": 8226489,
      "conso_all_conv": 37.92312711132,
      "n_match": 9968,
      "mean_conso_per_match": 0.003804487069755217,
      "mean_conso_per_token": 4.60988e-06,
      "mean_win_prob": 0.45149070431905136,
      "win_rate": 0.46780074245008524,
      "useful": 1626,
      "creative": 336,
      "complete": 1193,
      "clear_formatting": 1311,
      "incorrect": 731,
      "superficial": 760,
      "instructions_not_followed": 253,
      "total_prefs": 6210,
      "positive_prefs_ratio": 0.7191626409017713
    },
    {
      "model_name": "ministral-8b-instruct-2410",
      "median": 962.2570210335678,
      "p2.5": 955.5911481474013,
      "p97.5": 968.8414765945308,
      "rank": 69,
      "rank_p2.5": 67,
      "rank_p97.5": 73,
      "total_output_tokens": 7488476,
      "conso_all_conv": 28.215529181359997,
      "n_match": 9278,
      "mean_conso_per_match": 0.003041121920819142,
      "mean_conso_per_token": 3.7678599999999997e-06,
      "mean_win_prob": 0.4460524201621619,
      "win_rate": 0.47576819407008086,
      "useful": 1796,
      "creative": 412,
      "complete": 1332,
      "clear_formatting": 1695,
      "incorrect": 876,
      "superficial": 927,
      "instructions_not_followed": 274,
      "total_prefs": 7312,
      "positive_prefs_ratio": 0.7159463894967177
    },
    {
      "model_name": "gpt-4o-2024-08-06",
      "median": 961.1971063302826,
      "p2.5": 952.9219831269237,
      "p97.5": 969.867675176061,
      "rank": 70,
      "rank_p2.5": 66,
      "rank_p97.5": 74,
      "total_output_tokens": 3903917,
      "conso_all_conv": 341.53480337171993,
      "n_match": 5896,
      "mean_conso_per_match": 0.05792652703048167,
      "mean_conso_per_token": 8.748515999999998e-05,
      "mean_win_prob": 0.4446040783444367,
      "win_rate": 0.48863297150610585,
      "useful": 1230,
      "creative": 243,
      "complete": 593,
      "clear_formatting": 1002,
      "incorrect": 275,
      "superficial": 590,
      "instructions_not_followed": 115,
      "total_prefs": 4048,
      "positive_prefs_ratio": 0.7579051383399209
    },
    {
      "model_name": "Apertus-8B-Instruct-2509",
      "median": 960.6261163193014,
      "p2.5": 909.8337138559517,
      "p97.5": 1014.185304960044,
      "rank": 71,
      "rank_p2.5": 44,
      "rank_p97.5": 83,
      "total_output_tokens": 52304,
      "conso_all_conv": 0.19707414943999998,
      "n_match": 86,
      "mean_conso_per_match": 0.002291559877209302,
      "mean_conso_per_token": 3.7678599999999997e-06,
      "mean_win_prob": 0.4438242368578382,
      "win_rate": 0.46880952380952384,
      "useful": 2,
      "creative": 0,
      "complete": 3,
      "clear_formatting": 2,
      "incorrect": 3,
      "superficial": 5,
      "instructions_not_followed": 0,
      "total_prefs": 15,
      "positive_prefs_ratio": 0.4666666666666667
    },
    {
      "model_name": "qwen2.5-32b-instruct",
      "median": 959.0063201967632,
      "p2.5": 902.5851180942547,
      "p97.5": 1017.1252433008033,
      "rank": 72,
      "rank_p2.5": 42,
      "rank_p97.5": 83,
      "total_output_tokens": 75812,
      "conso_all_conv": 0.5409898832799999,
      "n_match": 142,
      "mean_conso_per_match": 0.003809787910422534,
      "mean_conso_per_token": 7.135939999999998e-06,
      "mean_win_prob": 0.4416135244980132,
      "win_rate": 0.5557042253521126,
      "useful": 52,
      "creative": 16,
      "complete": 43,
      "clear_formatting": 57,
      "incorrect": 13,
      "superficial": 21,
      "instructions_not_followed": 15,
      "total_prefs": 217,
      "positive_prefs_ratio": 0.7741935483870968
    },
    {
      "model_name": "llama-3.1-405b",
      "median": 955.8817237616692,
      "p2.5": 949.4511264487442,
      "p97.5": 962.8440573304997,
      "rank": 73,
      "rank_p2.5": 69,
      "rank_p97.5": 75,
      "total_output_tokens": 10383810,
      "conso_all_conv": 2470.579070314,
      "n_match": 9973,
      "mean_conso_per_match": 0.24772676930853305,
      "mean_conso_per_token": 0.00023792606666666667,
      "mean_win_prob": 0.43735580122351175,
      "win_rate": 0.4950747166783672,
      "useful": 2224,
      "creative": 556,
      "complete": 1579,
      "clear_formatting": 1788,
      "incorrect": 947,
      "superficial": 890,
      "instructions_not_followed": 437,
      "total_prefs": 8421,
      "positive_prefs_ratio": 0.7299608122550766
    },
    {
      "model_name": "gemma-2-9b-it",
      "median": 951.8584304337653,
      "p2.5": 943.2384351050382,
      "p97.5": 961.4225778180322,
      "rank": 74,
      "rank_p2.5": 70,
      "rank_p97.5": 77,
      "total_output_tokens": 3108609,
      "conso_all_conv": 12.149055331769999,
      "n_match": 5115,
      "mean_conso_per_match": 0.002375181883043988,
      "mean_conso_per_token": 3.908196666666666e-06,
      "mean_win_prob": 0.4318873554575748,
      "win_rate": 0.5068660801564027,
      "useful": 1250,
      "creative": 403,
      "complete": 771,
      "clear_formatting": 1197,
      "incorrect": 472,
      "superficial": 595,
      "instructions_not_followed": 177,
      "total_prefs": 4865,
      "positive_prefs_ratio": 0.7442959917780062
    },
    {
      "model_name": "gpt-5-nano",
      "median": 948.7675299500521,
      "p2.5": 937.5329650889195,
      "p97.5": 959.2610051471803,
      "rank": 75,
      "rank_p2.5": 71,
      "rank_p97.5": 78,
      "total_output_tokens": 3005341,
      "conso_all_conv": 12.588982754669999,
      "n_match": 2854,
      "mean_conso_per_match": 0.00441099605980028,
      "mean_conso_per_token": 4.188869999999999e-06,
      "mean_win_prob": 0.4276975231405087,
      "win_rate": 0.39904695164681153,
      "useful": 206,
      "creative": 52,
      "complete": 209,
      "clear_formatting": 140,
      "incorrect": 108,
      "superficial": 126,
      "instructions_not_followed": 124,
      "total_prefs": 965,
      "positive_prefs_ratio": 0.6290155440414508
    },
    {
      "model_name": "qwq-32b",
      "median": 947.2197340711832,
      "p2.5": 931.4358107067444,
      "p97.5": 962.4433156204691,
      "rank": 76,
      "rank_p2.5": 69,
      "rank_p97.5": 80,
      "total_output_tokens": 1895013,
      "conso_all_conv": 13.522699067219996,
      "n_match": 1566,
      "mean_conso_per_match": 0.008635184589540228,
      "mean_conso_per_token": 7.135939999999998e-06,
      "mean_win_prob": 0.425603309053783,
      "win_rate": 0.4485997442455243,
      "useful": 291,
      "creative": 139,
      "complete": 343,
      "clear_formatting": 233,
      "incorrect": 140,
      "superficial": 105,
      "instructions_not_followed": 92,
      "total_prefs": 1343,
      "positive_prefs_ratio": 0.7490692479523455
    },
    {
      "model_name": "deepseek-r1-distill-llama-70b",
      "median": 945.0999632783911,
      "p2.5": 933.7506838958557,
      "p97.5": 955.2721888097566,
      "rank": 77,
      "rank_p2.5": 72,
      "rank_p97.5": 79,
      "total_output_tokens": 2863519,
      "conso_all_conv": 35.70445480593334,
      "n_match": 2981,
      "mean_conso_per_match": 0.011977341431041039,
      "mean_conso_per_token": 1.2468733333333335e-05,
      "mean_win_prob": 0.42273955746986297,
      "win_rate": 0.4397953706809795,
      "useful": 489,
      "creative": 130,
      "complete": 355,
      "clear_formatting": 363,
      "incorrect": 190,
      "superficial": 342,
      "instructions_not_followed": 126,
      "total_prefs": 1995,
      "positive_prefs_ratio": 0.6701754385964912
    },
    {
      "model_name": "hermes-3-llama-3.1-405b",
      "median": 940.4014737116505,
      "p2.5": 932.7162489875157,
      "p97.5": 947.7917139523985,
      "rank": 78,
      "rank_p2.5": 74,
      "rank_p97.5": 80,
      "total_output_tokens": 4092822,
      "conso_all_conv": 973.7890400268,
      "n_match": 6735,
      "mean_conso_per_match": 0.144586345957951,
      "mean_conso_per_token": 0.00023792606666666667,
      "mean_win_prob": 0.4164108013389465,
      "win_rate": 0.46634743875278395,
      "useful": 1450,
      "creative": 285,
      "complete": 830,
      "clear_formatting": 1109,
      "incorrect": 426,
      "superficial": 753,
      "instructions_not_followed": 184,
      "total_prefs": 5037,
      "positive_prefs_ratio": 0.7294024220766329
    },
    {
      "model_name": "hermes-4-70b",
      "median": 936.244666876612,
      "p2.5": 925.153103126758,
      "p97.5": 947.7115526888132,
      "rank": 79,
      "rank_p2.5": 75,
      "rank_p97.5": 82,
      "total_output_tokens": 1253486,
      "conso_all_conv": 15.629382671066667,
      "n_match": 2673,
      "mean_conso_per_match": 0.005847131564185061,
      "mean_conso_per_token": 1.2468733333333333e-05,
      "mean_win_prob": 0.41083444207583936,
      "win_rate": 0.375859872611465,
      "useful": 215,
      "creative": 39,
      "complete": 95,
      "clear_formatting": 134,
      "incorrect": 122,
      "superficial": 198,
      "instructions_not_followed": 84,
      "total_prefs": 887,
      "positive_prefs_ratio": 0.5445321307779031
    },
    {
      "model_name": "llama-3.1-8b",
      "median": 932.2687564325365,
      "p2.5": 925.9274178510068,
      "p97.5": 938.1632253640825,
      "rank": 80,
      "rank_p2.5": 78,
      "rank_p97.5": 82,
      "total_output_tokens": 7372632,
      "conso_all_conv": 27.779045207519996,
      "n_match": 10444,
      "mean_conso_per_match": 0.002659809001103025,
      "mean_conso_per_token": 3.7678599999999993e-06,
      "mean_win_prob": 0.40552195730653634,
      "win_rate": 0.4424234009957871,
      "useful": 1540,
      "creative": 373,
      "complete": 1014,
      "clear_formatting": 1159,
      "incorrect": 1043,
      "superficial": 978,
      "instructions_not_followed": 404,
      "total_prefs": 6511,
      "positive_prefs_ratio": 0.6275533712179389
    },
    {
      "model_name": "c4ai-command-r-08-2024",
      "median": 928.2978824163628,
      "p2.5": 920.3706731324211,
      "p97.5": 935.6424818227871,
      "rank": 81,
      "rank_p2.5": 78,
      "rank_p97.5": 83,
      "total_output_tokens": 4319206,
      "conso_all_conv": 32.640023781699995,
      "n_match": 5959,
      "mean_conso_per_match": 0.005477433089729819,
      "mean_conso_per_token": 7.556949999999999e-06,
      "mean_win_prob": 0.40023798386817366,
      "win_rate": 0.42968786709179396,
      "useful": 1075,
      "creative": 255,
      "complete": 843,
      "clear_formatting": 796,
      "incorrect": 471,
      "superficial": 660,
      "instructions_not_followed": 163,
      "total_prefs": 4263,
      "positive_prefs_ratio": 0.6964578935022285
    },
    {
      "model_name": "qwen2.5-7b-instruct",
      "median": 925.4006893525334,
      "p2.5": 907.5673206591161,
      "p97.5": 942.7463280629378,
      "rank": 82,
      "rank_p2.5": 76,
      "rank_p97.5": 83,
      "total_output_tokens": 1186919,
      "conso_all_conv": 4.305576367276667,
      "n_match": 1417,
      "mean_conso_per_match": 0.0030385154320936255,
      "mean_conso_per_token": 3.6275233333333336e-06,
      "mean_win_prob": 0.396397080211424,
      "win_rate": 0.49383909668313336,
      "useful": 402,
      "creative": 104,
      "complete": 284,
      "clear_formatting": 380,
      "incorrect": 231,
      "superficial": 203,
      "instructions_not_followed": 88,
      "total_prefs": 1692,
      "positive_prefs_ratio": 0.6914893617021277
    },
    {
      "model_name": "qwen2.5-coder-32b-instruct",
      "median": 925.1733746357072,
      "p2.5": 917.934929570649,
      "p97.5": 931.8363708993633,
      "rank": 83,
      "rank_p2.5": 80,
      "rank_p97.5": 83,
      "total_output_tokens": 6149486,
      "conso_all_conv": 43.882363126839984,
      "n_match": 7299,
      "mean_conso_per_match": 0.006012106196306341,
      "mean_conso_per_token": 7.1359399999999974e-06,
      "mean_win_prob": 0.3960962475197294,
      "win_rate": 0.43789423208658723,
      "useful": 1379,
      "creative": 293,
      "complete": 923,
      "clear_formatting": 1142,
      "incorrect": 790,
      "superficial": 742,
      "instructions_not_followed": 234,
      "total_prefs": 5503,
      "positive_prefs_ratio": 0.6790841359258586
    },
    {
      "model_name": "mixtral-8x7b-instruct-v0.1",
      "median": 883.2618332413805,
      "p2.5": 869.8028174164942,
      "p97.5": 895.8627411496702,
      "rank": 84,
      "rank_p2.5": 84,
      "rank_p97.5": 86,
      "total_output_tokens": 1575791,
      "conso_all_conv": 7.2642074150800005,
      "n_match": 2560,
      "mean_conso_per_match": 0.0028375810215156253,
      "mean_conso_per_token": 4.60988e-06,
      "mean_win_prob": 0.3421440927014306,
      "win_rate": 0.43488671874999996,
      "useful": 727,
      "creative": 164,
      "complete": 375,
      "clear_formatting": 503,
      "incorrect": 256,
      "superficial": 389,
      "instructions_not_followed": 159,
      "total_prefs": 2573,
      "positive_prefs_ratio": 0.687524290711232
    },
    {
      "model_name": "olmo-3-32b-think",
      "median": 880.1527709332884,
      "p2.5": 853.1748751501239,
      "p97.5": 907.3333653905297,
      "rank": 85,
      "rank_p2.5": 84,
      "rank_p97.5": 88,
      "total_output_tokens": 1326949,
      "conso_all_conv": 9.469028447059998,
      "n_match": 564,
      "mean_conso_per_match": 0.016789057530248223,
      "mean_conso_per_token": 7.135939999999998e-06,
      "mean_win_prob": 0.33827717166118637,
      "win_rate": 0.3575886524822695,
      "useful": 53,
      "creative": 16,
      "complete": 50,
      "clear_formatting": 23,
      "incorrect": 56,
      "superficial": 43,
      "instructions_not_followed": 47,
      "total_prefs": 288,
      "positive_prefs_ratio": 0.4930555555555556
    },
    {
      "model_name": "lfm-40b",
      "median": 880.1524410012432,
      "p2.5": 868.8065284333462,
      "p97.5": 891.072764306751,
      "rank": 86,
      "rank_p2.5": 84,
      "rank_p97.5": 86,
      "total_output_tokens": 2000824,
      "conso_all_conv": 8.661980599626665,
      "n_match": 3578,
      "mean_conso_per_match": 0.0024209001116899565,
      "mean_conso_per_token": 4.329206666666666e-06,
      "mean_win_prob": 0.33827676240078935,
      "win_rate": 0.416296813862493,
      "useful": 841,
      "creative": 166,
      "complete": 419,
      "clear_formatting": 647,
      "incorrect": 357,
      "superficial": 572,
      "instructions_not_followed": 121,
      "total_prefs": 3123,
      "positive_prefs_ratio": 0.6637848222862632
    },
    {
      "model_name": "phi-3.5-mini-instruct",
      "median": 859.4229001597655,
      "p2.5": 846.5168775247994,
      "p97.5": 873.4625904865701,
      "rank": 87,
      "rank_p2.5": 86,
      "rank_p97.5": 88,
      "total_output_tokens": 2149046,
      "conso_all_conv": 6.589354700793333,
      "n_match": 2535,
      "mean_conso_per_match": 0.0025993509667823797,
      "mean_conso_per_token": 3.0661766666666664e-06,
      "mean_win_prob": 0.3130418997168436,
      "win_rate": 0.4021104536489152,
      "useful": 636,
      "creative": 226,
      "complete": 477,
      "clear_formatting": 533,
      "incorrect": 428,
      "superficial": 449,
      "instructions_not_followed": 300,
      "total_prefs": 3049,
      "positive_prefs_ratio": 0.6139717940308298
    },
    {
      "model_name": "mistral-nemo-2407",
      "median": 850.6352188172361,
      "p2.5": 841.539679608714,
      "p97.5": 859.1691069327522,
      "rank": 88,
      "rank_p2.5": 87,
      "rank_p97.5": 89,
      "total_output_tokens": 3305342,
      "conso_all_conv": 14.30950862201333,
      "n_match": 6251,
      "mean_conso_per_match": 0.0022891551147037805,
      "mean_conso_per_token": 4.329206666666666e-06,
      "mean_win_prob": 0.30264729931808865,
      "win_rate": 0.37482482802751566,
      "useful": 1413,
      "creative": 225,
      "complete": 661,
      "clear_formatting": 900,
      "incorrect": 638,
      "superficial": 1088,
      "instructions_not_followed": 292,
      "total_prefs": 5217,
      "positive_prefs_ratio": 0.6131876557408472
    },
    {
      "model_name": "mixtral-8x22b-instruct-v0.1",
      "median": 839.9244557603643,
      "p2.5": 830.9130338288958,
      "p97.5": 849.0012101574403,
      "rank": 89,
      "rank_p2.5": 88,
      "rank_p97.5": 90,
      "total_output_tokens": 3041056,
      "conso_all_conv": 53.644106197759996,
      "n_match": 5455,
      "mean_conso_per_match": 0.009833933308480293,
      "mean_conso_per_token": 1.7639959999999998e-05,
      "mean_win_prob": 0.29023570184184055,
      "win_rate": 0.36710357470210814,
      "useful": 1117,
      "creative": 203,
      "complete": 516,
      "clear_formatting": 702,
      "incorrect": 535,
      "superficial": 934,
      "instructions_not_followed": 276,
      "total_prefs": 4283,
      "positive_prefs_ratio": 0.5925752976885361
    },
    {
      "model_name": "chocolatine-2-14b-instruct-v2.0.3-q8",
      "median": 817.714080678383,
      "p2.5": 800.4526435393001,
      "p97.5": 834.1736971634198,
      "rank": 90,
      "rank_p2.5": 90,
      "rank_p97.5": 91,
      "total_output_tokens": 533384,
      "conso_all_conv": 1.9348629056266669,
      "n_match": 1796,
      "mean_conso_per_match": 0.0010773178761841128,
      "mean_conso_per_token": 3.6275233333333336e-06,
      "mean_win_prob": 0.2654424362559162,
      "win_rate": 0.3317316258351893,
      "useful": 280,
      "creative": 37,
      "complete": 100,
      "clear_formatting": 199,
      "incorrect": 161,
      "superficial": 370,
      "instructions_not_followed": 50,
      "total_prefs": 1197,
      "positive_prefs_ratio": 0.5146198830409356
    },
    {
      "model_name": "Yi-1.5-9B-Chat",
      "median": 763.3884227322033,
      "p2.5": 658.5922441136802,
      "p97.5": 853.7451978526623,
      "rank": 91,
      "rank_p2.5": 88,
      "rank_p97.5": 93,
      "total_output_tokens": 47531,
      "conso_all_conv": 0.1857604957633333,
      "n_match": 65,
      "mean_conso_per_match": 0.0028578537809743586,
      "mean_conso_per_token": 3.908196666666666e-06,
      "mean_win_prob": 0.21051212678920397,
      "win_rate": 0.32599999999999996,
      "useful": 16,
      "creative": 5,
      "complete": 14,
      "clear_formatting": 19,
      "incorrect": 12,
      "superficial": 17,
      "instructions_not_followed": 14,
      "total_prefs": 97,
      "positive_prefs_ratio": 0.5567010309278351
    },
    {
      "model_name": "chocolatine-14b-instruct-dpo-v1.2-q4",
      "median": 749.044041919858,
      "p2.5": 700.0538555177683,
      "p97.5": 792.3659124415228,
      "rank": 92,
      "rank_p2.5": 91,
      "rank_p97.5": 93,
      "total_output_tokens": 131187,
      "conso_all_conv": 0.6047563275600001,
      "n_match": 309,
      "mean_conso_per_match": 0.001957140218640777,
      "mean_conso_per_token": 4.609880000000001e-06,
      "mean_win_prob": 0.1974092968672108,
      "win_rate": 0.2402265372168285,
      "useful": 83,
      "creative": 17,
      "complete": 39,
      "clear_formatting": 43,
      "incorrect": 52,
      "superficial": 107,
      "instructions_not_followed": 50,
      "total_prefs": 391,
      "positive_prefs_ratio": 0.46547314578005117
    },
    {
      "model_name": "qwen2-7b-instruct",
      "median": 726.288187654013,
      "p2.5": 630.6360342799483,
      "p97.5": 803.2879723636338,
      "rank": 93,
      "rank_p2.5": 91,
      "rank_p97.5": 93,
      "total_output_tokens": 43550,
      "conso_all_conv": 0.15797864116666668,
      "n_match": 80,
      "mean_conso_per_match": 0.0019747330145833335,
      "mean_conso_per_token": 3.6275233333333336e-06,
      "mean_win_prob": 0.17783240445860038,
      "win_rate": 0.2525,
      "useful": 19,
      "creative": 4,
      "complete": 12,
      "clear_formatting": 22,
      "incorrect": 11,
      "superficial": 14,
      "instructions_not_followed": 7,
      "total_prefs": 89,
      "positive_prefs_ratio": 0.6404494382022472
    }
  ]
}
