from typing import Annotated, Any, Literal

from pydantic import (
    Field,
    ValidationInfo,
    computed_field,
    field_validator,
    model_validator,
)
from pydantic_core import PydanticCustomError

from backend.llms.models import (
    FRIENDLY_SIZE,
    Distribution,
    FriendlySize,
    LLMDataBase,
    LLMDataEnhanced,
)
from backend.llms.utils import convert_range_to_value, get_llm_impact
from utils.utils import MarkdownSerializer


# Raw LLM model definitions from 'utils/models/models.json'
class LLMDataRawBase(LLMDataBase):
    """
    Individual LLM raw model definition (before enrichment).

    Raw model data loaded from 'utils/models/models.json'.
    Contains basic model information (name, params, licensing).
    Gets enriched with license data, architecture info, and rankings to become Model class.

    Attributes:
        new: Whether this is a newly added model
        status: Model status (archived, missing_data, disabled, enabled)
        id: Unique model identifier (e.g., "openai/gpt-4")
        simple_name: Human-readable model name
        license: License identifier (maps to License class)
        fully_open_source: Whether model weights are fully open/public
        release_date: Model release date in MM/YYYY format
        arch: Model architecture (transformer, moe, etc. - maps to Arch class)
        params: Total parameters in billions
        active_params: Active parameters (only for MoE models)
        reasoning: Extended thinking capability (False, True, or "hybrid")
        quantization: Quantization scheme applied (q4, q8, or None for full precision)
        url: Model homepage or documentation URL
        endpoint: API access configuration (None for unavailable models)
        desc: Detailed model description
        size_desc: Human-readable size category (e.g., "Small but Mighty")
        fyi: Additional notes for users
        pricey: Whether model has high API costs (triggers stricter rate limits)
    """

    # LLMDataBase override
    release_date: str = Field(pattern=r"^[0-9]{02}/[0-9]{4}$")  # as validator instead?
    # Raw specific fields
    desc: Annotated[str, MarkdownSerializer]
    size_desc: Annotated[str, MarkdownSerializer]
    fyi: Annotated[str, MarkdownSerializer]

    @model_validator(mode="before")
    @classmethod
    def insert_defaults(cls, data: Any) -> Any:
        """
        Insert default values, that way we do not need to repeat types and
        make sure we are based on `LLMDataEnhanced` types.
        """
        DEFAULTS = {
            "new": False,
            "status": "enabled",
            "fully_open_source": False,
            "active_params": None,
            "reasoning": False,
            "quantization": None,
            "url": None,
            "endpoint": None,
            "pricey": False,
            "specific_portals": None,
        }
        for key, value in DEFAULTS.items():
            if not key in data:
                data[key] = value

        return data

    @field_validator("arch", mode="after")
    @classmethod
    def check_arch_exists(cls, value: str, info: ValidationInfo) -> str:
        assert info.context is not None
        assert info.context["archs"] is not None

        if value.replace("maybe-", "") not in info.context["archs"]:
            raise PydanticCustomError(
                "missing_arch", f"Missing arch '{value}' infos in 'archs.json'."
            )

        if info.data.get("license") != "proprietary" and "maybe" in value:
            raise PydanticCustomError(
                "wrong_arch",
                f"Arch should not be 'maybe' since license is not 'proprietary'.",
            )

        return value

    @field_validator("active_params", mode="before")
    @classmethod
    def check_active_params_is_defined_if_moe(
        cls, value: int | float | None, info: ValidationInfo
    ) -> int | float | None:
        if "arch" in info.data and "moe" in info.data.get("arch", "") and value is None:
            raise PydanticCustomError(
                "missing_active_params",
                f"Model's arch is '{info.data['arch']}' and requires 'active_params' to be defined.",
            )

        return value

    @model_validator(mode="after")
    def check_endpoint(self):
        if self.status == "enabled" and not self.endpoint:
            raise PydanticCustomError(
                "endpoint", "Model is enabled but no endpoint has been found."
            )
        return self


# Enriched model definition generated from RawModel + licenses + rankings + preferences
class LLMDataRaw(LLMDataEnhanced, LLMDataRawBase):
    """
    Complete LLM raw definition with enriched metadata.

    Inherits from RawModel and adds:
    - License data (distribution, reuse rights)
    - Organisation/vendor information
    - Ranking data (Elo, confidence intervals)
    - User preference statistics
    - Computed fields (friendly size, RAM requirements, energy impact)

    Generated by build_models.py from 'utils/models/models.json' and saved as
    'utils/models/generated-models.json'.

    Computed Properties:
        friendly_size: Human-readable category (XS, S, M, L, XL) based on params
        required_ram: Estimated RAM needed to run model (depends on quantization)
        wh_per_million_token: Energy consumption per million tokens
    """

    status: Literal["archived", "enabled", "disabled"] = "enabled"

    @model_validator(mode="before")
    @classmethod
    def insert_defaults(cls, data: Any) -> Any:
        """
        Insert default values, that way we do not need to repeat types and
        make sure we are based on `LLMDataEnhanced` types.
        """
        DEFAULTS = {
            "commercial_use": None,
            "data": None,
            "prefs": None,
        }
        for key, value in DEFAULTS.items():
            if not key in data:
                data[key] = value

        return data

    @field_validator("distribution", mode="before")
    @classmethod
    def check_distribution(
        cls, value: Distribution, info: ValidationInfo
    ) -> Distribution:
        if info.data["fully_open_source"]:
            value = "fully-open-source"

        return value

    @computed_field  # type: ignore[prop-decorator]
    @property
    def friendly_size(self) -> FriendlySize:
        intervals = [(0, 15), (15, 60), (60, 100), (100, 400), (400, float("inf"))]

        for i, (lower, upper) in enumerate(intervals):
            if lower <= self.params < upper:
                return FRIENDLY_SIZE[i]

        raise Exception("Error: Could not guess friendly_size")

    @computed_field  # type: ignore[prop-decorator]
    @property
    def required_ram(self) -> int | float:
        if self.quantization == "q8":
            return self.params * 2

        # We suppose from q4 to fp16
        return self.params

    @computed_field  # type: ignore[prop-decorator]
    @property
    def wh_per_million_token(self) -> int | float:
        impact = get_llm_impact(self, 1_000_000, None)
        energy_kwh = convert_range_to_value(impact.energy.value)

        return energy_kwh * 1000
