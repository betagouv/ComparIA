{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61666521",
   "metadata": {},
   "source": [
    "# `RankingPipeline`\n",
    "\n",
    "Dans ce script on teste la pipeline complète, permettant de paramétrer les méthodes de calcul des scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b395c80f",
   "metadata": {},
   "source": [
    "## Calcul des scores\n",
    "\n",
    "La méthode `run` lance le calcul des scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca2d365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "cache_dir = input(\"Indicate path to all Hugging Face caches:\")\n",
    "os.environ[\"HF_DATASETS_CACHE\"] = cache_dir\n",
    "os.environ[\"HF_HUB_CACHE\"] = cache_dir\n",
    "os.environ[\"HF_TOKEN\"] = getpass(\"Enter your HuggingFace token:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b3074abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from rank_comparia.pipeline import RankingPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fceda6d",
   "metadata": {},
   "source": [
    "### Paramètres de `RankingPipeline`  \n",
    "\n",
    "- `method` : Méthode de classement utilisé : `elo_random`, `elo_ordered`, `ml`  \n",
    "- `include_votes` : Utilisation des données de votes  \n",
    "- `include_reactions` : Utilisation des données de réactions\n",
    "- `bootstrap_samples` : Nombres d'échantillons pour cacluler la version *Bootstrap* \n",
    "- `mean_how` : Moyenner par nombre de token générés ou par matchs effectués\n",
    "- `batch` : si on batch le nombre de match \n",
    "- `export_path` : le chemin vers le dossier dans lequel exporter les graphes et les scores finaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05af6e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since ministere-culture/comparia-votes couldn't be found on the Hugging Face Hub (offline mode is enabled).\n",
      "Found the latest cached dataset configuration 'default' at /home/jupyterhub-users/shared/projet_comparia/huggingface_hub/ministere-culture___comparia-votes/default/0.0.0/679f56e14f413546403b3468d717c4417e394326 (last modified on Mon Jul 28 10:06:44 2025).\n",
      "Using the latest cached version of the dataset since ministere-culture/comparia-conversations couldn't be found on the Hugging Face Hub (offline mode is enabled).\n",
      "Found the latest cached dataset configuration 'default' at /home/jupyterhub-users/shared/projet_comparia/huggingface_hub/ministere-culture___comparia-conversations/default/0.0.0/dc40af6af1c14e68bf39d55f6e1573d2d6582f19 (last modified on Wed Jun  4 17:40:30 2025).\n",
      "Using the latest cached version of the dataset since ministere-culture/comparia-reactions couldn't be found on the Hugging Face Hub (offline mode is enabled).\n",
      "Found the latest cached dataset configuration 'default' at /home/jupyterhub-users/shared/projet_comparia/huggingface_hub/ministere-culture___comparia-reactions/default/0.0.0/80befa851337d9f295096cef3d100b40d220dc07 (last modified on Mon Jul 28 10:06:54 2025).\n",
      "Using the latest cached version of the dataset since ministere-culture/comparia-conversations couldn't be found on the Hugging Face Hub (offline mode is enabled).\n",
      "Found the latest cached dataset configuration 'default' at /home/jupyterhub-users/shared/projet_comparia/huggingface_hub/ministere-culture___comparia-conversations/default/0.0.0/dc40af6af1c14e68bf39d55f6e1573d2d6582f19 (last modified on Wed Jun  4 17:40:30 2025).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final votes dataset contains 55617 conversations pairs.\n",
      "Reactions data originally contains 22993 conversations pairs.\n",
      "Final reactions dataset contains 21244 conversations pairs.\n"
     ]
    }
   ],
   "source": [
    "pipeline = RankingPipeline(\n",
    "    method=\"elo_random\",\n",
    "    include_votes=True,\n",
    "    include_reactions=True,\n",
    "    bootstrap_samples=5,\n",
    "    mean_how=\"token\",\n",
    "    batch=False,\n",
    "    export_path=Path(\"output\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0e0e8637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (76_861, 11)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>conversation_pair_id</th><th>model_a</th><th>model_b</th><th>score</th><th>categories</th><th>model_a_active_params</th><th>model_b_active_params</th><th>total_conv_a_output_tokens</th><th>total_conv_a_kwh</th><th>total_conv_b_output_tokens</th><th>total_conv_b_kwh</th></tr><tr><td>str</td><td>str</td><td>str</td><td>i32</td><td>list[str]</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;e0a4afe42906427fb44dab8f7d8b66…</td><td>&quot;gpt-4o-mini-2024-07-18&quot;</td><td>&quot;gemini-2.0-flash-001&quot;</td><td>2</td><td>[&quot;Business &amp; Economics &amp; Finance&quot;, &quot;Education&quot;]</td><td>35.0</td><td>40.0</td><td>317.0</td><td>0.002396</td><td>542.0</td><td>0.004476</td></tr><tr><td>&quot;c0ce05dddccd4feaa35118d9f58891…</td><td>&quot;gemma-2-9b-it&quot;</td><td>&quot;hermes-3-llama-3.1-405b&quot;</td><td>2</td><td>[&quot;Health &amp; Wellness &amp; Medicine&quot;, &quot;Society &amp; Social Issues &amp; Human Rights&quot;]</td><td>9.0</td><td>405.0</td><td>566.0</td><td>0.002212</td><td>767.0</td><td>0.182489</td></tr><tr><td>&quot;fa0f3f8dd8b1438cbdc748fab481dc…</td><td>&quot;gpt-4o-2024-08-06&quot;</td><td>&quot;aya-expanse-8b&quot;</td><td>1</td><td>[&quot;Business &amp; Economics &amp; Finance&quot;]</td><td>200.0</td><td>8.0</td><td>526.0</td><td>0.03231</td><td>729.0</td><td>0.002747</td></tr><tr><td>&quot;e85752b0f339459385bfc064a35ec3…</td><td>&quot;mixtral-8x7b-instruct-v0.1&quot;</td><td>&quot;gemini-1.5-pro-001&quot;</td><td>0</td><td>[&quot;Natural Science &amp; Formal Science &amp; Technology&quot;]</td><td>null</td><td>null</td><td>292.0</td><td>0.001346</td><td>668.0</td><td>0.089563</td></tr><tr><td>&quot;1a03ebdfe29a4762a7d97d6247041d…</td><td>&quot;gpt-4o-mini-2024-07-18&quot;</td><td>&quot;gemini-2.0-flash-001&quot;</td><td>2</td><td>[&quot;Education&quot;, &quot;Natural Science &amp; Formal Science &amp; Technology&quot;]</td><td>35.0</td><td>40.0</td><td>822.0</td><td>0.006212</td><td>731.0</td><td>0.006037</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;712ff01209d846c9b786eb544e3c59…</td><td>&quot;gemini-2.0-flash-001&quot;</td><td>&quot;claude-3-5-sonnet-v2&quot;</td><td>2</td><td>[&quot;Food &amp; Drink &amp; Cooking&quot;, &quot;Health &amp; Wellness &amp; Medicine&quot;]</td><td>40.0</td><td>300.0</td><td>1851.0</td><td>0.015287</td><td>338.0</td><td>0.045373</td></tr><tr><td>&quot;2bc5df446aa74c5786c10a3e135259…</td><td>&quot;claude-3-5-sonnet-v2&quot;</td><td>&quot;deepseek-v3-chat&quot;</td><td>0</td><td>[&quot;Natural Science &amp; Formal Science &amp; Technology&quot;, &quot;Education&quot;]</td><td>300.0</td><td>37.0</td><td>785.0</td><td>0.105377</td><td>882.0</td><td>0.041477</td></tr><tr><td>&quot;2000efa884d74caca883ba98efc9f5…</td><td>&quot;mistral-small-24b-instruct-250…</td><td>&quot;gpt-4o-mini-2024-07-18&quot;</td><td>2</td><td>[&quot;Natural Science &amp; Formal Science &amp; Technology&quot;]</td><td>24.0</td><td>35.0</td><td>454.0</td><td>0.00273</td><td>846.0</td><td>0.006393</td></tr><tr><td>&quot;6c9edcb7c7844eb495711fc1ab4818…</td><td>&quot;gemini-1.5-pro-002&quot;</td><td>&quot;llama-3.1-70b&quot;</td><td>0</td><td>[&quot;Health &amp; Wellness &amp; Medicine&quot;, &quot;Natural Science &amp; Formal Science &amp; Technology&quot;]</td><td>220.0</td><td>70.0</td><td>827.0</td><td>0.110882</td><td>812.0</td><td>0.010125</td></tr><tr><td>&quot;357c4967184f4edca025b9b36c9701…</td><td>&quot;mixtral-8x7b-instruct-v0.1&quot;</td><td>&quot;phi-3.5-mini-instruct&quot;</td><td>0</td><td>[&quot;Politics &amp; Government&quot;, &quot;Natural Science &amp; Formal Science &amp; Technology&quot;, … &quot;Business &amp; Economics &amp; Finance&quot;]</td><td>14.0</td><td>3.8</td><td>459.0</td><td>0.002116</td><td>925.0</td><td>0.002836</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (76_861, 11)\n",
       "┌────────────┬────────────┬────────────┬───────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ conversati ┆ model_a    ┆ model_b    ┆ score ┆ … ┆ total_con ┆ total_con ┆ total_con ┆ total_con │\n",
       "│ on_pair_id ┆ ---        ┆ ---        ┆ ---   ┆   ┆ v_a_outpu ┆ v_a_kwh   ┆ v_b_outpu ┆ v_b_kwh   │\n",
       "│ ---        ┆ str        ┆ str        ┆ i32   ┆   ┆ t_tokens  ┆ ---       ┆ t_tokens  ┆ ---       │\n",
       "│ str        ┆            ┆            ┆       ┆   ┆ ---       ┆ f64       ┆ ---       ┆ f64       │\n",
       "│            ┆            ┆            ┆       ┆   ┆ f64       ┆           ┆ f64       ┆           │\n",
       "╞════════════╪════════════╪════════════╪═══════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ e0a4afe429 ┆ gpt-4o-min ┆ gemini-2.0 ┆ 2     ┆ … ┆ 317.0     ┆ 0.002396  ┆ 542.0     ┆ 0.004476  │\n",
       "│ 06427fb44d ┆ i-2024-07- ┆ -flash-001 ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ ab8f7d8b66 ┆ 18         ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ …          ┆            ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ c0ce05dddc ┆ gemma-2-9b ┆ hermes-3-l ┆ 2     ┆ … ┆ 566.0     ┆ 0.002212  ┆ 767.0     ┆ 0.182489  │\n",
       "│ cd4feaa351 ┆ -it        ┆ lama-3.1-4 ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 18d9f58891 ┆            ┆ 05b        ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ …          ┆            ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ fa0f3f8dd8 ┆ gpt-4o-202 ┆ aya-expans ┆ 1     ┆ … ┆ 526.0     ┆ 0.03231   ┆ 729.0     ┆ 0.002747  │\n",
       "│ b1438cbdc7 ┆ 4-08-06    ┆ e-8b       ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 48fab481dc ┆            ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ …          ┆            ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ e85752b0f3 ┆ mixtral-8x ┆ gemini-1.5 ┆ 0     ┆ … ┆ 292.0     ┆ 0.001346  ┆ 668.0     ┆ 0.089563  │\n",
       "│ 39459385bf ┆ 7b-instruc ┆ -pro-001   ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ c064a35ec3 ┆ t-v0.1     ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ …          ┆            ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 1a03ebdfe2 ┆ gpt-4o-min ┆ gemini-2.0 ┆ 2     ┆ … ┆ 822.0     ┆ 0.006212  ┆ 731.0     ┆ 0.006037  │\n",
       "│ 9a4762a7d9 ┆ i-2024-07- ┆ -flash-001 ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 7d6247041d ┆ 18         ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ …          ┆            ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ …          ┆ …          ┆ …          ┆ …     ┆ … ┆ …         ┆ …         ┆ …         ┆ …         │\n",
       "│ 712ff01209 ┆ gemini-2.0 ┆ claude-3-5 ┆ 2     ┆ … ┆ 1851.0    ┆ 0.015287  ┆ 338.0     ┆ 0.045373  │\n",
       "│ d846c9b786 ┆ -flash-001 ┆ -sonnet-v2 ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ eb544e3c59 ┆            ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ …          ┆            ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 2bc5df446a ┆ claude-3-5 ┆ deepseek-v ┆ 0     ┆ … ┆ 785.0     ┆ 0.105377  ┆ 882.0     ┆ 0.041477  │\n",
       "│ a74c5786c1 ┆ -sonnet-v2 ┆ 3-chat     ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 0a3e135259 ┆            ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ …          ┆            ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 2000efa884 ┆ mistral-sm ┆ gpt-4o-min ┆ 2     ┆ … ┆ 454.0     ┆ 0.00273   ┆ 846.0     ┆ 0.006393  │\n",
       "│ d74caca883 ┆ all-24b-in ┆ i-2024-07- ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ ba98efc9f5 ┆ struct-250 ┆ 18         ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ …          ┆ …          ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 6c9edcb7c7 ┆ gemini-1.5 ┆ llama-3.1- ┆ 0     ┆ … ┆ 827.0     ┆ 0.110882  ┆ 812.0     ┆ 0.010125  │\n",
       "│ 844eb49571 ┆ -pro-002   ┆ 70b        ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 1fc1ab4818 ┆            ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ …          ┆            ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 357c496718 ┆ mixtral-8x ┆ phi-3.5-mi ┆ 0     ┆ … ┆ 459.0     ┆ 0.002116  ┆ 925.0     ┆ 0.002836  │\n",
       "│ 4f4edca025 ┆ 7b-instruc ┆ ni-instruc ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ b9b36c9701 ┆ t-v0.1     ┆ t          ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ …          ┆            ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "└────────────┴────────────┴────────────┴───────┴───┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d10db3",
   "metadata": {},
   "source": [
    "## Match_list()\n",
    "\n",
    "Cette fonction permet de construire la liste des matchs effectués dans l'arène. Chaque élément de la liste correspond à un match joué avec :\n",
    "- les deux modèles qui ont joué le match\n",
    "- l'issue du match : 0 si c'eslt modèle B qui gagne, 2 si c'est le modèle A qui gagne et 1 s'il y a égalité.\n",
    "- l'id de la conversation du match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1e05ab48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Match(model_a='gpt-4o-mini-2024-07-18', model_b='gemini-2.0-flash-001', score=<MatchScore.A: 2>, id='e0a4afe42906427fb44dab8f7d8b66af-72f12096597742c494f0c2bd0aa7d8be'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.A: 2>, id='c0ce05dddccd4feaa35118d9f58891ff-bdf8062d6abb4732b768c354b0975523'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='aya-expanse-8b', score=<MatchScore.Draw: 1>, id='fa0f3f8dd8b1438cbdc748fab481dcdc-a07a1b31957b4df889ca9cdac69b0d13'),\n",
       " Match(model_a='mixtral-8x7b-instruct-v0.1', model_b='gemini-1.5-pro-001', score=<MatchScore.B: 0>, id='e85752b0f339459385bfc064a35ec3d5-adcf3308040f49c7afd1c9d863e7f7d8'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='gemini-2.0-flash-001', score=<MatchScore.A: 2>, id='1a03ebdfe29a4762a7d97d6247041dee-0af0467081434c0eb7ede68fd2ccb76b'),\n",
       " Match(model_a='phi-4', model_b='c4ai-command-r-08-2024', score=<MatchScore.B: 0>, id='0ff20c842d7d482ab5810d0f84b78971-9f0cbe06c0b14384a8ebf835f0fdef73'),\n",
       " Match(model_a='deepseek-r1-distill-llama-70b', model_b='mistral-large-2411', score=<MatchScore.Draw: 1>, id='5b092cc80c7f4dab806ea45c325d0669-9993276242fb4d1095e251144750d97a'),\n",
       " Match(model_a='llama-3.1-8b', model_b='llama-3.1-70b', score=<MatchScore.B: 0>, id='0ae9dab2c3ef43d9bad85aac984a8d37-04ac6d8ac2c74d138b657e78b56ad3d5'),\n",
       " Match(model_a='llama-3.3-70b', model_b='phi-4', score=<MatchScore.B: 0>, id='5b610446540c4cb38b25668064b8c8e7-4131730dba4644e891cc20d808dc983b'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='mistral-nemo-2407', score=<MatchScore.A: 2>, id='e898f345bdae40199a5b40a65c95bee3-918377a1dcf74e408477f3ac5c69cd11'),\n",
       " Match(model_a='mistral-small-3.1-24b', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.A: 2>, id='6f2ce33b6ec14710aedd662459eee72b-998d2197407f467594ac1b1663a419c9'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='deepseek-v3-chat', score=<MatchScore.A: 2>, id='87ff715e3e14488999a87c2d01fd78a7-c0d3d66d76d145adb88e3d4f81549ebe'),\n",
       " Match(model_a='llama-3.1-70b', model_b='ministral-8b-instruct-2410', score=<MatchScore.B: 0>, id='4e8aeb967c3744f6a1d78588741f2117-c197ef2bffe745f1a0060a98ae183738'),\n",
       " Match(model_a='lfm-40b', model_b='claude-3-5-sonnet-v2', score=<MatchScore.B: 0>, id='c19f6fca69f74dfea70afb1a8af3720b-37e7c89d54114c22b9b80e4c543738c4'),\n",
       " Match(model_a='command-a', model_b='mistral-small-3.1-24b', score=<MatchScore.A: 2>, id='9e97a9e684424ab69fe96f5d03e5d4f2-2dddb06c23844db8983d2f17302f1251'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.B: 0>, id='3b619c99ad144cb78a97f002beef43b5-300f53e549304454918aef75a303d898'),\n",
       " Match(model_a='llama-3.1-405b', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.A: 2>, id='25c2e6fccf9d4a8fa12a0e5ed607439d-fa8bc7f3e2cc490d9c951768c80ba407'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='ministral-8b-instruct-2410', score=<MatchScore.Draw: 1>, id='5cf7a129845d4c6dba31193bfed3cc9a-860482cf14ad45afbfe084ffc8f29a80'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.B: 0>, id='576dbdee025540ad83024136d537291b-8c8d7af0e9fa456a82bd54ba22de3a28'),\n",
       " Match(model_a='phi-4', model_b='llama-4-scout', score=<MatchScore.A: 2>, id='82bdcca3b59a45b6bfaac8fdfe474161-829ccfece071472f995063aa11d0e560'),\n",
       " Match(model_a='c4ai-command-r-08-2024', model_b='llama-3.1-8b', score=<MatchScore.B: 0>, id='edd08eb63938484099381bedf7cb81c3-c50cbbcb689d42849ca013f86e454850'),\n",
       " Match(model_a='qwen2.5-7b-instruct', model_b='mistral-nemo-2407', score=<MatchScore.A: 2>, id='1fcfd6f6e1034df2ba49b589f47d9a9a-6e49ae61baf246d08edadd9bd07000f4'),\n",
       " Match(model_a='llama-3.1-405b', model_b='deepseek-r1', score=<MatchScore.Draw: 1>, id='c007fda475894a5eb4faf96cf255747c-14c5551b3c334776972cad544b86706a'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='ministral-8b-instruct-2410', score=<MatchScore.A: 2>, id='2afddc0c37e344a9b34eaa11cf4dd93a-0dbecb7bdaf84a92a3ae0a319a6b5fb7'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='gpt-4o-2024-08-06', score=<MatchScore.Draw: 1>, id='dee85205d26d406ca743d126fc269df8-050b426203f94948a814d41afc2bfc14'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='mistral-nemo-2407', score=<MatchScore.Draw: 1>, id='fe79f0c1016e457699207a3c63ebc1d5-6eebaf24363444e89343af38a445d5ae'),\n",
       " Match(model_a='llama-3.1-70b', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.B: 0>, id='5cd751ddafe74aa38c79fec92b13f13c-12f508c434b04a2c8c35fef0103af1a9'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='gemma-2-9b-it', score=<MatchScore.B: 0>, id='6e1642a5c2cf4d0fa78eca174b12e2de-4d1576670c3040dd9dbb20c9d97cbb05'),\n",
       " Match(model_a='llama-3.1-nemotron-70b-instruct', model_b='chocolatine-2-14b-instruct-v2.0.3-q8', score=<MatchScore.A: 2>, id='014440301171438b87d4bc2247bb95ef-e3559682b0a743b9a664c3a181f1ebde'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='llama-3.1-nemotron-70b-instruct', score=<MatchScore.A: 2>, id='5bca093674d44c9482acafdf1325a0de-864472abbec043228f1c31cdb969a726'),\n",
       " Match(model_a='llama-3.1-8b', model_b='gemini-1.5-pro-002', score=<MatchScore.Draw: 1>, id='540574ecb6f2406bade27d47678b208b-dba95c16b10c46fcbf6e2351c4d40559'),\n",
       " Match(model_a='gpt-4.1-nano', model_b='llama-3.3-70b', score=<MatchScore.A: 2>, id='8d0ccb75f9d44906974d1577be536912-c123a4238e9d4f54b6b140208779c9e6'),\n",
       " Match(model_a='gemma-3-12b', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.A: 2>, id='f1eba233afe446acb9441964c234b084-363f8e2154524bbfb61f5af09f6f1793'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='deepseek-v3-chat', score=<MatchScore.B: 0>, id='4c6c7ed6b0de484383d44ce983c6735b-6307d04c905440beab6be6b88f1519cc'),\n",
       " Match(model_a='llama-3.1-nemotron-70b-instruct', model_b='llama-3.1-70b', score=<MatchScore.A: 2>, id='ab18cf780e394ceda5d1452f482c62d8-72d62936f1364a4bb202b1b4b72515b8'),\n",
       " Match(model_a='aya-expanse-8b', model_b='gpt-4o-2024-08-06', score=<MatchScore.Draw: 1>, id='79923b4203de4a758e66bc2f7bd37020-0e6682e4783b430fa15fc06b9687a23a'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='deepseek-v3-chat', score=<MatchScore.B: 0>, id='caf18896b53a426a8084558a005319c6-ad7e59f9221a4b7fa40c546eaafa9c95'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='deepseek-v3-chat', score=<MatchScore.Draw: 1>, id='a6d1968b3de4486996a981d3236506fe-1f07099863964d748aee71481da54707'),\n",
       " Match(model_a='deepseek-r1', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.A: 2>, id='472a01724da841ec9c6bc20a0c5427d7-bf1e7bbb856e42cbb8d0107380ec233a'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='gpt-4o-2024-08-06', score=<MatchScore.A: 2>, id='14c5a0b48218452393e142ad94de59f2-8cbd727229f040dd9d3d293f42ee1878'),\n",
       " Match(model_a='gemma-2-27b-it-q8', model_b='mixtral-8x7b-instruct-v0.1', score=<MatchScore.A: 2>, id='2c27e9fa3bcb4eaba0d63dcfa682c3ed-ca2ee916b570405793e8529aa412844e'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='gemma-2-9b-it', score=<MatchScore.Draw: 1>, id='478fc475af8e4839aac189c92c939aec-35d6aaffa92b40e096cf745c34687681'),\n",
       " Match(model_a='mistral-small-24b-instruct-2501', model_b='claude-3-5-sonnet-v2', score=<MatchScore.Draw: 1>, id='e3662b9dff3b415485ac3d4adaa2794d-209d282798f54c86837666713a97e0b4'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='mistral-large-2411', score=<MatchScore.Draw: 1>, id='a9045b28e224487da2f62e8bba463d74-45f7eb2a431a4ad4b08eb7029c8f9c0c'),\n",
       " Match(model_a='llama-3.1-nemotron-70b-instruct', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.A: 2>, id='263d2e4716e4457e858b910f736745b2-6435fd126033462cbdeb7ca65b63ee0d'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='llama-3.1-405b', score=<MatchScore.Draw: 1>, id='9adca24dd08d43889573bd9bec01fe9a-b8328934f340465eb440c22235421584'),\n",
       " Match(model_a='gemma-3-4b', model_b='deepseek-v3-chat', score=<MatchScore.Draw: 1>, id='0f0e4e0625d5466b8cce29be5751c2e0-f935a7c87e96469c90ad0cd019de1175'),\n",
       " Match(model_a='deepseek-v3-0324', model_b='mistral-small-3.1-24b', score=<MatchScore.Draw: 1>, id='214800dcd7f24839989140221ab6d1ba-65ef039f185e418c96efed36507e4a39'),\n",
       " Match(model_a='llama-3.1-8b', model_b='llama-3.1-70b', score=<MatchScore.B: 0>, id='e7739cfb87b24490afe11c896f1b1280-d4c892868ed44c368986cbd3301b3a99'),\n",
       " Match(model_a='chocolatine-2-14b-instruct-v2.0.3-q8', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.A: 2>, id='d68432e820734e2b9ea79d2ed56f78de-b15e2b1866a949a59c6d075314f1558d'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='deepseek-v3-chat', score=<MatchScore.A: 2>, id='82a39c9776be41c08c932405988aad25-162faa6c8a7840aaa1044981e8707853'),\n",
       " Match(model_a='phi-3.5-mini-instruct', model_b='mixtral-8x7b-instruct-v0.1', score=<MatchScore.B: 0>, id='49672ef30db44e6f86e8bfcba64a06d0-18c25254dcc84b90bd7fff05d7dbded7'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='claude-3-5-sonnet-v2', score=<MatchScore.B: 0>, id='ddba864ba57641b1b93502fe2a7aa373-3d61ba43a9e844f6873dd3f09905be51'),\n",
       " Match(model_a='mixtral-8x7b-instruct-v0.1', model_b='ministral-8b-instruct-2410', score=<MatchScore.A: 2>, id='43c5632658054d1b93e851f295ff5e3b-6214036d6f64437e966ae3bbca05b66c'),\n",
       " Match(model_a='llama-3.1-70b', model_b='llama-3.1-8b', score=<MatchScore.A: 2>, id='20574fc2b50c44989e18a0b76c6e729e-807a8fc31e264c0498e557e75259bdfa'),\n",
       " Match(model_a='deepseek-r1-distill-llama-70b', model_b='qwq-32b', score=<MatchScore.A: 2>, id='4b8c38c9058b4a938f486a5903de1188-4ad6d22898bf42a58b987f4078568461'),\n",
       " Match(model_a='mistral-small-3.1-24b', model_b='command-a', score=<MatchScore.Draw: 1>, id='f914a533415547ebb08af35e8f7f1591-603f6dcfd8dd44f7a6054f9edb989951'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='gemini-1.5-pro-002', score=<MatchScore.Draw: 1>, id='1323e06974824557a75e76af3a258f15-c05eaef7cfed4b369ba1cb838813b9e7'),\n",
       " Match(model_a='llama-3.3-70b', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.A: 2>, id='d34d5d6d1d164d3689e8c714e5227913-a7c51b5da5d1421e911a53ca7fd41705'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='llama-3.1-nemotron-70b-instruct', score=<MatchScore.A: 2>, id='25ef4df0908f4523b42d951e0cc9741e-390c08b7aa4e4bc694d8748052e6fd49'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='gemma-2-9b-it', score=<MatchScore.A: 2>, id='406707b166de4ff592dd3a07ebb55d88-75a51cefc5af4ad6b17d831b3e2f05cf'),\n",
       " Match(model_a='lfm-40b', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.B: 0>, id='174493bb4762447b80b4353e5e8c1796-8f794325041a41088f93799bf97100fd'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='mistral-nemo-2407', score=<MatchScore.B: 0>, id='216cf9d6a7f14bd6afccff7a556e31b8-787dcd0b42384fd492dcd5639aab9163'),\n",
       " Match(model_a='chocolatine-2-14b-instruct-v2.0.3-q8', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.B: 0>, id='d97caaa3c51d46de8312a9f9f0c7c67d-0b2af3a91f4f45f695f7a16d42bc0bfd'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='claude-3-5-sonnet-v2', score=<MatchScore.A: 2>, id='84b77bfe373942db8df900547cd39b1c-5f424776b1cf4a0fae4756a80c861b64'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='mistral-large-2411', score=<MatchScore.B: 0>, id='aacf863f1d2a435fa6f7756525c30f08-d0085c199a2c4f48a258746af702d90d'),\n",
       " Match(model_a='llama-3.1-405b', model_b='gemini-1.5-pro-001', score=<MatchScore.B: 0>, id='93ba36c1bc3b4167b8cafc4156de7c95-2daff384fc3d4dd081b5e22bea5e3480'),\n",
       " Match(model_a='c4ai-command-r-08-2024', model_b='deepseek-r1-distill-llama-70b', score=<MatchScore.A: 2>, id='607c90be693f49f58390172a546d2c1a-7b279db4889d49808d264f5252a4b752'),\n",
       " Match(model_a='llama-3.1-405b', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.A: 2>, id='f207d1caec7943798421ccaa950a414f-f12b3c19f1f54a03950c326dcc121d60'),\n",
       " Match(model_a='llama-3.1-8b', model_b='c4ai-command-r-08-2024', score=<MatchScore.Draw: 1>, id='3b017aff5ac6457e98f690ac8ac3a37c-401c34c07c784ed68bad60487d69e6e3'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='command-a', score=<MatchScore.Draw: 1>, id='67fe1b22f375473d9230792371c3acce-9713a7fee32d4a4cb1f9c8d8599882ac'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='claude-3-7-sonnet', score=<MatchScore.B: 0>, id='71a65ad0d5b14c439cacd36d910d24b2-7caab8e52e854b289b48dcedcf779b2e'),\n",
       " Match(model_a='gemma-3-12b', model_b='gemma-3-4b', score=<MatchScore.A: 2>, id='f32187102cc24c7daf303758490ec70a-d5fe5e61d1e0452382099a0619bbd067'),\n",
       " Match(model_a='llama-3.3-70b', model_b='claude-3-5-sonnet-v2', score=<MatchScore.Draw: 1>, id='291e0636643c4abeb2689522f8e6cdb6-326aa6cf1b8848b2954517015439366a'),\n",
       " Match(model_a='deepseek-v3-0324', model_b='mistral-saba', score=<MatchScore.A: 2>, id='f2710263f7f7453587da3e690e921c88-a3c5182aa2224e15ad944d51669aebe8'),\n",
       " Match(model_a='gemini-1.5-pro-001', model_b='llama-3.1-70b', score=<MatchScore.A: 2>, id='e11034d526954550a816f33104f5fc15-bad832aba7144d649383f25f34f473cf'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='gemini-2.0-flash-001', score=<MatchScore.B: 0>, id='7220d567d2944feda72b89130e189ead-96681ca16da54dc4b398ad3feadfc23e'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='mistral-small-3.1-24b', score=<MatchScore.Draw: 1>, id='25414586fec14450adc503869a7fd3a1-e5841f18d4294af3aaaf1209d142cc7d'),\n",
       " Match(model_a='gemma-2-27b-it-q8', model_b='llama-3.1-8b', score=<MatchScore.B: 0>, id='972ad36e065b4c51b16479c32495dc78-3ca163f60d7249b0aa33e482d21cbc93'),\n",
       " Match(model_a='llama-3.1-405b', model_b='claude-3-5-sonnet-v2', score=<MatchScore.A: 2>, id='31946e2a346d48a1aa61095ce33b4801-2ba4bd8e085946008df065e31399649e'),\n",
       " Match(model_a='gemini-2.0-flash-exp', model_b='phi-3.5-mini-instruct', score=<MatchScore.A: 2>, id='dd82418672c14ace8f1bfa567b037f15-00e5239ddd8342b3a9bed84c1db02c02'),\n",
       " Match(model_a='gemma-3-4b', model_b='ministral-8b-instruct-2410', score=<MatchScore.Draw: 1>, id='581bd7de160f48799d82f1e8ee929ec1-69ad431fd80a460ebfb9adfcb0d0dffe'),\n",
       " Match(model_a='llama-3.1-nemotron-70b-instruct', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.A: 2>, id='011af312fc2b43209f123295291ccb48-e80178f45f684d74af88531f9da55968'),\n",
       " Match(model_a='c4ai-command-r-08-2024', model_b='mistral-large-2411', score=<MatchScore.Draw: 1>, id='9cbc043a489b40a790bdd43c464dcc23-02d971bdd13a45ce9d8691d8ba7e9cee'),\n",
       " Match(model_a='deepseek-r1', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.A: 2>, id='2951f60382884171a4637119dfd7ab57-ad2e4ae97c744cbfa3208e7f11b31ae1'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='deepseek-r1', score=<MatchScore.B: 0>, id='407eab48731e4ab490d67cbe63859a5b-4842cddc106d4ec4adf39888728030df'),\n",
       " Match(model_a='llama-3.1-405b', model_b='lfm-40b', score=<MatchScore.B: 0>, id='7d007b4ff2a34810a810fcd56fb4821a-dd6a09bca4cf4738bab219ad550eed5c'),\n",
       " Match(model_a='o4-mini', model_b='deepseek-v3-0324', score=<MatchScore.B: 0>, id='e335a5df0df64d30a0049cf02dba1f11-9de6af0514db46309a98cfe34ddf3719'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='llama-3.3-70b', score=<MatchScore.Draw: 1>, id='02be31837e234e0aa7880953a2e87628-de01d6eb749249c59b4abb4ce3596e56'),\n",
       " Match(model_a='o3-mini', model_b='gemma-3-12b', score=<MatchScore.Draw: 1>, id='5cc4e1935a5444ad8b68f824224d61e4-592e4a7bf2c14f1cbf5c6a6d42f72d0a'),\n",
       " Match(model_a='deepseek-v3-0324', model_b='gpt-4.1-mini', score=<MatchScore.B: 0>, id='43a5b0c44f2443658ec9ba57cd8bcb76-0b8ce2d9149f451a9c90308418316a5c'),\n",
       " Match(model_a='llama-3.1-8b', model_b='Yi-1.5-9B-Chat', score=<MatchScore.A: 2>, id='5f59973efdba41f4bde4409758325d06-fc51a67ac7ad4d509ce2de29abed638d'),\n",
       " Match(model_a='llama-3.1-70b', model_b='llama-3.1-nemotron-70b-instruct', score=<MatchScore.Draw: 1>, id='dd9eb3152c9444a58efe4bdd2f8fabeb-dacfbe9e0c074e54ae0618dc4419c971'),\n",
       " Match(model_a='llama-3.1-70b', model_b='mistral-nemo-2407', score=<MatchScore.A: 2>, id='152f2d2bac2449acbea1f1e8288eefd5-16ffc1cf4f184a4dbb10630ca36ae3b5'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='llama-3.1-70b', score=<MatchScore.A: 2>, id='2b8ef5cf40644fcd93bb72093534e7d6-0a8169aa4eb34650a4b71b808039e5e6'),\n",
       " Match(model_a='mixtral-8x7b-instruct-v0.1', model_b='mistral-nemo-2407', score=<MatchScore.A: 2>, id='a66818eab4544f7387d0e7247791f9ba-1897eade1650460381eebdf5585f9e89'),\n",
       " Match(model_a='gemma-3-4b', model_b='deepseek-r1-distill-llama-70b', score=<MatchScore.Draw: 1>, id='7d0c99b1b3d84c34866b1ad99ba33513-6222c729e78b42f088830e68695b96a8'),\n",
       " Match(model_a='lfm-40b', model_b='gemini-1.5-pro-002', score=<MatchScore.B: 0>, id='0209356c157e4e9ca172c59337c8882b-bded5d3981a94363b0c64f4343fbf286'),\n",
       " Match(model_a='deepseek-v3-0324', model_b='gpt-4.1-nano', score=<MatchScore.A: 2>, id='c5d87af88afd42b48a2ef9fd9e472ada-13a44f34074a4c8f8f4733d4374c8653'),\n",
       " Match(model_a='deepseek-v3-0324', model_b='gpt-4.1-nano', score=<MatchScore.A: 2>, id='90badfab4ec34bedbd9f2970b42565a8-292f8cb5c6804530a8ad245c69e9a2bf'),\n",
       " Match(model_a='gemini-2.0-flash-001', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.A: 2>, id='a131538f649d4921bcc8f37cd4ad15a8-c0c460e4570041b2b29557ac24cdbe10'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='mistral-nemo-2407', score=<MatchScore.B: 0>, id='e63d6d26a1d94854bc30af06ead5e1c3-8126e274ebcf422081fdd362e8b66f50'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.Draw: 1>, id='0ba416fb8cde4a23a6aaab9313dc7d31-5ce59ee5f4ae4b90b31d7058b733771f'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='aya-expanse-8b', score=<MatchScore.A: 2>, id='ef5d863727ac46b5ae75e27c7190d9c6-cc1cfce2e8f84da8a4c0260aee805c61'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='mistral-large-2411', score=<MatchScore.B: 0>, id='44b979dc687243aeb7e23f016d0d4c22-943b18cde22741f9b1fe7d43bab2a0f9'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='deepseek-v3-chat', score=<MatchScore.B: 0>, id='f5fddc37232240e9ba9f515685eaabe6-464baba47490464181b85efee531cbfc'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='llama-3.1-405b', score=<MatchScore.A: 2>, id='209b46c9f9f9404dbb302a42b7672561-b4d5e896e17d463e94355784f6f2cf6e'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='mistral-large-2411', score=<MatchScore.A: 2>, id='e5ca00eff83b45fe8986f894e8f4d493-a1b10842e43b40049c2585b0ab6150ba'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='mistral-large-2411', score=<MatchScore.B: 0>, id='536a0766efd145c0a3215b75750fe98b-f28ddc3b9cb8443191feef1b49e0fc57'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='gpt-4o-2024-08-06', score=<MatchScore.A: 2>, id='06ac90b0ca0143198c8b9055c1d81bb0-bd48dfd1c85d48feb79e3dd4f8294f6b'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.A: 2>, id='adce6a6f5d27488186dc6761970e0f82-1bacde6f6bc54705b778a4053ceba826'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='gpt-4o-2024-08-06', score=<MatchScore.Draw: 1>, id='a6cbeac67ba84b829849c47f698849f4-eec5441cf41543e788f9ed2434790256'),\n",
       " Match(model_a='llama-3.1-nemotron-70b-instruct', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.Draw: 1>, id='5d8d18c8e4ce46d9b63fb476617310d7-3a4e12557b05481596e99e7981792c60'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='gemini-1.5-pro-002', score=<MatchScore.A: 2>, id='1c4a07ffa99545edbd0ea7bac8bd193f-42bdbda32fb44efb9a0b22bcafaa060c'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.B: 0>, id='d533ad3194c9492497571681a99206a3-6044077f74564837913ac04902ce6040'),\n",
       " Match(model_a='llama-3.1-405b', model_b='chocolatine-2-14b-instruct-v2.0.3-q8', score=<MatchScore.Draw: 1>, id='08c6750ff3584b22b89e66ef37ec8e32-cb061a20af274548901cbdeda40a45ca'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='lfm-40b', score=<MatchScore.Draw: 1>, id='95dc3cbfb2044398a913c09aef3e8bd2-9decbbe7582947568a3ca9de1fa3df6a'),\n",
       " Match(model_a='llama-3.1-8b', model_b='claude-3-5-sonnet-v2', score=<MatchScore.Draw: 1>, id='375cdcc046e44969af5a55c8f5dfa4d2-26054b8fd6884b51954e92cc2f991225'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='gemini-1.5-pro-001', score=<MatchScore.B: 0>, id='84cdf9c1c53a47ee8e5ae85743df615d-e949c4d1735a4af7bdb216a25b276779'),\n",
       " Match(model_a='llama-3.1-70b', model_b='phi-4', score=<MatchScore.A: 2>, id='bf6af94c08b94e8b9905b49368e767af-5e9df8082e9e4ab3b42331ddac825d9f'),\n",
       " Match(model_a='gemini-2.0-flash-001', model_b='mistral-nemo-2407', score=<MatchScore.Draw: 1>, id='813ffbe0b40449d8bba3139a7c00c2e5-59d7222cdfcb423c9eefc2cba77aaa9c'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='mistral-large-2411', score=<MatchScore.Draw: 1>, id='6023f1841363428bac6aa2ba42f4652d-43d26ece2768431386877c0b6034a2a6'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='gpt-4o-2024-08-06', score=<MatchScore.B: 0>, id='4676aa5f679d40b99c88ce602a98dd77-92d2092c188d440a86206d43e743c158'),\n",
       " Match(model_a='llama-3.1-nemotron-70b-instruct', model_b='claude-3-5-sonnet-v2', score=<MatchScore.Draw: 1>, id='2e64e129632b4b11987202f46d3fdf5e-e31a0f3977694ae8b37fce68d68254b5'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='claude-3-5-sonnet-v2', score=<MatchScore.Draw: 1>, id='411adf52c7f54fa0835e777754cc826b-2d22c1e8789c4b77b0708eeb270392f4'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='gemini-1.5-pro-002', score=<MatchScore.A: 2>, id='9cff9f825da945e28fd61f41516566b6-204a36149a9e4052934e518f69a7ca64'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='mistral-nemo-2407', score=<MatchScore.Draw: 1>, id='9fae1dbaef764902bc7d9d385e9402a4-dd9e8c17eb5242e19ace75bc7cd4489d'),\n",
       " Match(model_a='phi-3.5-mini-instruct', model_b='llama-3.1-405b', score=<MatchScore.B: 0>, id='00d840abb49a4b5fbebe42ae65f8c388-924d39f197344cff838db7ade10e0b80'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='ministral-8b-instruct-2410', score=<MatchScore.Draw: 1>, id='f6de5e994e6b4ab888a73adf5205eabb-300c81da1d1c4cdebd2491a7c9961596'),\n",
       " Match(model_a='llama-3.1-nemotron-70b-instruct', model_b='ministral-8b-instruct-2410', score=<MatchScore.Draw: 1>, id='230cc673f2534248ade5c158ea6acf59-ae7c789dab2c4f37867def740ae276af'),\n",
       " Match(model_a='o3-mini', model_b='mistral-large-2411', score=<MatchScore.Draw: 1>, id='5ce17f7511e548fc9d8501820dd6ef6b-89c58caa554e42938ef1b7d54db0f364'),\n",
       " Match(model_a='mixtral-8x7b-instruct-v0.1', model_b='gemma-2-9b-it', score=<MatchScore.B: 0>, id='276a0ad9c1f54fcab74a4f5181c5a9ae-60ca9f9da5ac4f678595f8c010d1c358'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='claude-3-5-sonnet-v2', score=<MatchScore.B: 0>, id='017edb9d78e54a42817a629bf0e3bfd2-6bd4ef66e7594200a45e7473d988294e'),\n",
       " Match(model_a='llama-3.1-405b', model_b='llama-3.1-70b', score=<MatchScore.A: 2>, id='7ba66e56f7e24804a14d5c037a8bd6ee-d9ba1c94f47743ea941bfae1d1b8f321'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='gemma-2-27b-it-q8', score=<MatchScore.B: 0>, id='408972117266490a9868097081d6ebdb-b77b50925b8c49df974eb48b4979e3d0'),\n",
       " Match(model_a='mistral-large-2411', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.A: 2>, id='919774b7c9b145b0bd10fdf64fa2f4bf-2bf695e0fef74cb49c388da59364e447'),\n",
       " Match(model_a='llama-3.1-405b', model_b='qwen2.5-7b-instruct', score=<MatchScore.A: 2>, id='3cd265251a894e839c9cb5896edb430c-35784c6495cc4bcfa1a8d8cffaa46168'),\n",
       " Match(model_a='llama-3.3-70b', model_b='gemma-3-27b', score=<MatchScore.Draw: 1>, id='1c41f9e258bd4e97afbd022febf79b1b-e8eb53770c8f44398827697343d27855'),\n",
       " Match(model_a='mistral-small-3.1-24b', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.A: 2>, id='d5bdddfbec5c4a9fab0568761867c1e5-7e81df8414ba46938fb33a8cc7df4225'),\n",
       " Match(model_a='gemma-2-27b-it-q8', model_b='chocolatine-14b-instruct-dpo-v1.2-q4', score=<MatchScore.A: 2>, id='a84d0fba8589417eb654d25ad3b8f781-e8e56ef1e47645bdaefa7f2e5220c7f7'),\n",
       " Match(model_a='llama-3.1-405b', model_b='mixtral-8x7b-instruct-v0.1', score=<MatchScore.A: 2>, id='a8b9f87ee6e64232a5831db4e8b20595-62dcac1052ba456580c018585e49037b'),\n",
       " Match(model_a='mistral-large-2411', model_b='llama-3.1-nemotron-70b-instruct', score=<MatchScore.A: 2>, id='f25c259e8bc142a38011880d89fe051c-c2d0700f7ca74418b6196ff07cd4eaa8'),\n",
       " Match(model_a='deepseek-v3-0324', model_b='mistral-saba', score=<MatchScore.A: 2>, id='64df6db8633a467d8ff4b7ddbaf49c85-f03f0bbf82764b63985b7cd49dfa4a14'),\n",
       " Match(model_a='mistral-saba', model_b='gemma-3-27b', score=<MatchScore.B: 0>, id='b0aee132c30345aaba6c64708b62f7fc-bdf7b604889f4cd693cd8cf83e798295'),\n",
       " Match(model_a='llama-3.1-70b', model_b='deepseek-v3-chat', score=<MatchScore.Draw: 1>, id='3404515c05d14a39ab21df3820d9b279-596667f698bf4f8db0b7726d20db1baa'),\n",
       " Match(model_a='llama-3.1-70b', model_b='ministral-8b-instruct-2410', score=<MatchScore.B: 0>, id='00c74a842c54474181d5d785da17fe95-45ea4e85196c4d718e33d20317c20552'),\n",
       " Match(model_a='mistral-small-24b-instruct-2501', model_b='llama-3.3-70b', score=<MatchScore.A: 2>, id='7519964d3296438ab7b789f0b3bec0af-ced701153b654088a5a31ab2e6403716'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='llama-3.3-70b', score=<MatchScore.Draw: 1>, id='2182604e0a894f3a98a6dfb0249c13a2-514676e7f2ff4bbd998064820d79b4eb'),\n",
       " Match(model_a='command-a', model_b='c4ai-command-r-08-2024', score=<MatchScore.Draw: 1>, id='f09aceb6f50549fa9597644c53fbf6c5-5c370ada8ca6488583c51c1960bda32e'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='ministral-8b-instruct-2410', score=<MatchScore.B: 0>, id='797476f72d5c40fdaf38f9b6ce44c50f-fbc2c6244ea24b43b2b712127e654554'),\n",
       " Match(model_a='mistral-large-2411', model_b='llama-3.1-70b', score=<MatchScore.B: 0>, id='71b293f459fb4e3ab1a1c1d4e52a2c39-718c2b20144942a197803adc7858d397'),\n",
       " Match(model_a='llama-3.1-nemotron-70b-instruct', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.Draw: 1>, id='21f3098a7c324c0cb53840826ef86cb7-f32c4768d8b94d99a3c000006ec11515'),\n",
       " Match(model_a='deepseek-r1', model_b='mistral-nemo-2407', score=<MatchScore.A: 2>, id='5e9a61f2f5e44e08959b2e5907569d5f-ee7818f844724cfa9d715b3441e1e899'),\n",
       " Match(model_a='llama-3.1-nemotron-70b-instruct', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.A: 2>, id='df6d564e8d794642988d79c059638bcf-ab2e1271ddff4eb2944d9ae16adb4221'),\n",
       " Match(model_a='gpt-4.1-mini', model_b='gemma-3-12b', score=<MatchScore.Draw: 1>, id='54eab06cdea74560bf85dbf43b9b2bc5-8b1f2f1870fa40ac8889cc635bc7d73b'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='ministral-8b-instruct-2410', score=<MatchScore.B: 0>, id='297dce73763f4e7e832433e011901403-c9782947edfe48bfbc5f53ce913a75f7'),\n",
       " Match(model_a='llama-3.3-70b', model_b='phi-4', score=<MatchScore.A: 2>, id='a85fded3b1344ad29602edfc8fd91177-2ba52612997c418aa273193cdf2d6471'),\n",
       " Match(model_a='command-a', model_b='qwq-32b', score=<MatchScore.A: 2>, id='6a3278e05334460690a45132a8f5dd81-83391e11611f441e84068266f5229fc9'),\n",
       " Match(model_a='llama-3.1-nemotron-70b-instruct', model_b='llama-3.3-70b', score=<MatchScore.A: 2>, id='9cf9a1208f114eb2a7d219439138b637-f662471c116c4e829a950588021eca83'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='llama-3.1-405b', score=<MatchScore.Draw: 1>, id='7a15e1f8463d4aa0bff18faaf095eb0e-7096cc1438da440caf5009f58cc5b576'),\n",
       " Match(model_a='deepseek-r1', model_b='gemini-2.0-flash-001', score=<MatchScore.Draw: 1>, id='7ccae9d68d344b8c9e0b426e02fadf6b-9ff68180d78d4501a72c6cd792e60e3e'),\n",
       " Match(model_a='gemma-3-27b', model_b='deepseek-v3-0324', score=<MatchScore.A: 2>, id='03e6721d211348428335f53754fa9c7b-2fb4574deb3b40339f43aaf5ee7becc3'),\n",
       " Match(model_a='gemma-3-4b', model_b='mistral-large-2411', score=<MatchScore.B: 0>, id='abe07a4738db486794dd604ccfcf9119-0711f9c746db4c7f81c3df231ea23d98'),\n",
       " Match(model_a='llama-3.1-405b', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.Draw: 1>, id='a00efd1391a043f5af0375c49b5af682-625e1a83cf8b40bb85805e0a7fc5ad70'),\n",
       " Match(model_a='gemma-3-12b', model_b='gpt-4.1-nano', score=<MatchScore.Draw: 1>, id='658d7b2ecd4342b88ed89892becb715f-f30218fc88af417891237326512d06df'),\n",
       " Match(model_a='deepseek-r1-distill-llama-70b', model_b='o4-mini', score=<MatchScore.A: 2>, id='d24f26f44d4e439498975b6dfb4c70b0-ccb1d7c5f60b4c81a368c12aa103afd7'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='llama-3.1-70b', score=<MatchScore.B: 0>, id='a6f15aacda7143fbb407e0562cdab3f0-47760cdc113649f0a0e63248e2dbb5b4'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='llama-3.1-70b', score=<MatchScore.B: 0>, id='8b5fe75fe1024d8d87ff4559ba16ba58-871f92d26f014ae6aaceb21875c39306'),\n",
       " Match(model_a='gemini-1.5-pro-001', model_b='phi-3.5-mini-instruct', score=<MatchScore.A: 2>, id='03a9190d312a469b98712870f87feea2-75c7e2ba54d44e9885e49ee65dfb8af3'),\n",
       " Match(model_a='deepseek-r1', model_b='o3-mini', score=<MatchScore.Draw: 1>, id='c5a586c9f068478e9d125d78cc7f4eeb-74ab21043cdd48af83e7a1e8bed4ec6e'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='gpt-4o-2024-08-06', score=<MatchScore.Draw: 1>, id='bfff7bf96c46411096dfc28713fc15c0-b5361e4d16854fddab99ddebf72eae1b'),\n",
       " Match(model_a='gemini-1.5-pro-001', model_b='mixtral-8x7b-instruct-v0.1', score=<MatchScore.B: 0>, id='b392a4ea07cc423bbb380985aa2fbee3-b15a822554de4469b65be72f07b0ba09'),\n",
       " Match(model_a='llama-3.1-405b', model_b='deepseek-v3-chat', score=<MatchScore.B: 0>, id='ee147e83da324c1fb048cf506289dcbd-f74707a0fe5b4edc941dd1e6e3bd4678'),\n",
       " Match(model_a='phi-3.5-mini-instruct', model_b='mixtral-8x7b-instruct-v0.1', score=<MatchScore.B: 0>, id='aeba8411373643fbb1685dca1af55dc3-8f0dba88a96549e6ab4c70cef9169feb'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='llama-3.1-70b', score=<MatchScore.Draw: 1>, id='87c5bf2c31c54b9db310c55a0392973f-5c65fdea2d0143ca9b8206a28f91dc7f'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='llama-3.1-405b', score=<MatchScore.B: 0>, id='6f486b8530f24b9d920a84bdc6d70eb3-bdb2b7cb9e034a2fb3e56db5ffb674bb'),\n",
       " Match(model_a='aya-expanse-8b', model_b='deepseek-v3-chat', score=<MatchScore.B: 0>, id='f3f28841d4b84545af35aeddef27c820-31e76601e2824912af1907b8c86bc1c7'),\n",
       " Match(model_a='mistral-saba', model_b='gemma-3-4b', score=<MatchScore.A: 2>, id='2762a27a52404e5b99ffb98dcf3d3ece-86ae1e359312473f83dddad8eaca79e4'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='claude-3-5-sonnet-v2', score=<MatchScore.A: 2>, id='d0e7c198e1a34713b00921578c066e66-ad516ee11dce45dab7dcc308e132fc69'),\n",
       " Match(model_a='gemini-2.0-flash-001', model_b='llama-3.3-70b', score=<MatchScore.Draw: 1>, id='6202b36bd7034337b0f90b3d698a716d-af284f55090849338162370e5c787af9'),\n",
       " Match(model_a='gemma-3-27b', model_b='gemini-2.0-flash-001', score=<MatchScore.A: 2>, id='535b7dc4d8134879b0810c604258cbf9-87ce55aed38149209220fe9aab810a25'),\n",
       " Match(model_a='phi-4', model_b='mistral-nemo-2407', score=<MatchScore.A: 2>, id='1ea7f675c22c40f19f445921609507a8-189028505fbf4f799970064fdd0bf834'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='llama-3.1-nemotron-70b-instruct', score=<MatchScore.A: 2>, id='f205b63b0f3e4ac984699f245e7a2b53-84f9bb2cde2a48198cab62c99ca5b4f4'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='llama-3.1-8b', score=<MatchScore.A: 2>, id='abff44185edd47c7a54c79b0c84f0b3d-0c6c7223b6de465b9c0e006fe0aed7f4'),\n",
       " Match(model_a='phi-4', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.Draw: 1>, id='3b5dd6369508464e8e63270846b64013-e5ec2ad630424f73acc0cb20c2802e65'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='deepseek-r1', score=<MatchScore.A: 2>, id='e3ccfda391a3463aa95e8e6cfb4c4c6f-aaada2c6b0f246ca8deef0067d53a8ae'),\n",
       " Match(model_a='phi-4', model_b='gemma-2-9b-it', score=<MatchScore.Draw: 1>, id='a2ba3f487bc64197b28872b8dacb11fd-fff8922bd33944fa89956f4616a1e779'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='mistral-large-2411', score=<MatchScore.Draw: 1>, id='5b4346a65fc24bf195b9c537729f30fa-579d3eae9c684d359deb38dd402a8606'),\n",
       " Match(model_a='c4ai-command-r-08-2024', model_b='lfm-40b', score=<MatchScore.Draw: 1>, id='50c56661ba0343aa860e6d4c3edf87c6-0f8368e4172f460f87c8813c76e25127'),\n",
       " Match(model_a='chocolatine-2-14b-instruct-v2.0.3-q8', model_b='phi-4', score=<MatchScore.B: 0>, id='c214dd9fa77f4b34954b191c7cddbcde-8f917657e2794465a79bbb240f0208d4'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.Draw: 1>, id='2a00dafcbdcd44b2b77328f7efe2a271-d152d5e8d0b746409df5ed9a35ef0251'),\n",
       " Match(model_a='deepseek-v3-0324', model_b='mistral-saba', score=<MatchScore.Draw: 1>, id='92970f5366f240688755e206a0fcae02-8f23d1bbec35406fb137b358bca2c485'),\n",
       " Match(model_a='mistral-large-2411', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.Draw: 1>, id='21da79bf4cc74cda847921559ad14067-94a509d639a64a05b2a55df4eaf205df'),\n",
       " Match(model_a='mistral-small-24b-instruct-2501', model_b='deepseek-v3-chat', score=<MatchScore.B: 0>, id='f051a7ecdacb435887a312d1bcf2ab2f-159132e4ee60467692adbe995682356b'),\n",
       " Match(model_a='mixtral-8x7b-instruct-v0.1', model_b='llama-3.1-8b', score=<MatchScore.A: 2>, id='42439b5ff27a495d9c3795bd8fbc986c-a4e4309a435d48c8a85e5479c4f9414e'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='mistral-nemo-2407', score=<MatchScore.A: 2>, id='de4f1f54f1c447ec8b8b66e86c36e657-b0564ee3e40e4bc7b0fcffc5f0f224ac'),\n",
       " Match(model_a='deepseek-v3-0324', model_b='ministral-8b-instruct-2410', score=<MatchScore.A: 2>, id='9f088f06061042c9ad38a5e88a889015-2e7a6c065d2e4b6ab5ad0f164f1f815d'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.Draw: 1>, id='75984d9eb1404149bd59069f7bf7489f-2a28a10c8ed14f6592bb3d9a4441c277'),\n",
       " Match(model_a='aya-expanse-8b', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.Draw: 1>, id='5cf153909cf9482f8add6b0432c307d6-5ee32e0fddcf42719705c263e05ca4a4'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.B: 0>, id='2b3a3cbadbc44e74b339b8a6cda324b6-599c86122ede44beb46025f42db23f87'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='gemini-1.5-pro-001', score=<MatchScore.B: 0>, id='94f22e1684ff4e078c3d1bd04d325cc5-a4e266c368bc47c1b42491376d1ca6c7'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='deepseek-v3-chat', score=<MatchScore.Draw: 1>, id='1e3fe371e3d24035a0f280d1b81bdd3c-799044a360344302aa9e933ee1d888e7'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='aya-expanse-8b', score=<MatchScore.B: 0>, id='e770a81646a9415682e3fc524f3f57b5-945cc0dc8a7f4d50b2f0b6553e02c93d'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.A: 2>, id='de99de00b4b84151b3ba0251cab72461-9f0d32abff3f4fb38465ad3ff458a4a7'),\n",
       " Match(model_a='llama-3.1-nemotron-70b-instruct', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.A: 2>, id='1cbe0a6261514a1a92606ed027e818bc-e27acf74d78e4d2fb3de08f80ff879d6'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='chocolatine-2-14b-instruct-v2.0.3-q8', score=<MatchScore.A: 2>, id='9750ef0a5c6449fe9678062711517085-fd2f6af3ae7a44ed826182a365ce1c0f'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='command-a', score=<MatchScore.B: 0>, id='798c6e20ef7b4b0794e2eaa70c1a9e97-38485c0a260f4a1fbbedc17c42256ff8'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.Draw: 1>, id='414c759b21c24994a7908970cca6d64d-0c57a87b6b4e460aa8fdb7c52c00493c'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='llama-3.1-70b', score=<MatchScore.A: 2>, id='8cd7c988685042bead8ea48071d72b97-0d07ab7ac7734c4fb46d591d4a13e253'),\n",
       " Match(model_a='phi-3.5-mini-instruct', model_b='gemma-2-9b-it', score=<MatchScore.B: 0>, id='b1c7045117054f488edda82711d2ee2e-c70b61bd8edb4bc9b27edc4b6045f1dd'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='llama-3.1-405b', score=<MatchScore.B: 0>, id='5fb63478250247a38ac8c015bdb9019a-565da6dc0c1b4ab2aef713c872c84d3c'),\n",
       " Match(model_a='mixtral-8x7b-instruct-v0.1', model_b='llama-3.1-405b', score=<MatchScore.B: 0>, id='78389a7affcf49f09f49d50fde0908bd-f9ad5c7f0d0e4ae08d4ff3c5ea685675'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='gemini-2.0-flash-exp', score=<MatchScore.B: 0>, id='14161a232cc2413a8ed051971a694620-a98a10533c0f4be1883fe79b1ebec34b'),\n",
       " Match(model_a='llama-3.1-70b', model_b='gemma-2-9b-it', score=<MatchScore.B: 0>, id='a9d1212a751143e0a4d616bb2d8002ef-458b89d0b4c04e8cb8be124df5d48fd9'),\n",
       " Match(model_a='mistral-saba', model_b='command-a', score=<MatchScore.A: 2>, id='cbcc4be324f84adfa12743f704d7cb76-8649603249224945b593e028e1ba5d4f'),\n",
       " Match(model_a='llama-3.1-70b', model_b='lfm-40b', score=<MatchScore.A: 2>, id='caaf7b359dd8443889ee95b923d82cb9-ca70bc202a7649d8ad7720f9827430b6'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='deepseek-v3-chat', score=<MatchScore.Draw: 1>, id='9f7a46188c6a422f8287acc4ea21a29d-c7dcd94dc7b640648a9dffa80bc6d577'),\n",
       " Match(model_a='phi-4', model_b='llama-3.3-70b', score=<MatchScore.B: 0>, id='a1f15bfcaa654d7285f9e87fb0fcb0df-3fa240ea05024a7ea1bc1bc317e8fa11'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.A: 2>, id='61c622eabb7d4163b781e187dcfb4ce3-cea38373c18f43f69ab5922bdedc92c7'),\n",
       " Match(model_a='llama-3.1-405b', model_b='ministral-8b-instruct-2410', score=<MatchScore.Draw: 1>, id='7edf7eb5ccf249cf8b4c1d04a36f55c7-f354d07ae91b485fb6b94336f726f3d0'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='gpt-4o-2024-08-06', score=<MatchScore.B: 0>, id='09fea13e378f4c90b8c6d98c83d30530-1ad0c3809b8f4266b203458b8c6b7e1c'),\n",
       " Match(model_a='llama-3.1-405b', model_b='gemma-2-9b-it', score=<MatchScore.A: 2>, id='b2b85115db5744409ad6d21ab671cab0-6ba0b9ab87a146eebced9a29ff3b09e8'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='mistral-nemo-2407', score=<MatchScore.Draw: 1>, id='0f8e1032df0f418bb3cf6ad655f4b913-24d3e802b20c4aa3851ed7bdd78b610a'),\n",
       " Match(model_a='grok-3-mini-beta', model_b='claude-3-7-sonnet', score=<MatchScore.B: 0>, id='16df351af1264649ba4d13a04dc91bda-76fef2e618b04b7591ca6ba055782333'),\n",
       " Match(model_a='llama-3.1-70b', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.B: 0>, id='49b90c37f270476ca56d347082426fe1-600200e1d2c74f7594ef5fd8a53c1ea7'),\n",
       " Match(model_a='llama-3.1-8b', model_b='qwen2.5-7b-instruct', score=<MatchScore.B: 0>, id='8a8d51c97f5a4884b39a6bcf7e32beb4-34d55c5f9c3c472ba09caad23281cd67'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='mistral-small-3.1-24b', score=<MatchScore.A: 2>, id='2825da9a43534b74ac5cf48b13cbd37b-6140bda22dce440089c4fe6554583f91'),\n",
       " Match(model_a='llama-3.1-405b', model_b='gemini-2.0-flash-exp', score=<MatchScore.A: 2>, id='453dfd36bc9348968d80f8e865dd6906-8f043e1d87984fc799ccc619a2ba961e'),\n",
       " Match(model_a='mistral-large-2411', model_b='gemini-1.5-pro-002', score=<MatchScore.Draw: 1>, id='296dd9df7c184fb29713f3b57c85eb94-2c296703450c403ab08966c02ce4d1e5'),\n",
       " Match(model_a='o3-mini', model_b='llama-3.1-405b', score=<MatchScore.A: 2>, id='5a50ecdf63c647278a6610487ffd8023-ab6a591b9b044374891d0f5254c2d8c7'),\n",
       " Match(model_a='mistral-small-3.1-24b', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.B: 0>, id='49ebb560163c4b07ac2516b2f3f89a43-702c506a914e4425984f44d9a695f742'),\n",
       " Match(model_a='llama-3.1-405b', model_b='qwen2.5-7b-instruct', score=<MatchScore.B: 0>, id='5fcd9156f6ac466a99dafc250a8083f2-5086f07c56d646ceac3c2ac7bae2f3fa'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='llama-3.1-8b', score=<MatchScore.A: 2>, id='7c28b79fc3e54fa59da175b29a4adfa4-6331ffd84cb34afbae9ad2890eb87714'),\n",
       " Match(model_a='gpt-4.1-mini', model_b='llama-3.1-8b', score=<MatchScore.A: 2>, id='561cb339a73b40939663bd88963d28c9-dc5be77d101c4a4fa383be07b33433ce'),\n",
       " Match(model_a='command-a', model_b='mistral-nemo-2407', score=<MatchScore.A: 2>, id='ca5dffde12044f1dac2542c74a661198-e3ca62c735224e99970db4607e852f52'),\n",
       " Match(model_a='mistral-small-3.1-24b', model_b='gemma-3-27b', score=<MatchScore.B: 0>, id='d28ece41c579424e86dc821ab9f3f063-d9582f5408584067b2e4cd60cd0018f4'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='deepseek-v3-chat', score=<MatchScore.B: 0>, id='75bdd891c353433d9bd9b7b8462bd5c4-7199aedaa1c24c27b246bc299de017db'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='llama-3.1-405b', score=<MatchScore.B: 0>, id='5999397b74304d4a898daf95f8d35b4e-3cfb6a5aba04476a9d19f76f2d029f02'),\n",
       " Match(model_a='mistral-small-24b-instruct-2501', model_b='llama-3.1-8b', score=<MatchScore.B: 0>, id='5d1a49a3761548f480b0e2dd6ea9442d-0cd539fe128d4ee1b58723b9fa2ad897'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='gemini-2.0-flash-001', score=<MatchScore.Draw: 1>, id='64d4df28920e4bae81b04b5f278df0b7-8e69513bad7649a393d5a5b5859f6156'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='gemma-2-9b-it', score=<MatchScore.A: 2>, id='f3784751724143e08c3be9dc6ca17bec-ab6779d7c9964f978e65f5206fde3246'),\n",
       " Match(model_a='phi-3.5-mini-instruct', model_b='mistral-nemo-2407', score=<MatchScore.B: 0>, id='0e01ab5a41d244e1a596589004dd36e2-76383e86466e42e68a4c5aa6039209c9'),\n",
       " Match(model_a='gpt-4.1-nano', model_b='llama-3.1-nemotron-70b-instruct', score=<MatchScore.B: 0>, id='4b4f7adfc0ff4944901fa3e2f6892380-bafffe2ca2f14340bd99012eab3c1522'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='deepseek-v3-chat', score=<MatchScore.Draw: 1>, id='2915a078e2f94804b600044213a8084a-e282a07789df4af7b21f640eb152839a'),\n",
       " Match(model_a='gpt-4.1-mini', model_b='deepseek-v3-0324', score=<MatchScore.B: 0>, id='52654165f8f14609b5a2ef2ad8fe8be7-61357b6e492841689bccc9c607faeea9'),\n",
       " Match(model_a='llama-3.1-405b', model_b='deepseek-r1', score=<MatchScore.A: 2>, id='13514e6e933c42369acdedf975358f41-8e6dc92301514c1495a335f11b3bbff8'),\n",
       " Match(model_a='phi-4', model_b='gemini-2.0-flash-001', score=<MatchScore.Draw: 1>, id='c57f6b4b167d41fa8bee4a0fbc31a594-dee3fd9220e64fc7bc1d63b2f1cd85f0'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.Draw: 1>, id='c604213de1ee43efacdce729bd65abb7-7f2e0e6f5a1c43a29dd85e009bf2e5ea'),\n",
       " Match(model_a='claude-3-7-sonnet', model_b='gemini-2.0-flash-001', score=<MatchScore.Draw: 1>, id='53993509d26d49fd9d68b03fa07854a2-a1c10a7fdddf4c6eb5373553b140c50a'),\n",
       " Match(model_a='llama-3.1-70b', model_b='deepseek-v3-chat', score=<MatchScore.Draw: 1>, id='a50a7faca38a47b88d0d47dc4463e270-92f07629698a415082ab4285ee2dcdbd'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='gemini-1.5-pro-002', score=<MatchScore.A: 2>, id='1c0a3062174141ff940dfc4774b65540-9b4ef68497d84af09bf0c00528bfa373'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='qwen2.5-7b-instruct', score=<MatchScore.B: 0>, id='e4fd42cf3a6341d1873df022660107d2-e83e41d59ba44b14b6c1cb840354f953'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='gemma-3-12b', score=<MatchScore.Draw: 1>, id='28f1b18ec91241619c91a02da5004535-646c688caf7a4212bb2cd0deaaaf7468'),\n",
       " Match(model_a='mistral-large-2411', model_b='gpt-4o-2024-08-06', score=<MatchScore.A: 2>, id='0a5215d82f27419bbdc8d95db11d2bcc-a0b2a778aac74fd595b58dd2bd5bdedd'),\n",
       " Match(model_a='mistral-large-2411', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.Draw: 1>, id='210f9ddf78d447a3bacf9e21b3fdb7bd-685f4602c7d64cf893fa66dddc39e1d1'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='mistral-nemo-2407', score=<MatchScore.A: 2>, id='01ef3247104a4093a9dc294a3a38deb6-db8b4582f0524582b24f437c4db3e90f'),\n",
       " Match(model_a='llama-3.1-70b', model_b='llama-3.3-70b', score=<MatchScore.Draw: 1>, id='6295e215e8ff41b1840cbbe3daac123f-384d65b8d99d4cbf8be1535884b74042'),\n",
       " Match(model_a='qwen2.5-7b-instruct', model_b='llama-3.1-8b', score=<MatchScore.B: 0>, id='2f48576bafca49db900b8eefcc680b52-63c4b6fcfe1e4f7fa512a3f9528b51ff'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='mistral-nemo-2407', score=<MatchScore.A: 2>, id='3ab8ffd21b1e46e18d080b4b31c90e18-bbeaa82c74a64e46b9958137ca2c7d13'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='chocolatine-2-14b-instruct-v2.0.3-q8', score=<MatchScore.A: 2>, id='4ba7e9cffdb44043afe1841474d99b81-d2fae57ad75d4b03b992393c8aa5dbca'),\n",
       " Match(model_a='c4ai-command-r-08-2024', model_b='deepseek-v3-0324', score=<MatchScore.B: 0>, id='2226e5d9a2a748be8729177e65eec9a2-b21d341483734a599ed028c4ed6ab667'),\n",
       " Match(model_a='llama-3.1-70b', model_b='mistral-nemo-2407', score=<MatchScore.B: 0>, id='228a6e0d34eb414fbc6fe3821fbddc24-6ffd7d328188479eaf26f6103c73567a'),\n",
       " Match(model_a='mistral-large-2411', model_b='ministral-8b-instruct-2410', score=<MatchScore.Draw: 1>, id='23e70a49ff06418988e58b4799a71ad6-dd4e74262f814476ac73db793e3449cf'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='lfm-40b', score=<MatchScore.Draw: 1>, id='8bc930df113d46c59f1c8367c9c45646-9e2ee4b34ced4746b878be71e9592f4b'),\n",
       " Match(model_a='qwq-32b', model_b='o4-mini', score=<MatchScore.A: 2>, id='55e4261972234e4b9a57f75973631d42-a0891bb6f8e8458ea91654bb26228382'),\n",
       " Match(model_a='llama-3.1-70b', model_b='phi-3.5-mini-instruct', score=<MatchScore.A: 2>, id='f51c843b6a3a4941a4fd0243bc5401b0-f49468e3e7954d9fa234754ccbaa56ee'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.Draw: 1>, id='fa70f7258d704151ae0918807df48f57-cf5243294fc54578a2591c89f62cfb17'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='deepseek-r1', score=<MatchScore.A: 2>, id='1d2b48db28404f619c6d62bcb7681126-2fc0cab08a9a40679d57c3c9a552eac0'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='gemini-2.0-flash-001', score=<MatchScore.Draw: 1>, id='bc621e4f1e25479db719cc6935872f89-fa1f523a17f14a2cb917f7477e94ac42'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.A: 2>, id='f652cf28654446d29f1edd16b05cd63e-483fbf7ebfcd468d920cc08802db85f3'),\n",
       " Match(model_a='gemini-2.0-flash-exp', model_b='deepseek-v3-chat', score=<MatchScore.A: 2>, id='680b145c282d4359bdb22fd386b9a613-84962bf674a84e1582d73c112679e8d9'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='llama-3.1-8b', score=<MatchScore.A: 2>, id='503c81f68b854f4d9d99e3400565e20a-5a324a6e34ce4111b2bacddee7c726ac'),\n",
       " Match(model_a='llama-3.1-nemotron-70b-instruct', model_b='claude-3-5-sonnet-v2', score=<MatchScore.A: 2>, id='b026d8bcfc6a4e8dace8c35cae699392-0caa87011f5a4caeab14010c07a2bd3f'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='mixtral-8x7b-instruct-v0.1', score=<MatchScore.B: 0>, id='ccd3b0384aa14c839a262f5f2013e756-bf5f64fad97d404da3d61f2319ed3b41'),\n",
       " Match(model_a='gemma-2-27b-it-q8', model_b='llama-3.1-405b', score=<MatchScore.A: 2>, id='dec0fb134573405596474050f9b146b4-126b4dc2428c4831aa99c08bf5365625'),\n",
       " Match(model_a='llama-3.1-405b', model_b='ministral-8b-instruct-2410', score=<MatchScore.B: 0>, id='7784b11a94764f09aabea06a2422b5b9-6ea07a324f1446c0bd40f4ebcb0ad18c'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='gpt-4o-2024-08-06', score=<MatchScore.A: 2>, id='a0ed2fa0b0f0422eb1977250adcf0a7a-1076a7c3ad9c451f962556261d528e65'),\n",
       " Match(model_a='llama-3.3-70b', model_b='chocolatine-2-14b-instruct-v2.0.3-q8', score=<MatchScore.Draw: 1>, id='7c866757823a4c9e98c2d10249cb4137-0e341740cf3f4eef8d37f1857b480ab9'),\n",
       " Match(model_a='deepseek-r1-distill-llama-70b', model_b='o3-mini', score=<MatchScore.Draw: 1>, id='e511a26adf024fe4b04178831e044845-b8c19c3c5aa54ba093de58a153784e71'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='phi-3.5-mini-instruct', score=<MatchScore.A: 2>, id='eca74439cea64df5ad63f1d7ca273175-58827d9830c74aaa8c10d91a7cd75474'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='deepseek-r1', score=<MatchScore.B: 0>, id='fc93204630d24a0780e453a61f050069-2d817222e43845d487aba2109dc7277f'),\n",
       " Match(model_a='lfm-40b', model_b='gemini-2.0-flash-001', score=<MatchScore.B: 0>, id='cfc1d33108434d44b1870fd666ec42ed-b91c76667dbd4a17a220e56c698316de'),\n",
       " Match(model_a='qwen2.5-7b-instruct', model_b='gemini-1.5-pro-001', score=<MatchScore.Draw: 1>, id='e153b142ba74446f83948d1e9aa9d4de-9069a62d92924ee8a9dd3637cf400f20'),\n",
       " Match(model_a='llama-3.1-405b', model_b='qwen2.5-7b-instruct', score=<MatchScore.B: 0>, id='70d57d458e88433497b3010162444667-3b0ca603e9c44cfdb2cf6c099b5298bb'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='mistral-small-3.1-24b', score=<MatchScore.B: 0>, id='149b88ea090b4e2c97f868ca7024b368-489f8fcfa242405597064e25111b20f2'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='mistral-large-2411', score=<MatchScore.A: 2>, id='c7b75416429e450a9964284a0442b864-832a6f35cc6c4cd0bfe247098cf7203f'),\n",
       " Match(model_a='llama-3.1-70b', model_b='gemini-1.5-pro-002', score=<MatchScore.Draw: 1>, id='316dd9cf938942189a8898e5397d15f4-34b19fe384324f608d282d581858989c'),\n",
       " Match(model_a='mistral-large-2411', model_b='aya-expanse-8b', score=<MatchScore.Draw: 1>, id='2808a3562f32410fb60bcb35dfbb6685-b8a840ab270b4bf88ba3847701be0796'),\n",
       " Match(model_a='mistral-small-3.1-24b', model_b='gemini-2.0-flash-001', score=<MatchScore.B: 0>, id='8801b5eb691f45e7ba0fccdf78de6627-cfc7cf4586d74152bd3c37362977244f'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='claude-3-5-sonnet-v2', score=<MatchScore.A: 2>, id='97b9980b51484ab5bb38fe0a782dba6b-7a6214c3446e4a4ab82531c6023e2b02'),\n",
       " Match(model_a='mistral-small-24b-instruct-2501', model_b='llama-3.3-70b', score=<MatchScore.B: 0>, id='d98c24ddfb664d2d84c259697a9b8c2a-854fee9b0e794342b9d082edf4bd801a'),\n",
       " Match(model_a='mistral-small-24b-instruct-2501', model_b='lfm-40b', score=<MatchScore.Draw: 1>, id='c87b260bd629486d8485429b944bea61-c5544129f2044f1588b446c5c959afbc'),\n",
       " Match(model_a='gemma-3-27b', model_b='gemma-3-4b', score=<MatchScore.A: 2>, id='9a0f812d2d174a128919de0c9673180b-edd0d91ed2cb4d3abd3f3aa7d338a054'),\n",
       " Match(model_a='qwen2.5-7b-instruct', model_b='phi-3.5-mini-instruct', score=<MatchScore.B: 0>, id='1833e087dbe248d9b9ed8a4631bd6686-93614ef8231041d99dc3d25bf554b43a'),\n",
       " Match(model_a='llama-3.1-405b', model_b='llama-3.1-8b', score=<MatchScore.B: 0>, id='5ab1bbce48494c4493357d79fed26e2f-29ed540d94bc484bb788528751b1d960'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='mistral-large-2411', score=<MatchScore.Draw: 1>, id='5e8ea787d93e4d7fafcc00f4e35fba48-62e809f712cf46b3b0f24c1284c2bfeb'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='phi-4', score=<MatchScore.B: 0>, id='902ac29bb95a43e5a477c26243dd1f4f-0d564eaf633b4318b3974f73b4fca6a2'),\n",
       " Match(model_a='mistral-large-2411', model_b='deepseek-v3-chat', score=<MatchScore.B: 0>, id='878595d3c3484b208787d064edcf77a0-98070e0e06e34f3e945a4f512edabe66'),\n",
       " Match(model_a='llama-3.1-405b', model_b='deepseek-v3-chat', score=<MatchScore.A: 2>, id='05c6da56c01e49af8bdcd8e1fcef10e1-f357a1660913434ab3ad0a7ed4102008'),\n",
       " Match(model_a='deepseek-v3-0324', model_b='gemma-3-27b', score=<MatchScore.Draw: 1>, id='29b1ae8b72494147938152db43103081-998134a216b247989ab0082f5970a372'),\n",
       " Match(model_a='gemini-2.0-flash-exp', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.A: 2>, id='4739df57e0fa4fee8afabe55953cc34d-024c59d39e114e82b98e113577da0919'),\n",
       " Match(model_a='qwen2.5-7b-instruct', model_b='mistral-nemo-2407', score=<MatchScore.B: 0>, id='aa5df00bf51d441ba6d0cc3eff1086b5-4b3c51766d3544aa9ad9bed459656d70'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='deepseek-v3-0324', score=<MatchScore.Draw: 1>, id='406aafc0995c4ea5b9adac82ed75f5e0-698541a9f3a54caba2da9fec0c851847'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.A: 2>, id='8c37de56414f4548beed4d109987bf61-f8dce134b2b247ca86564e363b13551e'),\n",
       " Match(model_a='deepseek-r1-distill-llama-70b', model_b='llama-3.1-8b', score=<MatchScore.B: 0>, id='116ba12883904f4f9dd6b42743732499-27cd230b8125408d94e73733d483d182'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='llama-3.3-70b', score=<MatchScore.A: 2>, id='b62b3032ca2348839ea5dca5a2140325-95409c904b0544d5bed92cbd12784d1a'),\n",
       " Match(model_a='deepseek-r1', model_b='mistral-small-3.1-24b', score=<MatchScore.B: 0>, id='7205cbfdab0540f99d87935621da7a2f-4f0c772f9b2d40978d5afd1335bc921c'),\n",
       " Match(model_a='gemma-3-4b', model_b='phi-4', score=<MatchScore.A: 2>, id='d3e563cfd5494df987a1c9ab4b28824f-d60ee79e90a44970b9ef6a80a9cd5dae'),\n",
       " Match(model_a='llama-3.1-8b', model_b='gemini-1.5-pro-001', score=<MatchScore.Draw: 1>, id='69b5677bd08d44e68144fa905ba8ddbe-cb3ce8c5e02947f3a5eb606561673157'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='mistral-nemo-2407', score=<MatchScore.A: 2>, id='b7adf31aeeb54b5c9c731647ca6c315c-b54ff730218f46048939007920494930'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='mixtral-8x7b-instruct-v0.1', score=<MatchScore.A: 2>, id='591431369579401f9b9addcfef124838-166762e055484b80858e1069a19b0e84'),\n",
       " Match(model_a='llama-3.1-8b', model_b='gemini-2.0-flash-001', score=<MatchScore.A: 2>, id='2130eaed971a4c1da510d6833d08135f-fee403f324bd4282a80bd2022fde59e5'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='gemini-2.0-flash-exp', score=<MatchScore.B: 0>, id='d158d481edf741fbab4df5896ddda27b-62a1c4998c694c13ab2f61aefe04ebb4'),\n",
       " Match(model_a='o3-mini', model_b='lfm-40b', score=<MatchScore.Draw: 1>, id='ea032e0d5ba948eba1ecee1d3631aef5-a1b67152bdad4ab7b409a7a21b720f89'),\n",
       " Match(model_a='phi-4', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.B: 0>, id='898445c8b18241b58b8cf2af6e65c3ee-8d1609598e4e4b1198b236d6758e6b21'),\n",
       " Match(model_a='phi-3.5-mini-instruct', model_b='gpt-4o-2024-08-06', score=<MatchScore.B: 0>, id='020e7ba559b94fd9bd99873c00ef83c4-2c29c5bb75c04a41ad77f49f8ce72e00'),\n",
       " Match(model_a='mixtral-8x7b-instruct-v0.1', model_b='ministral-8b-instruct-2410', score=<MatchScore.B: 0>, id='6b1c4e47d66f4ba992e275f8fbf14a3f-020d5134929d44f1ad3f0b9bb4fba4da'),\n",
       " Match(model_a='command-a', model_b='gemma-3-4b', score=<MatchScore.B: 0>, id='598b9ec85e954f7db373812fa2882cc8-54db79b431234814845b6628fbd685ae'),\n",
       " Match(model_a='mistral-small-3.1-24b', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.A: 2>, id='f6dd6a3a7d3b471a84d3e553d4ee128f-0b839e85a76c4254a7f8bfb77eccadce'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='llama-3.1-405b', score=<MatchScore.A: 2>, id='352a81211b2a4a78be7cbc2f86dbc92d-d2f7f25ceaf949e395a99174904e8950'),\n",
       " Match(model_a='deepseek-r1', model_b='qwq-32b', score=<MatchScore.Draw: 1>, id='6af2f97347f742ecab008a3ef53dbfbf-559b79f8b2fe4696890c3b8ac756359b'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='gemini-1.5-pro-001', score=<MatchScore.B: 0>, id='3031192082044e3e9df26962b3b61043-8f19cc43e60c4908ba455d435c789e30'),\n",
       " Match(model_a='o3-mini', model_b='mistral-large-2411', score=<MatchScore.A: 2>, id='da566ddf5ff04e9bbbf533196083959b-10646bb353204d619d083bf8457a9cee'),\n",
       " Match(model_a='lfm-40b', model_b='gemini-1.5-pro-002', score=<MatchScore.B: 0>, id='2e96b1716a624db1b8aba2d91a7d3e10-5324b22e3c6143d7a623771ddd307239'),\n",
       " Match(model_a='llama-3.1-8b', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.A: 2>, id='ab15d0dc754c46898fd5e0cc9dba1933-4d61887754df46ff92125b82e34e1566'),\n",
       " Match(model_a='deepseek-r1-distill-llama-70b', model_b='gemini-2.0-flash-001', score=<MatchScore.Draw: 1>, id='4e385f068b2d47b985ba38e80143259f-343e3bcc9e7b45f88491c13e48ef52ce'),\n",
       " Match(model_a='gemini-1.5-pro-001', model_b='llama-3.1-8b', score=<MatchScore.A: 2>, id='c5bc4ae502844edcac7c3215e7b45182-a3732ffe82b349d3bdc2af0b852c7b88'),\n",
       " Match(model_a='lfm-40b', model_b='qwen2.5-7b-instruct', score=<MatchScore.B: 0>, id='7cf061e459b74381aa3d28442d364eda-1779ccf0298742bca6c23237bffff837'),\n",
       " Match(model_a='chocolatine-14b-instruct-dpo-v1.2-q4', model_b='qwen2.5-7b-instruct', score=<MatchScore.A: 2>, id='fb7db1e44a404ace9ee123ad6a865281-b71221ab22d246888bfd4ff11572f09a'),\n",
       " Match(model_a='phi-3.5-mini-instruct', model_b='gemma-2-9b-it', score=<MatchScore.A: 2>, id='da1d462572ea4d9c9de201ba8c1bc396-23dbe7a86fbe49db8178d459486f5efa'),\n",
       " Match(model_a='gemma-3-27b', model_b='claude-3-5-sonnet-v2', score=<MatchScore.A: 2>, id='90f37d29269f4bdb938a9105877ae5bc-3c6bfa35fe684b50b8b0caf8f86490c9'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='lfm-40b', score=<MatchScore.Draw: 1>, id='baa98e1d9cd142d29a71a726b1896945-c7af8be91eb74e5cbaa96ee92cfc41de'),\n",
       " Match(model_a='gpt-4.1-mini', model_b='phi-4', score=<MatchScore.A: 2>, id='a5e81820b68f4f19a0de9068bc687abf-09a00cbf222c4c81bb68bd269743ad18'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='mixtral-8x7b-instruct-v0.1', score=<MatchScore.A: 2>, id='200666b51f604acead8e20864e77511b-e1217c63f87b485aad250b23b58f06f8'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='gemini-1.5-pro-002', score=<MatchScore.B: 0>, id='6a250b4a4ec740e3ab3100ed826a7b51-b0e94a8110bb49c29eddade831b3935e'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='llama-3.1-405b', score=<MatchScore.B: 0>, id='a1da3d4e7f8a49ad93fc694b1e80737b-2bf147b621e94d35a534014a61539ce9'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='llama-3.1-8b', score=<MatchScore.B: 0>, id='fffaa655344b482f9dafc22f7a388120-6ad66fe26e884556823bc9d9dfceba69'),\n",
       " Match(model_a='qwq-32b', model_b='c4ai-command-r-08-2024', score=<MatchScore.Draw: 1>, id='683ff6bc06b6434ea9f9f690eff28174-b7ef2dbcead2447a92e9e5b0e64fc52a'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.A: 2>, id='5f22b8ad2bfc41e0b6682105cf253ac0-d0ccab0cc9bb4158b9e81df393d06132'),\n",
       " Match(model_a='gemini-2.0-flash-exp', model_b='gemma-2-9b-it', score=<MatchScore.A: 2>, id='2f07c7113d9f404799086b7398599427-b82117562ea14b01b58d6810aa2297ba'),\n",
       " Match(model_a='llama-3.3-70b', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.B: 0>, id='4068cd983191401d98ba77d954eec5a2-6804c26355564aedbd0d69f8ec246dc9'),\n",
       " Match(model_a='llama-3.1-8b', model_b='llama-3.1-70b', score=<MatchScore.B: 0>, id='0713d6b1f52042e5a3f8f25abb9cca56-4473ecc033484b47b082bbc4d821a6ba'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.B: 0>, id='e888f53515a84367a5cef95dbfc6b7b6-0d27a38681934206b01ce0c602d300f3'),\n",
       " Match(model_a='gemini-1.5-pro-001', model_b='lfm-40b', score=<MatchScore.A: 2>, id='2a3c243951a0421daf150659efaa61f1-09150b233bd94d22b5b2ac67a30c4290'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='gemma-2-9b-it', score=<MatchScore.Draw: 1>, id='eec220c77de24293ab668523665780c8-0e357adee0024b9f87cb40773ce1f04d'),\n",
       " Match(model_a='llama-3.3-70b', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.A: 2>, id='b40b3271fdb743c9a9543ebec7eac781-35269dbdc73f423492c4588b1fb22903'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='claude-3-5-sonnet-v2', score=<MatchScore.A: 2>, id='4f3f81fd147b495a8a37c8978c8b8fbc-5a1ecb3601234b0bb3b6b95fc688db16'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.Draw: 1>, id='745f5622bf86472787baf2cf03ba2c28-40297cc3a87a40758f2000b4cff0809c'),\n",
       " Match(model_a='phi-4', model_b='mistral-nemo-2407', score=<MatchScore.A: 2>, id='f99aecd8dc3e4fa4a5ae2881ae3313f6-b107eb70d466498d827d7c414b108fa6'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='deepseek-v3-chat', score=<MatchScore.B: 0>, id='f1d676289d6c49428082bc0a7cfcae6a-f2959d19d5f7448c8ea639d6b323addf'),\n",
       " Match(model_a='llama-3.3-70b', model_b='gemma-3-27b', score=<MatchScore.B: 0>, id='4622b5356d154fc3aec1d96b4c519806-b7d1b9a54523448eae2b574252b5593a'),\n",
       " Match(model_a='gemma-3-12b', model_b='o4-mini', score=<MatchScore.Draw: 1>, id='6db01261276d4d039e34b4e837e4846d-40239dc9cb95483988237d538771f2cb'),\n",
       " Match(model_a='llama-3.1-nemotron-70b-instruct', model_b='gpt-4.1-nano', score=<MatchScore.A: 2>, id='34a7854c3b8f4cffbac9ce3e193c062d-b6ea5fdec0854c128eb35ffe0673c0f0'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='claude-3-5-sonnet-v2', score=<MatchScore.A: 2>, id='2b7473794d914c458c2497b3557637c9-a69e85fa0388495dab2dc793c8aa283b'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='llama-3.1-nemotron-70b-instruct', score=<MatchScore.Draw: 1>, id='a068cddd37c248038d5c2e242a02cd49-8b6928f9655c4627a67e3d97b8ab8703'),\n",
       " Match(model_a='llama-3.1-70b', model_b='llama-3.3-70b', score=<MatchScore.B: 0>, id='ef39d4c482f74404bcccc57e14537894-1836f58c9bc94133ada7ff33e7052681'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='llama-3.1-70b', score=<MatchScore.A: 2>, id='8b0fbbe14b0b43a4879e12a4883eb382-8d14f36690a547db9e4f2b7254b7272a'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='phi-3.5-mini-instruct', score=<MatchScore.A: 2>, id='9b396ba5588b40c5b7cfedb34a2e91a2-6d4e8f814c2a48daa68fee76d93aa717'),\n",
       " Match(model_a='mistral-saba', model_b='command-a', score=<MatchScore.A: 2>, id='cd7a9c74437544b6b237cc9b81147a38-83334d8bea97460199dd8189fbf5316d'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='llama-3.1-8b', score=<MatchScore.B: 0>, id='ae2991c56bab4372964cd8ab024a8c98-a0fb2ade84c34993b4d6a9632d5c4426'),\n",
       " Match(model_a='llama-3.1-nemotron-70b-instruct', model_b='llama-3.1-8b', score=<MatchScore.B: 0>, id='e92f369d86e64afe9b8059259c3892a8-e77a22e17a354409abcf2b60ce137bea'),\n",
       " Match(model_a='llama-3.3-70b', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.A: 2>, id='e5c6dcf8eee54994b561ec5e328df9f7-e2e820b5fbfb4c7abbb1e677583679b2'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='mistral-saba', score=<MatchScore.Draw: 1>, id='2f27f74d78e04606acde435d270b609e-5137117dfe2f438a8c15f8fa966a47bf'),\n",
       " Match(model_a='claude-3-7-sonnet', model_b='gpt-4.1-nano', score=<MatchScore.B: 0>, id='80034eda147a415b9ff85377e84a85c1-b772dc53bdfa4f2e98f620a9c00470d8'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='llama-3.1-405b', score=<MatchScore.A: 2>, id='1535fb35bfb44f2eadc47ce7d4ac4b7f-67d171bfd4e44c71a8320b09630fa26b'),\n",
       " Match(model_a='c4ai-command-r-08-2024', model_b='llama-3.1-8b', score=<MatchScore.A: 2>, id='b7617bff80354e79904027e1f3d5862d-ad65dcfbd51c461f965a05173d1cfb3e'),\n",
       " Match(model_a='phi-4', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.B: 0>, id='99e31f4d3a294fbdab2facd4b2099081-0b980f0f9f7b4954814aab9d78fea720'),\n",
       " Match(model_a='llama-3.1-70b', model_b='phi-4', score=<MatchScore.Draw: 1>, id='809626c6936641919b289cd1ec9ba84a-fca75c02f77542ae9b285008243de5f4'),\n",
       " Match(model_a='mistral-small-24b-instruct-2501', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.A: 2>, id='4fee9234a53547b5ac99164b5f290dbd-4af7ef270e65453bb829232685a18e8f'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='deepseek-v3-0324', score=<MatchScore.A: 2>, id='44ec7a0138bb42dab5e4e4ec8556608c-8e9ff71ceb9147e7a070c823eacf7cb3'),\n",
       " Match(model_a='llama-3.1-70b', model_b='phi-4', score=<MatchScore.A: 2>, id='92a5ae50d54a41e4a9dff6e64e58de59-213e81ccf74340c691b46550727495e0'),\n",
       " Match(model_a='llama-3.1-8b', model_b='deepseek-v3-chat', score=<MatchScore.Draw: 1>, id='b3ce2be64b9748a8a0a528b65dc1aa5e-da7cbb1170b14c2181ee88a18e50d1d6'),\n",
       " Match(model_a='qwq-32b', model_b='mistral-large-2411', score=<MatchScore.A: 2>, id='8fdcae4971a54407bae19c67574abef8-d658e086dd104f7888f7eef1cfb90c39'),\n",
       " Match(model_a='gemma-3-12b', model_b='llama-3.1-8b', score=<MatchScore.A: 2>, id='9b811a41fe174c7789fbe280872b5ee1-6b3ede2ccef64864a04d2ea12070dc16'),\n",
       " Match(model_a='c4ai-command-r-08-2024', model_b='deepseek-v3-chat', score=<MatchScore.B: 0>, id='e2b5b2213a114d3a919a319d4fb74a3a-0e71982bd4ca483aa5014bee78f4abf8'),\n",
       " Match(model_a='phi-4', model_b='llama-3.1-nemotron-70b-instruct', score=<MatchScore.Draw: 1>, id='8f344b71821c40e3ac9b5adaacb575c4-29b652c4ddc24ce68cd55c715de30319'),\n",
       " Match(model_a='gemma-3-27b', model_b='gpt-4.1-mini', score=<MatchScore.A: 2>, id='b95257a1069740cbb218477cfebcff8f-922cc128360d4320a5c123307629b7d8'),\n",
       " Match(model_a='llama-3.3-70b', model_b='gemini-2.0-flash-001', score=<MatchScore.B: 0>, id='fd389bf66d5e464d9fd94b710f9583ce-ea93039b24374d8d9015b2e635922cb7'),\n",
       " Match(model_a='gemma-3-12b', model_b='mistral-large-2411', score=<MatchScore.Draw: 1>, id='2b92ef91ea674e458e603926aab0f272-54f4d42f82364d6b920d22a417f7d8c0'),\n",
       " Match(model_a='o3-mini', model_b='ministral-8b-instruct-2410', score=<MatchScore.A: 2>, id='e9de3e863b2e4c8bb2dad117abd6ae9a-44c53db24f89407b87b1575a549768a0'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='c4ai-command-r-08-2024', score=<MatchScore.A: 2>, id='ab807615eb24421b8ae147dcaa5ce819-31907fd97fb2463fa01f43f9067c1128'),\n",
       " Match(model_a='qwen2.5-7b-instruct', model_b='mistral-nemo-2407', score=<MatchScore.A: 2>, id='449b4a4f2497432f9dae98aac0faee30-08eba9baf9d14b8f8fbed4f92c8ef4ba'),\n",
       " Match(model_a='lfm-40b', model_b='command-a', score=<MatchScore.A: 2>, id='89685051e744466fb47759c8c539e477-9573779676c14f719aab93cd27cdba8d'),\n",
       " Match(model_a='llama-3.1-70b', model_b='mistral-large-2411', score=<MatchScore.A: 2>, id='472f1b6682d043799968090c92fe3ca5-bdb10e8d3051461f90eadc8fe48458e3'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='mixtral-8x7b-instruct-v0.1', score=<MatchScore.A: 2>, id='08e5fdbecd29456c89dd750420b012d0-e59580bce24144d6b7822e34ea61a9a1'),\n",
       " Match(model_a='phi-4', model_b='llama-3.1-70b', score=<MatchScore.Draw: 1>, id='49311feca7e7428ba290533e27faf9d7-f9f9c6cb89434e7eb34470d1c883e31a'),\n",
       " Match(model_a='mixtral-8x7b-instruct-v0.1', model_b='mistral-nemo-2407', score=<MatchScore.B: 0>, id='635f1908cdb94fb38480e043e224333e-fbf7c2256b60475899b5f5170ed59db5'),\n",
       " Match(model_a='mistral-small-3.1-24b', model_b='deepseek-v3-0324', score=<MatchScore.B: 0>, id='0bd4c710c80d43ecbdbe920b588b9b44-130a1a4be9c746a1aae74dc0c179e063'),\n",
       " Match(model_a='llama-3.1-405b', model_b='gemma-2-9b-it', score=<MatchScore.B: 0>, id='3907b79d06de4639b0adf30e383ee76d-d1d313d26812419fabace81c9f7b9b6f'),\n",
       " Match(model_a='mistral-small-24b-instruct-2501', model_b='claude-3-5-sonnet-v2', score=<MatchScore.Draw: 1>, id='561210ee3e384d92982ac9e95c959903-2b1532d9f7ee4df2af7a51efc0279d3a'),\n",
       " Match(model_a='llama-3.1-nemotron-70b-instruct', model_b='c4ai-command-r-08-2024', score=<MatchScore.Draw: 1>, id='8ef5b89f0d0e4c688127a6b37bfcbd16-805ea5c8f74147c2af22e4ebc3854964'),\n",
       " Match(model_a='qwen2.5-32b-instruct', model_b='gemini-1.5-pro-001', score=<MatchScore.B: 0>, id='4410606ae30d4c68b7bc3041441b8412-310f0cb827ff4928865306cb69791c59'),\n",
       " Match(model_a='gemini-1.5-pro-001', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.A: 2>, id='7f9f82a014d94944b7644b6826065f4b-fa646bbe62cd4f3ab313f5ea00e69b67'),\n",
       " Match(model_a='gpt-4.1-mini', model_b='claude-3-7-sonnet', score=<MatchScore.B: 0>, id='67757741916c4fe19cb5534c29e51a7c-2227f246400f4f29b64ab6482d957d15'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='gemini-1.5-pro-001', score=<MatchScore.B: 0>, id='91e893cee0434531a4c0c5fe0f0480b3-d40e9be46afa4d5d8992820e77bae430'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='gemini-2.0-flash-exp', score=<MatchScore.Draw: 1>, id='b1e231d063324b0ba606294b3ca67d73-456a8dce77a64f6c970a5f8a62d9b006'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='gemini-2.0-flash-exp', score=<MatchScore.B: 0>, id='77b5fb3b10b0405da52258171a80c40e-b72f8d0af71a468a958a158d477f1cd2'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='ministral-8b-instruct-2410', score=<MatchScore.B: 0>, id='363887c3eed440dea99cf39a35f7490c-1a8bc6f99ff8412398fbd4611dbb4d20'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='gpt-4.1-mini', score=<MatchScore.Draw: 1>, id='2d392aa442b144a983eb73dfb998bca1-86c7aec7dc0842ff887ce42d2222f2b9'),\n",
       " Match(model_a='llama-3.1-8b', model_b='chocolatine-2-14b-instruct-v2.0.3-q8', score=<MatchScore.Draw: 1>, id='535629ef9936482f9a9f3152aa484245-9a99300109034f34a008a19465ad225a'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='c4ai-command-r-08-2024', score=<MatchScore.B: 0>, id='1602d835d1e14134b3a8632836860532-f41b8d09ae8f444a91b35fb598df02cc'),\n",
       " Match(model_a='qwq-32b', model_b='deepseek-r1', score=<MatchScore.Draw: 1>, id='1c2c0e28650a4c53a463e18259792308-2d6724e80c024ee896ca5d21965d5a00'),\n",
       " Match(model_a='llama-3.1-nemotron-70b-instruct', model_b='chocolatine-2-14b-instruct-v2.0.3-q8', score=<MatchScore.A: 2>, id='da682e7c4b1d4b42abfe4d6ef277804d-529ee6d71c99454b83fffb5eb567e145'),\n",
       " Match(model_a='chocolatine-2-14b-instruct-v2.0.3-q8', model_b='llama-3.1-nemotron-70b-instruct', score=<MatchScore.B: 0>, id='07c3ae91460b4078983ba4a35df6f2ba-d4380831cd834225bc1dbbc07bc9e0a8'),\n",
       " Match(model_a='gemma-3-27b', model_b='deepseek-v3-chat', score=<MatchScore.Draw: 1>, id='9187bc7c613c47d1bb9d6e4771a89e12-c0e77ae013dc4658b8ddf2accae68714'),\n",
       " Match(model_a='c4ai-command-r-08-2024', model_b='mistral-nemo-2407', score=<MatchScore.A: 2>, id='dc3f7cb92fb74b5e928cd25d6df5c80f-4ca9d388647c4b84a412e1a381cc468b'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='mistral-large-2411', score=<MatchScore.A: 2>, id='fa2c07566d5648afac18213f6f64a9c0-90c940ad475141d3bdfb3f65d560bf6c'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='aya-expanse-8b', score=<MatchScore.B: 0>, id='abd775a9bad243f9b8ccef8f9d8cdc37-1c65af9aa8984d8ca8a1ca36a022ecab'),\n",
       " Match(model_a='mistral-small-24b-instruct-2501', model_b='mistral-small-3.1-24b', score=<MatchScore.B: 0>, id='50fb788381ee4f78a4d86d0fb635da5c-484ee7091a694ff3862b0a4cab0ee666'),\n",
       " Match(model_a='llama-3.1-405b', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.B: 0>, id='484ad92e312842cfa04ebac763239aa5-a2a7a0d0d0034b608df3c0c97f639e58'),\n",
       " Match(model_a='gemini-2.0-flash-exp', model_b='gpt-4o-2024-08-06', score=<MatchScore.Draw: 1>, id='ed6c398d1c994f02a127bae811091b0c-97b9514272504876b80647626ba4808a'),\n",
       " Match(model_a='mistral-small-3.1-24b', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.Draw: 1>, id='5c36a3c982984d28a273fa5fdffc0c9e-42a5fc5ce5f24adb9d6d93210db03f5f'),\n",
       " Match(model_a='phi-3.5-mini-instruct', model_b='gemini-1.5-pro-001', score=<MatchScore.B: 0>, id='d15feb9993214790921b50125b688e50-843c60b142234606926a7078325f3984'),\n",
       " Match(model_a='llama-3.1-405b', model_b='mistral-nemo-2407', score=<MatchScore.A: 2>, id='386e473c17ac46bf926d96c5e54614df-ec5a2cbf828a4469a9efd1f074987793'),\n",
       " Match(model_a='gemma-3-12b', model_b='claude-3-5-sonnet-v2', score=<MatchScore.B: 0>, id='6bcfa4b24f77402ab8282a2fa255f169-6d9b2c8a5e2941b6804c19dce5b26509'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='claude-3-5-sonnet-v2', score=<MatchScore.A: 2>, id='158a76d2928a4d348c8b0fec71de39c2-2a4219c13d39486980a4cc26aa98dbef'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='mistral-large-2411', score=<MatchScore.Draw: 1>, id='1d4fc493ff24464fa469e997bd3e6b7b-7448a43be43b44988da815c9f3ef0be2'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='ministral-8b-instruct-2410', score=<MatchScore.A: 2>, id='1695e7d05311486c88286762613d18fe-d021dff1d67947099b492e7332ac528c'),\n",
       " Match(model_a='mixtral-8x7b-instruct-v0.1', model_b='gemini-1.5-pro-001', score=<MatchScore.B: 0>, id='596bd2f417d8489db0279f9e918f3c0a-bacc78bba5bb4dffbb3fe80562154e66'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='lfm-40b', score=<MatchScore.A: 2>, id='104400e8f3e84db4bf5733dffc0e4075-ab772873167042319031e7bcfd82153f'),\n",
       " Match(model_a='lfm-40b', model_b='mistral-large-2411', score=<MatchScore.Draw: 1>, id='1a4ca4b25394401da295eea33aa7e030-4c02395322b74911bef4081235e8e122'),\n",
       " Match(model_a='deepseek-v3-0324', model_b='gemma-3-12b', score=<MatchScore.Draw: 1>, id='a1f60ce6d32343b4989b3e42b09d673b-bd8c18052f56406b9a028a84bba65676'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.Draw: 1>, id='36174a02440b4d33a1c0d75caff94b8a-1e9078cd59a843db86e747d141b9a82b'),\n",
       " Match(model_a='llama-3.1-nemotron-70b-instruct', model_b='llama-4-scout', score=<MatchScore.A: 2>, id='54bf5f5c73c54543bd688173c6365f76-11a473c94ffa426287c5ac3582de6948'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='phi-4', score=<MatchScore.Draw: 1>, id='f45aed5c18534326a410fd577b7f6360-035bccb143c6478ba1cd82a9f2f79897'),\n",
       " Match(model_a='llama-3.1-nemotron-70b-instruct', model_b='mistral-small-3.1-24b', score=<MatchScore.Draw: 1>, id='3275b1b6411c4c759578625b882dac6d-592a0e2c7c184428b14947660df7aee9'),\n",
       " Match(model_a='llama-4-scout', model_b='llama-3.1-405b', score=<MatchScore.B: 0>, id='309c64a4d4dd43c98a02c39f78735d38-e9473976de83429780fac7ba653a764b'),\n",
       " Match(model_a='command-a', model_b='phi-4', score=<MatchScore.B: 0>, id='a030f1a898f14648b2223f63370f9639-002132fa92354c6b9cf9e8f8d0388417'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='llama-3.3-70b', score=<MatchScore.Draw: 1>, id='e34986a7bda247e084dab575404f4b22-ce8ad8ee26124c3784001a6c6edd01de'),\n",
       " Match(model_a='llama-3.1-nemotron-70b-instruct', model_b='claude-3-5-sonnet-v2', score=<MatchScore.Draw: 1>, id='cacd4353a0574963bc4796a8533ac51e-c62dbbf2623e4a2ebd7c62cf10383ece'),\n",
       " Match(model_a='llama-3.1-70b', model_b='ministral-8b-instruct-2410', score=<MatchScore.B: 0>, id='277c81e453a748a5b949d333f86c0587-9c4c0750f4a746dfa3e8ec33b2c0a978'),\n",
       " Match(model_a='llama-3.1-nemotron-70b-instruct', model_b='ministral-8b-instruct-2410', score=<MatchScore.B: 0>, id='71226d0b36f146b2abb28b8b44695e17-28e6b8db366e4b95ba1c5bb15d49bdf4'),\n",
       " Match(model_a='llama-3.1-405b', model_b='mistral-nemo-2407', score=<MatchScore.B: 0>, id='7adf996d861d49f1aedf9f82cccbb4fd-4644272675b64294b387b7bdfae43b4a'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='gemini-1.5-pro-002', score=<MatchScore.B: 0>, id='8edc5d51d9264ea09f5ee2f187484a11-543793bb79d9400cbf20f72cb2d8f2a6'),\n",
       " Match(model_a='gemini-2.0-flash-exp', model_b='gemini-1.5-pro-002', score=<MatchScore.A: 2>, id='b411d41d837644e5a2fa016a4c3d649e-9c03cf1537d743e8a9dad153db4c3c8f'),\n",
       " Match(model_a='gemma-3-27b', model_b='llama-3.1-405b', score=<MatchScore.A: 2>, id='d197afbd547b4ecb90b2af282a8b74a0-e0462f8bc4874efa97ebf4faf6657404'),\n",
       " Match(model_a='phi-3.5-mini-instruct', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.A: 2>, id='eedd0617633649b983637013d9de4a83-f71814e0a22e42bb8ac1d222e721040a'),\n",
       " Match(model_a='gpt-4.1-mini', model_b='claude-3-7-sonnet', score=<MatchScore.Draw: 1>, id='bd2435f2d2174432b5f88c71250d8a73-d8ce901a8fb049e1812d27fdf134b8c5'),\n",
       " Match(model_a='llama-3.1-405b', model_b='gpt-4o-2024-08-06', score=<MatchScore.Draw: 1>, id='3c488de13020403d848ea0d5df1243a7-3a34aee5e20a48c1836ea92f02a82a69'),\n",
       " Match(model_a='qwen2.5-7b-instruct', model_b='mixtral-8x7b-instruct-v0.1', score=<MatchScore.B: 0>, id='fab632d4ca4f4a60877e67dd1621c480-7a11146244fb471bb69144010c91950a'),\n",
       " Match(model_a='lfm-40b', model_b='claude-3-5-sonnet-v2', score=<MatchScore.B: 0>, id='4f35b930ffdf4f0e8bad410ffeec9c15-032a6ba1f8b0436dbecff6ccf06f820d'),\n",
       " Match(model_a='gemma-3-12b', model_b='phi-4', score=<MatchScore.A: 2>, id='562d505041c647b3b43ea39ae2eb5a0f-63aeaf4f182945228b75014357087cb6'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='mistral-nemo-2407', score=<MatchScore.A: 2>, id='054452967a23422195f0705cf633dbe5-a8912f7eea734ff8a2f8ab50ebed8349'),\n",
       " Match(model_a='llama-3.1-8b', model_b='claude-3-5-sonnet-v2', score=<MatchScore.B: 0>, id='40c5d8a505be45d6b860d905716ef325-08c0330ce29144858e3e0461da79c52b'),\n",
       " Match(model_a='gpt-4.1-mini', model_b='deepseek-v3-0324', score=<MatchScore.Draw: 1>, id='d59ebc1179174fd18137197ad95d9230-b56ed2c554cb4fd086370e84f21646e6'),\n",
       " Match(model_a='mixtral-8x7b-instruct-v0.1', model_b='llama-3.1-70b', score=<MatchScore.A: 2>, id='8c952ee40adf4d19a9abbf227d129437-c4bd9db4214a4a2681248327109c8dc8'),\n",
       " Match(model_a='mixtral-8x7b-instruct-v0.1', model_b='qwen2.5-7b-instruct', score=<MatchScore.B: 0>, id='4ac6996d31c846ba867504c4eb78035b-8c4d2669fe334c70bd2c7180911b4434'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='llama-3.1-8b', score=<MatchScore.B: 0>, id='95f128a3e22341b0a1b0648e071c6006-1260ade18f05483aa254bf40296f5901'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='gpt-4o-2024-08-06', score=<MatchScore.A: 2>, id='6f6d220dc4564cdd99645001c66adfbc-4c788e8c45484a22af95466e4185f641'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='deepseek-v3-chat', score=<MatchScore.B: 0>, id='3d3ae3c4e89e4eecaf2cefc508efe1d7-72e68fc50a7a429c8dbae7f4e0d6827b'),\n",
       " Match(model_a='phi-3.5-mini-instruct', model_b='qwen2.5-7b-instruct', score=<MatchScore.B: 0>, id='1b4ca39e4a004f319371f3df6e1d3f0d-d400bb1e9d2a4652a31eebae19698238'),\n",
       " Match(model_a='qwq-32b', model_b='gemma-2-9b-it', score=<MatchScore.B: 0>, id='77e4aac297e445528a54ef60e476f468-f776230a33104f9eaa707fb7d051da06'),\n",
       " Match(model_a='lfm-40b', model_b='gemma-3-27b', score=<MatchScore.A: 2>, id='2602a98edaa9487598659c1adb56cae1-3c0e609a292041cd96f220df17837274'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='phi-4', score=<MatchScore.A: 2>, id='2ba46e11c9144f1fb51840c2b57a062f-18a81cd137bd4595a8c23ca78c555777'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='gpt-4.1-mini', score=<MatchScore.B: 0>, id='6323cfc2ccf54c86b23ba613fc9c17aa-776a0a9309d2424a927bea8c20e80c0d'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='mixtral-8x7b-instruct-v0.1', score=<MatchScore.Draw: 1>, id='3994ca3e8cc2438493e8116cf236fbef-718978dc6b5045ec94fd49de93c0a1b8'),\n",
       " Match(model_a='mistral-large-2411', model_b='mistral-nemo-2407', score=<MatchScore.Draw: 1>, id='c6c6d52d893a45caa2eaa36fe61b148a-c8b1af8d75db4b22b553c3b8623e3027'),\n",
       " Match(model_a='gemma-2-27b-it-q8', model_b='phi-3.5-mini-instruct', score=<MatchScore.A: 2>, id='eb87d74c9ae848ee88dfc03ef15defae-2c8394b5cd3746318a5a57f7c7852b05'),\n",
       " Match(model_a='gemini-2.0-flash-001', model_b='gemma-3-12b', score=<MatchScore.B: 0>, id='c19f4cbdffd94059ba3f9eac8f36f482-44d03478028d450c82dfecbf8b740a97'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='llama-3.1-405b', score=<MatchScore.Draw: 1>, id='6a8ee1fc1c374eada2477a2ba2d0ce55-1b566f0299ba41629e45ccbf4a019265'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='llama-3.1-70b', score=<MatchScore.B: 0>, id='0122ddab51bc4382b71c7704ec9234e3-ef30662cbb9347d3bdbe749f8a55b83b'),\n",
       " Match(model_a='gemini-1.5-pro-001', model_b='phi-3.5-mini-instruct', score=<MatchScore.A: 2>, id='b44147a7709e4550bf251b20dde16fa8-085241a6ade741c497192b9722f9e9b7'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='gemini-2.0-flash-001', score=<MatchScore.B: 0>, id='46338dd411f9442da369816fbf8011f2-91998d345ea4400badb958586b9e9235'),\n",
       " Match(model_a='phi-3.5-mini-instruct', model_b='llama-3.1-70b', score=<MatchScore.A: 2>, id='17a7bc0119394320a323c5e2f9c88739-73cb8d62dc624320850315343d06f17a'),\n",
       " Match(model_a='llama-3.1-405b', model_b='deepseek-v3-chat', score=<MatchScore.Draw: 1>, id='78a0ee4123e04c94b78d8171f2148d23-beedde81fb2b4aa699769acb1139833a'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='gemma-3-12b', score=<MatchScore.Draw: 1>, id='133e8ba762cd4d27b4be6201d3c12440-a076e6c6828845a9a8ecda6f078ce995'),\n",
       " Match(model_a='llama-3.3-70b', model_b='gemma-2-9b-it', score=<MatchScore.A: 2>, id='a5d3ec2dbd7f47c98b85d69647f380d0-9c581692afeb4c5f9a82105316e8a35f'),\n",
       " Match(model_a='phi-4', model_b='claude-3-5-sonnet-v2', score=<MatchScore.A: 2>, id='79717f58b2c94fa181969cc2751f3f89-f89e35657f824a80b954310d9e3be31b'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.A: 2>, id='4fb3aadd55474a77b82392ca6dfed721-f0b62f852b884d1f8b4a4d22fea8aaf9'),\n",
       " Match(model_a='chocolatine-14b-instruct-dpo-v1.2-q4', model_b='lfm-40b', score=<MatchScore.B: 0>, id='35488c43b8094aeca9e46e819ab9dd81-e109801321d54646a71d93489d6e8a7e'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='command-a', score=<MatchScore.Draw: 1>, id='e32e330f439346a4bd28f21e39ea9208-e15fef38fe6e4544bda875f096f7bf3b'),\n",
       " Match(model_a='c4ai-command-r-08-2024', model_b='gemma-3-27b', score=<MatchScore.B: 0>, id='a248985f6605466398ec56a94a1a293d-2637da10304e4ed4b3d7646a7dc41f52'),\n",
       " Match(model_a='qwen2.5-7b-instruct', model_b='mistral-nemo-2407', score=<MatchScore.A: 2>, id='d45aa2636ec8407f9f1633b047494935-5528c34227df49b9a3115cb37912527a'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='gpt-4o-2024-08-06', score=<MatchScore.A: 2>, id='1c9a2586dea742a39dbb0b623daf7978-7ebe90422f354877975d3ba66bd2e8fc'),\n",
       " Match(model_a='llama-3.1-405b', model_b='chocolatine-14b-instruct-dpo-v1.2-q4', score=<MatchScore.A: 2>, id='90e7802f7db84e4d9983309d5cb461c2-5601fe75d83c449ea8ea671bf66c4f3b'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='gemini-1.5-pro-001', score=<MatchScore.A: 2>, id='ad71d3e9b48f4034bafcf5c9a3141299-0e4b355d06ec47f38eb6a5f111f12a2c'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='gemini-1.5-pro-002', score=<MatchScore.A: 2>, id='81ec3674335d45a7bfc58ad341ca87fd-0bd9e2878c1b40b987038b29f810af4d'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.A: 2>, id='b35cbd5b3fff4e0ea5b53e08789fb7bc-5633f7e3778140a7b0bdf92c6bdc314e'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='aya-expanse-8b', score=<MatchScore.B: 0>, id='a0e48d07a4004e538beadf795287efdc-478f1a7fcd384bb190186be649ea5ba2'),\n",
       " Match(model_a='gemini-1.5-pro-001', model_b='gemma-2-9b-it', score=<MatchScore.A: 2>, id='51e59d493bc744ddaebf6870dda8494d-8c894be6531f4c38b73bdd47bdaf1fc4'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='gpt-4o-2024-08-06', score=<MatchScore.Draw: 1>, id='50753482da0f4854a68e8538afea8605-3be7ea4547b5497d96c4fc4e84b6eac2'),\n",
       " Match(model_a='llama-3.1-8b', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.A: 2>, id='83c0afe62776495582426a641c5b3e1c-d0d72a2f155847c4b4f1c9dd950a001a'),\n",
       " Match(model_a='llama-3.3-70b', model_b='llama-3.3-70b', score=<MatchScore.A: 2>, id='2065963d97d449159e828ab16e701139-936c4cd70c1a4b92b58f0fbb6e8e77ec'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.A: 2>, id='e20dc41971a54dbf8580683242af97bc-9e1c5d719c2a40c88615d9087a32c179'),\n",
       " Match(model_a='phi-4', model_b='qwq-32b', score=<MatchScore.A: 2>, id='caedadca32ff4b6e94ad2fbe49a6e4ca-31133e7594e04ea69500c135a8491a4b'),\n",
       " Match(model_a='mistral-small-24b-instruct-2501', model_b='mistral-large-2411', score=<MatchScore.A: 2>, id='6640dd461ff44a8b8da33a01a8b05bfd-9d33dc7c194f445fb664203d07bbf83c'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='gemini-1.5-pro-001', score=<MatchScore.B: 0>, id='acd997bb7b8947a18d9c4f179d46e733-780b5c0c08544a9198a53565dafdb7c8'),\n",
       " Match(model_a='deepseek-r1', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.Draw: 1>, id='52e7cd56e0e7487b812d531f1f952fa5-bf40ff0d8f744207be59dd466252d8e7'),\n",
       " Match(model_a='llama-3.1-70b', model_b='lfm-40b', score=<MatchScore.A: 2>, id='47c648729019446badb13cc1fb11f4ab-8ff27be8b3ef4dcaba1834cc8455482a'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='claude-3-5-sonnet-v2', score=<MatchScore.B: 0>, id='79bfe081cff04056a66ab49d56dc6cb4-7e4a2a8a327749e88e34621f843a2206'),\n",
       " Match(model_a='mistral-small-24b-instruct-2501', model_b='aya-expanse-8b', score=<MatchScore.A: 2>, id='caaf4c1a2c8f4d5a9cd22ae754a4e774-38bd417d8b654b8f88bcd4e0a015e9c6'),\n",
       " Match(model_a='phi-4', model_b='llama-3.1-nemotron-70b-instruct', score=<MatchScore.B: 0>, id='90eb95770f2a4782a507290a2c9a0e1f-c7ef3f1809414896887f615ca5220d02'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='gemini-1.5-pro-002', score=<MatchScore.B: 0>, id='451bbb13cf124df6b553f15f25f2db96-ee78e48e9db8419c91412d26d9865c00'),\n",
       " Match(model_a='qwen2.5-7b-instruct', model_b='ministral-8b-instruct-2410', score=<MatchScore.Draw: 1>, id='6553eac595ab47939ea72bfdb185831e-6f1b07903f824938a4d450fda12caebb'),\n",
       " Match(model_a='phi-4', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.Draw: 1>, id='2c4ae680d8e54dfca21f1be54f96c22a-714e134ce66045cfbc3909684f944d19'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='mistral-small-3.1-24b', score=<MatchScore.B: 0>, id='91f18c71344445c6a9f7fcb3bfd679c4-0a7e2492cfeb454e957732b3ac6b8a93'),\n",
       " Match(model_a='llama-3.1-405b', model_b='mistral-saba', score=<MatchScore.B: 0>, id='35fa5a3597804c2b9e2bb9f54da962ae-5304ef46f6384865a1d7dc97db55fb22'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='gpt-4o-2024-08-06', score=<MatchScore.Draw: 1>, id='9e263461d4d34ee7b6094f02625d79bc-a46cdc98f21749e8901cc906db087a16'),\n",
       " Match(model_a='mistral-small-3.1-24b', model_b='deepseek-r1', score=<MatchScore.A: 2>, id='1110b43396744072877d0eda850d31be-4eef1b6f28e64026942b54652bb63db0'),\n",
       " Match(model_a='c4ai-command-r-08-2024', model_b='llama-3.3-70b', score=<MatchScore.B: 0>, id='3f5c19ebbd5647c89c625dcc841d995c-4cde0a1b2c694b3aa09251d180760d4e'),\n",
       " Match(model_a='mistral-large-2411', model_b='aya-expanse-8b', score=<MatchScore.B: 0>, id='d0b5ce40075d4b51aa62f2b43c060715-0077a745d5294ece8e790bcdb6f68a62'),\n",
       " Match(model_a='lfm-40b', model_b='claude-3-5-sonnet-v2', score=<MatchScore.B: 0>, id='1ea6ca598a734b189eeb07a56920b27c-7ddcd1d50ba74180995a697f40195c87'),\n",
       " Match(model_a='llama-3.1-405b', model_b='llama-3.1-nemotron-70b-instruct', score=<MatchScore.Draw: 1>, id='8f8fb2370d0c46658b5d5c2937862c81-d68c2378c9d84e9e90dcfd672dd21b9c'),\n",
       " Match(model_a='deepseek-v3-0324', model_b='o4-mini', score=<MatchScore.A: 2>, id='9c46224e1157493ab50fa63650d04c1e-dfde1594601244dba3c46992b43a15f4'),\n",
       " Match(model_a='phi-4', model_b='mistral-small-3.1-24b', score=<MatchScore.Draw: 1>, id='7ddda102f4da49bba418fa4db9cadb16-b61ebfce79234f23ae7df2e3836807e4'),\n",
       " Match(model_a='llama-3.1-405b', model_b='deepseek-v3-0324', score=<MatchScore.B: 0>, id='4912d38734234bd39fc8eb924b3d0f3f-e8c5c034757f48359f4ad0be9d717c65'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='claude-3-5-sonnet-v2', score=<MatchScore.Draw: 1>, id='dff09ffea2ad4f729ab0efa8aea3c8ec-fa179be753814cbab78e129b1526bc5c'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='mistral-large-2411', score=<MatchScore.Draw: 1>, id='0d8ca7b74a02413fa84226e199ddd2ff-97f7a91fad2e468ab98e45477d3a381d'),\n",
       " Match(model_a='lfm-40b', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.A: 2>, id='9314eb9ac1a943aeaf9776cff90ae31f-e10d2788490147688a26ec532e06534d'),\n",
       " Match(model_a='grok-3-mini-beta', model_b='deepseek-r1', score=<MatchScore.B: 0>, id='32562afea6fc430ebc05b5dabfbb662e-bece068ec73147f2930d70bd57dc9b1b'),\n",
       " Match(model_a='llama-4-scout', model_b='gemini-2.0-flash-001', score=<MatchScore.B: 0>, id='45f020fb12ea47dbb948b1700c04a676-f869a13654844cf8b77456fa2a42ac26'),\n",
       " Match(model_a='llama-3.1-405b', model_b='mixtral-8x7b-instruct-v0.1', score=<MatchScore.A: 2>, id='d1afed74688d44f8b90267c2764584a4-b4e0c4103a4249c391250e01fe0dba8d'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.Draw: 1>, id='82688913ad4d423d917e31f3c7c79103-6c5d0075702447808144a60477ea039a'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='gemma-2-9b-it', score=<MatchScore.A: 2>, id='3075ffab62b1413cb32cbcd59d9eef4a-dfc79782e83e42888f2fa84f9674d8b3'),\n",
       " Match(model_a='c4ai-command-r-08-2024', model_b='llama-3.1-nemotron-70b-instruct', score=<MatchScore.B: 0>, id='1f0493efd8bb4ff79683b5bfbb36e266-d154b93659684dbf9a23fb0408e2186e'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='deepseek-v3-chat', score=<MatchScore.B: 0>, id='5b383961364f4d13a61865a5f3dcd51a-02a6009a8b75462da799170365a4758d'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='claude-3-5-sonnet-v2', score=<MatchScore.A: 2>, id='dcd5a13511c54fc5a8bb81231f557b6f-6300846e86594ab589dbb8039512dd8b'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='command-a', score=<MatchScore.B: 0>, id='002a4715623644538fca5f101ab8a69e-34fe81edbaed4384bd04d1040d0702cb'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='llama-3.3-70b', score=<MatchScore.A: 2>, id='aa9188011f784150bfb871837a86b459-38068a83686545778e36f4fea7120b22'),\n",
       " Match(model_a='gemma-3-4b', model_b='gpt-4.1-nano', score=<MatchScore.Draw: 1>, id='7c79b56695104cedbd19ad4fa10a2509-95002c63420249efa5b29a1f05df3959'),\n",
       " Match(model_a='mistral-small-24b-instruct-2501', model_b='lfm-40b', score=<MatchScore.A: 2>, id='6b3e210f7c09410bb502a55da5838051-5186019490d14e88837f503ccdb9bb78'),\n",
       " Match(model_a='mistral-saba', model_b='phi-4', score=<MatchScore.Draw: 1>, id='b8416dea3bb34040bfc46f32fa24888a-2a81c38d1e284e8bb0c800317ab41da4'),\n",
       " Match(model_a='mixtral-8x7b-instruct-v0.1', model_b='mistral-nemo-2407', score=<MatchScore.B: 0>, id='055a52c6e23a4f27a7164f8038972626-c1e5afb042934c20afaef39e20404345'),\n",
       " Match(model_a='llama-3.1-nemotron-70b-instruct', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.B: 0>, id='4873171f6dd8416ba8ff53240ada1254-894a1106492b484b95c74679eccfc715'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='phi-4', score=<MatchScore.A: 2>, id='ee565eaccf4f45838a428867be3c2b31-659256fc58c0456a865d47aef5f146cf'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='mistral-nemo-2407', score=<MatchScore.A: 2>, id='19340935e16648599ae037acc2f907a8-dc52a4ea8a874b8186400ab34d0e2371'),\n",
       " Match(model_a='phi-3.5-mini-instruct', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.A: 2>, id='bc148b0e481f4991a077a2a17c74a2a8-5ac0e225c64947ecb869ed14cc6350b1'),\n",
       " Match(model_a='deepseek-r1', model_b='qwq-32b', score=<MatchScore.A: 2>, id='af0b7e486e7941af991f074cc8729526-9354e0cfeec04be0996280cea493eabd'),\n",
       " Match(model_a='gpt-4.1-mini', model_b='gemini-2.0-flash-001', score=<MatchScore.A: 2>, id='c0b03e0b7b974718b6d455fa73a2e8c1-2aaf761fd0144e238ece8c9c2a87f723'),\n",
       " Match(model_a='gemini-2.0-flash-001', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.Draw: 1>, id='dbae63105a5143f8ac7ee7acfdb25868-1691d226c55a4f5692b0b7dcc3680e04'),\n",
       " Match(model_a='deepseek-r1', model_b='claude-3-7-sonnet', score=<MatchScore.Draw: 1>, id='02e632aa4d6141b0b178f731639fabe2-a09691f622754e56a86e54695a7f7f9e'),\n",
       " Match(model_a='phi-4', model_b='mistral-large-2411', score=<MatchScore.Draw: 1>, id='da566c53accf4eddb34e918f0b2f9cac-e1e54ba03e8d4093b2676fd79071cba8'),\n",
       " Match(model_a='lfm-40b', model_b='o3-mini', score=<MatchScore.Draw: 1>, id='65590b9e8d8543cb8fc40baa8501f807-c3ddcd0c3f164fc7a7cfc362b778f91c'),\n",
       " Match(model_a='llama-3.1-405b', model_b='llama-3.1-405b', score=<MatchScore.A: 2>, id='da0976ce9bc2428cac6f1c0e3652eca6-9db118c1c0cb46db990e12c5fd39b77e'),\n",
       " Match(model_a='gemma-3-4b', model_b='deepseek-r1-distill-llama-70b', score=<MatchScore.B: 0>, id='e4c4fc95cb994b5fa6fe39a32428ec1f-af4860b79e1f4369a12b9695f3bae188'),\n",
       " Match(model_a='gemma-3-27b', model_b='gpt-4.1-nano', score=<MatchScore.A: 2>, id='4a751b33b7ed4203a3b364eeeb75bece-11700cf21b144bd48e3432daa7ff9b1a'),\n",
       " Match(model_a='gemini-2.0-flash-001', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.A: 2>, id='7cd9683c809b450db843553a0aba14cf-6c02ed487e6c423c92816fe7e83d157f'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='llama-3.1-405b', score=<MatchScore.Draw: 1>, id='807bc5859f5449049290968c6a782eb6-b12228e7af3a459798cf621ab935d195'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='llama-3.1-70b', score=<MatchScore.B: 0>, id='df018cd2aae149e5b163d9fcf8f575aa-69edce4c277d418b9ae17b437f6479ab'),\n",
       " Match(model_a='deepseek-r1', model_b='gpt-4.1-mini', score=<MatchScore.A: 2>, id='4b99198b159b43248e2e03b0ac4b0ba8-39597e0aad49407c976ba487063069f7'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='c4ai-command-r-08-2024', score=<MatchScore.B: 0>, id='da2fd6a0bd5849b6999a1f1c01921809-3e2cd883d4144c4c892abb8019e99f2e'),\n",
       " Match(model_a='llama-3.1-70b', model_b='chocolatine-2-14b-instruct-v2.0.3-q8', score=<MatchScore.Draw: 1>, id='c33d781818d54d4596b95c88ed8cc333-8592c90af51d44fda5df85de4b7059aa'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='gemini-2.0-flash-001', score=<MatchScore.B: 0>, id='450b77412b194273a25624b598f5d9c1-2ecde00aca3745dba8a35b37d11f031e'),\n",
       " Match(model_a='mistral-large-2411', model_b='llama-3.1-405b', score=<MatchScore.A: 2>, id='bbf342db7c8c4c7689398046662007d6-57f5050ed2214f2db15316efa3709937'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='llama-3.1-405b', score=<MatchScore.B: 0>, id='5e8de90dc82b40e9b6212dd3673ec4ae-573e479053b64e84904193e79d46e04d'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='gemini-2.0-flash-exp', score=<MatchScore.B: 0>, id='56e9ea325c3a457989ecaf4a995e2729-70c65558dd7f42eebe6b660f80b8ac71'),\n",
       " Match(model_a='gemma-2-27b-it-q8', model_b='qwen2.5-7b-instruct', score=<MatchScore.A: 2>, id='a42db26179a04f4f86c8946f21b3ce2e-fd9968cc3d4849e1b7fdb242bf675a05'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='gemma-2-9b-it', score=<MatchScore.A: 2>, id='4972d88cdd4149a1a2426077d0de0f66-fd5c1e04cc0747bbb72365320b6e4bba'),\n",
       " Match(model_a='llama-3.1-70b', model_b='llama-3.3-70b', score=<MatchScore.A: 2>, id='5ad04ef768894b65b8347d66b915e89e-24dd18ed11ea4341a5c35643afb5485e'),\n",
       " Match(model_a='llama-3.3-70b', model_b='phi-4', score=<MatchScore.A: 2>, id='d875880ae7d349a4859ef562eb716163-921ff66db9344b78a4ccac7693f57d05'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='gemini-2.0-flash-001', score=<MatchScore.B: 0>, id='3884ff6f8f314f4a9cd1dc467f6469f7-d065bceb37574db3bb80cfb3b5fc63f9'),\n",
       " Match(model_a='llama-3.1-70b', model_b='qwq-32b', score=<MatchScore.A: 2>, id='1b815633b5eb46b2adc7a04fadafc958-5509cbf7259b4b4b8ae3f71aaa21e0ce'),\n",
       " Match(model_a='llama-3.1-8b', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.B: 0>, id='c09db21b85984c8795817d47d06b5eae-1c3cbe7168c844fbbafb5e1fe1153565'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='claude-3-5-sonnet-v2', score=<MatchScore.B: 0>, id='82d83b8602394600998dcdd310c0123a-f3799382c8b94653a01506620609bc08'),\n",
       " Match(model_a='qwen2.5-7b-instruct', model_b='phi-3.5-mini-instruct', score=<MatchScore.B: 0>, id='01fec3230454433ea82588ce65faca0f-16a744cb41e34178a03ef364575d2607'),\n",
       " Match(model_a='llama-3.1-70b', model_b='phi-3.5-mini-instruct', score=<MatchScore.A: 2>, id='a948d438edd846d0bd2e909ae712d2c8-d395002aeee449ce93c9a735dab80719'),\n",
       " Match(model_a='gpt-4.1-nano', model_b='deepseek-v3-0324', score=<MatchScore.B: 0>, id='b648ffd3c1c7405e9d80012fb812367c-8f30603f0ffe4f87a201bbbecab00316'),\n",
       " Match(model_a='mistral-small-24b-instruct-2501', model_b='deepseek-v3-chat', score=<MatchScore.Draw: 1>, id='469169f321cd4ee892a422d76572e821-2b00e1600f90474bbe7b2adcd6f1edcd'),\n",
       " Match(model_a='qwen2.5-32b-instruct', model_b='llama-3.1-405b', score=<MatchScore.A: 2>, id='ffb2638447e14f429ba41046170545a3-0f0cc3cc31e643aeb86921d53e9f9092'),\n",
       " Match(model_a='mistral-large-2411', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.A: 2>, id='e6586f626cfa4cd9a94349e0fa4aba69-eb3f399337b743e3a252a2528b3eb445'),\n",
       " Match(model_a='llama-3.1-405b', model_b='llama-3.1-8b', score=<MatchScore.B: 0>, id='2c5ada4e8bd24c438d3e12c8885f6a3f-042821586018407fa05ac90abc60b14a'),\n",
       " Match(model_a='gemini-2.0-flash-001', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.B: 0>, id='d4abd887c88b48eb93c89831af550dff-2fc23bb6eeaa4d62a3bdaa35464fa696'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='c4ai-command-r-08-2024', score=<MatchScore.Draw: 1>, id='2a5ee0aa75ed42138f0af33e1a0e3c49-3a4d402c2e7546c6bdb8a29c5066dedd'),\n",
       " Match(model_a='llama-3.1-70b', model_b='c4ai-command-r-08-2024', score=<MatchScore.Draw: 1>, id='5657fa0c559948608d95c86d790b4fe4-2a6e836847184a8e9c4ffbe0d49684f4'),\n",
       " Match(model_a='phi-3.5-mini-instruct', model_b='llama-3.1-70b', score=<MatchScore.A: 2>, id='68f454f474e44e24b524d7048d0ae67c-2625219d94184414abdd530c056cf5d4'),\n",
       " Match(model_a='chocolatine-2-14b-instruct-v2.0.3-q8', model_b='gemma-2-9b-it', score=<MatchScore.B: 0>, id='e68944df884448ed8dc0702fd7b58511-1c327234596045cab6f4333e2b15f4ad'),\n",
       " Match(model_a='qwen2.5-7b-instruct', model_b='phi-3.5-mini-instruct', score=<MatchScore.Draw: 1>, id='b70caad251074638b1675f3b33624d23-91e5305dc0fb48548ee5b778b22bc305'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.A: 2>, id='f13dcc19354848ad986b1698e76f372c-2229acc458d348a2bc0a67740fc78c4c'),\n",
       " Match(model_a='mistral-large-2411', model_b='lfm-40b', score=<MatchScore.A: 2>, id='342b6566107d4b3889e1a8fc4de1eaec-afbb7137660d4f87817628a4811ec7e7'),\n",
       " Match(model_a='mistral-large-2411', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.A: 2>, id='4ca51a4d2c7547fab8433f9622cf6b08-bc0047eb39484c1a92a79d6c894fdc25'),\n",
       " Match(model_a='grok-3-mini-beta', model_b='deepseek-r1', score=<MatchScore.B: 0>, id='b6e972d08c4b4d06a40c47509b1b8af9-ed59d2a6579c4604bdda05593c05e90a'),\n",
       " Match(model_a='phi-4', model_b='llama-3.1-405b', score=<MatchScore.A: 2>, id='af42d2f08ec240c38532eb21b628aa1b-2781f067d65449439ca5bd49a5c56118'),\n",
       " Match(model_a='mistral-large-2411', model_b='claude-3-5-sonnet-v2', score=<MatchScore.Draw: 1>, id='5f3e6a6ad6954e81934fe24fa4bc27a9-9e98328242224f87b849de82fe6a0c4b'),\n",
       " Match(model_a='c4ai-command-r-08-2024', model_b='lfm-40b', score=<MatchScore.B: 0>, id='13b83a1cb1ac48298733e3306b786e12-65420ed98e124cfea789d35d1a99b4ba'),\n",
       " Match(model_a='lfm-40b', model_b='command-a', score=<MatchScore.B: 0>, id='28ed7fb0ade849599b6e4c449a5a4ffc-1b906522a4dd41a7830d564cf505364f'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='claude-3-5-sonnet-v2', score=<MatchScore.Draw: 1>, id='551b1f8593434c0ca60ef4d47505875e-50dd7268e6194dd8be48fb037613af60'),\n",
       " Match(model_a='mistral-small-3.1-24b', model_b='chocolatine-2-14b-instruct-v2.0.3-q8', score=<MatchScore.B: 0>, id='10f5f36edbd844d391f62d4eed50946c-5427fa55b36e4d4f901a948dacc80256'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='phi-4', score=<MatchScore.A: 2>, id='d90d2900752b4d19bdae9ffb68a56f77-96ea2c8fa7104519bed75c1e3d7ef827'),\n",
       " Match(model_a='gemma-3-27b', model_b='mistral-large-2411', score=<MatchScore.A: 2>, id='051834aa13f3463fa3c37e9d241076aa-b51af19797f1421bb64046e188bb908f'),\n",
       " Match(model_a='gemini-1.5-pro-001', model_b='llama-3.1-70b', score=<MatchScore.B: 0>, id='4d4a7d4ea6d44f1b9988b164b026c083-973dd380c5a0480bac640e45318fb32f'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='llama-3.1-nemotron-70b-instruct', score=<MatchScore.B: 0>, id='252a414443b5428582effb15a6039584-7854981fcf444661a15619a5630f2316'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='gpt-4o-2024-08-06', score=<MatchScore.Draw: 1>, id='320417eb9e2e446fa38ff9880dd822b2-8b26be061fdd4eb5bab006d20fd4686a'),\n",
       " Match(model_a='qwen2.5-7b-instruct', model_b='gemini-1.5-pro-001', score=<MatchScore.A: 2>, id='213685a0e1d84e7d8123ab2bb94672f6-161eb2ae66024344b7458cda54f8cfb0'),\n",
       " Match(model_a='gemma-3-27b', model_b='mistral-small-3.1-24b', score=<MatchScore.A: 2>, id='d83f168b860b445597d570d86ccd6068-7c23324b93894b298b33e8e9964973b7'),\n",
       " Match(model_a='mistral-saba', model_b='gpt-4.1-mini', score=<MatchScore.A: 2>, id='1bbb99f285e54f0396b3d1384aa7c3d7-5c14ccafd2cc4e5886bb5a1a13f7ff3e'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='llama-3.1-405b', score=<MatchScore.A: 2>, id='5a78d9b2025b4ab78bf62b49c57b8331-a68663254fa34c569aafba9bb5706e7e'),\n",
       " Match(model_a='llama-3.1-405b', model_b='gemma-2-9b-it', score=<MatchScore.B: 0>, id='df7839c7712346fba7a1d6d7cc97d3fe-01c9592264024e20b03f9caf7f350f59'),\n",
       " Match(model_a='phi-3.5-mini-instruct', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.Draw: 1>, id='0abeacc8a32042b4884ecc0fda5e23a1-bf71152e1ce948c9b6288911b3026b66'),\n",
       " Match(model_a='lfm-40b', model_b='command-a', score=<MatchScore.Draw: 1>, id='0d189772d6f04c53b786c9d774c65017-a27439dce44f493e878f712be4f9a49e'),\n",
       " Match(model_a='gemini-2.0-flash-001', model_b='gpt-4.1-mini', score=<MatchScore.Draw: 1>, id='08997373ff144418925b15b235c669d5-0dbb6a23b62141c1ad8343af0784fad7'),\n",
       " Match(model_a='mistral-large-2411', model_b='deepseek-v3-chat', score=<MatchScore.Draw: 1>, id='f62cf3c3766447018feb9bd921c64873-ffba2737650a4792b81ec7f6070fce4b'),\n",
       " Match(model_a='gemini-2.0-flash-exp', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.A: 2>, id='669bd9b72ce3475ea6b95a83c7b20cef-0a3abd90b2834bbca4f850793ff19012'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='qwen2.5-32b-instruct', score=<MatchScore.A: 2>, id='8601424235494d0f9a65a8de2ff7ab38-4d515cd5ca3a471e8195b5db0e3969ee'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='gpt-4o-2024-08-06', score=<MatchScore.A: 2>, id='4d6748ea997444bd9cb0a182072f10b8-1f2153b1105f4b8cbbb45979fa925984'),\n",
       " Match(model_a='llama-3.1-70b', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.B: 0>, id='a39b5369a3f94d1183c18c221f361d76-6dc25e7a9f364a19b673c2872004474e'),\n",
       " Match(model_a='mixtral-8x7b-instruct-v0.1', model_b='gemini-1.5-pro-002', score=<MatchScore.Draw: 1>, id='f662d6067d1b42de9e6b4a84bbbc13ad-82785af58f494e0b946b6ed381bad802'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='llama-3.1-70b', score=<MatchScore.B: 0>, id='b26955a03aca4669af5f91f4bd1806ca-21ba11dc50eb4422abcf0caac3fa3dcb'),\n",
       " Match(model_a='gemma-3-27b', model_b='llama-3.1-405b', score=<MatchScore.A: 2>, id='d32b77a578f0470aafb6bc52b0be67c1-0fa765bea10047398513e0175c41ba0b'),\n",
       " Match(model_a='gemini-2.0-flash-exp', model_b='gemini-2.0-flash-exp', score=<MatchScore.A: 2>, id='4a52c6aa2a0c4ba5af05f4ec9e5992df-f9f66e42c9ba48f89df3f4836b6dcf37'),\n",
       " Match(model_a='deepseek-r1', model_b='mistral-large-2411', score=<MatchScore.Draw: 1>, id='87122890357d44ecb105c55a6e161fe3-2bd1f4dabad44de880472b21363934f2'),\n",
       " Match(model_a='phi-3.5-mini-instruct', model_b='mixtral-8x7b-instruct-v0.1', score=<MatchScore.B: 0>, id='3773e7273994455ca3ac7eebbf8c0273-61ea9bfd069d4b218a7497cd8600d24b'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='gpt-4o-2024-08-06', score=<MatchScore.A: 2>, id='86a7a9f622c24b7cab2d6821d5240da1-a179d37ef3054d4f8d5bf97447ec2706'),\n",
       " Match(model_a='gpt-4.1-mini', model_b='deepseek-v3-0324', score=<MatchScore.B: 0>, id='c09416b33f9e4c4fb4a35cdc9118424a-0f723d98f3e34fe098f9b4ede76a3bdd'),\n",
       " Match(model_a='gemini-2.0-flash-exp', model_b='llama-3.1-405b', score=<MatchScore.A: 2>, id='a85752861f3f4510ad7277086d512d69-6d4aab800b0b4715bda0bf958981f295'),\n",
       " Match(model_a='llama-3.1-8b', model_b='gemini-1.5-pro-002', score=<MatchScore.A: 2>, id='ef93e6d4a159498ab67fff1037d90d14-c350b6ea29c944d9b36a3857e6ec5496'),\n",
       " Match(model_a='gemma-3-27b', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.A: 2>, id='08182167fa8d41d49147e96fd885c225-da4ec03a375246d0be29faac7fb241b2'),\n",
       " Match(model_a='qwq-32b', model_b='chocolatine-2-14b-instruct-v2.0.3-q8', score=<MatchScore.A: 2>, id='3281c539bd5f4e21a413076c64ce514e-ecfa9dc14e7a40febf3e67fe24e12399'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='mistral-large-2411', score=<MatchScore.Draw: 1>, id='e8ed6aae543b4887807460c333474a18-9a750411ecf04d28b2fbe2a4554787a4'),\n",
       " Match(model_a='lfm-40b', model_b='gemma-2-9b-it', score=<MatchScore.B: 0>, id='7a118b76928f4b99a61345ac6482420e-1da1e8c085b54de8b6d87e0012bd832c'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='llama-3.3-70b', score=<MatchScore.B: 0>, id='f8d2e73acc0c42c391ea0f34b6d1c82e-5f865f9168d3422baf6c6d98ce51a390'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.A: 2>, id='c55be23a6d9840feb569ca473d781772-0726d51e9ba340348b91be5b211f56e9'),\n",
       " Match(model_a='c4ai-command-r-08-2024', model_b='gpt-4o-2024-08-06', score=<MatchScore.A: 2>, id='79b94ea7f7654c39890f1584ebb599dd-9c118331707242ae88d7663cf4ace3b1'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='llama-3.1-8b', score=<MatchScore.Draw: 1>, id='febce2d3319645c7b036f99d8b8c5626-875bcf3d9c2949e7aa300be41c13e901'),\n",
       " Match(model_a='mistral-large-2411', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.A: 2>, id='a0d4558595494982bb8239ebcb908318-f39d3ec243514660b17ad2740773da65'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='llama-3.1-405b', score=<MatchScore.A: 2>, id='476fdf77a36a4b63bf04ac2f25c09d97-cc1bd9eb38094e5481333887c8437b95'),\n",
       " Match(model_a='llama-3.1-70b', model_b='gemini-1.5-pro-001', score=<MatchScore.B: 0>, id='462735d54f5f48268831f8e4fb78d8af-1eaa56455b334f8581a799f023020d08'),\n",
       " Match(model_a='qwq-32b', model_b='grok-3-mini-beta', score=<MatchScore.A: 2>, id='855c369612084280acca99fce4493459-c9547558b5d44956bb4ba0c433e02f98'),\n",
       " Match(model_a='lfm-40b', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.B: 0>, id='1c5649ed811e4790b49dbfb4eb1e6254-4eae3624978b427ab702be35ff80cfbe'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='gemini-1.5-pro-001', score=<MatchScore.B: 0>, id='87e5d28e4d544e4083cb821fd6153a7b-001867210319495795dafd8628d8bf1a'),\n",
       " Match(model_a='qwen2.5-7b-instruct', model_b='gemma-2-9b-it', score=<MatchScore.B: 0>, id='a2fff4c8cf5c4e228d22447527bceef8-9b4990df58ff4c1abd657f4f6f545301'),\n",
       " Match(model_a='command-a', model_b='mistral-large-2411', score=<MatchScore.A: 2>, id='f2af937565ed407fa87156e89b0e568b-6629534a9b0746b3843ff68a513b64e5'),\n",
       " Match(model_a='mistral-small-24b-instruct-2501', model_b='ministral-8b-instruct-2410', score=<MatchScore.B: 0>, id='8079cd324a50455d810a3e5365f2b47a-c7492331b493433b8fb50ea1e61e54f0'),\n",
       " Match(model_a='mixtral-8x7b-instruct-v0.1', model_b='phi-3.5-mini-instruct', score=<MatchScore.A: 2>, id='c9891c4586e94f0fac3cee75d100733d-32a5416766314d2c862c259b6b97c69a'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.B: 0>, id='48687f6bfb6e4349bec24fad4261513c-e6e35bb630834bfe959dcb4c6ccee933'),\n",
       " Match(model_a='mistral-large-2411', model_b='gpt-4o-2024-08-06', score=<MatchScore.A: 2>, id='24e70b1a2117444082ce42493e65fe01-e5c651a7e3ab4c75b0640214eb5b1c96'),\n",
       " Match(model_a='c4ai-command-r-08-2024', model_b='mistral-saba', score=<MatchScore.Draw: 1>, id='58ca30a8060a42c79e806cd574efad18-e6c1c194749d4edd804ab1c8faade5f0'),\n",
       " Match(model_a='gemma-3-27b', model_b='gemma-2-9b-it', score=<MatchScore.B: 0>, id='cfca8e7204e84ec1823b9c383e2a5253-7620d12d1509416880456f4f40d05245'),\n",
       " Match(model_a='mistral-small-24b-instruct-2501', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.A: 2>, id='82247c2cfc504150ad7383bf129988dd-b58447b8538044b3b89f102ac02ed670'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='qwen2.5-7b-instruct', score=<MatchScore.A: 2>, id='a05d15a19a5b42b5a10f32cf53f150d1-224de00c92bf4647ac94d5137e3c5a0e'),\n",
       " Match(model_a='phi-4', model_b='deepseek-v3-0324', score=<MatchScore.B: 0>, id='ce5c2d9e874e48eab636335a0605f1df-4054f791ea1d4f509db72066ebc9c537'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.B: 0>, id='4e074b77ca334a0b81a290975904fad2-6a811be165be406ca9fbcd6853a453b1'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='phi-3.5-mini-instruct', score=<MatchScore.A: 2>, id='78e457de647b4e47a4a54908ba84c007-1568dbe2115746fba233a2c106bcfca3'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.Draw: 1>, id='730f6ec180ba49cb963ee167ded15854-5a87edb1b14d4f5eab1ecc1914fd51a8'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='lfm-40b', score=<MatchScore.B: 0>, id='7bedc7e35e08431f8e1ddc66e373bf7e-701cc48b5c6d4ae994c074b36e2d1db0'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='llama-3.1-70b', score=<MatchScore.B: 0>, id='0c249000cd124ff0bb5d317afb0c069b-a0d8f7ca07ad445bb9c739e6c44e5c63'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.B: 0>, id='139b5adc7bca4ae3b3c1bdb3411fdb76-8ccc8bea8b6948bd98f93f9de8000eb8'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='gpt-4o-2024-08-06', score=<MatchScore.A: 2>, id='1bea689e8cd14adea7f7e0d1919b459c-4a41c00b22134df49632dc872307204b'),\n",
       " Match(model_a='llama-3.1-8b', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.A: 2>, id='e18466113a8e41d1a6c2a9406985256f-48da87ccf1ec49cea1ab74ee6486d775'),\n",
       " Match(model_a='llama-3.1-70b', model_b='mixtral-8x7b-instruct-v0.1', score=<MatchScore.A: 2>, id='27dacd279ee14115b341695911b42128-73c8e2d38aee48a9b33126a3ffbef82c'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.B: 0>, id='e868c864763c4badbcc46eddb8c625b6-7b69431bcc7b4630a68eed1231de3b33'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='deepseek-r1-distill-llama-70b', score=<MatchScore.A: 2>, id='27d23ba511eb4afb834384533fcfd912-ae17f157b8ab4868bee0ee78765d5c1c'),\n",
       " Match(model_a='c4ai-command-r-08-2024', model_b='llama-3.1-405b', score=<MatchScore.B: 0>, id='78ceec6d441e4cc1aeca15da4c1689b1-c359c0796dd5409fa2534e5b64e28c05'),\n",
       " Match(model_a='gpt-4.1-mini', model_b='llama-3.1-8b', score=<MatchScore.A: 2>, id='cd46e76be68643df9481832446084712-fd7a810fcaf049c4bf5fa482583f52a1'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='ministral-8b-instruct-2410', score=<MatchScore.B: 0>, id='0bc59d1bf96e49dbb7ea4d740daa8f83-53e301234c2b46b38c03d6d3a029376d'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='o3-mini', score=<MatchScore.A: 2>, id='4aa4d1db46fe43daabdb8168c38d5c08-8b80aea18bf1432f80b9c9774eb00e1f'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='gemma-3-12b', score=<MatchScore.A: 2>, id='18d44afe991d4ded8839df75572b644a-201c446bdea649ba814221d37aeecbf2'),\n",
       " Match(model_a='mistral-small-3.1-24b', model_b='command-a', score=<MatchScore.Draw: 1>, id='77fff59b0a5f48a99142a316b6434afd-16fb31e98b794d5092c2a3c86b0985a4'),\n",
       " Match(model_a='llama-3.1-70b', model_b='llama-3.3-70b', score=<MatchScore.Draw: 1>, id='44d21bdcfdc34499ba72244c0e55d123-a1846d474a7e49549a972183297e0495'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='llama-3.3-70b', score=<MatchScore.B: 0>, id='fd5bb1f4b4c44475a4f2f9b0734b2cdb-a3ca81f11eef4adf9b3d58f5c924e675'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='claude-3-5-sonnet-v2', score=<MatchScore.Draw: 1>, id='4f97a6a1133a45da8767d42b0908a7c7-eeb0df29bbde449ea81edb8a9a8ed68c'),\n",
       " Match(model_a='claude-3-7-sonnet', model_b='llama-4-scout', score=<MatchScore.A: 2>, id='cb4c18e1642b4885a671b30bdceee0c2-6c418618a99f42979f3ceaae76e7d27b'),\n",
       " Match(model_a='llama-3.1-nemotron-70b-instruct', model_b='llama-3.1-8b', score=<MatchScore.Draw: 1>, id='e9b1f132f49040678aee7c2575aefbaa-a229658645e54429a8d6ed86201aa863'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='gemma-2-9b-it', score=<MatchScore.A: 2>, id='c8bd966f06b64b32a2c305c7c814e659-ac7485159ae54d0c89d2f3049ea778f8'),\n",
       " Match(model_a='llama-3.1-405b', model_b='gemini-1.5-pro-002', score=<MatchScore.Draw: 1>, id='928a50211a2244a883d64f031c5e0f1f-59a54293c1fe475e96d37fc37d9b97b4'),\n",
       " Match(model_a='c4ai-command-r-08-2024', model_b='mistral-nemo-2407', score=<MatchScore.B: 0>, id='b9fa695f51074245b4e6353b099a74b7-0a12217b79244215b55983e9da0dae3d'),\n",
       " Match(model_a='llama-3.1-70b', model_b='ministral-8b-instruct-2410', score=<MatchScore.A: 2>, id='56d4daeb8d7f4104afd29acfec133350-5cc5e09ebc314960a73af2695d778354'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='gpt-4o-2024-08-06', score=<MatchScore.B: 0>, id='c0c62f8e32df4ce38ee58a37a4f1d086-40234c9dda674caab785046e5ad748b9'),\n",
       " Match(model_a='c4ai-command-r-08-2024', model_b='llama-3.1-405b', score=<MatchScore.A: 2>, id='d84ef01886f94b5a9a2ccca2d8c49d4c-128c36b00230442b8b1d2fa18df5d966'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='gemma-2-9b-it', score=<MatchScore.B: 0>, id='d3ce11bd9bb142c2b1edb1ab378d19f4-7586fd00af854e5ebb52a12d095457ea'),\n",
       " Match(model_a='llama-3.1-nemotron-70b-instruct', model_b='chocolatine-2-14b-instruct-v2.0.3-q8', score=<MatchScore.A: 2>, id='93b6609fedb442b99f1038db72b8934c-9d4135feb7a3433f8c2c6ac90d251cfd'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='qwq-32b', score=<MatchScore.A: 2>, id='222c03ae712c47ccac2cd1bbcd109b3a-8c7c8deca63f44aeb22bbe4e9ee8fdaa'),\n",
       " Match(model_a='aya-expanse-8b', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.A: 2>, id='50c70ea5cd06483bb1b9b52b16cbc1b0-3a4c053e7c514c2ab70642c8b656dc11'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='llama-3.3-70b', score=<MatchScore.B: 0>, id='d9b717904cc447d7b92af9889d9f8762-51b014a7979e450a8ee7e10797ce995d'),\n",
       " Match(model_a='deepseek-r1-distill-llama-70b', model_b='gemma-3-4b', score=<MatchScore.B: 0>, id='7bfd69923ff848099ac136f18ae93faf-3b0e7f4e07ab42c4bf7eb08aedd6b0d3'),\n",
       " Match(model_a='phi-3.5-mini-instruct', model_b='gemma-2-27b-it-q8', score=<MatchScore.B: 0>, id='0dbc6605d19242a6b3b40cdd4f57895d-ec0bec308039401d86d64cdb1eae5f0e'),\n",
       " Match(model_a='llama-3.1-405b', model_b='ministral-8b-instruct-2410', score=<MatchScore.A: 2>, id='05024f33a7384cf2b2951f207a76deb9-49d09cefb3424add8ac7d2b18f544b77'),\n",
       " Match(model_a='deepseek-v3-0324', model_b='c4ai-command-r-08-2024', score=<MatchScore.A: 2>, id='14594a19a4c34876b59cb50ea8da4820-839c4b4d8296471e8c0bc6dbea134e47'),\n",
       " Match(model_a='llama-3.3-70b', model_b='mistral-small-3.1-24b', score=<MatchScore.A: 2>, id='f0086af9d39f43b699ee72d6a14c5a67-b5560f4a42b84ecdb87c33f55673c14e'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='mistral-large-2411', score=<MatchScore.Draw: 1>, id='f4f0ce0e867440c88d47afb19c98ff08-42b6e85a5dfb4d63a085f55a9c0993f1'),\n",
       " Match(model_a='mistral-small-24b-instruct-2501', model_b='command-a', score=<MatchScore.Draw: 1>, id='efc9a5d312124317bd1248cbe14c2af8-3eb346a19a8848c881209d2ada0220a0'),\n",
       " Match(model_a='llama-3.1-405b', model_b='gemini-2.0-flash-001', score=<MatchScore.B: 0>, id='47dab2e849bc470da258c866e1a04a5c-dafdc2846723457fa7514d542fd4eff0'),\n",
       " Match(model_a='llama-3.1-8b', model_b='mistral-large-2411', score=<MatchScore.Draw: 1>, id='5ec38c7c59c84f06be59c3fd03569360-c72234b9957b451cac12c24233559316'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='gemini-1.5-pro-001', score=<MatchScore.B: 0>, id='bb6b931c044e46c98cbe53f59df64495-bf111fe7bf854a738c12be5dabfab423'),\n",
       " Match(model_a='o3-mini', model_b='gemma-2-9b-it', score=<MatchScore.A: 2>, id='0b8a89ce563743dd858006e0d88cb308-2c343c6dc3de4baf874d02f61ce4b6cb'),\n",
       " Match(model_a='mistral-small-24b-instruct-2501', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.A: 2>, id='de019adb28934d3bbb245b4aa68165a2-b0283bb3e6c649eb837bedde60887093'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.B: 0>, id='c850761886284a51980553cb52929a37-9f5cf7191ff848d3bb0eb93cd3b518a9'),\n",
       " Match(model_a='llama-3.1-8b', model_b='llama-3.1-70b', score=<MatchScore.A: 2>, id='51c5f967637c4814bc6790d9c41a45e3-b170acba29634eebb149d1ba10dadd14'),\n",
       " Match(model_a='phi-3.5-mini-instruct', model_b='ministral-8b-instruct-2410', score=<MatchScore.B: 0>, id='6ff1dc63af5e4a7f8c2791d444dce414-db4085ce0c8c4f22b8bf6206218a0b7e'),\n",
       " Match(model_a='lfm-40b', model_b='claude-3-5-sonnet-v2', score=<MatchScore.B: 0>, id='f320a6d89c20411a870fa348eca03d4c-06b7e789a3a1487c98c7a34411390ed1'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.B: 0>, id='b9eecff919134fba9d59e3c173941608-c1f53408aaf4464dab2b285d67a68199'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='deepseek-r1-distill-llama-70b', score=<MatchScore.A: 2>, id='b7876d0f32f24bd6b4da12003211715f-1c983edc86844ba98b3b594a81ace675'),\n",
       " Match(model_a='llama-3.1-70b', model_b='ministral-8b-instruct-2410', score=<MatchScore.B: 0>, id='1cc773cc52214595aff74b4729ef20cd-f6c174d45b704816bf6a3bcab2b320af'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='command-a', score=<MatchScore.B: 0>, id='9755159ed72f4d2785e58cad50961003-f9efda89b2564a4f94f67889d72eddca'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='gemma-3-27b', score=<MatchScore.A: 2>, id='3558e9077dd44406993d8d61c37f1023-aa76a6dbfbea487586692a6f5cf73e5f'),\n",
       " Match(model_a='deepseek-r1-distill-llama-70b', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.Draw: 1>, id='f03d6b970af74f729b1adb4e8a60266b-522ddd30cc714eb2b499a03f2637fe49'),\n",
       " Match(model_a='mixtral-8x7b-instruct-v0.1', model_b='llama-3.1-405b', score=<MatchScore.Draw: 1>, id='85c61f95e1dd4158827b246317ef1f64-d39ed55bc2654277ba3af1ce6878ab37'),\n",
       " Match(model_a='llama-3.1-405b', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.Draw: 1>, id='94a70e67d0d64a41861e308802612128-5147a9c3270c416eafef32a8334ad866'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='gpt-4o-2024-08-06', score=<MatchScore.Draw: 1>, id='c033523ac2b14a27b0d6b2e65cd2d514-e1d57499f10241858f9d1620d08928c5'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.Draw: 1>, id='7ba8cd4c063c40d2b807b849c9038157-0cf86b128e14449ba3ffaf05205c1dd0'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='llama-3.1-70b', score=<MatchScore.A: 2>, id='2684c716b60544c19fd6347af1cf4067-f5b8bb624c0245c3b05b84155a690eb7'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.B: 0>, id='4d61a4a1955046e3882388d447a35ef6-ea1827ec790b46b7b470e01876cbc59f'),\n",
       " Match(model_a='mistral-small-24b-instruct-2501', model_b='gemini-1.5-pro-002', score=<MatchScore.A: 2>, id='6c205d79fedf4af8bbf5625433b8c640-fcb73aa3b64b47a0b5907681ec3db61e'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='llama-3.1-405b', score=<MatchScore.A: 2>, id='62063a7f8b8b495d98e151f5a87f6bfd-0a42ba0894534befb0ee8f8412f9b5ab'),\n",
       " Match(model_a='o3-mini', model_b='llama-3.1-nemotron-70b-instruct', score=<MatchScore.B: 0>, id='4ca2821e9cf4411b9e7a1e8a83c801f5-4e8b577e7df14d5b806a5ce948dbdac5'),\n",
       " Match(model_a='qwen2.5-7b-instruct', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.B: 0>, id='3f5cd6fd2dd34af683621a7c3aab9886-51f1d6440b404f059c3735c45c785280'),\n",
       " Match(model_a='mistral-small-24b-instruct-2501', model_b='chocolatine-2-14b-instruct-v2.0.3-q8', score=<MatchScore.Draw: 1>, id='9601f393ca0144e6955b38fd9e722fc4-94900578a4974856bc49b48423abd962'),\n",
       " Match(model_a='llama-3.1-8b', model_b='llama-3.1-nemotron-70b-instruct', score=<MatchScore.B: 0>, id='df6f88fa6098422599a1a96c5a168ba4-9670f0dfb8a34e8a84f4d6d407c02f09'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='deepseek-r1-distill-llama-70b', score=<MatchScore.B: 0>, id='9ada118bde0e4e598d31c7ad1298b8d8-04e789f5d13344d48bfc69510f221fa5'),\n",
       " Match(model_a='gpt-4.1-mini', model_b='mistral-small-3.1-24b', score=<MatchScore.Draw: 1>, id='42102bef2402418bb95199dc414cc269-756bb3a77aac464bb3d5bfefa46ac56e'),\n",
       " Match(model_a='llama-3.1-nemotron-70b-instruct', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.B: 0>, id='91a34646a62c4ea0bead65ada5c12b80-76b5252235bf43c7881bd63549ffe7cc'),\n",
       " Match(model_a='qwq-32b', model_b='o4-mini', score=<MatchScore.Draw: 1>, id='693f3111e7bb47ca9c49d3f2fe3476f4-860b9da9e42e429e8ac16015229ba5b2'),\n",
       " Match(model_a='gpt-4.1-mini', model_b='mistral-small-3.1-24b', score=<MatchScore.Draw: 1>, id='a36a3740196f49ceab8c8b14b00cc21f-1865656dd62a44fa91fa274045002358'),\n",
       " Match(model_a='mistral-small-3.1-24b', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.A: 2>, id='130a63d6351547f18ce88da3359ff5b4-539a5a19c4b14378b1964fb90ff262e5'),\n",
       " Match(model_a='llama-3.3-70b', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.A: 2>, id='f1d2b7e7b4014199a4abc2bb4c28bd37-624971b5d8d047ec9b6a65b366887ccd'),\n",
       " Match(model_a='lfm-40b', model_b='llama-3.1-405b', score=<MatchScore.B: 0>, id='62ffe93e2d274a6b82be4c2a982e655f-4a4d134e76794cc1883513d5ca040481'),\n",
       " Match(model_a='deepseek-r1-distill-llama-70b', model_b='gemma-2-9b-it', score=<MatchScore.A: 2>, id='880eec2947a5424fb2f7f319806d4e66-538ae1eed48642ecb00be4f3b69114f1'),\n",
       " Match(model_a='gemini-2.0-flash-001', model_b='gemma-3-27b', score=<MatchScore.A: 2>, id='5ae227e388d44baba0d2a292c5bffd8c-5703e9c410e741668ec9d7d63705cdec'),\n",
       " Match(model_a='c4ai-command-r-08-2024', model_b='gemini-2.0-flash-001', score=<MatchScore.Draw: 1>, id='1be9be16157745c5b91ad82bbd54ba1e-5c271dc5b4794feab9f4f7ab28bb1a57'),\n",
       " Match(model_a='mistral-small-24b-instruct-2501', model_b='llama-3.1-nemotron-70b-instruct', score=<MatchScore.Draw: 1>, id='0b145f52013b48988775c9da057708dc-243c13c299ba4908a314baa74ba0ce02'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='ministral-8b-instruct-2410', score=<MatchScore.A: 2>, id='3e18dfad023d47f09b5b023c52d0f46b-9affed45d6e4477ab8161b9d3e038d28'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.Draw: 1>, id='d2b943a501ed43d9a2088adb3cb2a84f-a1d1f6a5d1b24c8f805b7c6df314dce8'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='llama-3.3-70b', score=<MatchScore.A: 2>, id='6e5cbd693e864a9594bb600bb6b15ceb-e83c74577f7e42c2b55987f82f9d4da0'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='ministral-8b-instruct-2410', score=<MatchScore.A: 2>, id='9bbb329038ca47ce8ad6f891123684d1-1bfbaf2f8cbc410880aedf7b36c4a4bd'),\n",
       " Match(model_a='grok-3-mini-beta', model_b='deepseek-r1', score=<MatchScore.Draw: 1>, id='2f6635f7d93248ca8fe81549bafda197-04069c3f4d734b97957a63574548daab'),\n",
       " Match(model_a='o3-mini', model_b='llama-3.3-70b', score=<MatchScore.A: 2>, id='50bdd2ca07994d199de587075851febd-78fd765547ec410faf5fe1814b87a50a'),\n",
       " Match(model_a='llama-3.3-70b', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.A: 2>, id='46c10f9ff1ac4e449c1c3b94fd829e7e-5ee4487068d64ddfa6bf80b3b00f0fd8'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='llama-3.1-nemotron-70b-instruct', score=<MatchScore.Draw: 1>, id='1319a7abbecf4b2184fd52df52bb4996-49b74fd27a0d44d2805331011a7fec04'),\n",
       " Match(model_a='mistral-large-2411', model_b='claude-3-5-sonnet-v2', score=<MatchScore.Draw: 1>, id='1172f1ce525445ec8a17aa8afecaae71-766aa503835e4911b376ecc16eefa919'),\n",
       " Match(model_a='chocolatine-14b-instruct-dpo-v1.2-q4', model_b='gemma-2-27b-it-q8', score=<MatchScore.B: 0>, id='b042a718005d4c0b8b28bb13d9b9903b-380260451c094ebcbbe08ce938349c9c'),\n",
       " Match(model_a='gemini-1.5-pro-001', model_b='chocolatine-14b-instruct-dpo-v1.2-q4', score=<MatchScore.A: 2>, id='bf1168e53a184d6f9c1486f5a0ce0b99-b9aeac0f9b3c487b92e50172d4247305'),\n",
       " Match(model_a='mistral-large-2411', model_b='gemma-3-12b', score=<MatchScore.Draw: 1>, id='e807bad5e3f74bc7a961af91574b1711-366e444a8ebe46959c1f818c7c6c7109'),\n",
       " Match(model_a='gemma-3-12b', model_b='gemma-3-4b', score=<MatchScore.A: 2>, id='c1fea8b81b3546dba0fc916927a8b136-709055bd6c6c4f91a6e2419bce3b5194'),\n",
       " Match(model_a='gemini-1.5-pro-001', model_b='mistral-nemo-2407', score=<MatchScore.A: 2>, id='461a8d373ed545f2aef467f402641ec2-76ba8d093d574ee5b23cb10b6222f641'),\n",
       " Match(model_a='llama-3.1-8b', model_b='gemma-2-9b-it', score=<MatchScore.Draw: 1>, id='c5ffbc878dc94179ad315e128aeeeea6-5b21b9b994f14371a5ff2a6a7e730b66'),\n",
       " Match(model_a='gemma-3-4b', model_b='llama-3.3-70b', score=<MatchScore.A: 2>, id='417c174d2a88456091f1c87f8e7e4968-dacfbd65b45640e28ddd78bb09df2527'),\n",
       " Match(model_a='mistral-small-3.1-24b', model_b='o4-mini', score=<MatchScore.B: 0>, id='7ad1707c5bb44529816fc5d317a16448-32ee8a62a4ff4ccf8ed1825432add75d'),\n",
       " Match(model_a='deepseek-r1-distill-llama-70b', model_b='lfm-40b', score=<MatchScore.B: 0>, id='9858bd48336c46538ea4112792e46f10-dc6002aad92d40e095d55a12b4229f91'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='lfm-40b', score=<MatchScore.A: 2>, id='13164925714b4c429f1949c9e0e4e43d-a57f46c1a08d407286d38e58ce5f91a3'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='mistral-nemo-2407', score=<MatchScore.B: 0>, id='02c658f82d3545549e5401d7d874d633-9a079c6bcfc549a097fba2def1a02894'),\n",
       " Match(model_a='mistral-saba', model_b='claude-3-7-sonnet', score=<MatchScore.Draw: 1>, id='79a036cea31e4569a7f67d7a64da78f6-cc1e9003bcb3478c8376b81a5bf7df71'),\n",
       " Match(model_a='llama-3.1-8b', model_b='llama-3.1-nemotron-70b-instruct', score=<MatchScore.A: 2>, id='1e048b915e914aab94f2aefa97f35030-d0aa81cbee9341c0bfea781bf97faca3'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.A: 2>, id='398842d92d094ffcb277f323a8ca4a95-af2c1736cf4340bbbcf7a91d8f248064'),\n",
       " Match(model_a='llama-3.1-8b', model_b='gemma-3-27b', score=<MatchScore.B: 0>, id='58d7519fe3b44d33948530c7a19d7d41-b668f25afed8426d94d648c43a8ed3cd'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='mistral-large-2411', score=<MatchScore.A: 2>, id='78fc922cce104d8e97aaa3230939b0c8-5fad2080544e48f0bb53d42ae00bcff4'),\n",
       " Match(model_a='lfm-40b', model_b='mistral-nemo-2407', score=<MatchScore.A: 2>, id='5e382ed8024f4ba4a00db8b7ec4772cb-f605b859e6264840b08dc2975d4b958d'),\n",
       " Match(model_a='llama-3.1-8b', model_b='phi-3.5-mini-instruct', score=<MatchScore.A: 2>, id='13e4fcdd11f24687a7db422af15a93d2-b83daf73bb034b45a2bf1b096bbd5c89'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='mixtral-8x7b-instruct-v0.1', score=<MatchScore.A: 2>, id='17e9f01ec4b94f2fa3e343815c70a4d7-3e781ea3eb8641e19738edfcd305feaf'),\n",
       " Match(model_a='gemini-1.5-pro-001', model_b='mixtral-8x7b-instruct-v0.1', score=<MatchScore.B: 0>, id='5cca4118ddc84a6bb5de037cd97e2bcb-c8f706f23c7747fd9b67c49b868b51a5'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='mistral-nemo-2407', score=<MatchScore.A: 2>, id='31bdd54d42f044fe83ec59214a896797-ffc2b50fabe349fc89749d9c176dc00f'),\n",
       " Match(model_a='gemma-3-27b', model_b='deepseek-v3-0324', score=<MatchScore.Draw: 1>, id='5b4edf5f79174fbc9f2bada348aa757d-f647cbe0e4fa40378c0b49dc60aeeacd'),\n",
       " Match(model_a='lfm-40b', model_b='phi-3.5-mini-instruct', score=<MatchScore.B: 0>, id='00088e7ba3e34f7fb38a88e287b039e5-5200764a61324a4aac117dddcfe8831d'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='ministral-8b-instruct-2410', score=<MatchScore.A: 2>, id='624852218aaa419da3c73dd9865fd0a9-4e665d6862494487b2c16daffc7bd1ca'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='gemma-3-12b', score=<MatchScore.B: 0>, id='62f7c312e71646369cc862d1f945c50f-cff59ed0bd6244bbad545ad27e2b0572'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='gemini-2.0-flash-001', score=<MatchScore.Draw: 1>, id='6bd92233fec3495fa3eb290c39191cd6-b7903cb17f9147f09ce580cfbc8b642b'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='llama-3.1-nemotron-70b-instruct', score=<MatchScore.B: 0>, id='f0036a61517844c78239f6611e502da5-b4c9f8d2f1034a6b90448ae6a0167b43'),\n",
       " Match(model_a='gemma-3-12b', model_b='llama-3.3-70b', score=<MatchScore.A: 2>, id='83a826c4c7f647bf93a93d1c91518f13-17787007dc4a45048bfea27623a6ff1f'),\n",
       " Match(model_a='phi-4', model_b='llama-3.1-8b', score=<MatchScore.B: 0>, id='503a7366dbdc44f480fda51d2a6aee00-f1395c8ce22d4512a71d82698149ef66'),\n",
       " Match(model_a='llama-3.1-70b', model_b='llama-3.1-8b', score=<MatchScore.B: 0>, id='4f0aa059b10a49adba646d21cceec9cf-5a1c44d4e1d3405b936b7dbc604fe756'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='gemini-2.0-flash-001', score=<MatchScore.B: 0>, id='74a4fc8e7f3a439eb6bded03fe2132a4-ecc3b5e4fafb4da784abd001fad5bed6'),\n",
       " Match(model_a='qwen2.5-7b-instruct', model_b='phi-3.5-mini-instruct', score=<MatchScore.B: 0>, id='120f6362f09d408aaf22818defb576ba-c6e6347e05c84c99bc8fb257c73d0cd1'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='phi-4', score=<MatchScore.B: 0>, id='026aae811bad465abfc63d21733a1877-8b77bc8416314d0c9457b200b52b9a70'),\n",
       " Match(model_a='llama-3.1-70b', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.Draw: 1>, id='8a4c80224f2745ed89426a5c84ff7009-15c98b7bb16c42fe8c4aa72f034335a0'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.A: 2>, id='5f9cf5a91ec44d319480e29380d9ab8c-2a58341dea4a4eaf899e1ae083e9229c'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='phi-3.5-mini-instruct', score=<MatchScore.Draw: 1>, id='5d9a0c5fee7d426091724753e268f1b1-24ce2621a8274efeaba5f6c99298d7f4'),\n",
       " Match(model_a='gpt-4.1-mini', model_b='gemma-3-12b', score=<MatchScore.B: 0>, id='f0b55e225a8e44089faa57a8f1cdf7d9-a05ac192eec5475d9d5fc1b82129cd1c'),\n",
       " Match(model_a='gpt-4.1-mini', model_b='claude-3-7-sonnet', score=<MatchScore.A: 2>, id='21ee9e16be78435184c19e48bc3c7c05-4147ffbeef7a4ab1a6e146eea588f345'),\n",
       " Match(model_a='gemma-3-12b', model_b='llama-3.3-70b', score=<MatchScore.A: 2>, id='f981720596d742c886ce6cd812beb108-0c022e2536dc4f359ec571a0f2b1fe7d'),\n",
       " Match(model_a='gemini-1.5-pro-001', model_b='ministral-8b-instruct-2410', score=<MatchScore.B: 0>, id='03e2c75467024a02be628c87571b8657-ff902c4bd2ff4d2fa7c8adc38727d5c1'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='phi-4', score=<MatchScore.A: 2>, id='61e47016bde6420bb1c9a162e923963e-cff58408fe564dbebc3d2c04baf4e807'),\n",
       " Match(model_a='mistral-saba', model_b='mistral-large-2411', score=<MatchScore.A: 2>, id='74229830fcc84bacb48d9fc7cff6bc49-91b3849788424c4097df7f9c8342007b'),\n",
       " Match(model_a='gpt-4.1-mini', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.A: 2>, id='dbe7e13211e04a5584079062626e617e-bffd011d62cb4e6abf9c66644fc4fc3c'),\n",
       " Match(model_a='llama-3.1-405b', model_b='mistral-nemo-2407', score=<MatchScore.B: 0>, id='b9a0e2237f694ff19e65b5d268e0947d-da7a75daf53a43c49761525b065f3902'),\n",
       " Match(model_a='gemini-2.0-flash-exp', model_b='llama-3.1-70b', score=<MatchScore.Draw: 1>, id='f3590d24ae7e441d9bf6efc56933d49f-da18b29065864adca81977f329e8c69f'),\n",
       " Match(model_a='mistral-large-2411', model_b='o4-mini', score=<MatchScore.A: 2>, id='42f26908c4e1490eaecf5e21f5071ec5-6afd17ad0cb04ce98fefdee699129033'),\n",
       " Match(model_a='lfm-40b', model_b='mistral-nemo-2407', score=<MatchScore.Draw: 1>, id='9e9c62ad4d9844a5bda8ce5ece119863-087a101ee4c943349cd6a94a074c1dee'),\n",
       " Match(model_a='mixtral-8x7b-instruct-v0.1', model_b='llama-3.1-8b', score=<MatchScore.B: 0>, id='39f8e9f37a4143a68f1028a99521a356-cb5ed65011fe427091896e310e56d47b'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='chocolatine-2-14b-instruct-v2.0.3-q8', score=<MatchScore.Draw: 1>, id='afbfc182bf3546d8b8b8077b479f36b5-f056c4228f2d40c2a97ca473e8fa936b'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.A: 2>, id='e86d8ad4cbfa44528e5029fcd06ceb56-bb16a707ffa945f48c03bfad32a61cac'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='gemma-2-9b-it', score=<MatchScore.A: 2>, id='aac0f62dd17b4eeda0ad0179c9357694-6d81b66387014b219eee9fc56813b051'),\n",
       " Match(model_a='gemma-3-4b', model_b='gemini-2.0-flash-001', score=<MatchScore.Draw: 1>, id='227bc543801b4ba0bc19fec7aa657ce5-49f9cb7ecafe4bf787d8eb7049db935e'),\n",
       " Match(model_a='llama-3.1-70b', model_b='llama-3.1-405b', score=<MatchScore.A: 2>, id='5989ff9f41d34239a38d7c499c1037ef-06fef795f3da4d2c914eb3311c19bf8a'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.Draw: 1>, id='74a4d2645e2b4bfda0193c4492224ea4-dfce6a37f39b4e1a85bed45c98504fb1'),\n",
       " Match(model_a='llama-3.3-70b', model_b='gpt-4o-2024-08-06', score=<MatchScore.B: 0>, id='6d311306a80446fd91ba0d5e6c9043c9-910207b077474ff2b184723d1f5e1869'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='llama-3.1-70b', score=<MatchScore.B: 0>, id='f67499f5a39042caa06a73dbc0ceda4a-ea33f3d2b937452cb82d157876905e34'),\n",
       " Match(model_a='deepseek-v3-0324', model_b='ministral-8b-instruct-2410', score=<MatchScore.Draw: 1>, id='0c19ee5b878d4e72867ab65bfdd61732-235ab1b5508640fca0a2cc031cf3c1e6'),\n",
       " Match(model_a='llama-3.1-405b', model_b='gemini-2.0-flash-exp', score=<MatchScore.Draw: 1>, id='9af4e2cce6f34348b20d0007a8b15f13-90e11bc2315f4371905c0cb2b347aeff'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='phi-4', score=<MatchScore.Draw: 1>, id='2ad0f605c5ec4104b4913ff5a1205d5c-2c22066c79654af8ae3189d4f9866dc5'),\n",
       " Match(model_a='lfm-40b', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.Draw: 1>, id='62724c3aea3440ce8dbb71bf9ecc4913-e8f8bc38be364f0295ba60e1ecfb849d'),\n",
       " Match(model_a='llama-3.1-70b', model_b='phi-3.5-mini-instruct', score=<MatchScore.B: 0>, id='943d90518f6e428282149c76b8e31982-e938fc00e8ce49e6806f9fc593586019'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='llama-3.1-70b', score=<MatchScore.A: 2>, id='0c6e1d45276b44b1ab82135551712cc5-4d26a8629fab4d748d0c67d64932cfd4'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='gemini-2.0-flash-exp', score=<MatchScore.B: 0>, id='2f5ee079d2dd4321bd88513ba8518ace-265e5da7027b47a29ab098712a38428d'),\n",
       " Match(model_a='llama-3.1-70b', model_b='claude-3-5-sonnet-v2', score=<MatchScore.B: 0>, id='a810637e176b415e8638aca3c235c052-d6681608c1d64e5495a8c317c352fdfd'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='phi-3.5-mini-instruct', score=<MatchScore.A: 2>, id='1c89b9db33814b76a6325501352b5068-30f600cdac814bfa994f96cbca49e95b'),\n",
       " Match(model_a='aya-expanse-8b', model_b='gemini-1.5-pro-002', score=<MatchScore.B: 0>, id='2e22fb3a518b42998910bb4297163e7c-944681fbc27d4f34990007bc307378f7'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='llama-3.1-405b', score=<MatchScore.B: 0>, id='87f4f28f703647d49f56d54a9167afe4-ea22587990494bc08fe90e36186e7f70'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='mixtral-8x7b-instruct-v0.1', score=<MatchScore.A: 2>, id='9ad30998da4d4540a42a68e36216d04e-151e9e856e7742b89e83359553e9f7b2'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='gemini-2.0-flash-exp', score=<MatchScore.A: 2>, id='ee0b2928719a4d0f9c7dbfb438637566-2a5ee118164743eda4e9e15194c9b51b'),\n",
       " Match(model_a='phi-3.5-mini-instruct', model_b='mixtral-8x7b-instruct-v0.1', score=<MatchScore.B: 0>, id='1ed708853bce4bddb725b612b98e0292-957ed5ee173241318aac368e47594bd7'),\n",
       " Match(model_a='phi-3.5-mini-instruct', model_b='llama-3.1-405b', score=<MatchScore.B: 0>, id='2927a7f00ef34b56a9f1a2078624853f-ba6bf317dbe24ec794d44655987ca12a'),\n",
       " Match(model_a='mixtral-8x7b-instruct-v0.1', model_b='gemini-1.5-pro-001', score=<MatchScore.B: 0>, id='80c7d67783fa4d0292222006ad570978-b24844a760fa43aa87bf50061a09c342'),\n",
       " Match(model_a='llama-3.1-8b', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.B: 0>, id='e46bf959678f49aba5183bc31a4837fa-bde87b721bf94fa6833968368ef299a4'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.B: 0>, id='323e9e05035a4b20aebd44865ccc1546-2e643dab206f42b6b8aeab5ae5ea1f69'),\n",
       " Match(model_a='gpt-4.1-mini', model_b='deepseek-v3-0324', score=<MatchScore.A: 2>, id='0a4088e14d394761859b7f0ff86387b4-4c15b09fbf9c4bfaa3203b17226ca5e0'),\n",
       " Match(model_a='chocolatine-14b-instruct-dpo-v1.2-q4', model_b='gemma-2-27b-it-q8', score=<MatchScore.B: 0>, id='a08c3b47172c4cb79a5d370eafc93096-aa123854bfc54bdf9874830b408963f3'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='aya-expanse-8b', score=<MatchScore.A: 2>, id='28da7b5a34a04665b31b5d6678ad07d0-9432a11ff3704309b48c9d9064629473'),\n",
       " Match(model_a='lfm-40b', model_b='o3-mini', score=<MatchScore.B: 0>, id='a9d0f3ebb5934ed7a5d77091cf5cfe42-9dab14b11bcb40b398a217b80d6acaac'),\n",
       " Match(model_a='phi-3.5-mini-instruct', model_b='qwen2.5-7b-instruct', score=<MatchScore.B: 0>, id='f6ca15c262f941ef93f2f8c527383932-e4a066e534284d9a9b0d4dd6ef8accc0'),\n",
       " Match(model_a='llama-3.1-405b', model_b='llama-3.1-70b', score=<MatchScore.A: 2>, id='c70ba415cf4b44a388a0be18a57b1d8b-45ddcb4ecf7443df83957a2436426de0'),\n",
       " Match(model_a='llama-3.1-8b', model_b='gemini-1.5-pro-001', score=<MatchScore.B: 0>, id='57bc600f8f814ba8b025ed09b5f9e2bb-0867653236134ccf999824ee49cb766b'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='llama-3.3-70b', score=<MatchScore.B: 0>, id='28a18d9f67c240c99e0dfb892c2f2ff0-84f8cb94099544f39c881bf7ac70bcb7'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='mistral-nemo-2407', score=<MatchScore.A: 2>, id='a00feb503a8e4a45b037a333bfdb19e4-c528a657255c4a608bd82333b9d97d97'),\n",
       " Match(model_a='gemini-2.0-flash-001', model_b='gpt-4.1-nano', score=<MatchScore.Draw: 1>, id='4e186b4f8abc4209b62c3193b84e08b8-3c51f0246fe04ab7b994d6504cc3ab48'),\n",
       " Match(model_a='llama-3.1-405b', model_b='gemma-2-9b-it', score=<MatchScore.A: 2>, id='fce4885b601244debed5165de32f1b2d-0ee720f58abe41878b0bdb54a158c671'),\n",
       " Match(model_a='mistral-large-2411', model_b='mixtral-8x7b-instruct-v0.1', score=<MatchScore.A: 2>, id='736021462cf042788aad1bb38642259e-e198abca2534423db7ec757304f92b98'),\n",
       " Match(model_a='llama-3.1-8b', model_b='llama-3.1-nemotron-70b-instruct', score=<MatchScore.A: 2>, id='b0076b3840794883af4297330385c676-8830057743a34b30bd38a78034eacc7a'),\n",
       " Match(model_a='c4ai-command-r-08-2024', model_b='chocolatine-2-14b-instruct-v2.0.3-q8', score=<MatchScore.Draw: 1>, id='296b7535d2394119b0e5a7325b946dfd-c9d23fb1d423472eb5fbcd516f4193c3'),\n",
       " Match(model_a='mistral-large-2411', model_b='claude-3-7-sonnet', score=<MatchScore.A: 2>, id='66a6ede71d2f4024b70a4044128e8c07-ab95ee263b614dc699dbf09eadfcbc26'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='qwen2.5-7b-instruct', score=<MatchScore.A: 2>, id='33d67647da404694a0e40d044a14aded-99e29533a2fd48ecbeceab58c080e28b'),\n",
       " Match(model_a='llama-3.1-405b', model_b='llama-3.1-8b', score=<MatchScore.A: 2>, id='77eddd1816b147b49eb6861db85cdebf-599a1ecfb22446c98ef8492fc73ed17b'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='gemma-2-9b-it', score=<MatchScore.Draw: 1>, id='713272c406214e049867d216c58aaac7-a7840dc5d57b4a7caa2aafc4083820cc'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.A: 2>, id='90b32e44e0ef4bee9cfb94edfa3cd00b-5bc6989be2b348d7b294664cae1245e9'),\n",
       " Match(model_a='qwq-32b', model_b='deepseek-r1', score=<MatchScore.B: 0>, id='fd5238a5998642cdb96d2472401c4d77-a801bc59419b4e16adb670c756d892bd'),\n",
       " Match(model_a='llama-3.1-8b', model_b='gemini-1.5-pro-001', score=<MatchScore.B: 0>, id='4f10f162e5ba4eb19844818b37971360-8224753012644cb3a1b050e64d8970d9'),\n",
       " Match(model_a='chocolatine-2-14b-instruct-v2.0.3-q8', model_b='claude-3-5-sonnet-v2', score=<MatchScore.B: 0>, id='77f4a7f61a24467184473381530927b1-5670178107284ded9928e15515c777cd'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='phi-4', score=<MatchScore.A: 2>, id='3fc08a420be94743a59ff5be6ef5164c-f2b094acc45f4ed584bc7693305b9a18'),\n",
       " Match(model_a='gemini-2.0-flash-001', model_b='gemma-3-12b', score=<MatchScore.Draw: 1>, id='9ac68927e3d3463eb79090ea1eba69ae-4ba7f93d8b6e4fb19251f8c76dcb3d98'),\n",
       " Match(model_a='qwq-32b', model_b='deepseek-r1', score=<MatchScore.A: 2>, id='068a56517f9b41939265bdfaa34b6221-e28415f1868044c9aecdf4a8da2b6bae'),\n",
       " Match(model_a='llama-3.1-nemotron-70b-instruct', model_b='mistral-nemo-2407', score=<MatchScore.A: 2>, id='55e3a2833547430aa8499b15cdfe13ae-9a719c6ae6c74d23853437bca80121e8'),\n",
       " Match(model_a='llama-3.1-70b', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.B: 0>, id='6e5d0ce648724cf8b14d4def20b8503b-b5003ecf3c584fd7926ffd0446c29680'),\n",
       " Match(model_a='llama-3.1-70b', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.B: 0>, id='8ddf22baaa004b2f9acef2d5081cdaaa-6ca9b5c91b2549779ae71078cb12f62a'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='gemini-1.5-pro-002', score=<MatchScore.A: 2>, id='6af7e71cdca14aeeb253c12801808b5d-3c730e13685240018097e815bda52457'),\n",
       " Match(model_a='phi-3.5-mini-instruct', model_b='llama-3.1-8b', score=<MatchScore.A: 2>, id='721d9ed01c244137aef1043610e6e7e8-24e2abbbb1b14273b9c047931f8f4230'),\n",
       " Match(model_a='gemma-3-12b', model_b='gemma-3-27b', score=<MatchScore.A: 2>, id='d5822bf396a34b7eae6cfda4e8887189-544ffc12f1304f059825d459d81f23e1'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='mistral-nemo-2407', score=<MatchScore.A: 2>, id='ef815af26997491099b3ed121f69a447-203d02de494a4c028848a20e86c253f2'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.A: 2>, id='ff82a664cf1a4f43a45cf4f08bdbe9d4-42553fca5e1b441fa22638a096e7fc64'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.A: 2>, id='fed0b2574faa4085bcb797544952279a-82afaa6627ef47a1a77a2931b024ed52'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='gemini-2.0-flash-exp', score=<MatchScore.Draw: 1>, id='420e6f1806754cf1a2a86193e3c34591-2e416b2d1637457ea9a38bab2502e7f9'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='c4ai-command-r-08-2024', score=<MatchScore.Draw: 1>, id='90112671ed6b495d8ab0462596085b26-06d71fbe63154855bd770ca02d9b51aa'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='chocolatine-2-14b-instruct-v2.0.3-q8', score=<MatchScore.A: 2>, id='0b76989ad16d4031b26c699f1e142f91-0b5645ee06eb496db657879bee276846'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='gemini-1.5-pro-002', score=<MatchScore.A: 2>, id='a432a9e9090c43f3a16f3a1487f5b47a-af2e7897cb4943c280a93cad240bf3e1'),\n",
       " Match(model_a='llama-3.3-70b', model_b='mistral-large-2411', score=<MatchScore.A: 2>, id='35cdafb05a5142e9816c4f1799d115fc-55c9b4e9ed70421d860639bd0b8ddc52'),\n",
       " Match(model_a='llama-3.1-405b', model_b='qwq-32b', score=<MatchScore.Draw: 1>, id='a364833aec0e46fa8be3925c601de8c1-9abddee6a0d74066908ac3ca620d5759'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='gemma-2-9b-it', score=<MatchScore.Draw: 1>, id='7a933edc620d4a5598f664d7840ccb60-ced082a66a79416f8a33f293f3939cc2'),\n",
       " Match(model_a='llama-3.1-70b', model_b='gemma-2-9b-it', score=<MatchScore.B: 0>, id='7667f565947f4d818c091792a32fb0a2-3fc7b9b517fa4b9ebd0a693f568d2ba6'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='phi-4', score=<MatchScore.A: 2>, id='a70f53f6dbac4693b9a025cb36692bfe-53a4134e4bd24d179932ffe55a01785c'),\n",
       " Match(model_a='phi-3.5-mini-instruct', model_b='llama-3.1-405b', score=<MatchScore.B: 0>, id='f8cd0b4a329246d2b9cdac2de3dca7bd-e8a7ed28b0c249969526769c81e32459'),\n",
       " Match(model_a='deepseek-r1', model_b='mistral-large-2411', score=<MatchScore.Draw: 1>, id='6762e21e81364870ad9fad4cf12c7309-b8232038405d47d1aca1c051cd07f3a0'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='ministral-8b-instruct-2410', score=<MatchScore.A: 2>, id='44549fa413ac445dbf4c7301203aae4e-8c200a980dd940eabf88d80cb16a4a04'),\n",
       " Match(model_a='gemma-3-27b', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.A: 2>, id='06e834c7c5354e20999ff10f48ba4e22-3278a1f2d74f40e9a28a4306e81ab633'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='c4ai-command-r-08-2024', score=<MatchScore.B: 0>, id='84e7493e919e430ba138c2f7a3d4eaaa-7136ca3152ee42eca7cbf515c7307355'),\n",
       " Match(model_a='llama-3.1-70b', model_b='command-a', score=<MatchScore.A: 2>, id='6da26481391d44648f6ceec90fb326a7-52c7a596f79b44b8890b0c929f33c805'),\n",
       " Match(model_a='llama-3.1-8b', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.A: 2>, id='2b479d7665564563a2a637a0da04bfc8-2a7e8de2517849ab98e155b85899bdd0'),\n",
       " Match(model_a='llama-3.3-70b', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.Draw: 1>, id='7795845fe1354535ad82a40d2e82b8d1-a25cc05d084b47ac8c9f7f0f66df997c'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='gemini-1.5-pro-002', score=<MatchScore.Draw: 1>, id='916f9c60b1894a9aa1868681e0ecb1f1-ec6b9aac39a2464db9c1cc1faa205eb5'),\n",
       " Match(model_a='gemini-2.0-flash-001', model_b='llama-3.1-nemotron-70b-instruct', score=<MatchScore.Draw: 1>, id='3c40a09c74bb491b8cbd6a8cf160d873-a52a000d9c194b88a0f3adca8f55ca88'),\n",
       " Match(model_a='mistral-large-2411', model_b='gpt-4o-2024-08-06', score=<MatchScore.Draw: 1>, id='6b705917f5ba439ba572ff8ec88bd37a-bd788614eef740d1a7958c3a251d7f6e'),\n",
       " Match(model_a='mistral-large-2411', model_b='gemma-2-9b-it', score=<MatchScore.B: 0>, id='770ae29c5ce74b91b0bbba29a0ca23a5-2f58ca8148a44fa89d04b486c179ba51'),\n",
       " Match(model_a='phi-3.5-mini-instruct', model_b='gemini-1.5-pro-001', score=<MatchScore.B: 0>, id='6b0d1cc6dff947c5b3aebe784e84dfff-e78977344e6b4f7a9971eafee730c677'),\n",
       " Match(model_a='llama-3.1-8b', model_b='gemini-1.5-pro-002', score=<MatchScore.B: 0>, id='72668582cd1040d2b811643f22900e69-6b3927ca1e1b499b9d67a7c573fc51d2'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='o3-mini', score=<MatchScore.A: 2>, id='40c1220036744dcbaaf093f0fc21d95c-aa2213a739504bf18c7f713e914fe806'),\n",
       " Match(model_a='llama-3.1-8b', model_b='c4ai-command-r-08-2024', score=<MatchScore.Draw: 1>, id='53b37e50d9fb4348aa577a46ac629736-f8be586220b54898aed85ca0513d9e39'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.A: 2>, id='8cdb9e94b47643e3b6c132b27676801d-07a2372d4b784f76a73514e192c15025'),\n",
       " Match(model_a='command-a', model_b='mistral-large-2411', score=<MatchScore.Draw: 1>, id='dae7bfe23715413286af6f24e92b0ed2-fecb5bc9fcce4d728e39a21e5afd9982'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.A: 2>, id='b50a038f2ec24f52b600d8050e5eaa5d-b5619ac972c240a788337a481145b0c2'),\n",
       " Match(model_a='mixtral-8x7b-instruct-v0.1', model_b='llama-3.1-405b', score=<MatchScore.B: 0>, id='095bab6c7215484c8cab8b5786ec5297-88d99651f9674b4fbac89eb03c91ddec'),\n",
       " Match(model_a='gemini-2.0-flash-exp', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.A: 2>, id='1ab681f8a267497185d17e522763fc6a-1b86b8059e63476d85b69e1aa19bf557'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='mistral-large-2411', score=<MatchScore.A: 2>, id='118365cf975e4b0d9adde54a61ad87ec-8a6be1344dcf4690b07004dfbc4aaffb'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='llama-3.1-nemotron-70b-instruct', score=<MatchScore.A: 2>, id='7701a8bb7b7d4a298459c50f0ce56f6f-6a708c8671fb4552a5122a6514b71315'),\n",
       " Match(model_a='gemini-2.0-flash-exp', model_b='deepseek-v3-chat', score=<MatchScore.Draw: 1>, id='41c4c676923048d9bbc7f9943e734222-2afd77426517401a8b79913f124729d3'),\n",
       " Match(model_a='mistral-small-24b-instruct-2501', model_b='gpt-4o-2024-08-06', score=<MatchScore.Draw: 1>, id='e27d251004ae4fd2a2dc000bf7b14d25-37e3a7df56124a76ae7c35c31dad0bf0'),\n",
       " Match(model_a='mistral-large-2411', model_b='mistral-small-3.1-24b', score=<MatchScore.A: 2>, id='d99832000f5e4574b3f25a9c6c7717d6-4aeaec86354f403582fb1810bfb523bb'),\n",
       " Match(model_a='llama-3.3-70b', model_b='deepseek-v3-chat', score=<MatchScore.B: 0>, id='991ceacadcf6460291b2b66f392ad2d4-d0cacf5d0b5b4f0fb94528558165edf3'),\n",
       " Match(model_a='llama-3.1-70b', model_b='mistral-nemo-2407', score=<MatchScore.A: 2>, id='4b5d01f2f9944b0c80e10e93c9d31d5a-fb930996d10242ac8ca3e5d93a8106dc'),\n",
       " Match(model_a='c4ai-command-r-08-2024', model_b='phi-4', score=<MatchScore.B: 0>, id='793396ecd6784bf68e76a01b72512bf2-2a68bd1e705c441784186bf071a80e29'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='mistral-nemo-2407', score=<MatchScore.Draw: 1>, id='cea49cd7a40b4997bea7e5fe2f56ec71-9b6495988010495c9c0586d28b190e1b'),\n",
       " Match(model_a='llama-3.1-nemotron-70b-instruct', model_b='gemma-3-27b', score=<MatchScore.Draw: 1>, id='0a4a467f6515406fb9c4a0c47f04c6db-96375e32b68f45e8967f53756f759a14'),\n",
       " Match(model_a='mistral-large-2411', model_b='gpt-4o-2024-08-06', score=<MatchScore.Draw: 1>, id='64057de7994a444ba821710d4e039cc8-3a0bb268ed2a4e51af5246f7beffee4a'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='mixtral-8x7b-instruct-v0.1', score=<MatchScore.B: 0>, id='300daec8da0d43efb0e1577b35406b6f-1626cb7e1be341cdbb5420f961cc6785'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='llama-3.1-405b', score=<MatchScore.A: 2>, id='c5cda6cd8ffc43718637a89c082db2b4-ab63d6cc48034f74aee3383bf0076b9e'),\n",
       " Match(model_a='c4ai-command-r-08-2024', model_b='ministral-8b-instruct-2410', score=<MatchScore.A: 2>, id='69b7c3e854464abe90a7f7ef9cd4a95b-1c5c3a22b69f4afba9b328a45c00b9f5'),\n",
       " Match(model_a='gemma-3-12b', model_b='mistral-small-3.1-24b', score=<MatchScore.Draw: 1>, id='1560decd5b2f452aa4e917651f1111f6-0de9726875514345ae0f246f23e6d628'),\n",
       " Match(model_a='phi-3.5-mini-instruct', model_b='gemma-2-9b-it', score=<MatchScore.A: 2>, id='de51caeadcf54893957a17022d11d520-a5e8a0432c364557a371b6ebe9403ed2'),\n",
       " Match(model_a='llama-3.1-405b', model_b='mixtral-8x7b-instruct-v0.1', score=<MatchScore.B: 0>, id='671caa4c098c410ea6c22e975f6a3ed8-394619150c044480bdc8f41c89e175d0'),\n",
       " Match(model_a='llama-3.1-8b', model_b='qwq-32b', score=<MatchScore.Draw: 1>, id='74d930cb26bb419c89cdb99a451ede8b-0e0e6fdfff7444ca908fbf35e34852c9'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='gpt-4o-2024-08-06', score=<MatchScore.A: 2>, id='ccba727ae70f4c909485650b8db64bf4-f30c40631a7a4357ac6d33bc5d84a960'),\n",
       " Match(model_a='llama-3.1-405b', model_b='deepseek-v3-chat', score=<MatchScore.A: 2>, id='515e2778538e4306ab246902f605be84-8b47076f13a245719089093d79bcfba3'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='mistral-nemo-2407', score=<MatchScore.B: 0>, id='9382108d73244a6cab2494a184b40864-96770af05d014e1c87f46bfdf7a96100'),\n",
       " Match(model_a='deepseek-r1-distill-llama-70b', model_b='qwq-32b', score=<MatchScore.B: 0>, id='1c7fa59ce9cb4282b5b206bfd66a3cec-a2f6e35d9b484f50a0212321186fc1f0'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='mistral-nemo-2407', score=<MatchScore.B: 0>, id='81d33a300d9a4499ad2482748d4a8fbe-a72c4af469a64bfb9f0e22a369f72c81'),\n",
       " Match(model_a='llama-3.1-8b', model_b='phi-4', score=<MatchScore.B: 0>, id='086418857c2542e487e12d65c64d4920-d3b04c88d3cc45f399f1ca4155102cb7'),\n",
       " Match(model_a='llama-3.3-70b', model_b='llama-3.1-405b', score=<MatchScore.A: 2>, id='e1bbc5cb1a754957a6be37d0e2f64935-73443e18d1144eef8c95df268ae113cb'),\n",
       " Match(model_a='phi-4', model_b='gemini-2.0-flash-exp', score=<MatchScore.Draw: 1>, id='1d901088128141c9800957a52c2a4b19-0a8140a711f545b5a00869014cc856c3'),\n",
       " Match(model_a='llama-3.1-405b', model_b='mistral-small-3.1-24b', score=<MatchScore.B: 0>, id='64f1553727834ff2bfdefdb08ee6e1d5-94cbaa8318174c4cb241a416572ebba8'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='claude-3-5-sonnet-v2', score=<MatchScore.A: 2>, id='ad55fa72cb414a00a309da36aa6b9bad-e7cc6d0fe65941e185aaaab8a2ad3744'),\n",
       " Match(model_a='llama-3.1-8b', model_b='gemini-1.5-pro-002', score=<MatchScore.B: 0>, id='4b3d2b6a27ac46198a4302bedc714aaa-7d9c2e037560458ba94cadd2ca03b4ad'),\n",
       " Match(model_a='mistral-large-2411', model_b='gpt-4.1-mini', score=<MatchScore.A: 2>, id='d8381cceb5204054a0b4dcc79e652f44-f9cbe49c6346424786b47e13a7e7f718'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='mistral-large-2411', score=<MatchScore.A: 2>, id='d413587c5efc409d831cec04f03b24de-2bb5f0b7d611488b8a6fde995acdf41c'),\n",
       " Match(model_a='gemini-1.5-pro-001', model_b='gemma-2-27b-it-q8', score=<MatchScore.B: 0>, id='db3780db2f2e45baaf1e7b4b595bffa9-feaf959f98754ed8bf523f17930bf098'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='deepseek-v3-chat', score=<MatchScore.B: 0>, id='8f605f0d3f344122a13b1374afe7b8a1-5dcb6e97d1744df586567d2ba21a99f1'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='claude-3-5-sonnet-v2', score=<MatchScore.A: 2>, id='69daac9b31804b7b96fadaedf4409485-2e7882cff4844df4bf4e52adecdae55e'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='gemini-2.0-flash-exp', score=<MatchScore.B: 0>, id='db72096053d1424d8c8c319a7484ab0a-7ac9ea1b3c064d3f977d920f7184d993'),\n",
       " Match(model_a='mistral-large-2411', model_b='c4ai-command-r-08-2024', score=<MatchScore.Draw: 1>, id='4807a1d82d814d3e9cbd057f584eb36f-bbe45ff2bb814436b282d25843726c6e'),\n",
       " Match(model_a='mistral-small-24b-instruct-2501', model_b='deepseek-v3-chat', score=<MatchScore.A: 2>, id='80f9c98f04194c9487d9b953c5804072-4e800f06218e4d04b8f11f3a267d33c9'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='gpt-4.1-mini', score=<MatchScore.Draw: 1>, id='ee6144b905db4d3bbc6b8d62a1d63e80-4bcad8d66709492bab1dd5ba4267c5a8'),\n",
       " Match(model_a='llama-3.1-8b', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.A: 2>, id='952e5bb3dc194c24815dce69361006a8-88ceada3388a4a16b1cce342e93dd4ff'),\n",
       " Match(model_a='llama-3.1-405b', model_b='gpt-4.1-mini', score=<MatchScore.B: 0>, id='d355eb0aa63d44358122cd0a9d49f509-4c2a87b165a340aa8c7a8576c9e66136'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='llama-3.1-nemotron-70b-instruct', score=<MatchScore.Draw: 1>, id='b8ef5e970e9d411887c31ea31b94f544-1782d7b92c264fc8a9084a4090f45ec3'),\n",
       " Match(model_a='gemini-2.0-flash-exp', model_b='gpt-4o-2024-08-06', score=<MatchScore.A: 2>, id='6fa45c148cdf4428b335d6cd0c643077-b410c1eafbaf4a9fb8b8613f9bdc206f'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='gemini-1.5-pro-002', score=<MatchScore.A: 2>, id='438d2e8594f74c88857edcd3ae3e3390-35199b16cee647d89ed76125506df198'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='mixtral-8x7b-instruct-v0.1', score=<MatchScore.A: 2>, id='9778e180273c4e3abea189539def7e5f-6c68c2fbf5564a6d818ed0e17b169908'),\n",
       " Match(model_a='chocolatine-2-14b-instruct-v2.0.3-q8', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.Draw: 1>, id='75b44d6dfdd947af864c6935cf2c5723-c016c19f72d944299853483a8b833467'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='gemma-2-9b-it', score=<MatchScore.A: 2>, id='a1e53f1c790f42659b15abff6663914c-271c406b733f45d292058cacef53a44a'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='deepseek-v3-chat', score=<MatchScore.B: 0>, id='e02b6b93839647ef8d88135863231a2f-54ff62bb8bba41c6a3da61c3df96ee7d'),\n",
       " Match(model_a='gemini-2.0-flash-001', model_b='grok-3-mini-beta', score=<MatchScore.B: 0>, id='f727ae2bd1d742d887d6626b3b08a699-90a13ff8d9ef4292b269f8f6c1abd994'),\n",
       " Match(model_a='mistral-large-2411', model_b='llama-3.1-405b', score=<MatchScore.B: 0>, id='90f07c3348254add9922e1be4ecc465e-3334fd56d5ed462ead5a8ec2517beb15'),\n",
       " Match(model_a='phi-4', model_b='mistral-small-3.1-24b', score=<MatchScore.A: 2>, id='12ee9cf76520404f964f912bc512bd52-f022af57c136411298b8582b630cb3ac'),\n",
       " Match(model_a='o4-mini', model_b='gpt-4.1-mini', score=<MatchScore.B: 0>, id='e611b22a28fc4d75bb5d0a98fc80249d-9f172b9479e04fe781ed51a2cefc99c6'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='llama-3.1-405b', score=<MatchScore.A: 2>, id='40ce08cc1aa64d828d47de5b10463614-1bc400083008486a83b75a108dde04b3'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='gemini-1.5-pro-001', score=<MatchScore.B: 0>, id='e2b88cd6e7174a0b9a04b551c181c4f0-a6e824efc0eb4b509bb4f05206476a0e'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='deepseek-v3-chat', score=<MatchScore.B: 0>, id='82df5fa4d6a3417fb00b01d8edf78338-a8fab67cd8204253afac8ce4d5c4a984'),\n",
       " Match(model_a='deepseek-r1', model_b='mistral-small-3.1-24b', score=<MatchScore.Draw: 1>, id='07bd53551d31487188feba68480de261-677a0da084bd4ad39776e4cc3cff7c62'),\n",
       " Match(model_a='mistral-small-24b-instruct-2501', model_b='llama-3.3-70b', score=<MatchScore.B: 0>, id='428892479438443998ded6e6eb47b2d9-c43dc2a009214059bb963525fc59a16c'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.Draw: 1>, id='9a89bb1a29964ffaab8c733fd32ea5b7-28031b6690e24194b54d42d6c650711d'),\n",
       " Match(model_a='llama-3.3-70b', model_b='phi-4', score=<MatchScore.A: 2>, id='3aa21475ad1d49a0be785a162f48dc4b-763592a3e5884eec851fa56f7903b9f0'),\n",
       " Match(model_a='qwen2.5-7b-instruct', model_b='phi-3.5-mini-instruct', score=<MatchScore.A: 2>, id='e7dca66e81dc46a4a1eb02e79880ef47-97e1ea8b95b349f0848a852ef2eb9256'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='mistral-nemo-2407', score=<MatchScore.A: 2>, id='96b857692dab4f12b953ef80477193aa-5d5bc19ac09a40ceaec3e5c39ed3ff78'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='claude-3-5-sonnet-v2', score=<MatchScore.B: 0>, id='dd817fb4d3474722a1681e2a344fd5b9-13e4c0afb57c4af5a98f82e8978e0a2c'),\n",
       " Match(model_a='mistral-large-2411', model_b='gpt-4o-2024-08-06', score=<MatchScore.B: 0>, id='4fec10c2b3c3452e983c8689447db631-cd854d4d64b84c9cbd109826710e749e'),\n",
       " Match(model_a='qwen2.5-7b-instruct', model_b='ministral-8b-instruct-2410', score=<MatchScore.B: 0>, id='049622689cc94f31859a6c641039d2dc-b85f815c51e14373baea51ec738c57b8'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.Draw: 1>, id='0107779a61b64b27b3d23261b9464cc7-599304f751c045609f5060d8bc6cc8a6'),\n",
       " Match(model_a='mistral-small-3.1-24b', model_b='llama-3.1-405b', score=<MatchScore.Draw: 1>, id='fa82b61f956145b0955715f8d9b53eae-f9f66b4b583348e1ac67b04b51e78110'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='gpt-4o-2024-08-06', score=<MatchScore.B: 0>, id='411cda50887f48aa84046d6cfcd3a442-e85bcea5732e4db3a67302a521d32139'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.Draw: 1>, id='aec22bacf677467cab6cfa766519f4b3-816488b4f4d9415aba0ee7c40b11162a'),\n",
       " Match(model_a='llama-3.1-8b', model_b='aya-expanse-8b', score=<MatchScore.B: 0>, id='82e6ee34b83949af9b1d15dec2af93da-30c0b63f854b457bb1426bb1950af80d'),\n",
       " Match(model_a='llama-3.1-70b', model_b='phi-4', score=<MatchScore.Draw: 1>, id='3287356c3ca045c0b2251c67c0060eb7-08f623ba0daa4cd39de49541996b7016'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.B: 0>, id='52fdbfa4b8ab44c7817b22bbe080c710-ed52d798687e483eafbb18ccad0fcf27'),\n",
       " Match(model_a='llama-3.1-nemotron-70b-instruct', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.A: 2>, id='2fdc503dc02e46d282c07a03f5c5533c-7e1da330e8624e0091f914104c5c5776'),\n",
       " Match(model_a='llama-3.1-nemotron-70b-instruct', model_b='deepseek-r1-distill-llama-70b', score=<MatchScore.A: 2>, id='14dafea764204057b8cca5097a054654-06dc41b037b84d7087bd5ce15f8bbb64'),\n",
       " Match(model_a='llama-3.1-8b', model_b='phi-3.5-mini-instruct', score=<MatchScore.B: 0>, id='3845de2b1aee4bce841e39fb9af9ef75-4da778fe9d424047884f734aeee0e4e2'),\n",
       " Match(model_a='gemma-3-27b', model_b='chocolatine-2-14b-instruct-v2.0.3-q8', score=<MatchScore.A: 2>, id='f402ce145f3743aab39c08a7fde87c4b-f9b7dd12ec224b2ebc72b95697d4e7dd'),\n",
       " Match(model_a='gemma-3-27b', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.A: 2>, id='5fa97a43701f4b9ab11a489425491cd6-642a48f5cdcf40ceaa36c035e46d9150'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='deepseek-r1-distill-llama-70b', score=<MatchScore.Draw: 1>, id='0369eecbea4d4904957ff66a302d0bab-d5457a5886e948df905f297e60a5d28e'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='llama-3.1-405b', score=<MatchScore.A: 2>, id='d9fb04f9a0cb465a849e433d96db3f01-2e262211472648f58b14f31e0063dc8a'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='mistral-large-2411', score=<MatchScore.A: 2>, id='8580003374ed42f3a616256615bfc1e3-3137175b4a8741f0a9398fafd12f48b1'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.B: 0>, id='a6e3402fef0d4e11995a814adf9cf26b-651ac9fb9ec04ab09e3687a782209eb1'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.A: 2>, id='ecd731412aac46158d917b7536f7c61a-bfec1025898941bc8349f822ffc05d7a'),\n",
       " Match(model_a='gemma-3-27b', model_b='lfm-40b', score=<MatchScore.Draw: 1>, id='a69ec93315c247aabe4959dcd21bc9bf-f625aac75c364efd86b05670f8e2fd63'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='gpt-4o-2024-08-06', score=<MatchScore.A: 2>, id='54bc1540eca14b33b315174682bf09d9-ec03aa7860604049a5bd1e288ca69bbf'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='gemma-2-9b-it', score=<MatchScore.A: 2>, id='3c832074cc5d4a10a6869cb0df253b16-446d286f9af943b58fb3143d3594daca'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='gemma-2-9b-it', score=<MatchScore.Draw: 1>, id='025e8feb170b4ef6a9fab957284b5d56-a3cfc8b4aa5944b39cbf6a63611e94aa'),\n",
       " Match(model_a='gpt-4.1-mini', model_b='c4ai-command-r-08-2024', score=<MatchScore.A: 2>, id='0cc648af37b6488eb183859a597fefe9-4e7ca0f783ec4952a325c97886b5b5aa'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='gpt-4o-2024-08-06', score=<MatchScore.A: 2>, id='f2c52594983c4e67aa58beaafed70649-3f20a51a00d144608eb0774e48683a3f'),\n",
       " Match(model_a='mistral-small-24b-instruct-2501', model_b='mistral-large-2411', score=<MatchScore.B: 0>, id='6c1874e6f72a4d5689ae2b1b09a055da-b7d8d5a7793441289f869ec8197d21fc'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='llama-3.1-405b', score=<MatchScore.B: 0>, id='685f56a9b85245518ddfefacb325cb80-04a9752c1ceb4055abbf90e3c9646224'),\n",
       " Match(model_a='mistral-small-24b-instruct-2501', model_b='chocolatine-2-14b-instruct-v2.0.3-q8', score=<MatchScore.A: 2>, id='8c3adf69d9b540ee8545a842d5f31cff-bf223e2cf4994fa1bc951d90141838d5'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='gemini-1.5-pro-002', score=<MatchScore.B: 0>, id='d6343293d7f04993ad4f0b08659685b3-46f83064d5464e46a850d9ac86fbb7bc'),\n",
       " Match(model_a='gemma-3-4b', model_b='gemini-1.5-pro-002', score=<MatchScore.Draw: 1>, id='34ca8137f8f546b6b3aa567876b3db6e-44b4c558ffc84c8eb04c9c3de55414d7'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='c4ai-command-r-08-2024', score=<MatchScore.Draw: 1>, id='502db37710b64856a084cd9d3987d38f-db8b5f4da84b4df3b6ff94c3f68b5a52'),\n",
       " Match(model_a='llama-3.1-70b', model_b='claude-3-5-sonnet-v2', score=<MatchScore.B: 0>, id='906eaaefbd2f4c46a540e1fbd5b66d2e-afd32f16194f47f08a0d75bf5fb1ef3f'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.A: 2>, id='b8430fd48f6341d39dcb1f8a6226df2e-b86cfb2d05314d18bb45f165e0e53390'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='llama-3.1-405b', score=<MatchScore.A: 2>, id='783b10f7871b4f26b66dec16021ccba4-8bd7d9be48af432aa96283a79458597b'),\n",
       " Match(model_a='gpt-4.1-mini', model_b='gemma-3-27b', score=<MatchScore.B: 0>, id='f59164146732458f84af0d9aa2ecef80-567e07bb2dc04005a0fb6476028e837c'),\n",
       " Match(model_a='llama-3.1-405b', model_b='llama-3.3-70b', score=<MatchScore.Draw: 1>, id='3020674850af468e975c6bf5729f9018-a14441f8fe6346bea3c193a6e8fbc290'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='deepseek-v3-chat', score=<MatchScore.A: 2>, id='0cb4ac86c3c14620922f4c92c1037db1-ae20c278e20748b182106a14270fa2ca'),\n",
       " Match(model_a='llama-3.1-405b', model_b='llama-3.3-70b', score=<MatchScore.B: 0>, id='b8c9bd46609146bc873792d795f9faeb-c1d6b7c1acf24b09be68c1102ea2fcbe'),\n",
       " Match(model_a='mistral-large-2411', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.A: 2>, id='4fa472b3fc7e4d6588cf0af89a2d07da-faccc8013fd24abe82f85f12ce86820d'),\n",
       " Match(model_a='chocolatine-14b-instruct-dpo-v1.2-q4', model_b='llama-3.1-8b', score=<MatchScore.A: 2>, id='75c41466b82542b28469c7fe18efc23c-4a9785053e7f44bd9e9054ea59f7c3b4'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.B: 0>, id='852a1fca6d234d6896d803dd654cb028-6963bf36f8c740c1bf3a2c5fa8ab1185'),\n",
       " Match(model_a='mistral-small-24b-instruct-2501', model_b='deepseek-r1', score=<MatchScore.A: 2>, id='576bf5e88b234c02b761b1bda972793f-768de786ad804dd999b13231ed7e80f1'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='deepseek-v3-0324', score=<MatchScore.B: 0>, id='abbb23da28b9412e90b152c6c2ee38bf-e9677147b654443099002daaac75148b'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.Draw: 1>, id='c21545cc9af04fb393b08fb5ae99fb69-65d5560eec964b5f87951d4d54b49130'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.Draw: 1>, id='c46bed9eb17a418cad2c5e1f0db1686f-f17e1bfa6e454969b119bc6d2e955399'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='gemma-2-9b-it', score=<MatchScore.Draw: 1>, id='7ddfd75e06e047f3808c69f78119631a-ee065811789c4c8b825baffe832f4203'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='llama-3.1-8b', score=<MatchScore.A: 2>, id='31dfc2feccfd45f68d2ae52d96963870-eaa53a0e3c584d9fa6b0e18fe9c7c276'),\n",
       " Match(model_a='aya-expanse-8b', model_b='ministral-8b-instruct-2410', score=<MatchScore.A: 2>, id='b2cd1e1b701349ceb5ff8d5a79652f0d-f66e3746d5f54a9eb653b847dc5483aa'),\n",
       " Match(model_a='llama-3.1-405b', model_b='gemini-2.0-flash-001', score=<MatchScore.B: 0>, id='f2c887c507e54b388ad3703c06d36ed7-546cd0e790c544c0aa3d7665683733c2'),\n",
       " Match(model_a='llama-3.3-70b', model_b='ministral-8b-instruct-2410', score=<MatchScore.B: 0>, id='15cdeafb1d7944f7ac9cfd4b4ed45960-1879e076837d4631b2af8db419d2f46e'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='llama-3.1-nemotron-70b-instruct', score=<MatchScore.Draw: 1>, id='17f342ad3ba848468bcff8fd8329e406-ca5f9426fee34225a02b2b37af31645d'),\n",
       " Match(model_a='llama-3.3-70b', model_b='ministral-8b-instruct-2410', score=<MatchScore.A: 2>, id='e47cacb44a4a41f4a0a735383206556d-6c461485182048dc8d8e51199b335f1a'),\n",
       " Match(model_a='o3-mini', model_b='gemini-2.0-flash-001', score=<MatchScore.B: 0>, id='7f892cfe22f744959669aefd1ae601b6-614f16e956e4435cac1808128fcd6a3b'),\n",
       " Match(model_a='deepseek-v3-0324', model_b='claude-3-7-sonnet', score=<MatchScore.B: 0>, id='c31e742255c84f83b3838961a62816ad-1c010ce681654638825d67b6f928efe9'),\n",
       " Match(model_a='mistral-large-2411', model_b='gemma-3-27b', score=<MatchScore.B: 0>, id='259b851959404ef29e41ee9a4a2aa7e2-3848f1e84efd45ca8388ebcbda9d77df'),\n",
       " Match(model_a='llama-3.1-405b', model_b='gemini-1.5-pro-002', score=<MatchScore.Draw: 1>, id='728a7cb0eef14963a9b5839ddfabf2d1-3afb95ad1b464cafb47404b2fe8c3b7c'),\n",
       " Match(model_a='phi-4', model_b='llama-3.3-70b', score=<MatchScore.B: 0>, id='7a1b1214cd6d49e189f4c8427e21c9bf-126659bc2156459d904c576194ba40ea'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='claude-3-5-sonnet-v2', score=<MatchScore.B: 0>, id='f38999101a014824a9e15d8cdea635a3-aa4b88d3552645e0bb2d9cabd3bacb7c'),\n",
       " Match(model_a='gpt-4.1-mini', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.A: 2>, id='c8a3642a7e264711b4ef98776007f028-c51e783d44d740d0b5975cf9316e7c9f'),\n",
       " Match(model_a='mistral-small-3.1-24b', model_b='llama-3.1-70b', score=<MatchScore.Draw: 1>, id='89beaf7e606b431ba04c076a4a9d6ad8-a21b1b6dff9d46a1a4b05210d7c2c357'),\n",
       " Match(model_a='qwq-32b', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.A: 2>, id='235a9b9a26d94ca7b6f0803a7703d2b6-69ae311cf1e34ba591d6ffd2523b0a3a'),\n",
       " Match(model_a='phi-4', model_b='llama-3.1-405b', score=<MatchScore.Draw: 1>, id='3ac71df8ed6946acbae1827a276bdb09-2a34716884ca4ce389422c5e81c84b0b'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='deepseek-v3-chat', score=<MatchScore.B: 0>, id='a1532a70fa444f228a01d5b3dc05e92d-37ca3607cd9345e181bfbeafca7794db'),\n",
       " Match(model_a='llama-3.1-nemotron-70b-instruct', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.A: 2>, id='298d8651056d4db98c0bd8f6e7e493f7-142d97ffc9474b71aa474b449a6ec4a3'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='lfm-40b', score=<MatchScore.A: 2>, id='35ffdb371f854c8082ce7128994a2443-7ce451e116d54926bfb57f921682454b'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='mistral-large-2411', score=<MatchScore.A: 2>, id='45dc83a100ba4889bcdeb35a15776e99-d56bd0c352ea48629aa71318d0922038'),\n",
       " Match(model_a='gemini-2.0-flash-001', model_b='deepseek-v3-chat', score=<MatchScore.Draw: 1>, id='b086d00eae694e54bfff55514196c6be-558717c1a3d4493086a548231ce0d358'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='llama-3.1-405b', score=<MatchScore.A: 2>, id='0ec8246fe9e34a37ad125c223b6fc4f9-27716ea0df3f429d84b4b0960812cbdb'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='chocolatine-2-14b-instruct-v2.0.3-q8', score=<MatchScore.A: 2>, id='b611e3de94254b47b2a5df3af2cc3f2d-41784cb45f8648eca090cc031d1949ac'),\n",
       " Match(model_a='deepseek-r1', model_b='deepseek-r1-distill-llama-70b', score=<MatchScore.Draw: 1>, id='30faf61c5d2e46f2af7007ddaf0494a9-96a91b8a1e104c499058b2219a402829'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.A: 2>, id='3ca54485b971407fa220f9316c05bcc2-a80e2a78687b47bc960fdb69e341b639'),\n",
       " Match(model_a='mixtral-8x7b-instruct-v0.1', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.Draw: 1>, id='bc68d6ae376448189ee8226a809de0bd-c3a2516ba38645d4b68ccd08c95ebe44'),\n",
       " Match(model_a='deepseek-r1', model_b='mistral-saba', score=<MatchScore.Draw: 1>, id='2380ab57304c43e184819e9b32f1409c-9c2a62654613446e8676e7ac4df11301'),\n",
       " Match(model_a='llama-3.1-405b', model_b='mistral-nemo-2407', score=<MatchScore.B: 0>, id='320c566648ca47aca215e0e4d13f08a7-d935dd2763e04183a4a5436690a54150'),\n",
       " Match(model_a='mistral-large-2411', model_b='gpt-4o-2024-08-06', score=<MatchScore.A: 2>, id='e3ca28707cdf4b858b566564b1374bab-d76f4a9a2ac54432b945ddb6d0f44bd6'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='ministral-8b-instruct-2410', score=<MatchScore.Draw: 1>, id='8fff31b60e7b4473903ea64160daa991-fd56c7c3f55d4810abdce1c2d60c3ef8'),\n",
       " Match(model_a='llama-3.1-405b', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.A: 2>, id='b89f0d9bc1e5432194a29f977292925d-02ee625cc6ed411a9d318250aa6d741e'),\n",
       " Match(model_a='llama-3.1-70b', model_b='qwen2.5-7b-instruct', score=<MatchScore.A: 2>, id='4524a481b90e49aebac67935ecbe1e5c-277c642d630a4d35a22b73f99834216a'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='c4ai-command-r-08-2024', score=<MatchScore.Draw: 1>, id='3b97f18baca74f72896def8033eed40c-148595f51a4b4f94a37d769894b82a58'),\n",
       " Match(model_a='llama-3.1-8b', model_b='gemini-1.5-pro-001', score=<MatchScore.B: 0>, id='4793329fa4a8431fa99823baba52d60b-24a400f4e13a4e1e83fdf621dcc490b4'),\n",
       " Match(model_a='mistral-small-24b-instruct-2501', model_b='c4ai-command-r-08-2024', score=<MatchScore.A: 2>, id='341b7379cdc849b5a93c5fd7b5044044-46f59950368547a296dae2f6ac3f9dc4'),\n",
       " Match(model_a='o4-mini', model_b='ministral-8b-instruct-2410', score=<MatchScore.Draw: 1>, id='fde7141e8bdb49178c905800d59272bf-f2d7e4938f1d46b78596b578acbeecd8'),\n",
       " Match(model_a='llama-3.1-70b', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.B: 0>, id='c914487ff62046e4b2d9e2a5604c9757-ca7a580304eb40c58b513b4b7ce80fb3'),\n",
       " ...]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.match_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b1574044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing bootstrap scores from a sample of 76861 matches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing bootstrap samples: 100%|██████████| 5/5 [00:00<00:00,  5.48it/s]\n"
     ]
    }
   ],
   "source": [
    "scores = pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3bcac115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (52, 9)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model_name</th><th>median</th><th>p2.5</th><th>p97.5</th><th>total_output_tokens</th><th>conso_all_conv</th><th>n_match</th><th>mean_conso_per_match</th><th>mean_conso_per_token</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>u32</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;Yi-1.5-9B-Chat&quot;</td><td>774.241171</td><td>723.795812</td><td>816.145812</td><td>47531.0</td><td>0.182743</td><td>65</td><td>0.002811</td><td>0.000004</td></tr><tr><td>&quot;aya-expanse-8b&quot;</td><td>1009.908116</td><td>974.484095</td><td>1147.204097</td><td>1.05781e6</td><td>3.98568</td><td>1302</td><td>0.003061</td><td>0.000004</td></tr><tr><td>&quot;c4ai-command-r-08-2024&quot;</td><td>931.936808</td><td>876.647061</td><td>976.315158</td><td>2.747666e6</td><td>20.763975</td><td>3598</td><td>0.005771</td><td>0.000008</td></tr><tr><td>&quot;chocolatine-14b-instruct-dpo-v…</td><td>786.607742</td><td>648.945278</td><td>829.370282</td><td>131187.0</td><td>0.602249</td><td>309</td><td>0.001949</td><td>0.000005</td></tr><tr><td>&quot;chocolatine-2-14b-instruct-v2.…</td><td>841.683681</td><td>788.800519</td><td>914.163245</td><td>533384.0</td><td>1.934863</td><td>1796</td><td>0.001077</td><td>0.000004</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;qwen2-7b-instruct&quot;</td><td>779.862264</td><td>686.265866</td><td>864.205276</td><td>43550.0</td><td>0.153078</td><td>80</td><td>0.001913</td><td>0.000004</td></tr><tr><td>&quot;qwen2.5-32b-instruct&quot;</td><td>1015.134656</td><td>922.150664</td><td>1045.036653</td><td>75812.0</td><td>0.531085</td><td>142</td><td>0.00374</td><td>0.000007</td></tr><tr><td>&quot;qwen2.5-7b-instruct&quot;</td><td>933.475457</td><td>835.779738</td><td>1015.902373</td><td>1.186919e6</td><td>4.305576</td><td>1420</td><td>0.003032</td><td>0.000004</td></tr><tr><td>&quot;qwen2.5-coder-32b-instruct&quot;</td><td>922.406688</td><td>908.776973</td><td>983.476495</td><td>4.0819e6</td><td>29.128193</td><td>4954</td><td>0.00588</td><td>0.000007</td></tr><tr><td>&quot;qwq-32b&quot;</td><td>952.820114</td><td>935.365865</td><td>979.222152</td><td>1.757717e6</td><td>12.542963</td><td>1479</td><td>0.008481</td><td>0.000007</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (52, 9)\n",
       "┌────────────┬───────────┬───────────┬───────────┬───┬───────────┬─────────┬───────────┬───────────┐\n",
       "│ model_name ┆ median    ┆ p2.5      ┆ p97.5     ┆ … ┆ conso_all ┆ n_match ┆ mean_cons ┆ mean_cons │\n",
       "│ ---        ┆ ---       ┆ ---       ┆ ---       ┆   ┆ _conv     ┆ ---     ┆ o_per_mat ┆ o_per_tok │\n",
       "│ str        ┆ f64       ┆ f64       ┆ f64       ┆   ┆ ---       ┆ u32     ┆ ch        ┆ en        │\n",
       "│            ┆           ┆           ┆           ┆   ┆ f64       ┆         ┆ ---       ┆ ---       │\n",
       "│            ┆           ┆           ┆           ┆   ┆           ┆         ┆ f64       ┆ f64       │\n",
       "╞════════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═════════╪═══════════╪═══════════╡\n",
       "│ Yi-1.5-9B- ┆ 774.24117 ┆ 723.79581 ┆ 816.14581 ┆ … ┆ 0.182743  ┆ 65      ┆ 0.002811  ┆ 0.000004  │\n",
       "│ Chat       ┆ 1         ┆ 2         ┆ 2         ┆   ┆           ┆         ┆           ┆           │\n",
       "│ aya-expans ┆ 1009.9081 ┆ 974.48409 ┆ 1147.2040 ┆ … ┆ 3.98568   ┆ 1302    ┆ 0.003061  ┆ 0.000004  │\n",
       "│ e-8b       ┆ 16        ┆ 5         ┆ 97        ┆   ┆           ┆         ┆           ┆           │\n",
       "│ c4ai-comma ┆ 931.93680 ┆ 876.64706 ┆ 976.31515 ┆ … ┆ 20.763975 ┆ 3598    ┆ 0.005771  ┆ 0.000008  │\n",
       "│ nd-r-08-20 ┆ 8         ┆ 1         ┆ 8         ┆   ┆           ┆         ┆           ┆           │\n",
       "│ 24         ┆           ┆           ┆           ┆   ┆           ┆         ┆           ┆           │\n",
       "│ chocolatin ┆ 786.60774 ┆ 648.94527 ┆ 829.37028 ┆ … ┆ 0.602249  ┆ 309     ┆ 0.001949  ┆ 0.000005  │\n",
       "│ e-14b-inst ┆ 2         ┆ 8         ┆ 2         ┆   ┆           ┆         ┆           ┆           │\n",
       "│ ruct-dpo-v ┆           ┆           ┆           ┆   ┆           ┆         ┆           ┆           │\n",
       "│ …          ┆           ┆           ┆           ┆   ┆           ┆         ┆           ┆           │\n",
       "│ chocolatin ┆ 841.68368 ┆ 788.80051 ┆ 914.16324 ┆ … ┆ 1.934863  ┆ 1796    ┆ 0.001077  ┆ 0.000004  │\n",
       "│ e-2-14b-in ┆ 1         ┆ 9         ┆ 5         ┆   ┆           ┆         ┆           ┆           │\n",
       "│ struct-v2. ┆           ┆           ┆           ┆   ┆           ┆         ┆           ┆           │\n",
       "│ …          ┆           ┆           ┆           ┆   ┆           ┆         ┆           ┆           │\n",
       "│ …          ┆ …         ┆ …         ┆ …         ┆ … ┆ …         ┆ …       ┆ …         ┆ …         │\n",
       "│ qwen2-7b-i ┆ 779.86226 ┆ 686.26586 ┆ 864.20527 ┆ … ┆ 0.153078  ┆ 80      ┆ 0.001913  ┆ 0.000004  │\n",
       "│ nstruct    ┆ 4         ┆ 6         ┆ 6         ┆   ┆           ┆         ┆           ┆           │\n",
       "│ qwen2.5-32 ┆ 1015.1346 ┆ 922.15066 ┆ 1045.0366 ┆ … ┆ 0.531085  ┆ 142     ┆ 0.00374   ┆ 0.000007  │\n",
       "│ b-instruct ┆ 56        ┆ 4         ┆ 53        ┆   ┆           ┆         ┆           ┆           │\n",
       "│ qwen2.5-7b ┆ 933.47545 ┆ 835.77973 ┆ 1015.9023 ┆ … ┆ 4.305576  ┆ 1420    ┆ 0.003032  ┆ 0.000004  │\n",
       "│ -instruct  ┆ 7         ┆ 8         ┆ 73        ┆   ┆           ┆         ┆           ┆           │\n",
       "│ qwen2.5-co ┆ 922.40668 ┆ 908.77697 ┆ 983.47649 ┆ … ┆ 29.128193 ┆ 4954    ┆ 0.00588   ┆ 0.000007  │\n",
       "│ der-32b-in ┆ 8         ┆ 3         ┆ 5         ┆   ┆           ┆         ┆           ┆           │\n",
       "│ struct     ┆           ┆           ┆           ┆   ┆           ┆         ┆           ┆           │\n",
       "│ qwq-32b    ┆ 952.82011 ┆ 935.36586 ┆ 979.22215 ┆ … ┆ 12.542963 ┆ 1479    ┆ 0.008481  ┆ 0.000007  │\n",
       "│            ┆ 4         ┆ 5         ┆ 2         ┆   ┆           ┆         ┆           ┆           │\n",
       "└────────────┴───────────┴───────────┴───────────┴───┴───────────┴─────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140dac27",
   "metadata": {},
   "source": [
    "### Une autre méthode de calcul \n",
    "\n",
    "Ici on utilise uniquement les données de votes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e971e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since ministere-culture/comparia-reactions couldn't be found on the Hugging Face Hub (offline mode is enabled).\n",
      "Found the latest cached dataset configuration 'default' at /home/jupyterhub-users/shared/projet_comparia/huggingface_hub/ministere-culture___comparia-reactions/default/0.0.0/80befa851337d9f295096cef3d100b40d220dc07 (last modified on Mon Jul 28 10:06:54 2025).\n",
      "Using the latest cached version of the dataset since ministere-culture/comparia-conversations couldn't be found on the Hugging Face Hub (offline mode is enabled).\n",
      "Found the latest cached dataset configuration 'default' at /home/jupyterhub-users/shared/projet_comparia/huggingface_hub/ministere-culture___comparia-conversations/default/0.0.0/dc40af6af1c14e68bf39d55f6e1573d2d6582f19 (last modified on Wed Jun  4 17:40:30 2025).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reactions data originally contains 22993 conversations pairs.\n",
      "Final reactions dataset contains 21244 conversations pairs.\n",
      "Computing bootstrap scores from a sample of 21244 matches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing bootstrap samples: 100%|██████████| 5/5 [00:00<00:00, 25.20it/s]\n"
     ]
    }
   ],
   "source": [
    "pipeline = RankingPipeline(\n",
    "    method=\"elo_random\",\n",
    "    include_votes=False,\n",
    "    include_reactions=True,\n",
    "    bootstrap_samples=5,\n",
    "    mean_how=\"token\",\n",
    "    batch=False,\n",
    "    export_path=None,  # Path(\"output\"),\n",
    ")\n",
    "scores_votes = pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c91a29d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (48, 9)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model_name</th><th>median</th><th>p2.5</th><th>p97.5</th><th>total_output_tokens</th><th>conso_all_conv</th><th>n_match</th><th>mean_conso_per_match</th><th>mean_conso_per_token</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>u32</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;aya-expanse-8b&quot;</td><td>940.817651</td><td>924.158808</td><td>1022.448303</td><td>327851.0</td><td>1.235297</td><td>467</td><td>0.002645</td><td>0.000004</td></tr><tr><td>&quot;c4ai-command-r-08-2024&quot;</td><td>949.314328</td><td>913.310484</td><td>1005.993491</td><td>741453.0</td><td>5.603123</td><td>1079</td><td>0.005193</td><td>0.000008</td></tr><tr><td>&quot;chocolatine-2-14b-instruct-v2.…</td><td>807.375319</td><td>705.541094</td><td>888.0187</td><td>167003.0</td><td>0.605807</td><td>556</td><td>0.00109</td><td>0.000004</td></tr><tr><td>&quot;claude-3-5-sonnet-v2&quot;</td><td>979.612297</td><td>871.392429</td><td>1044.974816</td><td>992729.0</td><td>133.262452</td><td>1834</td><td>0.072662</td><td>0.000134</td></tr><tr><td>&quot;claude-3-7-sonnet&quot;</td><td>1086.632401</td><td>988.473159</td><td>1129.083656</td><td>287583.0</td><td>38.604711</td><td>296</td><td>0.130421</td><td>0.000134</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;phi-3.5-mini-instruct&quot;</td><td>931.243001</td><td>797.687846</td><td>966.268693</td><td>343212.0</td><td>1.052349</td><td>430</td><td>0.002447</td><td>0.000003</td></tr><tr><td>&quot;phi-4&quot;</td><td>1030.029215</td><td>964.638968</td><td>1077.368166</td><td>1.149348e6</td><td>5.298356</td><td>1498</td><td>0.003537</td><td>0.000005</td></tr><tr><td>&quot;qwen2.5-7b-instruct&quot;</td><td>946.331531</td><td>833.547935</td><td>1022.996342</td><td>313742.0</td><td>1.138106</td><td>392</td><td>0.002903</td><td>0.000004</td></tr><tr><td>&quot;qwen2.5-coder-32b-instruct&quot;</td><td>858.68396</td><td>800.259613</td><td>977.292582</td><td>1.168947e6</td><td>8.341536</td><td>1490</td><td>0.005598</td><td>0.000007</td></tr><tr><td>&quot;qwq-32b&quot;</td><td>935.418772</td><td>873.24118</td><td>1012.078056</td><td>353398.0</td><td>2.521827</td><td>298</td><td>0.008463</td><td>0.000007</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (48, 9)\n",
       "┌────────────┬───────────┬───────────┬───────────┬───┬───────────┬─────────┬───────────┬───────────┐\n",
       "│ model_name ┆ median    ┆ p2.5      ┆ p97.5     ┆ … ┆ conso_all ┆ n_match ┆ mean_cons ┆ mean_cons │\n",
       "│ ---        ┆ ---       ┆ ---       ┆ ---       ┆   ┆ _conv     ┆ ---     ┆ o_per_mat ┆ o_per_tok │\n",
       "│ str        ┆ f64       ┆ f64       ┆ f64       ┆   ┆ ---       ┆ u32     ┆ ch        ┆ en        │\n",
       "│            ┆           ┆           ┆           ┆   ┆ f64       ┆         ┆ ---       ┆ ---       │\n",
       "│            ┆           ┆           ┆           ┆   ┆           ┆         ┆ f64       ┆ f64       │\n",
       "╞════════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═════════╪═══════════╪═══════════╡\n",
       "│ aya-expans ┆ 940.81765 ┆ 924.15880 ┆ 1022.4483 ┆ … ┆ 1.235297  ┆ 467     ┆ 0.002645  ┆ 0.000004  │\n",
       "│ e-8b       ┆ 1         ┆ 8         ┆ 03        ┆   ┆           ┆         ┆           ┆           │\n",
       "│ c4ai-comma ┆ 949.31432 ┆ 913.31048 ┆ 1005.9934 ┆ … ┆ 5.603123  ┆ 1079    ┆ 0.005193  ┆ 0.000008  │\n",
       "│ nd-r-08-20 ┆ 8         ┆ 4         ┆ 91        ┆   ┆           ┆         ┆           ┆           │\n",
       "│ 24         ┆           ┆           ┆           ┆   ┆           ┆         ┆           ┆           │\n",
       "│ chocolatin ┆ 807.37531 ┆ 705.54109 ┆ 888.0187  ┆ … ┆ 0.605807  ┆ 556     ┆ 0.00109   ┆ 0.000004  │\n",
       "│ e-2-14b-in ┆ 9         ┆ 4         ┆           ┆   ┆           ┆         ┆           ┆           │\n",
       "│ struct-v2. ┆           ┆           ┆           ┆   ┆           ┆         ┆           ┆           │\n",
       "│ …          ┆           ┆           ┆           ┆   ┆           ┆         ┆           ┆           │\n",
       "│ claude-3-5 ┆ 979.61229 ┆ 871.39242 ┆ 1044.9748 ┆ … ┆ 133.26245 ┆ 1834    ┆ 0.072662  ┆ 0.000134  │\n",
       "│ -sonnet-v2 ┆ 7         ┆ 9         ┆ 16        ┆   ┆ 2         ┆         ┆           ┆           │\n",
       "│ claude-3-7 ┆ 1086.6324 ┆ 988.47315 ┆ 1129.0836 ┆ … ┆ 38.604711 ┆ 296     ┆ 0.130421  ┆ 0.000134  │\n",
       "│ -sonnet    ┆ 01        ┆ 9         ┆ 56        ┆   ┆           ┆         ┆           ┆           │\n",
       "│ …          ┆ …         ┆ …         ┆ …         ┆ … ┆ …         ┆ …       ┆ …         ┆ …         │\n",
       "│ phi-3.5-mi ┆ 931.24300 ┆ 797.68784 ┆ 966.26869 ┆ … ┆ 1.052349  ┆ 430     ┆ 0.002447  ┆ 0.000003  │\n",
       "│ ni-instruc ┆ 1         ┆ 6         ┆ 3         ┆   ┆           ┆         ┆           ┆           │\n",
       "│ t          ┆           ┆           ┆           ┆   ┆           ┆         ┆           ┆           │\n",
       "│ phi-4      ┆ 1030.0292 ┆ 964.63896 ┆ 1077.3681 ┆ … ┆ 5.298356  ┆ 1498    ┆ 0.003537  ┆ 0.000005  │\n",
       "│            ┆ 15        ┆ 8         ┆ 66        ┆   ┆           ┆         ┆           ┆           │\n",
       "│ qwen2.5-7b ┆ 946.33153 ┆ 833.54793 ┆ 1022.9963 ┆ … ┆ 1.138106  ┆ 392     ┆ 0.002903  ┆ 0.000004  │\n",
       "│ -instruct  ┆ 1         ┆ 5         ┆ 42        ┆   ┆           ┆         ┆           ┆           │\n",
       "│ qwen2.5-co ┆ 858.68396 ┆ 800.25961 ┆ 977.29258 ┆ … ┆ 8.341536  ┆ 1490    ┆ 0.005598  ┆ 0.000007  │\n",
       "│ der-32b-in ┆           ┆ 3         ┆ 2         ┆   ┆           ┆         ┆           ┆           │\n",
       "│ struct     ┆           ┆           ┆           ┆   ┆           ┆         ┆           ┆           │\n",
       "│ qwq-32b    ┆ 935.41877 ┆ 873.24118 ┆ 1012.0780 ┆ … ┆ 2.521827  ┆ 298     ┆ 0.008463  ┆ 0.000007  │\n",
       "│            ┆ 2         ┆           ┆ 56        ┆   ┆           ┆         ┆           ┆           │\n",
       "└────────────┴───────────┴───────────┴───────────┴───┴───────────┴─────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_votes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914dc5de",
   "metadata": {},
   "source": [
    "## Pipeline avec un ranker alternatif\n",
    "\n",
    "Utilisation du Ranker `MaximumLikelihood`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33484b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since ministere-culture/comparia-votes couldn't be found on the Hugging Face Hub (offline mode is enabled).\n",
      "Found the latest cached dataset configuration 'default' at /home/jupyterhub-users/shared/projet_comparia/huggingface_hub/ministere-culture___comparia-votes/default/0.0.0/679f56e14f413546403b3468d717c4417e394326 (last modified on Mon Jul 28 10:06:44 2025).\n",
      "Using the latest cached version of the dataset since ministere-culture/comparia-conversations couldn't be found on the Hugging Face Hub (offline mode is enabled).\n",
      "Found the latest cached dataset configuration 'default' at /home/jupyterhub-users/shared/projet_comparia/huggingface_hub/ministere-culture___comparia-conversations/default/0.0.0/dc40af6af1c14e68bf39d55f6e1573d2d6582f19 (last modified on Wed Jun  4 17:40:30 2025).\n",
      "Using the latest cached version of the dataset since ministere-culture/comparia-reactions couldn't be found on the Hugging Face Hub (offline mode is enabled).\n",
      "Found the latest cached dataset configuration 'default' at /home/jupyterhub-users/shared/projet_comparia/huggingface_hub/ministere-culture___comparia-reactions/default/0.0.0/80befa851337d9f295096cef3d100b40d220dc07 (last modified on Mon Jul 28 10:06:54 2025).\n",
      "Using the latest cached version of the dataset since ministere-culture/comparia-conversations couldn't be found on the Hugging Face Hub (offline mode is enabled).\n",
      "Found the latest cached dataset configuration 'default' at /home/jupyterhub-users/shared/projet_comparia/huggingface_hub/ministere-culture___comparia-conversations/default/0.0.0/dc40af6af1c14e68bf39d55f6e1573d2d6582f19 (last modified on Wed Jun  4 17:40:30 2025).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final votes dataset contains 55617 conversations pairs.\n",
      "Reactions data originally contains 22993 conversations pairs.\n",
      "Final reactions dataset contains 21244 conversations pairs.\n"
     ]
    }
   ],
   "source": [
    "pipeline = RankingPipeline(\n",
    "    method=\"ml\",\n",
    "    include_votes=True,\n",
    "    include_reactions=True,\n",
    "    mean_how=\"token\",\n",
    "    bootstrap_samples=5,\n",
    "    batch=False,\n",
    "    export_path=Path(\"output\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19d46e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing bootstrap scores from a sample of 76861 matches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing bootstrap samples: 100%|██████████| 5/5 [00:00<00:00,  6.09it/s]\n"
     ]
    }
   ],
   "source": [
    "scores_ml = pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76592e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since ministere-culture/comparia-votes couldn't be found on the Hugging Face Hub (offline mode is enabled).\n",
      "Found the latest cached dataset configuration 'default' at /home/jupyterhub-users/shared/projet_comparia/huggingface_hub/ministere-culture___comparia-votes/default/0.0.0/679f56e14f413546403b3468d717c4417e394326 (last modified on Mon Jul 28 10:06:44 2025).\n",
      "Using the latest cached version of the dataset since ministere-culture/comparia-conversations couldn't be found on the Hugging Face Hub (offline mode is enabled).\n",
      "Found the latest cached dataset configuration 'default' at /home/jupyterhub-users/shared/projet_comparia/huggingface_hub/ministere-culture___comparia-conversations/default/0.0.0/dc40af6af1c14e68bf39d55f6e1573d2d6582f19 (last modified on Wed Jun  4 17:40:30 2025).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final votes dataset contains 55617 conversations pairs.\n",
      "Computing bootstrap scores from a sample of 55617 matches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing bootstrap samples: 100%|██████████| 5/5 [00:00<00:00,  7.98it/s]\n"
     ]
    }
   ],
   "source": [
    "pipeline = RankingPipeline(\n",
    "    method=\"ml\",\n",
    "    include_votes=True,\n",
    "    include_reactions=False,\n",
    "    mean_how=\"token\",\n",
    "    bootstrap_samples=5,\n",
    "    batch=False,\n",
    ")\n",
    "\n",
    "scores_ml_votes = pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66711d3",
   "metadata": {},
   "source": [
    "## Comparaison des différentes méthodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "159fa36a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (52, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model_name</th><th>score_elo</th><th>score_elo_votes</th><th>score_ml</th><th>score_ml_votes</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;Yi-1.5-9B-Chat&quot;</td><td>820.155853</td><td>null</td><td>813.571738</td><td>755.436748</td></tr><tr><td>&quot;aya-expanse-8b&quot;</td><td>1050.031121</td><td>940.817651</td><td>1005.933372</td><td>1002.482744</td></tr><tr><td>&quot;c4ai-command-r-08-2024&quot;</td><td>955.966302</td><td>949.314328</td><td>953.636286</td><td>954.025745</td></tr><tr><td>&quot;chocolatine-14b-instruct-dpo-v…</td><td>765.275949</td><td>null</td><td>789.4</td><td>771.642505</td></tr><tr><td>&quot;chocolatine-2-14b-instruct-v2.…</td><td>863.132705</td><td>807.375319</td><td>848.395798</td><td>852.66589</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;qwen2-7b-instruct&quot;</td><td>780.921448</td><td>null</td><td>746.920477</td><td>770.749264</td></tr><tr><td>&quot;qwen2.5-32b-instruct&quot;</td><td>940.966675</td><td>null</td><td>998.703232</td><td>1002.393794</td></tr><tr><td>&quot;qwen2.5-7b-instruct&quot;</td><td>966.826827</td><td>946.331531</td><td>956.055307</td><td>978.358183</td></tr><tr><td>&quot;qwen2.5-coder-32b-instruct&quot;</td><td>946.653857</td><td>858.68396</td><td>952.915885</td><td>962.0599</td></tr><tr><td>&quot;qwq-32b&quot;</td><td>984.572892</td><td>935.418772</td><td>976.650091</td><td>972.870475</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (52, 5)\n",
       "┌─────────────────────────────────┬─────────────┬─────────────────┬─────────────┬────────────────┐\n",
       "│ model_name                      ┆ score_elo   ┆ score_elo_votes ┆ score_ml    ┆ score_ml_votes │\n",
       "│ ---                             ┆ ---         ┆ ---             ┆ ---         ┆ ---            │\n",
       "│ str                             ┆ f64         ┆ f64             ┆ f64         ┆ f64            │\n",
       "╞═════════════════════════════════╪═════════════╪═════════════════╪═════════════╪════════════════╡\n",
       "│ Yi-1.5-9B-Chat                  ┆ 820.155853  ┆ null            ┆ 813.571738  ┆ 755.436748     │\n",
       "│ aya-expanse-8b                  ┆ 1050.031121 ┆ 940.817651      ┆ 1005.933372 ┆ 1002.482744    │\n",
       "│ c4ai-command-r-08-2024          ┆ 955.966302  ┆ 949.314328      ┆ 953.636286  ┆ 954.025745     │\n",
       "│ chocolatine-14b-instruct-dpo-v… ┆ 765.275949  ┆ null            ┆ 789.4       ┆ 771.642505     │\n",
       "│ chocolatine-2-14b-instruct-v2.… ┆ 863.132705  ┆ 807.375319      ┆ 848.395798  ┆ 852.66589      │\n",
       "│ …                               ┆ …           ┆ …               ┆ …           ┆ …              │\n",
       "│ qwen2-7b-instruct               ┆ 780.921448  ┆ null            ┆ 746.920477  ┆ 770.749264     │\n",
       "│ qwen2.5-32b-instruct            ┆ 940.966675  ┆ null            ┆ 998.703232  ┆ 1002.393794    │\n",
       "│ qwen2.5-7b-instruct             ┆ 966.826827  ┆ 946.331531      ┆ 956.055307  ┆ 978.358183     │\n",
       "│ qwen2.5-coder-32b-instruct      ┆ 946.653857  ┆ 858.68396       ┆ 952.915885  ┆ 962.0599       │\n",
       "│ qwq-32b                         ┆ 984.572892  ┆ 935.418772      ┆ 976.650091  ┆ 972.870475     │\n",
       "└─────────────────────────────────┴─────────────┴─────────────────┴─────────────┴────────────────┘"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "pl.concat(\n",
    "    [\n",
    "        scores.select(\"model_name\", \"median\").rename(mapping={\"median\": \"score_elo\"}),\n",
    "        scores_votes.select(\"model_name\", \"median\").rename(mapping={\"median\": \"score_elo_votes\"}),\n",
    "        scores_ml.select(\"model_name\", \"median\").rename(mapping={\"median\": \"score_ml\"}),\n",
    "        scores_ml_votes.select(\"model_name\", \"median\").rename(mapping={\"median\": \"score_ml_votes\"}),\n",
    "    ],\n",
    "    how=\"align\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "953a2437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-6228dd39b63a4807b741a2f8f1eb50d3.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-6228dd39b63a4807b741a2f8f1eb50d3.vega-embed details,\n",
       "  #altair-viz-6228dd39b63a4807b741a2f8f1eb50d3.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-6228dd39b63a4807b741a2f8f1eb50d3\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-6228dd39b63a4807b741a2f8f1eb50d3\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-6228dd39b63a4807b741a2f8f1eb50d3\");\n",
       "    }\n",
       "\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      let deps = [\"vega-embed\"];\n",
       "      require(deps, displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-a0d001d462656ce12ff76e0886e63a14\"}, \"mark\": {\"type\": \"circle\", \"size\": 80}, \"encoding\": {\"color\": {\"field\": \"score_type\", \"title\": \"Score Type\", \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"model_name\", \"type\": \"nominal\"}, {\"field\": \"score\", \"type\": \"quantitative\"}, {\"field\": \"score_type\", \"type\": \"nominal\"}], \"x\": {\"field\": \"model_name\", \"sort\": [\"gemma-3-27b\", \"deepseek-v3-chat\", \"gemma-3-12b\", \"gemini-1.5-pro-001\", \"gemini-2.0-flash-001\", \"command-a\", \"grok-3-mini-beta\", \"gemini-2.0-flash-exp\", \"llama-4-scout\", \"claude-3-7-sonnet\", \"deepseek-v3-0324\", \"gemma-3-4b\", \"llama-3.1-nemotron-70b-instruct\", \"gpt-4.1-mini\", \"deepseek-r1\", \"aya-expanse-8b\", \"gemini-1.5-pro-002\", \"o3-mini\", \"llama-3.1-405b\", \"gpt-4.1-nano\", \"mistral-large-2411\", \"llama-3.1-70b\", \"gemma-2-27b-it-q8\", \"gemma-2-9b-it\", \"o4-mini\", \"llama-3.3-70b\", \"mistral-small-24b-instruct-2501\", \"phi-4\", \"jamba-1.5-large\", \"mistral-small-3.1-24b\", \"ministral-8b-instruct-2410\", \"qwq-32b\", \"llama-3.1-8b\", \"claude-3-5-sonnet-v2\", \"gpt-4o-mini-2024-07-18\", \"gpt-4o-2024-08-06\", \"hermes-3-llama-3.1-405b\", \"qwen2.5-7b-instruct\", \"mistral-saba\", \"deepseek-r1-distill-llama-70b\", \"c4ai-command-r-08-2024\", \"qwen2.5-coder-32b-instruct\", \"qwen2.5-32b-instruct\", \"lfm-40b\", \"mixtral-8x7b-instruct-v0.1\", \"mistral-nemo-2407\", \"phi-3.5-mini-instruct\", \"mixtral-8x22b-instruct-v0.1\", \"chocolatine-2-14b-instruct-v2.0.3-q8\", \"Yi-1.5-9B-Chat\", \"qwen2-7b-instruct\", \"chocolatine-14b-instruct-dpo-v1.2-q4\"], \"title\": \"model_name\", \"type\": \"nominal\"}, \"y\": {\"field\": \"score\", \"scale\": {\"domain\": [500, 1300]}, \"title\": \"Score\", \"type\": \"quantitative\"}}, \"height\": 400, \"width\": 600, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-a0d001d462656ce12ff76e0886e63a14\": [{\"model_name\": \"gemma-3-27b\", \"score_type\": \"Elo score (all data)\", \"score\": 1170.0464621307258}, {\"model_name\": \"deepseek-v3-chat\", \"score_type\": \"Elo score (all data)\", \"score\": 1137.8302495602277}, {\"model_name\": \"gemma-3-12b\", \"score_type\": \"Elo score (all data)\", \"score\": 1133.5666063119277}, {\"model_name\": \"gemini-1.5-pro-001\", \"score_type\": \"Elo score (all data)\", \"score\": 1132.4719675621654}, {\"model_name\": \"gemini-2.0-flash-001\", \"score_type\": \"Elo score (all data)\", \"score\": 1127.9756653819877}, {\"model_name\": \"command-a\", \"score_type\": \"Elo score (all data)\", \"score\": 1120.8078928575328}, {\"model_name\": \"grok-3-mini-beta\", \"score_type\": \"Elo score (all data)\", \"score\": 1112.5667093250154}, {\"model_name\": \"gemini-2.0-flash-exp\", \"score_type\": \"Elo score (all data)\", \"score\": 1095.2930293922661}, {\"model_name\": \"llama-4-scout\", \"score_type\": \"Elo score (all data)\", \"score\": 1085.2157675447727}, {\"model_name\": \"claude-3-7-sonnet\", \"score_type\": \"Elo score (all data)\", \"score\": 1077.1071302686057}, {\"model_name\": \"deepseek-v3-0324\", \"score_type\": \"Elo score (all data)\", \"score\": 1075.8965477858737}, {\"model_name\": \"gemma-3-4b\", \"score_type\": \"Elo score (all data)\", \"score\": 1072.9342394957098}, {\"model_name\": \"llama-3.1-nemotron-70b-instruct\", \"score_type\": \"Elo score (all data)\", \"score\": 1062.9736875283795}, {\"model_name\": \"gpt-4.1-mini\", \"score_type\": \"Elo score (all data)\", \"score\": 1055.6927308204924}, {\"model_name\": \"deepseek-r1\", \"score_type\": \"Elo score (all data)\", \"score\": 1052.2393056507763}, {\"model_name\": \"aya-expanse-8b\", \"score_type\": \"Elo score (all data)\", \"score\": 1050.0311205639641}, {\"model_name\": \"gemini-1.5-pro-002\", \"score_type\": \"Elo score (all data)\", \"score\": 1049.7925685706289}, {\"model_name\": \"o3-mini\", \"score_type\": \"Elo score (all data)\", \"score\": 1049.7166644143938}, {\"model_name\": \"llama-3.1-405b\", \"score_type\": \"Elo score (all data)\", \"score\": 1038.595378835994}, {\"model_name\": \"gpt-4.1-nano\", \"score_type\": \"Elo score (all data)\", \"score\": 1034.1876022425795}, {\"model_name\": \"mistral-large-2411\", \"score_type\": \"Elo score (all data)\", \"score\": 1034.1084220045814}, {\"model_name\": \"llama-3.1-70b\", \"score_type\": \"Elo score (all data)\", \"score\": 1030.9115035935731}, {\"model_name\": \"gemma-2-27b-it-q8\", \"score_type\": \"Elo score (all data)\", \"score\": 1030.0233002303557}, {\"model_name\": \"gemma-2-9b-it\", \"score_type\": \"Elo score (all data)\", \"score\": 1028.5735023709062}, {\"model_name\": \"o4-mini\", \"score_type\": \"Elo score (all data)\", \"score\": 1023.7277275737342}, {\"model_name\": \"llama-3.3-70b\", \"score_type\": \"Elo score (all data)\", \"score\": 1011.7457648140871}, {\"model_name\": \"mistral-small-24b-instruct-2501\", \"score_type\": \"Elo score (all data)\", \"score\": 1000.7726556859005}, {\"model_name\": \"phi-4\", \"score_type\": \"Elo score (all data)\", \"score\": 1000.0132575478493}, {\"model_name\": \"jamba-1.5-large\", \"score_type\": \"Elo score (all data)\", \"score\": 993.0777253269345}, {\"model_name\": \"mistral-small-3.1-24b\", \"score_type\": \"Elo score (all data)\", \"score\": 992.4097409145579}, {\"model_name\": \"ministral-8b-instruct-2410\", \"score_type\": \"Elo score (all data)\", \"score\": 992.3337674210221}, {\"model_name\": \"qwq-32b\", \"score_type\": \"Elo score (all data)\", \"score\": 984.5728917324278}, {\"model_name\": \"llama-3.1-8b\", \"score_type\": \"Elo score (all data)\", \"score\": 983.0214140096492}, {\"model_name\": \"claude-3-5-sonnet-v2\", \"score_type\": \"Elo score (all data)\", \"score\": 976.7185107174773}, {\"model_name\": \"gpt-4o-mini-2024-07-18\", \"score_type\": \"Elo score (all data)\", \"score\": 974.661003534892}, {\"model_name\": \"gpt-4o-2024-08-06\", \"score_type\": \"Elo score (all data)\", \"score\": 970.69356990639}, {\"model_name\": \"hermes-3-llama-3.1-405b\", \"score_type\": \"Elo score (all data)\", \"score\": 969.4000860796588}, {\"model_name\": \"qwen2.5-7b-instruct\", \"score_type\": \"Elo score (all data)\", \"score\": 966.8268270257432}, {\"model_name\": \"mistral-saba\", \"score_type\": \"Elo score (all data)\", \"score\": 964.3017578329532}, {\"model_name\": \"deepseek-r1-distill-llama-70b\", \"score_type\": \"Elo score (all data)\", \"score\": 956.5842341044297}, {\"model_name\": \"c4ai-command-r-08-2024\", \"score_type\": \"Elo score (all data)\", \"score\": 955.9663019085807}, {\"model_name\": \"qwen2.5-coder-32b-instruct\", \"score_type\": \"Elo score (all data)\", \"score\": 946.6538572135015}, {\"model_name\": \"qwen2.5-32b-instruct\", \"score_type\": \"Elo score (all data)\", \"score\": 940.9666750208979}, {\"model_name\": \"lfm-40b\", \"score_type\": \"Elo score (all data)\", \"score\": 918.3659147295266}, {\"model_name\": \"mixtral-8x7b-instruct-v0.1\", \"score_type\": \"Elo score (all data)\", \"score\": 918.1613115662735}, {\"model_name\": \"mistral-nemo-2407\", \"score_type\": \"Elo score (all data)\", \"score\": 900.1510165965757}, {\"model_name\": \"phi-3.5-mini-instruct\", \"score_type\": \"Elo score (all data)\", \"score\": 877.7638842903356}, {\"model_name\": \"mixtral-8x22b-instruct-v0.1\", \"score_type\": \"Elo score (all data)\", \"score\": 870.9218025386775}, {\"model_name\": \"chocolatine-2-14b-instruct-v2.0.3-q8\", \"score_type\": \"Elo score (all data)\", \"score\": 863.1327045850411}, {\"model_name\": \"Yi-1.5-9B-Chat\", \"score_type\": \"Elo score (all data)\", \"score\": 820.1558526488642}, {\"model_name\": \"qwen2-7b-instruct\", \"score_type\": \"Elo score (all data)\", \"score\": 780.9214477476031}, {\"model_name\": \"chocolatine-14b-instruct-dpo-v1.2-q4\", \"score_type\": \"Elo score (all data)\", \"score\": 765.2759485691982}, {\"model_name\": \"gemma-3-27b\", \"score_type\": \"Elo score (votes data)\", \"score\": 1115.0920966176081}, {\"model_name\": \"deepseek-v3-chat\", \"score_type\": \"Elo score (votes data)\", \"score\": 1101.064299673856}, {\"model_name\": \"gemma-3-12b\", \"score_type\": \"Elo score (votes data)\", \"score\": 1078.8882052664821}, {\"model_name\": \"gemini-1.5-pro-001\", \"score_type\": \"Elo score (votes data)\", \"score\": 1009.6872367820097}, {\"model_name\": \"gemini-2.0-flash-001\", \"score_type\": \"Elo score (votes data)\", \"score\": 1098.6293450600733}, {\"model_name\": \"command-a\", \"score_type\": \"Elo score (votes data)\", \"score\": 1116.965259896098}, {\"model_name\": \"grok-3-mini-beta\", \"score_type\": \"Elo score (votes data)\", \"score\": 1065.641609182302}, {\"model_name\": \"gemini-2.0-flash-exp\", \"score_type\": \"Elo score (votes data)\", \"score\": 1184.9466753553063}, {\"model_name\": \"llama-4-scout\", \"score_type\": \"Elo score (votes data)\", \"score\": 1038.6092296861684}, {\"model_name\": \"claude-3-7-sonnet\", \"score_type\": \"Elo score (votes data)\", \"score\": 1086.6324011174534}, {\"model_name\": \"deepseek-v3-0324\", \"score_type\": \"Elo score (votes data)\", \"score\": 1150.8638268341806}, {\"model_name\": \"gemma-3-4b\", \"score_type\": \"Elo score (votes data)\", \"score\": 1094.0733540110775}, {\"model_name\": \"llama-3.1-nemotron-70b-instruct\", \"score_type\": \"Elo score (votes data)\", \"score\": 1050.9845215374266}, {\"model_name\": \"gpt-4.1-mini\", \"score_type\": \"Elo score (votes data)\", \"score\": 1081.800637835067}, {\"model_name\": \"deepseek-r1\", \"score_type\": \"Elo score (votes data)\", \"score\": 1074.2982185773906}, {\"model_name\": \"aya-expanse-8b\", \"score_type\": \"Elo score (votes data)\", \"score\": 940.817651492033}, {\"model_name\": \"gemini-1.5-pro-002\", \"score_type\": \"Elo score (votes data)\", \"score\": 1032.2646745913457}, {\"model_name\": \"o3-mini\", \"score_type\": \"Elo score (votes data)\", \"score\": 1043.891247453272}, {\"model_name\": \"llama-3.1-405b\", \"score_type\": \"Elo score (votes data)\", \"score\": 1022.4709137063735}, {\"model_name\": \"gpt-4.1-nano\", \"score_type\": \"Elo score (votes data)\", \"score\": 999.2674833247349}, {\"model_name\": \"mistral-large-2411\", \"score_type\": \"Elo score (votes data)\", \"score\": 1020.634188300651}, {\"model_name\": \"llama-3.1-70b\", \"score_type\": \"Elo score (votes data)\", \"score\": 1000.8557121049191}, {\"model_name\": \"gemma-2-27b-it-q8\", \"score_type\": \"Elo score (votes data)\", \"score\": 933.0611606486199}, {\"model_name\": \"gemma-2-9b-it\", \"score_type\": \"Elo score (votes data)\", \"score\": 958.4798449053068}, {\"model_name\": \"o4-mini\", \"score_type\": \"Elo score (votes data)\", \"score\": 1083.7244775146569}, {\"model_name\": \"llama-3.3-70b\", \"score_type\": \"Elo score (votes data)\", \"score\": 976.5618948213632}, {\"model_name\": \"mistral-small-24b-instruct-2501\", \"score_type\": \"Elo score (votes data)\", \"score\": 977.8832882186872}, {\"model_name\": \"phi-4\", \"score_type\": \"Elo score (votes data)\", \"score\": 1030.0292152162406}, {\"model_name\": \"jamba-1.5-large\", \"score_type\": \"Elo score (votes data)\", \"score\": 1069.5813974806617}, {\"model_name\": \"mistral-small-3.1-24b\", \"score_type\": \"Elo score (votes data)\", \"score\": 1026.547810267163}, {\"model_name\": \"ministral-8b-instruct-2410\", \"score_type\": \"Elo score (votes data)\", \"score\": 949.1102323702058}, {\"model_name\": \"qwq-32b\", \"score_type\": \"Elo score (votes data)\", \"score\": 935.4187721158391}, {\"model_name\": \"llama-3.1-8b\", \"score_type\": \"Elo score (votes data)\", \"score\": 971.1159380476853}, {\"model_name\": \"claude-3-5-sonnet-v2\", \"score_type\": \"Elo score (votes data)\", \"score\": 979.6122972983841}, {\"model_name\": \"gpt-4o-mini-2024-07-18\", \"score_type\": \"Elo score (votes data)\", \"score\": 1004.5130532302081}, {\"model_name\": \"gpt-4o-2024-08-06\", \"score_type\": \"Elo score (votes data)\", \"score\": 1027.5477099291022}, {\"model_name\": \"hermes-3-llama-3.1-405b\", \"score_type\": \"Elo score (votes data)\", \"score\": 890.4926728900992}, {\"model_name\": \"qwen2.5-7b-instruct\", \"score_type\": \"Elo score (votes data)\", \"score\": 946.3315307263165}, {\"model_name\": \"mistral-saba\", \"score_type\": \"Elo score (votes data)\", \"score\": 965.0635129407218}, {\"model_name\": \"deepseek-r1-distill-llama-70b\", \"score_type\": \"Elo score (votes data)\", \"score\": 996.2864314025464}, {\"model_name\": \"c4ai-command-r-08-2024\", \"score_type\": \"Elo score (votes data)\", \"score\": 949.3143280907489}, {\"model_name\": \"qwen2.5-coder-32b-instruct\", \"score_type\": \"Elo score (votes data)\", \"score\": 858.6839602317594}, {\"model_name\": \"qwen2.5-32b-instruct\", \"score_type\": \"Elo score (votes data)\", \"score\": null}, {\"model_name\": \"lfm-40b\", \"score_type\": \"Elo score (votes data)\", \"score\": 863.6228407596884}, {\"model_name\": \"mixtral-8x7b-instruct-v0.1\", \"score_type\": \"Elo score (votes data)\", \"score\": 872.8888104561878}, {\"model_name\": \"mistral-nemo-2407\", \"score_type\": \"Elo score (votes data)\", \"score\": 799.8507729850655}, {\"model_name\": \"phi-3.5-mini-instruct\", \"score_type\": \"Elo score (votes data)\", \"score\": 931.243000989327}, {\"model_name\": \"mixtral-8x22b-instruct-v0.1\", \"score_type\": \"Elo score (votes data)\", \"score\": 791.3700630111557}, {\"model_name\": \"chocolatine-2-14b-instruct-v2.0.3-q8\", \"score_type\": \"Elo score (votes data)\", \"score\": 807.3753185478758}, {\"model_name\": \"Yi-1.5-9B-Chat\", \"score_type\": \"Elo score (votes data)\", \"score\": null}, {\"model_name\": \"qwen2-7b-instruct\", \"score_type\": \"Elo score (votes data)\", \"score\": null}, {\"model_name\": \"chocolatine-14b-instruct-dpo-v1.2-q4\", \"score_type\": \"Elo score (votes data)\", \"score\": null}, {\"model_name\": \"gemma-3-27b\", \"score_type\": \"BT score (all data)\", \"score\": 1127.0979395176664}, {\"model_name\": \"deepseek-v3-chat\", \"score_type\": \"BT score (all data)\", \"score\": 1111.057882178421}, {\"model_name\": \"gemma-3-12b\", \"score_type\": \"BT score (all data)\", \"score\": 1108.27801028091}, {\"model_name\": \"gemini-1.5-pro-001\", \"score_type\": \"BT score (all data)\", \"score\": 1087.4889783299259}, {\"model_name\": \"gemini-2.0-flash-001\", \"score_type\": \"BT score (all data)\", \"score\": 1119.749316846855}, {\"model_name\": \"command-a\", \"score_type\": \"BT score (all data)\", \"score\": 1108.4592019898012}, {\"model_name\": \"grok-3-mini-beta\", \"score_type\": \"BT score (all data)\", \"score\": 1070.4379974990684}, {\"model_name\": \"gemini-2.0-flash-exp\", \"score_type\": \"BT score (all data)\", \"score\": 1141.0016279572135}, {\"model_name\": \"llama-4-scout\", \"score_type\": \"BT score (all data)\", \"score\": 1038.2196507112228}, {\"model_name\": \"claude-3-7-sonnet\", \"score_type\": \"BT score (all data)\", \"score\": 1093.419500578569}, {\"model_name\": \"deepseek-v3-0324\", \"score_type\": \"BT score (all data)\", \"score\": 1098.5085538505753}, {\"model_name\": \"gemma-3-4b\", \"score_type\": \"BT score (all data)\", \"score\": 1072.2570948321315}, {\"model_name\": \"llama-3.1-nemotron-70b-instruct\", \"score_type\": \"BT score (all data)\", \"score\": 1074.0004361716385}, {\"model_name\": \"gpt-4.1-mini\", \"score_type\": \"BT score (all data)\", \"score\": 1069.9977691311444}, {\"model_name\": \"deepseek-r1\", \"score_type\": \"BT score (all data)\", \"score\": 1046.733269900499}, {\"model_name\": \"aya-expanse-8b\", \"score_type\": \"BT score (all data)\", \"score\": 1005.9333721542027}, {\"model_name\": \"gemini-1.5-pro-002\", \"score_type\": \"BT score (all data)\", \"score\": 1049.2610000362324}, {\"model_name\": \"o3-mini\", \"score_type\": \"BT score (all data)\", \"score\": 1014.3859988163214}, {\"model_name\": \"llama-3.1-405b\", \"score_type\": \"BT score (all data)\", \"score\": 1014.6009918549018}, {\"model_name\": \"gpt-4.1-nano\", \"score_type\": \"BT score (all data)\", \"score\": 995.103874436285}, {\"model_name\": \"mistral-large-2411\", \"score_type\": \"BT score (all data)\", \"score\": 1042.1555650833811}, {\"model_name\": \"llama-3.1-70b\", \"score_type\": \"BT score (all data)\", \"score\": 1004.0341923125818}, {\"model_name\": \"gemma-2-27b-it-q8\", \"score_type\": \"BT score (all data)\", \"score\": 1021.3188270972613}, {\"model_name\": \"gemma-2-9b-it\", \"score_type\": \"BT score (all data)\", \"score\": 983.3204804831505}, {\"model_name\": \"o4-mini\", \"score_type\": \"BT score (all data)\", \"score\": 1030.540089193577}, {\"model_name\": \"llama-3.3-70b\", \"score_type\": \"BT score (all data)\", \"score\": 1011.4858931259165}, {\"model_name\": \"mistral-small-24b-instruct-2501\", \"score_type\": \"BT score (all data)\", \"score\": 1016.9920871789433}, {\"model_name\": \"phi-4\", \"score_type\": \"BT score (all data)\", \"score\": 998.0347564333057}, {\"model_name\": \"jamba-1.5-large\", \"score_type\": \"BT score (all data)\", \"score\": 994.1030222236051}, {\"model_name\": \"mistral-small-3.1-24b\", \"score_type\": \"BT score (all data)\", \"score\": 1032.0515447106634}, {\"model_name\": \"ministral-8b-instruct-2410\", \"score_type\": \"BT score (all data)\", \"score\": 990.5421488539963}, {\"model_name\": \"qwq-32b\", \"score_type\": \"BT score (all data)\", \"score\": 976.6500907630782}, {\"model_name\": \"llama-3.1-8b\", \"score_type\": \"BT score (all data)\", \"score\": 937.7835300292027}, {\"model_name\": \"claude-3-5-sonnet-v2\", \"score_type\": \"BT score (all data)\", \"score\": 996.2813405390015}, {\"model_name\": \"gpt-4o-mini-2024-07-18\", \"score_type\": \"BT score (all data)\", \"score\": 1013.4383096684709}, {\"model_name\": \"gpt-4o-2024-08-06\", \"score_type\": \"BT score (all data)\", \"score\": 992.7350919877103}, {\"model_name\": \"hermes-3-llama-3.1-405b\", \"score_type\": \"BT score (all data)\", \"score\": 966.3131168446008}, {\"model_name\": \"qwen2.5-7b-instruct\", \"score_type\": \"BT score (all data)\", \"score\": 956.0553068489579}, {\"model_name\": \"mistral-saba\", \"score_type\": \"BT score (all data)\", \"score\": 1008.230562044557}, {\"model_name\": \"deepseek-r1-distill-llama-70b\", \"score_type\": \"BT score (all data)\", \"score\": 986.3637718288322}, {\"model_name\": \"c4ai-command-r-08-2024\", \"score_type\": \"BT score (all data)\", \"score\": 953.6362859023174}, {\"model_name\": \"qwen2.5-coder-32b-instruct\", \"score_type\": \"BT score (all data)\", \"score\": 952.915884837783}, {\"model_name\": \"qwen2.5-32b-instruct\", \"score_type\": \"BT score (all data)\", \"score\": 998.7032320120048}, {\"model_name\": \"lfm-40b\", \"score_type\": \"BT score (all data)\", \"score\": 916.1203022454964}, {\"model_name\": \"mixtral-8x7b-instruct-v0.1\", \"score_type\": \"BT score (all data)\", \"score\": 917.8862483457857}, {\"model_name\": \"mistral-nemo-2407\", \"score_type\": \"BT score (all data)\", \"score\": 883.3655768526012}, {\"model_name\": \"phi-3.5-mini-instruct\", \"score_type\": \"BT score (all data)\", \"score\": 893.7307130788022}, {\"model_name\": \"mixtral-8x22b-instruct-v0.1\", \"score_type\": \"BT score (all data)\", \"score\": 872.6474957874659}, {\"model_name\": \"chocolatine-2-14b-instruct-v2.0.3-q8\", \"score_type\": \"BT score (all data)\", \"score\": 848.3957978757174}, {\"model_name\": \"Yi-1.5-9B-Chat\", \"score_type\": \"BT score (all data)\", \"score\": 813.5717381444416}, {\"model_name\": \"qwen2-7b-instruct\", \"score_type\": \"BT score (all data)\", \"score\": 746.9204772374851}, {\"model_name\": \"chocolatine-14b-instruct-dpo-v1.2-q4\", \"score_type\": \"BT score (all data)\", \"score\": 789.4000002169539}, {\"model_name\": \"gemma-3-27b\", \"score_type\": \"BT score (votes data)\", \"score\": 1113.919370319289}, {\"model_name\": \"deepseek-v3-chat\", \"score_type\": \"BT score (votes data)\", \"score\": 1103.7373430995954}, {\"model_name\": \"gemma-3-12b\", \"score_type\": \"BT score (votes data)\", \"score\": 1105.5917546433302}, {\"model_name\": \"gemini-1.5-pro-001\", \"score_type\": \"BT score (votes data)\", \"score\": 1094.4552941653508}, {\"model_name\": \"gemini-2.0-flash-001\", \"score_type\": \"BT score (votes data)\", \"score\": 1131.0107851900702}, {\"model_name\": \"command-a\", \"score_type\": \"BT score (votes data)\", \"score\": 1114.9850261036372}, {\"model_name\": \"grok-3-mini-beta\", \"score_type\": \"BT score (votes data)\", \"score\": 1062.4600772425654}, {\"model_name\": \"gemini-2.0-flash-exp\", \"score_type\": \"BT score (votes data)\", \"score\": 1131.2040536768047}, {\"model_name\": \"llama-4-scout\", \"score_type\": \"BT score (votes data)\", \"score\": 1034.2467881691557}, {\"model_name\": \"claude-3-7-sonnet\", \"score_type\": \"BT score (votes data)\", \"score\": 1081.632957214719}, {\"model_name\": \"deepseek-v3-0324\", \"score_type\": \"BT score (votes data)\", \"score\": 1095.6735777339}, {\"model_name\": \"gemma-3-4b\", \"score_type\": \"BT score (votes data)\", \"score\": 1076.325289877907}, {\"model_name\": \"llama-3.1-nemotron-70b-instruct\", \"score_type\": \"BT score (votes data)\", \"score\": 1078.276889570925}, {\"model_name\": \"gpt-4.1-mini\", \"score_type\": \"BT score (votes data)\", \"score\": 1060.5204853352818}, {\"model_name\": \"deepseek-r1\", \"score_type\": \"BT score (votes data)\", \"score\": 1035.5130744093651}, {\"model_name\": \"aya-expanse-8b\", \"score_type\": \"BT score (votes data)\", \"score\": 1002.482743545027}, {\"model_name\": \"gemini-1.5-pro-002\", \"score_type\": \"BT score (votes data)\", \"score\": 1046.4569759592678}, {\"model_name\": \"o3-mini\", \"score_type\": \"BT score (votes data)\", \"score\": 1010.2599916604985}, {\"model_name\": \"llama-3.1-405b\", \"score_type\": \"BT score (votes data)\", \"score\": 1023.6283565343776}, {\"model_name\": \"gpt-4.1-nano\", \"score_type\": \"BT score (votes data)\", \"score\": 996.4015590407193}, {\"model_name\": \"mistral-large-2411\", \"score_type\": \"BT score (votes data)\", \"score\": 1050.0686518720274}, {\"model_name\": \"llama-3.1-70b\", \"score_type\": \"BT score (votes data)\", \"score\": 1019.2879380115559}, {\"model_name\": \"gemma-2-27b-it-q8\", \"score_type\": \"BT score (votes data)\", \"score\": 1048.7912754042113}, {\"model_name\": \"gemma-2-9b-it\", \"score_type\": \"BT score (votes data)\", \"score\": 987.1743044515848}, {\"model_name\": \"o4-mini\", \"score_type\": \"BT score (votes data)\", \"score\": 1012.4126310191839}, {\"model_name\": \"llama-3.3-70b\", \"score_type\": \"BT score (votes data)\", \"score\": 1008.1688101920107}, {\"model_name\": \"mistral-small-24b-instruct-2501\", \"score_type\": \"BT score (votes data)\", \"score\": 1021.156054741666}, {\"model_name\": \"phi-4\", \"score_type\": \"BT score (votes data)\", \"score\": 1003.1079058856641}, {\"model_name\": \"jamba-1.5-large\", \"score_type\": \"BT score (votes data)\", \"score\": 983.1627492222641}, {\"model_name\": \"mistral-small-3.1-24b\", \"score_type\": \"BT score (votes data)\", \"score\": 1034.8532166323794}, {\"model_name\": \"ministral-8b-instruct-2410\", \"score_type\": \"BT score (votes data)\", \"score\": 996.0162142456902}, {\"model_name\": \"qwq-32b\", \"score_type\": \"BT score (votes data)\", \"score\": 972.8704750807891}, {\"model_name\": \"llama-3.1-8b\", \"score_type\": \"BT score (votes data)\", \"score\": 935.510499143071}, {\"model_name\": \"claude-3-5-sonnet-v2\", \"score_type\": \"BT score (votes data)\", \"score\": 996.5396201961262}, {\"model_name\": \"gpt-4o-mini-2024-07-18\", \"score_type\": \"BT score (votes data)\", \"score\": 1012.7061627886942}, {\"model_name\": \"gpt-4o-2024-08-06\", \"score_type\": \"BT score (votes data)\", \"score\": 989.5790442866204}, {\"model_name\": \"hermes-3-llama-3.1-405b\", \"score_type\": \"BT score (votes data)\", \"score\": 976.0955784258989}, {\"model_name\": \"qwen2.5-7b-instruct\", \"score_type\": \"BT score (votes data)\", \"score\": 978.3581825088135}, {\"model_name\": \"mistral-saba\", \"score_type\": \"BT score (votes data)\", \"score\": 1013.0456828641878}, {\"model_name\": \"deepseek-r1-distill-llama-70b\", \"score_type\": \"BT score (votes data)\", \"score\": 988.0575240314109}, {\"model_name\": \"c4ai-command-r-08-2024\", \"score_type\": \"BT score (votes data)\", \"score\": 954.025745235083}, {\"model_name\": \"qwen2.5-coder-32b-instruct\", \"score_type\": \"BT score (votes data)\", \"score\": 962.0598997524314}, {\"model_name\": \"qwen2.5-32b-instruct\", \"score_type\": \"BT score (votes data)\", \"score\": 1002.3937943269309}, {\"model_name\": \"lfm-40b\", \"score_type\": \"BT score (votes data)\", \"score\": 910.5248050142854}, {\"model_name\": \"mixtral-8x7b-instruct-v0.1\", \"score_type\": \"BT score (votes data)\", \"score\": 929.3393281055958}, {\"model_name\": \"mistral-nemo-2407\", \"score_type\": \"BT score (votes data)\", \"score\": 888.5447892474573}, {\"model_name\": \"phi-3.5-mini-instruct\", \"score_type\": \"BT score (votes data)\", \"score\": 882.650795632809}, {\"model_name\": \"mixtral-8x22b-instruct-v0.1\", \"score_type\": \"BT score (votes data)\", \"score\": 868.3760224363342}, {\"model_name\": \"chocolatine-2-14b-instruct-v2.0.3-q8\", \"score_type\": \"BT score (votes data)\", \"score\": 852.6658901814192}, {\"model_name\": \"Yi-1.5-9B-Chat\", \"score_type\": \"BT score (votes data)\", \"score\": 755.4367476215427}, {\"model_name\": \"qwen2-7b-instruct\", \"score_type\": \"BT score (votes data)\", \"score\": 770.7492637096549}, {\"model_name\": \"chocolatine-14b-instruct-dpo-v1.2-q4\", \"score_type\": \"BT score (votes data)\", \"score\": 771.6425054656004}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import polars as pl\n",
    "import altair as alt\n",
    "\n",
    "df_pl = pl.concat(\n",
    "    [\n",
    "        scores.select(\"model_name\", \"median\").rename(mapping={\"median\": \"score_elo\"}),\n",
    "        scores_votes.select(\"model_name\", \"median\").rename(mapping={\"median\": \"score_elo_votes\"}),\n",
    "        scores_ml.select(\"model_name\", \"median\").rename(mapping={\"median\": \"score_ml\"}),\n",
    "        scores_ml_votes.select(\"model_name\", \"median\").rename(mapping={\"median\": \"score_ml_votes\"}),\n",
    "    ],\n",
    "    how=\"align\",\n",
    ").sort(\"score_elo\", descending=True)\n",
    "\n",
    "df = df_pl.to_pandas()\n",
    "df_long = df.melt(\n",
    "    id_vars=[\"model_name\"],\n",
    "    value_vars=[\"score_elo\", \"score_elo_votes\", \"score_ml\", \"score_ml_votes\"],\n",
    "    var_name=\"score_type\",\n",
    "    value_name=\"score\",\n",
    ")\n",
    "legend_labels = {\n",
    "    \"score_elo\": \"Elo score (all data)\",\n",
    "    \"score_elo_votes\": \"Elo score (votes data)\",\n",
    "    \"score_ml\": \"BT score (all data)\",\n",
    "    \"score_ml_votes\": \"BT score (votes data)\",\n",
    "}\n",
    "df_long[\"score_type\"] = df_long[\"score_type\"].map(legend_labels)\n",
    "\n",
    "chart = (\n",
    "    alt.Chart(df_long)\n",
    "    .mark_circle(size=80)\n",
    "    .encode(\n",
    "        x=alt.X(\"model_name:N\", sort=df[\"model_name\"].tolist(), title=\"model_name\"),\n",
    "        y=alt.Y(\"score:Q\", title=\"Score\", scale=alt.Scale(domain=[500, 1300])),\n",
    "        color=alt.Color(\"score_type:N\", title=\"Score Type\"),\n",
    "        tooltip=[\"model_name\", \"score\", \"score_type\"],\n",
    "    )\n",
    "    .properties(width=600, height=400)\n",
    ")\n",
    "\n",
    "chart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbd13bf",
   "metadata": {},
   "source": [
    "## Scores par catégorie\n",
    "\n",
    "Les méthodes `run_category` et `run_all_categories` permettent de calculer des scores pour une catégorie spécifiée ou pour toutes les catégories (avec un nombre de matchs total supérieur à un seuil)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f335bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since ministere-culture/comparia-votes couldn't be found on the Hugging Face Hub (offline mode is enabled).\n",
      "Found the latest cached dataset configuration 'default' at /home/jupyterhub-users/shared/projet_comparia/huggingface_hub/ministere-culture___comparia-votes/default/0.0.0/679f56e14f413546403b3468d717c4417e394326 (last modified on Mon Jul 28 10:06:44 2025).\n",
      "Using the latest cached version of the dataset since ministere-culture/comparia-conversations couldn't be found on the Hugging Face Hub (offline mode is enabled).\n",
      "Found the latest cached dataset configuration 'default' at /home/jupyterhub-users/shared/projet_comparia/huggingface_hub/ministere-culture___comparia-conversations/default/0.0.0/dc40af6af1c14e68bf39d55f6e1573d2d6582f19 (last modified on Wed Jun  4 17:40:30 2025).\n",
      "Using the latest cached version of the dataset since ministere-culture/comparia-reactions couldn't be found on the Hugging Face Hub (offline mode is enabled).\n",
      "Found the latest cached dataset configuration 'default' at /home/jupyterhub-users/shared/projet_comparia/huggingface_hub/ministere-culture___comparia-reactions/default/0.0.0/80befa851337d9f295096cef3d100b40d220dc07 (last modified on Mon Jul 28 10:06:54 2025).\n",
      "Using the latest cached version of the dataset since ministere-culture/comparia-conversations couldn't be found on the Hugging Face Hub (offline mode is enabled).\n",
      "Found the latest cached dataset configuration 'default' at /home/jupyterhub-users/shared/projet_comparia/huggingface_hub/ministere-culture___comparia-conversations/default/0.0.0/dc40af6af1c14e68bf39d55f6e1573d2d6582f19 (last modified on Wed Jun  4 17:40:30 2025).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final votes dataset contains 55617 conversations pairs.\n",
      "Reactions data originally contains 22993 conversations pairs.\n",
      "Final reactions dataset contains 21244 conversations pairs.\n"
     ]
    }
   ],
   "source": [
    "pipeline = RankingPipeline(\n",
    "    method=\"elo_random\",\n",
    "    include_votes=True,\n",
    "    include_reactions=True,\n",
    "    mean_how=\"token\",\n",
    "    bootstrap_samples=5,\n",
    "    batch=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ccbcb453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing bootstrap scores from a sample of 23033 matches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing bootstrap samples:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing bootstrap samples: 100%|██████████| 5/5 [00:00<00:00, 14.37it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (52, 9)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model_name</th><th>median</th><th>p2.5</th><th>p97.5</th><th>total_output_tokens</th><th>conso_all_conv</th><th>n_match</th><th>mean_conso_per_match</th><th>mean_conso_per_token</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>u32</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;Yi-1.5-9B-Chat&quot;</td><td>800.817442</td><td>741.422315</td><td>850.615496</td><td>47531.0</td><td>0.182743</td><td>65</td><td>0.002811</td><td>0.000004</td></tr><tr><td>&quot;aya-expanse-8b&quot;</td><td>971.809061</td><td>919.628331</td><td>1045.417157</td><td>1.05781e6</td><td>3.98568</td><td>1302</td><td>0.003061</td><td>0.000004</td></tr><tr><td>&quot;c4ai-command-r-08-2024&quot;</td><td>918.126747</td><td>902.835228</td><td>1019.960401</td><td>2.747666e6</td><td>20.763975</td><td>3598</td><td>0.005771</td><td>0.000008</td></tr><tr><td>&quot;chocolatine-14b-instruct-dpo-v…</td><td>810.954755</td><td>730.302308</td><td>924.922786</td><td>131187.0</td><td>0.602249</td><td>309</td><td>0.001949</td><td>0.000005</td></tr><tr><td>&quot;chocolatine-2-14b-instruct-v2.…</td><td>805.31044</td><td>763.368634</td><td>919.795801</td><td>533384.0</td><td>1.934863</td><td>1796</td><td>0.001077</td><td>0.000004</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;qwen2-7b-instruct&quot;</td><td>826.097891</td><td>752.052838</td><td>863.03069</td><td>43550.0</td><td>0.153078</td><td>80</td><td>0.001913</td><td>0.000004</td></tr><tr><td>&quot;qwen2.5-32b-instruct&quot;</td><td>1068.580006</td><td>1032.987712</td><td>1171.712044</td><td>75812.0</td><td>0.531085</td><td>142</td><td>0.00374</td><td>0.000007</td></tr><tr><td>&quot;qwen2.5-7b-instruct&quot;</td><td>932.091519</td><td>881.377309</td><td>1079.192671</td><td>1.186919e6</td><td>4.305576</td><td>1420</td><td>0.003032</td><td>0.000004</td></tr><tr><td>&quot;qwen2.5-coder-32b-instruct&quot;</td><td>946.687908</td><td>899.577859</td><td>1033.987153</td><td>4.0819e6</td><td>29.128193</td><td>4954</td><td>0.00588</td><td>0.000007</td></tr><tr><td>&quot;qwq-32b&quot;</td><td>924.262285</td><td>893.380412</td><td>974.77508</td><td>1.757717e6</td><td>12.542963</td><td>1479</td><td>0.008481</td><td>0.000007</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (52, 9)\n",
       "┌────────────┬───────────┬───────────┬───────────┬───┬───────────┬─────────┬───────────┬───────────┐\n",
       "│ model_name ┆ median    ┆ p2.5      ┆ p97.5     ┆ … ┆ conso_all ┆ n_match ┆ mean_cons ┆ mean_cons │\n",
       "│ ---        ┆ ---       ┆ ---       ┆ ---       ┆   ┆ _conv     ┆ ---     ┆ o_per_mat ┆ o_per_tok │\n",
       "│ str        ┆ f64       ┆ f64       ┆ f64       ┆   ┆ ---       ┆ u32     ┆ ch        ┆ en        │\n",
       "│            ┆           ┆           ┆           ┆   ┆ f64       ┆         ┆ ---       ┆ ---       │\n",
       "│            ┆           ┆           ┆           ┆   ┆           ┆         ┆ f64       ┆ f64       │\n",
       "╞════════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═════════╪═══════════╪═══════════╡\n",
       "│ Yi-1.5-9B- ┆ 800.81744 ┆ 741.42231 ┆ 850.61549 ┆ … ┆ 0.182743  ┆ 65      ┆ 0.002811  ┆ 0.000004  │\n",
       "│ Chat       ┆ 2         ┆ 5         ┆ 6         ┆   ┆           ┆         ┆           ┆           │\n",
       "│ aya-expans ┆ 971.80906 ┆ 919.62833 ┆ 1045.4171 ┆ … ┆ 3.98568   ┆ 1302    ┆ 0.003061  ┆ 0.000004  │\n",
       "│ e-8b       ┆ 1         ┆ 1         ┆ 57        ┆   ┆           ┆         ┆           ┆           │\n",
       "│ c4ai-comma ┆ 918.12674 ┆ 902.83522 ┆ 1019.9604 ┆ … ┆ 20.763975 ┆ 3598    ┆ 0.005771  ┆ 0.000008  │\n",
       "│ nd-r-08-20 ┆ 7         ┆ 8         ┆ 01        ┆   ┆           ┆         ┆           ┆           │\n",
       "│ 24         ┆           ┆           ┆           ┆   ┆           ┆         ┆           ┆           │\n",
       "│ chocolatin ┆ 810.95475 ┆ 730.30230 ┆ 924.92278 ┆ … ┆ 0.602249  ┆ 309     ┆ 0.001949  ┆ 0.000005  │\n",
       "│ e-14b-inst ┆ 5         ┆ 8         ┆ 6         ┆   ┆           ┆         ┆           ┆           │\n",
       "│ ruct-dpo-v ┆           ┆           ┆           ┆   ┆           ┆         ┆           ┆           │\n",
       "│ …          ┆           ┆           ┆           ┆   ┆           ┆         ┆           ┆           │\n",
       "│ chocolatin ┆ 805.31044 ┆ 763.36863 ┆ 919.79580 ┆ … ┆ 1.934863  ┆ 1796    ┆ 0.001077  ┆ 0.000004  │\n",
       "│ e-2-14b-in ┆           ┆ 4         ┆ 1         ┆   ┆           ┆         ┆           ┆           │\n",
       "│ struct-v2. ┆           ┆           ┆           ┆   ┆           ┆         ┆           ┆           │\n",
       "│ …          ┆           ┆           ┆           ┆   ┆           ┆         ┆           ┆           │\n",
       "│ …          ┆ …         ┆ …         ┆ …         ┆ … ┆ …         ┆ …       ┆ …         ┆ …         │\n",
       "│ qwen2-7b-i ┆ 826.09789 ┆ 752.05283 ┆ 863.03069 ┆ … ┆ 0.153078  ┆ 80      ┆ 0.001913  ┆ 0.000004  │\n",
       "│ nstruct    ┆ 1         ┆ 8         ┆           ┆   ┆           ┆         ┆           ┆           │\n",
       "│ qwen2.5-32 ┆ 1068.5800 ┆ 1032.9877 ┆ 1171.7120 ┆ … ┆ 0.531085  ┆ 142     ┆ 0.00374   ┆ 0.000007  │\n",
       "│ b-instruct ┆ 06        ┆ 12        ┆ 44        ┆   ┆           ┆         ┆           ┆           │\n",
       "│ qwen2.5-7b ┆ 932.09151 ┆ 881.37730 ┆ 1079.1926 ┆ … ┆ 4.305576  ┆ 1420    ┆ 0.003032  ┆ 0.000004  │\n",
       "│ -instruct  ┆ 9         ┆ 9         ┆ 71        ┆   ┆           ┆         ┆           ┆           │\n",
       "│ qwen2.5-co ┆ 946.68790 ┆ 899.57785 ┆ 1033.9871 ┆ … ┆ 29.128193 ┆ 4954    ┆ 0.00588   ┆ 0.000007  │\n",
       "│ der-32b-in ┆ 8         ┆ 9         ┆ 53        ┆   ┆           ┆         ┆           ┆           │\n",
       "│ struct     ┆           ┆           ┆           ┆   ┆           ┆         ┆           ┆           │\n",
       "│ qwq-32b    ┆ 924.26228 ┆ 893.38041 ┆ 974.77508 ┆ … ┆ 12.542963 ┆ 1479    ┆ 0.008481  ┆ 0.000007  │\n",
       "│            ┆ 5         ┆ 2         ┆           ┆   ┆           ┆         ┆           ┆           │\n",
       "└────────────┴───────────┴───────────┴───────────┴───┴───────────┴─────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.run_category(\"Education\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "efc06527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing bootstrap scores from a sample of 23033 matches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing bootstrap samples:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing bootstrap samples: 100%|██████████| 5/5 [00:00<00:00, 17.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing bootstrap scores from a sample of 8046 matches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing bootstrap samples: 100%|██████████| 5/5 [00:00<00:00, 49.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing bootstrap scores from a sample of 12297 matches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing bootstrap samples: 100%|██████████| 5/5 [00:00<00:00, 34.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing bootstrap scores from a sample of 10069 matches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing bootstrap samples: 100%|██████████| 5/5 [00:00<00:00, 37.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing bootstrap scores from a sample of 11206 matches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing bootstrap samples: 100%|██████████| 5/5 [00:00<00:00, 34.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing bootstrap scores from a sample of 5281 matches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing bootstrap samples: 100%|██████████| 5/5 [00:00<00:00, 68.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing bootstrap scores from a sample of 5714 matches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing bootstrap samples: 100%|██████████| 5/5 [00:00<00:00, 67.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing bootstrap scores from a sample of 31303 matches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing bootstrap samples: 100%|██████████| 5/5 [00:00<00:00, 12.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing bootstrap scores from a sample of 17013 matches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing bootstrap samples: 100%|██████████| 5/5 [00:00<00:00, 23.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing bootstrap scores from a sample of 13220 matches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing bootstrap samples: 100%|██████████| 5/5 [00:00<00:00, 28.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping Other which has less than 1000 matches.\n",
      "Computing bootstrap scores from a sample of 7920 matches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing bootstrap samples: 100%|██████████| 5/5 [00:00<00:00, 48.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing bootstrap scores from a sample of 5642 matches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing bootstrap samples: 100%|██████████| 5/5 [00:00<00:00, 81.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing bootstrap scores from a sample of 5913 matches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing bootstrap samples: 100%|██████████| 5/5 [00:00<00:00, 73.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping Shopping & Commodity which has less than 1000 matches.\n",
      "Skipping Daily Life & Home & Lifestyle which has less than 1000 matches.\n",
      "Skipping Religion & Spirituality which has less than 1000 matches.\n",
      "Skipping Sports which has less than 1000 matches.\n",
      "Skipping History which has less than 1000 matches.\n",
      "Skipping Real Estate which has less than 1000 matches.\n",
      "Skipping Philosophy which has less than 1000 matches.\n",
      "Skipping International which has less than 1000 matches.\n",
      "Skipping Psychology which has less than 1000 matches.\n",
      "Skipping Security which has less than 1000 matches.\n",
      "Skipping Philosophy & Spirituality which has less than 1000 matches.\n",
      "Skipping Fashion which has less than 1000 matches.\n",
      "Skipping Music which has less than 1000 matches.\n",
      "Skipping Marketing which has less than 1000 matches.\n",
      "Skipping Ethics & Debate which has less than 1000 matches.\n",
      "Skipping Philosophy & logic which has less than 1000 matches.\n",
      "Skipping Philosophy & Ethics which has less than 1000 matches.\n",
      "Skipping Industry which has less than 1000 matches.\n",
      "Skipping Robotics which has less than 1000 matches.\n",
      "Skipping Travel which has less than 1000 matches.\n",
      "Skipping Technology which has less than 1000 matches.\n",
      "Skipping Travel & Hobby which has less than 1000 matches.\n",
      "Skipping Philosophy and Ethics which has less than 1000 matches.\n",
      "Skipping Theology which has less than 1000 matches.\n",
      "Skipping Anthropology which has less than 1000 matches.\n",
      "Skipping Philosophy & Religion which has less than 1000 matches.\n",
      "Skipping Urban Planning which has less than 1000 matches.\n",
      "Skipping Agriculture which has less than 1000 matches.\n",
      "Skipping Linguistics which has less than 1000 matches.\n",
      "Skipping Philosophy & Metaphysics which has less than 1000 matches.\n",
      "Skipping Psychology & Mental Health which has less than 1000 matches.\n",
      "Skipping Sociology which has less than 1000 matches.\n",
      "Skipping Architecture and construction which has less than 1000 matches.\n",
      "Skipping Industry and artisanat which has less than 1000 matches.\n",
      "Skipping Biotechnology which has less than 1000 matches.\n",
      "Skipping Marketing & Sales which has less than 1000 matches.\n",
      "Skipping Mathematics which has less than 1000 matches.\n",
      "Skipping Engineering which has less than 1000 matches.\n",
      "Skipping Ethics which has less than 1000 matches.\n"
     ]
    }
   ],
   "source": [
    "results = pipeline.run_all_categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3972e690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Education': shape: (52, 4)\n",
       " ┌─────────────────────────────────┬─────────────┬─────────────┬─────────────┐\n",
       " │ model_name                      ┆ median      ┆ p2.5        ┆ p97.5       │\n",
       " │ ---                             ┆ ---         ┆ ---         ┆ ---         │\n",
       " │ str                             ┆ f64         ┆ f64         ┆ f64         │\n",
       " ╞═════════════════════════════════╪═════════════╪═════════════╪═════════════╡\n",
       " │ command-a                       ┆ 1165.939453 ┆ 1039.06224  ┆ 1175.586129 │\n",
       " │ claude-3-7-sonnet               ┆ 1163.001257 ┆ 1132.657457 ┆ 1185.869103 │\n",
       " │ gemini-2.0-flash-exp            ┆ 1151.385467 ┆ 1061.135761 ┆ 1183.146645 │\n",
       " │ gemini-2.0-flash-001            ┆ 1145.885573 ┆ 1089.733703 ┆ 1232.851487 │\n",
       " │ gemini-1.5-pro-001              ┆ 1129.806102 ┆ 1035.871364 ┆ 1159.290317 │\n",
       " │ …                               ┆ …           ┆ …           ┆ …           │\n",
       " │ chocolatine-2-14b-instruct-v2.… ┆ 832.347216  ┆ 797.186406  ┆ 900.729485  │\n",
       " │ Yi-1.5-9B-Chat                  ┆ 829.758799  ┆ 780.031175  ┆ 941.246462  │\n",
       " │ mixtral-8x22b-instruct-v0.1     ┆ 817.219989  ┆ 796.153141  ┆ 935.181973  │\n",
       " │ qwen2-7b-instruct               ┆ 790.944249  ┆ 780.485941  ┆ 832.325705  │\n",
       " │ chocolatine-14b-instruct-dpo-v… ┆ 750.713789  ┆ 711.130169  ┆ 854.953817  │\n",
       " └─────────────────────────────────┴─────────────┴─────────────┴─────────────┘,\n",
       " 'Arts': shape: (52, 4)\n",
       " ┌─────────────────────────────────┬─────────────┬─────────────┬─────────────┐\n",
       " │ model_name                      ┆ median      ┆ p2.5        ┆ p97.5       │\n",
       " │ ---                             ┆ ---         ┆ ---         ┆ ---         │\n",
       " │ str                             ┆ f64         ┆ f64         ┆ f64         │\n",
       " ╞═════════════════════════════════╪═════════════╪═════════════╪═════════════╡\n",
       " │ gemini-2.0-flash-exp            ┆ 1155.345652 ┆ 1033.139177 ┆ 1200.692732 │\n",
       " │ gemini-2.0-flash-001            ┆ 1147.093744 ┆ 1115.045402 ┆ 1204.79215  │\n",
       " │ gpt-4.1-mini                    ┆ 1120.028657 ┆ 996.75573   ┆ 1164.071072 │\n",
       " │ deepseek-v3-0324                ┆ 1114.668513 ┆ 1005.150562 ┆ 1208.04777  │\n",
       " │ gemma-3-27b                     ┆ 1113.286772 ┆ 996.734577  ┆ 1234.77517  │\n",
       " │ …                               ┆ …           ┆ …           ┆ …           │\n",
       " │ phi-3.5-mini-instruct           ┆ 877.150399  ┆ 787.502293  ┆ 968.473774  │\n",
       " │ qwen2-7b-instruct               ┆ 854.939854  ┆ 825.125927  ┆ 894.405282  │\n",
       " │ Yi-1.5-9B-Chat                  ┆ 837.101534  ┆ 749.458395  ┆ 871.753938  │\n",
       " │ chocolatine-2-14b-instruct-v2.… ┆ 817.636292  ┆ 734.257056  ┆ 901.960412  │\n",
       " │ chocolatine-14b-instruct-dpo-v… ┆ 748.137048  ┆ 735.934678  ┆ 781.090356  │\n",
       " └─────────────────────────────────┴─────────────┴─────────────┴─────────────┘,\n",
       " 'Entertainment & Travel & Hobby': shape: (52, 4)\n",
       " ┌─────────────────────────────────┬─────────────┬─────────────┬─────────────┐\n",
       " │ model_name                      ┆ median      ┆ p2.5        ┆ p97.5       │\n",
       " │ ---                             ┆ ---         ┆ ---         ┆ ---         │\n",
       " │ str                             ┆ f64         ┆ f64         ┆ f64         │\n",
       " ╞═════════════════════════════════╪═════════════╪═════════════╪═════════════╡\n",
       " │ gemini-2.0-flash-001            ┆ 1193.450552 ┆ 1067.145934 ┆ 1215.214003 │\n",
       " │ gpt-4.1-mini                    ┆ 1125.648129 ┆ 1022.797518 ┆ 1143.357495 │\n",
       " │ command-a                       ┆ 1124.330947 ┆ 1069.924183 ┆ 1149.261304 │\n",
       " │ deepseek-v3-0324                ┆ 1112.012653 ┆ 1068.372503 ┆ 1211.600656 │\n",
       " │ gemma-3-27b                     ┆ 1107.23699  ┆ 1048.20223  ┆ 1153.256932 │\n",
       " │ …                               ┆ …           ┆ …           ┆ …           │\n",
       " │ Yi-1.5-9B-Chat                  ┆ 843.044722  ┆ 769.170831  ┆ 993.71193   │\n",
       " │ qwen2-7b-instruct               ┆ 833.267211  ┆ 810.869446  ┆ 919.99044   │\n",
       " │ chocolatine-2-14b-instruct-v2.… ┆ 832.193781  ┆ 763.994555  ┆ 879.299004  │\n",
       " │ chocolatine-14b-instruct-dpo-v… ┆ 818.762016  ┆ 676.903177  ┆ 879.432064  │\n",
       " │ mistral-nemo-2407               ┆ 818.341895  ┆ 752.432317  ┆ 927.081405  │\n",
       " └─────────────────────────────────┴─────────────┴─────────────┴─────────────┘,\n",
       " 'Culture & Cultural geography': shape: (52, 4)\n",
       " ┌─────────────────────────────────┬─────────────┬─────────────┬─────────────┐\n",
       " │ model_name                      ┆ median      ┆ p2.5        ┆ p97.5       │\n",
       " │ ---                             ┆ ---         ┆ ---         ┆ ---         │\n",
       " │ str                             ┆ f64         ┆ f64         ┆ f64         │\n",
       " ╞═════════════════════════════════╪═════════════╪═════════════╪═════════════╡\n",
       " │ gemini-2.0-flash-exp            ┆ 1169.513973 ┆ 1102.306638 ┆ 1241.673725 │\n",
       " │ gemma-3-27b                     ┆ 1113.827422 ┆ 1089.532979 ┆ 1131.852596 │\n",
       " │ deepseek-v3-chat                ┆ 1110.810093 ┆ 1033.562233 ┆ 1166.330285 │\n",
       " │ claude-3-7-sonnet               ┆ 1095.136524 ┆ 1034.095841 ┆ 1203.063968 │\n",
       " │ gemini-2.0-flash-001            ┆ 1093.855486 ┆ 1057.851179 ┆ 1161.464313 │\n",
       " │ …                               ┆ …           ┆ …           ┆ …           │\n",
       " │ mistral-nemo-2407               ┆ 868.841308  ┆ 744.327876  ┆ 931.755954  │\n",
       " │ qwen2.5-7b-instruct             ┆ 861.087272  ┆ 816.095971  ┆ 992.013166  │\n",
       " │ qwen2-7b-instruct               ┆ 858.98184   ┆ 826.86734   ┆ 1008.845686 │\n",
       " │ chocolatine-2-14b-instruct-v2.… ┆ 810.593624  ┆ 768.083411  ┆ 833.691783  │\n",
       " │ chocolatine-14b-instruct-dpo-v… ┆ 712.566351  ┆ 683.348786  ┆ 734.183282  │\n",
       " └─────────────────────────────────┴─────────────┴─────────────┴─────────────┘,\n",
       " 'Politics & Government': shape: (52, 4)\n",
       " ┌─────────────────────────────────┬─────────────┬─────────────┬─────────────┐\n",
       " │ model_name                      ┆ median      ┆ p2.5        ┆ p97.5       │\n",
       " │ ---                             ┆ ---         ┆ ---         ┆ ---         │\n",
       " │ str                             ┆ f64         ┆ f64         ┆ f64         │\n",
       " ╞═════════════════════════════════╪═════════════╪═════════════╪═════════════╡\n",
       " │ gemma-3-27b                     ┆ 1143.456476 ┆ 1098.970666 ┆ 1196.422481 │\n",
       " │ gemma-3-12b                     ┆ 1140.268503 ┆ 1078.996232 ┆ 1147.923563 │\n",
       " │ deepseek-v3-chat                ┆ 1124.112217 ┆ 1067.365137 ┆ 1184.71257  │\n",
       " │ llama-3.1-nemotron-70b-instruc… ┆ 1120.097171 ┆ 1023.367641 ┆ 1168.663785 │\n",
       " │ gemini-2.0-flash-exp            ┆ 1105.05291  ┆ 1034.632755 ┆ 1241.969469 │\n",
       " │ …                               ┆ …           ┆ …           ┆ …           │\n",
       " │ mixtral-8x22b-instruct-v0.1     ┆ 886.729064  ┆ 837.378987  ┆ 958.114943  │\n",
       " │ lfm-40b                         ┆ 885.76163   ┆ 857.719106  ┆ 954.311259  │\n",
       " │ mistral-nemo-2407               ┆ 871.973323  ┆ 860.919267  ┆ 945.068737  │\n",
       " │ chocolatine-2-14b-instruct-v2.… ┆ 834.378888  ┆ 800.242753  ┆ 904.454226  │\n",
       " │ chocolatine-14b-instruct-dpo-v… ┆ 683.404191  ┆ 673.841127  ┆ 753.131431  │\n",
       " └─────────────────────────────────┴─────────────┴─────────────┴─────────────┘,\n",
       " 'Food & Drink & Cooking': shape: (52, 4)\n",
       " ┌─────────────────────────────────┬─────────────┬─────────────┬─────────────┐\n",
       " │ model_name                      ┆ median      ┆ p2.5        ┆ p97.5       │\n",
       " │ ---                             ┆ ---         ┆ ---         ┆ ---         │\n",
       " │ str                             ┆ f64         ┆ f64         ┆ f64         │\n",
       " ╞═════════════════════════════════╪═════════════╪═════════════╪═════════════╡\n",
       " │ gemini-2.0-flash-001            ┆ 1160.470438 ┆ 1071.500177 ┆ 1222.004438 │\n",
       " │ gemini-2.0-flash-exp            ┆ 1149.740077 ┆ 1133.309043 ┆ 1250.552288 │\n",
       " │ gemma-3-27b                     ┆ 1143.562973 ┆ 1066.564962 ┆ 1208.59118  │\n",
       " │ gemma-2-27b-it-q8               ┆ 1135.237685 ┆ 1050.164458 ┆ 1154.94857  │\n",
       " │ deepseek-v3-chat                ┆ 1132.191427 ┆ 1083.746706 ┆ 1192.531444 │\n",
       " │ …                               ┆ …           ┆ …           ┆ …           │\n",
       " │ phi-3.5-mini-instruct           ┆ 884.187455  ┆ 839.491184  ┆ 1019.43441  │\n",
       " │ mistral-nemo-2407               ┆ 876.392226  ┆ 861.386768  ┆ 1005.704789 │\n",
       " │ mixtral-8x22b-instruct-v0.1     ┆ 867.983787  ┆ 814.001178  ┆ 991.869902  │\n",
       " │ chocolatine-2-14b-instruct-v2.… ┆ 837.086001  ┆ 755.803554  ┆ 900.61502   │\n",
       " │ chocolatine-14b-instruct-dpo-v… ┆ 794.776531  ┆ 750.098769  ┆ 900.88945   │\n",
       " └─────────────────────────────────┴─────────────┴─────────────┴─────────────┘,\n",
       " 'Law & Justice': shape: (52, 4)\n",
       " ┌─────────────────────────────────┬─────────────┬─────────────┬─────────────┐\n",
       " │ model_name                      ┆ median      ┆ p2.5        ┆ p97.5       │\n",
       " │ ---                             ┆ ---         ┆ ---         ┆ ---         │\n",
       " │ str                             ┆ f64         ┆ f64         ┆ f64         │\n",
       " ╞═════════════════════════════════╪═════════════╪═════════════╪═════════════╡\n",
       " │ gemini-2.0-flash-exp            ┆ 1190.527462 ┆ 1170.036057 ┆ 1248.900859 │\n",
       " │ deepseek-v3-chat                ┆ 1172.231271 ┆ 1116.44934  ┆ 1189.801562 │\n",
       " │ gemma-3-27b                     ┆ 1132.137193 ┆ 1081.751124 ┆ 1177.901612 │\n",
       " │ gemma-3-12b                     ┆ 1130.287746 ┆ 976.205987  ┆ 1145.862581 │\n",
       " │ command-a                       ┆ 1113.620699 ┆ 1030.963023 ┆ 1150.805373 │\n",
       " │ …                               ┆ …           ┆ …           ┆ …           │\n",
       " │ mixtral-8x22b-instruct-v0.1     ┆ 868.787787  ┆ 831.823035  ┆ 945.374405  │\n",
       " │ chocolatine-2-14b-instruct-v2.… ┆ 859.653981  ┆ 829.029749  ┆ 922.602794  │\n",
       " │ mistral-nemo-2407               ┆ 855.263678  ┆ 829.026052  ┆ 888.317088  │\n",
       " │ chocolatine-14b-instruct-dpo-v… ┆ 836.583741  ┆ 765.207233  ┆ 888.733246  │\n",
       " │ phi-3.5-mini-instruct           ┆ 834.156911  ┆ 810.909833  ┆ 979.341159  │\n",
       " └─────────────────────────────────┴─────────────┴─────────────┴─────────────┘,\n",
       " 'Natural Science & Formal Science & Technology': shape: (52, 4)\n",
       " ┌─────────────────────────────┬─────────────┬─────────────┬─────────────┐\n",
       " │ model_name                  ┆ median      ┆ p2.5        ┆ p97.5       │\n",
       " │ ---                         ┆ ---         ┆ ---         ┆ ---         │\n",
       " │ str                         ┆ f64         ┆ f64         ┆ f64         │\n",
       " ╞═════════════════════════════╪═════════════╪═════════════╪═════════════╡\n",
       " │ gemini-2.0-flash-exp        ┆ 1185.795965 ┆ 1077.504348 ┆ 1193.262674 │\n",
       " │ gemma-3-12b                 ┆ 1148.79363  ┆ 1142.630112 ┆ 1212.295057 │\n",
       " │ gemini-2.0-flash-001        ┆ 1147.347708 ┆ 1066.655973 ┆ 1218.010601 │\n",
       " │ command-a                   ┆ 1140.998663 ┆ 1122.028208 ┆ 1168.607466 │\n",
       " │ claude-3-7-sonnet           ┆ 1125.971426 ┆ 1114.473909 ┆ 1170.243629 │\n",
       " │ …                           ┆ …           ┆ …           ┆ …           │\n",
       " │ lfm-40b                     ┆ 851.787561  ┆ 816.787033  ┆ 961.569651  │\n",
       " │ mixtral-8x22b-instruct-v0.1 ┆ 833.287396  ┆ 825.740388  ┆ 869.998028  │\n",
       " │ mistral-nemo-2407           ┆ 816.651913  ┆ 775.254037  ┆ 949.942189  │\n",
       " │ qwen2-7b-instruct           ┆ 792.061738  ┆ 738.837852  ┆ 798.645443  │\n",
       " │ Yi-1.5-9B-Chat              ┆ 776.884188  ┆ 711.247925  ┆ 823.395321  │\n",
       " └─────────────────────────────┴─────────────┴─────────────┴─────────────┘,\n",
       " 'Business & Economics & Finance': shape: (52, 4)\n",
       " ┌─────────────────────────────────┬─────────────┬─────────────┬─────────────┐\n",
       " │ model_name                      ┆ median      ┆ p2.5        ┆ p97.5       │\n",
       " │ ---                             ┆ ---         ┆ ---         ┆ ---         │\n",
       " │ str                             ┆ f64         ┆ f64         ┆ f64         │\n",
       " ╞═════════════════════════════════╪═════════════╪═════════════╪═════════════╡\n",
       " │ gemini-2.0-flash-exp            ┆ 1188.847806 ┆ 1115.840825 ┆ 1234.359415 │\n",
       " │ deepseek-v3-chat                ┆ 1153.931222 ┆ 1040.48834  ┆ 1227.708066 │\n",
       " │ gemini-2.0-flash-001            ┆ 1142.277306 ┆ 1067.930183 ┆ 1216.378853 │\n",
       " │ claude-3-7-sonnet               ┆ 1123.542124 ┆ 1071.207737 ┆ 1183.14553  │\n",
       " │ deepseek-v3-0324                ┆ 1106.58776  ┆ 1086.671639 ┆ 1126.402471 │\n",
       " │ …                               ┆ …           ┆ …           ┆ …           │\n",
       " │ chocolatine-2-14b-instruct-v2.… ┆ 893.787569  ┆ 845.735894  ┆ 935.868189  │\n",
       " │ phi-3.5-mini-instruct           ┆ 887.14584   ┆ 814.231641  ┆ 923.989789  │\n",
       " │ mistral-nemo-2407               ┆ 856.723067  ┆ 707.051273  ┆ 957.274915  │\n",
       " │ mixtral-8x22b-instruct-v0.1     ┆ 817.250679  ┆ 789.875375  ┆ 876.258081  │\n",
       " │ chocolatine-14b-instruct-dpo-v… ┆ 699.398247  ┆ 640.898766  ┆ 878.419188  │\n",
       " └─────────────────────────────────┴─────────────┴─────────────┴─────────────┘,\n",
       " 'Society & Social Issues & Human Rights': shape: (52, 4)\n",
       " ┌─────────────────────────────────┬─────────────┬─────────────┬─────────────┐\n",
       " │ model_name                      ┆ median      ┆ p2.5        ┆ p97.5       │\n",
       " │ ---                             ┆ ---         ┆ ---         ┆ ---         │\n",
       " │ str                             ┆ f64         ┆ f64         ┆ f64         │\n",
       " ╞═════════════════════════════════╪═════════════╪═════════════╪═════════════╡\n",
       " │ gemma-3-12b                     ┆ 1162.983572 ┆ 1117.058022 ┆ 1230.815927 │\n",
       " │ deepseek-v3-chat                ┆ 1158.625129 ┆ 1081.25456  ┆ 1169.301333 │\n",
       " │ llama-3.1-nemotron-70b-instruc… ┆ 1154.872759 ┆ 1092.249771 ┆ 1181.350771 │\n",
       " │ gemma-3-27b                     ┆ 1143.203522 ┆ 1016.578679 ┆ 1179.196288 │\n",
       " │ gemini-2.0-flash-exp            ┆ 1137.34241  ┆ 1085.685063 ┆ 1199.213769 │\n",
       " │ …                               ┆ …           ┆ …           ┆ …           │\n",
       " │ lfm-40b                         ┆ 846.311434  ┆ 826.591967  ┆ 1058.541761 │\n",
       " │ chocolatine-2-14b-instruct-v2.… ┆ 806.91541   ┆ 745.602582  ┆ 851.344496  │\n",
       " │ mixtral-8x22b-instruct-v0.1     ┆ 805.72604   ┆ 776.990051  ┆ 905.95069   │\n",
       " │ chocolatine-14b-instruct-dpo-v… ┆ 791.958037  ┆ 639.021632  ┆ 803.120869  │\n",
       " │ qwen2-7b-instruct               ┆ 773.610186  ┆ 667.450277  ┆ 841.682873  │\n",
       " └─────────────────────────────────┴─────────────┴─────────────┴─────────────┘,\n",
       " 'Personal Development & Human Resources & Career': shape: (52, 4)\n",
       " ┌─────────────────────────────────┬─────────────┬─────────────┬─────────────┐\n",
       " │ model_name                      ┆ median      ┆ p2.5        ┆ p97.5       │\n",
       " │ ---                             ┆ ---         ┆ ---         ┆ ---         │\n",
       " │ str                             ┆ f64         ┆ f64         ┆ f64         │\n",
       " ╞═════════════════════════════════╪═════════════╪═════════════╪═════════════╡\n",
       " │ command-a                       ┆ 1142.445776 ┆ 1093.949526 ┆ 1202.225614 │\n",
       " │ gemini-2.0-flash-001            ┆ 1141.128237 ┆ 1102.116723 ┆ 1189.523888 │\n",
       " │ deepseek-v3-0324                ┆ 1129.143495 ┆ 1097.29876  ┆ 1201.683136 │\n",
       " │ gemini-1.5-pro-001              ┆ 1113.733665 ┆ 1070.126348 ┆ 1146.528288 │\n",
       " │ gemini-2.0-flash-exp            ┆ 1112.451741 ┆ 1099.994715 ┆ 1173.601672 │\n",
       " │ …                               ┆ …           ┆ …           ┆ …           │\n",
       " │ mixtral-8x7b-instruct-v0.1      ┆ 868.409359  ┆ 822.229158  ┆ 1003.182953 │\n",
       " │ mistral-nemo-2407               ┆ 849.675074  ┆ 777.918849  ┆ 894.590502  │\n",
       " │ mixtral-8x22b-instruct-v0.1     ┆ 833.983186  ┆ 786.64086   ┆ 897.282367  │\n",
       " │ chocolatine-2-14b-instruct-v2.… ┆ 805.037247  ┆ 778.493901  ┆ 884.725207  │\n",
       " │ chocolatine-14b-instruct-dpo-v… ┆ 793.303895  ┆ 712.750074  ┆ 952.680502  │\n",
       " └─────────────────────────────────┴─────────────┴─────────────┴─────────────┘,\n",
       " 'Environment': shape: (52, 4)\n",
       " ┌─────────────────────────────────┬─────────────┬─────────────┬─────────────┐\n",
       " │ model_name                      ┆ median      ┆ p2.5        ┆ p97.5       │\n",
       " │ ---                             ┆ ---         ┆ ---         ┆ ---         │\n",
       " │ str                             ┆ f64         ┆ f64         ┆ f64         │\n",
       " ╞═════════════════════════════════╪═════════════╪═════════════╪═════════════╡\n",
       " │ gemini-2.0-flash-exp            ┆ 1169.398804 ┆ 1084.33287  ┆ 1242.534176 │\n",
       " │ gemma-3-4b                      ┆ 1156.00799  ┆ 1153.463142 ┆ 1283.848434 │\n",
       " │ deepseek-v3-chat                ┆ 1123.062843 ┆ 1062.602516 ┆ 1167.829637 │\n",
       " │ command-a                       ┆ 1113.282751 ┆ 1037.222889 ┆ 1186.90565  │\n",
       " │ gemini-1.5-pro-001              ┆ 1112.417253 ┆ 1079.276337 ┆ 1152.061909 │\n",
       " │ …                               ┆ …           ┆ …           ┆ …           │\n",
       " │ c4ai-command-r-08-2024          ┆ 881.314969  ┆ 799.971747  ┆ 1016.333682 │\n",
       " │ phi-3.5-mini-instruct           ┆ 880.548741  ┆ 784.608302  ┆ 929.678241  │\n",
       " │ chocolatine-2-14b-instruct-v2.… ┆ 878.400354  ┆ 775.00284   ┆ 902.414252  │\n",
       " │ mixtral-8x22b-instruct-v0.1     ┆ 856.223585  ┆ 729.544573  ┆ 902.209465  │\n",
       " │ mistral-nemo-2407               ┆ 832.324228  ┆ 818.950624  ┆ 969.937778  │\n",
       " └─────────────────────────────────┴─────────────┴─────────────┴─────────────┘,\n",
       " 'Health & Wellness & Medicine': shape: (52, 4)\n",
       " ┌─────────────────────────────────┬─────────────┬─────────────┬─────────────┐\n",
       " │ model_name                      ┆ median      ┆ p2.5        ┆ p97.5       │\n",
       " │ ---                             ┆ ---         ┆ ---         ┆ ---         │\n",
       " │ str                             ┆ f64         ┆ f64         ┆ f64         │\n",
       " ╞═════════════════════════════════╪═════════════╪═════════════╪═════════════╡\n",
       " │ gemma-3-12b                     ┆ 1193.680992 ┆ 1031.282779 ┆ 1203.357528 │\n",
       " │ gemini-2.0-flash-exp            ┆ 1155.40318  ┆ 1100.330992 ┆ 1163.297226 │\n",
       " │ gemini-2.0-flash-001            ┆ 1127.004177 ┆ 1064.836797 ┆ 1208.115688 │\n",
       " │ gemma-3-4b                      ┆ 1125.8799   ┆ 1024.148615 ┆ 1145.726761 │\n",
       " │ deepseek-v3-0324                ┆ 1121.319692 ┆ 1064.021689 ┆ 1185.128518 │\n",
       " │ …                               ┆ …           ┆ …           ┆ …           │\n",
       " │ mixtral-8x7b-instruct-v0.1      ┆ 872.995218  ┆ 817.557682  ┆ 885.552448  │\n",
       " │ llama-3.1-8b                    ┆ 863.91865   ┆ 844.516431  ┆ 953.820456  │\n",
       " │ chocolatine-14b-instruct-dpo-v… ┆ 856.773164  ┆ 783.987131  ┆ 929.84949   │\n",
       " │ lfm-40b                         ┆ 848.03237   ┆ 831.596227  ┆ 925.730481  │\n",
       " │ chocolatine-2-14b-instruct-v2.… ┆ 801.003789  ┆ 783.626218  ┆ 825.075249  │\n",
       " └─────────────────────────────────┴─────────────┴─────────────┴─────────────┘}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04843dbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
