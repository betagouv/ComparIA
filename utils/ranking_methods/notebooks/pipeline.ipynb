{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61666521",
   "metadata": {},
   "source": [
    "# `RankingPipeline`\n",
    "\n",
    "Dans ce script on teste la pipeline complète, permettant de paramétrer les méthodes de calcul des scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b395c80f",
   "metadata": {},
   "source": [
    "## Calcul des scores\n",
    "\n",
    "La méthode `run` lance le calcul des scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca2d365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "cache_dir = input(\"Indicate path to all Hugging Face caches:\")\n",
    "os.environ[\"HF_DATASETS_CACHE\"] = cache_dir\n",
    "os.environ[\"HF_HUB_CACHE\"] = cache_dir\n",
    "os.environ[\"HF_TOKEN\"] = getpass(\"Enter your HuggingFace token:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3074abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from rank_comparia.pipeline import RankingPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fceda6d",
   "metadata": {},
   "source": [
    "### Paramètres de `RankingPipeline`  \n",
    "\n",
    "- `method` : Méthode de classement utilisé : `elo_random`, `elo_ordered`, `ml`  \n",
    "- `include_votes` : Utilisation des données de votes  \n",
    "- `include_reactions` : Utilisation des données de réactions\n",
    "- `bootstrap_samples` : Nombres d'échantillons pour cacluler la version *Bootstrap* \n",
    "- `mean_how` : Moyenner par nombre de token générés ou par matchs effectués\n",
    "- `export_path` : le chemin vers le dossier dans lequel exporter les graphes et les scores finaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05af6e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since ministere-culture/comparia-votes couldn't be found on the Hugging Face Hub (offline mode is enabled).\n",
      "Found the latest cached dataset configuration 'default' at /home/jupyterhub-users/shared/projet_comparia/huggingface_hub/ministere-culture___comparia-votes/default/0.0.0/679f56e14f413546403b3468d717c4417e394326 (last modified on Mon Jul 28 10:06:44 2025).\n",
      "Using the latest cached version of the dataset since ministere-culture/comparia-conversations couldn't be found on the Hugging Face Hub (offline mode is enabled).\n",
      "Found the latest cached dataset configuration 'default' at /home/jupyterhub-users/shared/projet_comparia/huggingface_hub/ministere-culture___comparia-conversations/default/0.0.0/dc40af6af1c14e68bf39d55f6e1573d2d6582f19 (last modified on Wed Jun  4 17:40:30 2025).\n",
      "Using the latest cached version of the dataset since ministere-culture/comparia-reactions couldn't be found on the Hugging Face Hub (offline mode is enabled).\n",
      "Found the latest cached dataset configuration 'default' at /home/jupyterhub-users/shared/projet_comparia/huggingface_hub/ministere-culture___comparia-reactions/default/0.0.0/80befa851337d9f295096cef3d100b40d220dc07 (last modified on Mon Jul 28 10:06:54 2025).\n",
      "Using the latest cached version of the dataset since ministere-culture/comparia-conversations couldn't be found on the Hugging Face Hub (offline mode is enabled).\n",
      "Found the latest cached dataset configuration 'default' at /home/jupyterhub-users/shared/projet_comparia/huggingface_hub/ministere-culture___comparia-conversations/default/0.0.0/dc40af6af1c14e68bf39d55f6e1573d2d6582f19 (last modified on Wed Jun  4 17:40:30 2025).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final votes dataset contains 55617 conversations pairs.\n",
      "Reactions data originally contains 22993 conversations pairs.\n",
      "Final reactions dataset contains 21244 conversations pairs.\n"
     ]
    }
   ],
   "source": [
    "pipeline = RankingPipeline(\n",
    "    method=\"elo_random\",\n",
    "    include_votes=True,\n",
    "    include_reactions=True,\n",
    "    bootstrap_samples=5,\n",
    "    mean_how=\"token\",\n",
    "    export_path=Path(\"output\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e0e8637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (76_861, 11)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>conversation_pair_id</th><th>model_a</th><th>model_b</th><th>score</th><th>categories</th><th>model_a_active_params</th><th>model_b_active_params</th><th>total_conv_a_output_tokens</th><th>total_conv_a_kwh</th><th>total_conv_b_output_tokens</th><th>total_conv_b_kwh</th></tr><tr><td>str</td><td>str</td><td>str</td><td>i32</td><td>list[str]</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;0d9c65f6819c449b9b9e2830ad6682…</td><td>&quot;mistral-large-2411&quot;</td><td>&quot;chocolatine-2-14b-instruct-v2.…</td><td>1</td><td>[&quot;Health &amp; Wellness &amp; Medicine&quot;]</td><td>123.0</td><td>14.0</td><td>954.0</td><td>0.018991</td><td>193.0</td><td>0.0007</td></tr><tr><td>&quot;9bdb380027074066a8416468ea9e8b…</td><td>&quot;gpt-4o-2024-08-06&quot;</td><td>&quot;deepseek-v3-chat&quot;</td><td>2</td><td>[&quot;Food &amp; Drink &amp; Cooking&quot;]</td><td>200.0</td><td>37.0</td><td>532.0</td><td>0.032678</td><td>593.0</td><td>0.027886</td></tr><tr><td>&quot;02bd35e9d3234816bafed9da6d82e5…</td><td>&quot;gemma-2-9b-it&quot;</td><td>&quot;command-a&quot;</td><td>0</td><td>[&quot;Other&quot;]</td><td>9.0</td><td>111.0</td><td>114.0</td><td>0.000446</td><td>892.0</td><td>0.016255</td></tr><tr><td>&quot;d57e9a7d877c4ff28156aac96535af…</td><td>&quot;mistral-saba&quot;</td><td>&quot;gpt-4.1-nano&quot;</td><td>2</td><td>[&quot;Culture &amp; Cultural geography&quot;, &quot;Society &amp; Social Issues &amp; Human Rights&quot;, … &quot;Education&quot;]</td><td>24.0</td><td>35.0</td><td>4073.0</td><td>0.024492</td><td>3917.0</td><td>0.029601</td></tr><tr><td>&quot;7bfc4cc52b43422d87fc8bb5a4cf43…</td><td>&quot;llama-3.1-70b&quot;</td><td>&quot;gpt-4o-mini-2024-07-18&quot;</td><td>2</td><td>[&quot;Politics &amp; Government&quot;, &quot;Law &amp; Justice&quot;, … &quot;Natural Science &amp; Formal Science &amp; Technology&quot;]</td><td>70.0</td><td>35.0</td><td>548.0</td><td>0.006833</td><td>656.0</td><td>0.004957</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;48fd5c265a8f4b599d8d15b137865c…</td><td>&quot;mistral-small-24b-instruct-250…</td><td>&quot;ministral-8b-instruct-2410&quot;</td><td>1</td><td>[&quot;Education&quot;, &quot;Natural Science &amp; Formal Science &amp; Technology&quot;]</td><td>24.0</td><td>8.0</td><td>127.0</td><td>0.000764</td><td>221.0</td><td>0.000833</td></tr><tr><td>&quot;2f1d9e99ed5c46a680da725192dbab…</td><td>&quot;gpt-4o-mini-2024-07-18&quot;</td><td>&quot;gemini-1.5-pro-002&quot;</td><td>0</td><td>[&quot;Education&quot;]</td><td>35.0</td><td>220.0</td><td>147.0</td><td>0.001111</td><td>629.0</td><td>0.084334</td></tr><tr><td>&quot;c409b635e9d2480394e18080e48725…</td><td>&quot;phi-4&quot;</td><td>&quot;gemma-3-12b&quot;</td><td>0</td><td>[&quot;Natural Science &amp; Formal Science &amp; Technology&quot;]</td><td>14.7</td><td>12.0</td><td>509.0</td><td>0.002346</td><td>1010.0</td><td>0.004372</td></tr><tr><td>&quot;84f133738edb4d57820b4357d3039e…</td><td>&quot;gpt-4.1-mini&quot;</td><td>&quot;claude-3-7-sonnet&quot;</td><td>2</td><td>[&quot;Business &amp; Economics &amp; Finance&quot;, &quot;Natural Science &amp; Formal Science &amp; Technology&quot;]</td><td>70.0</td><td>300.0</td><td>907.0</td><td>0.011309</td><td>395.0</td><td>0.053024</td></tr><tr><td>&quot;8ce919feb5af40338fdbf46a17e45a…</td><td>&quot;qwq-32b&quot;</td><td>&quot;grok-3-mini-beta&quot;</td><td>1</td><td>[&quot;Business &amp; Economics &amp; Finance&quot;, &quot;Politics &amp; Government&quot;]</td><td>32.0</td><td>200.0</td><td>722.0</td><td>0.005152</td><td>1236.0</td><td>0.0759213</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (76_861, 11)\n",
       "┌────────────┬────────────┬────────────┬───────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ conversati ┆ model_a    ┆ model_b    ┆ score ┆ … ┆ total_con ┆ total_con ┆ total_con ┆ total_con │\n",
       "│ on_pair_id ┆ ---        ┆ ---        ┆ ---   ┆   ┆ v_a_outpu ┆ v_a_kwh   ┆ v_b_outpu ┆ v_b_kwh   │\n",
       "│ ---        ┆ str        ┆ str        ┆ i32   ┆   ┆ t_tokens  ┆ ---       ┆ t_tokens  ┆ ---       │\n",
       "│ str        ┆            ┆            ┆       ┆   ┆ ---       ┆ f64       ┆ ---       ┆ f64       │\n",
       "│            ┆            ┆            ┆       ┆   ┆ f64       ┆           ┆ f64       ┆           │\n",
       "╞════════════╪════════════╪════════════╪═══════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ 0d9c65f681 ┆ mistral-la ┆ chocolatin ┆ 1     ┆ … ┆ 954.0     ┆ 0.018991  ┆ 193.0     ┆ 0.0007    │\n",
       "│ 9c449b9b9e ┆ rge-2411   ┆ e-2-14b-in ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 2830ad6682 ┆            ┆ struct-v2. ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ …          ┆            ┆ …          ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 9bdb380027 ┆ gpt-4o-202 ┆ deepseek-v ┆ 2     ┆ … ┆ 532.0     ┆ 0.032678  ┆ 593.0     ┆ 0.027886  │\n",
       "│ 074066a841 ┆ 4-08-06    ┆ 3-chat     ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 6468ea9e8b ┆            ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ …          ┆            ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 02bd35e9d3 ┆ gemma-2-9b ┆ command-a  ┆ 0     ┆ … ┆ 114.0     ┆ 0.000446  ┆ 892.0     ┆ 0.016255  │\n",
       "│ 234816bafe ┆ -it        ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ d9da6d82e5 ┆            ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ …          ┆            ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ d57e9a7d87 ┆ mistral-sa ┆ gpt-4.1-na ┆ 2     ┆ … ┆ 4073.0    ┆ 0.024492  ┆ 3917.0    ┆ 0.029601  │\n",
       "│ 7c4ff28156 ┆ ba         ┆ no         ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ aac96535af ┆            ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ …          ┆            ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 7bfc4cc52b ┆ llama-3.1- ┆ gpt-4o-min ┆ 2     ┆ … ┆ 548.0     ┆ 0.006833  ┆ 656.0     ┆ 0.004957  │\n",
       "│ 43422d87fc ┆ 70b        ┆ i-2024-07- ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 8bb5a4cf43 ┆            ┆ 18         ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ …          ┆            ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ …          ┆ …          ┆ …          ┆ …     ┆ … ┆ …         ┆ …         ┆ …         ┆ …         │\n",
       "│ 48fd5c265a ┆ mistral-sm ┆ ministral- ┆ 1     ┆ … ┆ 127.0     ┆ 0.000764  ┆ 221.0     ┆ 0.000833  │\n",
       "│ 8f4b599d8d ┆ all-24b-in ┆ 8b-instruc ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 15b137865c ┆ struct-250 ┆ t-2410     ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ …          ┆ …          ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 2f1d9e99ed ┆ gpt-4o-min ┆ gemini-1.5 ┆ 0     ┆ … ┆ 147.0     ┆ 0.001111  ┆ 629.0     ┆ 0.084334  │\n",
       "│ 5c46a680da ┆ i-2024-07- ┆ -pro-002   ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 725192dbab ┆ 18         ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ …          ┆            ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ c409b635e9 ┆ phi-4      ┆ gemma-3-12 ┆ 0     ┆ … ┆ 509.0     ┆ 0.002346  ┆ 1010.0    ┆ 0.004372  │\n",
       "│ d2480394e1 ┆            ┆ b          ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 8080e48725 ┆            ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ …          ┆            ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 84f133738e ┆ gpt-4.1-mi ┆ claude-3-7 ┆ 2     ┆ … ┆ 907.0     ┆ 0.011309  ┆ 395.0     ┆ 0.053024  │\n",
       "│ db4d57820b ┆ ni         ┆ -sonnet    ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 4357d3039e ┆            ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ …          ┆            ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ 8ce919feb5 ┆ qwq-32b    ┆ grok-3-min ┆ 1     ┆ … ┆ 722.0     ┆ 0.005152  ┆ 1236.0    ┆ 0.0759213 │\n",
       "│ af40338fdb ┆            ┆ i-beta     ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ f46a17e45a ┆            ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "│ …          ┆            ┆            ┆       ┆   ┆           ┆           ┆           ┆           │\n",
       "└────────────┴────────────┴────────────┴───────┴───┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d10db3",
   "metadata": {},
   "source": [
    "## Match_list()\n",
    "\n",
    "Cette fonction permet de construire la liste des matchs effectués dans l'arène. Chaque élément de la liste correspond à un match joué avec :\n",
    "- les deux modèles qui ont joué le match\n",
    "- l'issue du match : 0 si c'eslt modèle B qui gagne, 2 si c'est le modèle A qui gagne et 1 s'il y a égalité.\n",
    "- l'id de la conversation du match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e05ab48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Match(model_a='mistral-large-2411', model_b='chocolatine-2-14b-instruct-v2.0.3-q8', score=<MatchScore.Draw: 1>, id='0d9c65f6819c449b9b9e2830ad66822f-265047fb74dd48ca8eab5adf55855132'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='deepseek-v3-chat', score=<MatchScore.A: 2>, id='9bdb380027074066a8416468ea9e8b77-b61f602cfc8d4c6c9a8f1cc7fe1315bd'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='command-a', score=<MatchScore.B: 0>, id='02bd35e9d3234816bafed9da6d82e55c-45a6395436cb4efda64b1c3046dd672a'),\n",
       " Match(model_a='mistral-saba', model_b='gpt-4.1-nano', score=<MatchScore.A: 2>, id='d57e9a7d877c4ff28156aac96535afcd-a931e6c0bd634a1f9854759494e4cbc5'),\n",
       " Match(model_a='llama-3.1-70b', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.A: 2>, id='7bfc4cc52b43422d87fc8bb5a4cf43ab-bc8364bc3f7d4540882df0343c7379ed'),\n",
       " Match(model_a='mistral-large-2411', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.B: 0>, id='ab104ab14d7d484da9d57324d0100121-0804eeca8bca43e5b6c38c727b192f65'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='lfm-40b', score=<MatchScore.A: 2>, id='a7b966db5644463880153760cd4fa97d-dd5ff4eb1b43424483e212d1810eed1b'),\n",
       " Match(model_a='llama-3.1-8b', model_b='mistral-nemo-2407', score=<MatchScore.A: 2>, id='f38b8eeb362d4342acda635efd4764c5-e17f77184ae94442a44dd210cd859e20'),\n",
       " Match(model_a='mistral-small-3.1-24b', model_b='gpt-4.1-nano', score=<MatchScore.A: 2>, id='36b75a4fbba941a79417143daf2c81c8-e67b38e333b0415daa74d2e791ebaea8'),\n",
       " Match(model_a='phi-3.5-mini-instruct', model_b='llama-3.1-70b', score=<MatchScore.A: 2>, id='ada0341a23be47a1bf65db051def0e9d-b5a7697f0b644899aadf08218079cd66'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='mistral-large-2411', score=<MatchScore.B: 0>, id='d7e9e02444554d9d8f2574ef13d61eac-a448e3007b994d05b2c1f283ab13345f'),\n",
       " Match(model_a='llama-3.1-70b', model_b='deepseek-v3-chat', score=<MatchScore.B: 0>, id='8ea3383dff2a4d5794ba41adbd5a0cfe-474e6e5f428c495c9e313a33163e5347'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='llama-3.1-nemotron-70b-instruct', score=<MatchScore.B: 0>, id='d8f4c159ef724df1b438f2306f1c3700-1ae9021fb1824c9499eccc0a818c3699'),\n",
       " Match(model_a='deepseek-r1-distill-llama-70b', model_b='o3-mini', score=<MatchScore.Draw: 1>, id='16f96ecf71394b72884fe63c08307a05-e1ceb0fc9d524a2d998d09290042f429'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='llama-3.1-8b', score=<MatchScore.Draw: 1>, id='b7973fb9a6ad4680863ecf5b6e1cb90a-9e3ef78d49bd4735b51110a3ce191a84'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.B: 0>, id='00ae60e97c864b909ce6dd2e0e02676c-f18783c1772d4167b06bc4176212808c'),\n",
       " Match(model_a='mistral-large-2411', model_b='llama-3.1-nemotron-70b-instruct', score=<MatchScore.B: 0>, id='c08ab62506da45188d4a40a484efee66-84644243ee084501b2068bab92e30904'),\n",
       " Match(model_a='gemini-1.5-pro-001', model_b='qwen2.5-7b-instruct', score=<MatchScore.A: 2>, id='7c4d71f87a7a4de3a6c8fe8b48703246-e7b7b4bfae044c5c93ece8783e3f1e6a'),\n",
       " Match(model_a='phi-4', model_b='gpt-4o-2024-08-06', score=<MatchScore.A: 2>, id='d5d2e46f5dd04e3686051f9a4547ba8a-ff882228d75a4497abf20e40b4009233'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.Draw: 1>, id='2d76cc8f4f814ccf8219b112fdddaa71-cefac65598bc47469bca37728a991e3c'),\n",
       " Match(model_a='aya-expanse-8b', model_b='phi-4', score=<MatchScore.B: 0>, id='c54e9e82beb34a7abce8bbbb3878b090-db70c2db527a40ab8eb2d4e5c05d41d2'),\n",
       " Match(model_a='llama-3.3-70b', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.A: 2>, id='1aae863ba5d644538c03778518981893-45e87ffd33204209bd784d47db476649'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.A: 2>, id='81d67c06c6464e63b88318983dfd4a6f-78d1b19ba5924f4da135cb28834bfdf4'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='qwq-32b', score=<MatchScore.A: 2>, id='eafdcf0e4f90406dadd1ee42921ce275-7fda688e9a7e4d1a94c1196ec63f3d29'),\n",
       " Match(model_a='mistral-small-24b-instruct-2501', model_b='phi-4', score=<MatchScore.A: 2>, id='b0c0b7539839438c91008b9ec63ea40d-f72ca5a4d42846178423c1a04a9b7e5b'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='c4ai-command-r-08-2024', score=<MatchScore.A: 2>, id='949586307ea7498bba0d5ceec1149ed3-e99e965aac1f4d84abfb8345e8025c6f'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='llama-3.1-70b', score=<MatchScore.A: 2>, id='e8c23a24865b412bb7cb246b3c107e7f-12920bffe16d4af1880fb672ca97ee0b'),\n",
       " Match(model_a='mistral-large-2411', model_b='gemini-2.0-flash-exp', score=<MatchScore.Draw: 1>, id='9dace52e19b04618ba96e0a6845f5511-3d9f880bd15d45c9a7c4ed743b700c5e'),\n",
       " Match(model_a='gemini-1.5-pro-001', model_b='phi-3.5-mini-instruct', score=<MatchScore.A: 2>, id='3a59a02744e043ac935b6803d45bbea9-275b0f4c65514003b587d55093876476'),\n",
       " Match(model_a='llama-3.1-405b', model_b='mistral-nemo-2407', score=<MatchScore.Draw: 1>, id='dbe120f957af40c698024069bc65ee42-15e0164711c44f1f8be2cbfe6ff99cb3'),\n",
       " Match(model_a='mistral-saba', model_b='llama-3.1-405b', score=<MatchScore.A: 2>, id='3c3cdccb766e48cd899d77f4eb4b6aab-1c422d7f85b94ce091775ed200680091'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='mistral-large-2411', score=<MatchScore.B: 0>, id='6d7fade1705d414eb76ff14c3828c996-36146ac9b4e147d3874489b213dfe8b0'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='claude-3-5-sonnet-v2', score=<MatchScore.A: 2>, id='42810760b3ef4acbad7afe1956148ea1-ce1274c86ab24efb8e92bdeb5cef6755'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='deepseek-v3-chat', score=<MatchScore.B: 0>, id='61b79c09c998460599a4f1a11c29a271-9588d405189d4a47ad7f8ae411c6313b'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='llama-3.1-8b', score=<MatchScore.A: 2>, id='cab18001531d476b8d32ce6c6e962892-cdb2abdbdae246a8818b435659bf9fd0'),\n",
       " Match(model_a='llama-3.3-70b', model_b='gemma-2-9b-it', score=<MatchScore.B: 0>, id='3a01499c561d4e3eaf7597ce2e597e97-03ad1c8d220f45d28b063c208e772472'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='deepseek-v3-0324', score=<MatchScore.B: 0>, id='10c1eb02894d4162b8bb0f1a5eea18cf-eb98a2831d744562ba018ce088e975cf'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.Draw: 1>, id='66c75b0e6c5947e89ff1a0377227ed8e-34cfe79ad2f8403cb24b688f06ea1ec7'),\n",
       " Match(model_a='deepseek-r1', model_b='claude-3-5-sonnet-v2', score=<MatchScore.B: 0>, id='a0d923d79e6243e6a503cfbb18ec69ed-7f0b2ba354f1413cb722d6d02bbd38ac'),\n",
       " Match(model_a='llama-3.1-405b', model_b='mistral-large-2411', score=<MatchScore.B: 0>, id='8d2700175fd8427eafb9d423870ed711-03396a59b806495fb7e01df2376f4ffa'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='gemini-2.0-flash-exp', score=<MatchScore.B: 0>, id='f9daa4e5db3c495287648dc69eaf7ab4-4940b7271dfa47bebbced88b3218d8a2'),\n",
       " Match(model_a='c4ai-command-r-08-2024', model_b='llama-3.1-70b', score=<MatchScore.A: 2>, id='de6b28b9c4464d84a479a5049bcadce5-c6eda6021d004a2fbf41328e2ce63968'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='llama-3.1-8b', score=<MatchScore.A: 2>, id='93864042200f421f8e669b2f4dfbab0a-7dea66c0c6ab49848a6697a775fd9d65'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='c4ai-command-r-08-2024', score=<MatchScore.Draw: 1>, id='eb748fb661724c2d9ca4b36d2594a370-5ee00f417e3244448eb40a115b1631fb'),\n",
       " Match(model_a='c4ai-command-r-08-2024', model_b='gemini-2.0-flash-001', score=<MatchScore.Draw: 1>, id='d9e64b5f6fc7409d93f887cce4112f3e-3378d52e1d0b4e89bb5e722b00ac2ed7'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='llama-3.1-70b', score=<MatchScore.A: 2>, id='1fdcd38e26664301bd0bb3b326ce80ee-63eda14680874e719994b57e5a2051a0'),\n",
       " Match(model_a='deepseek-r1-distill-llama-70b', model_b='o3-mini', score=<MatchScore.B: 0>, id='d26b21a1dd374cd396632fdae3cf664e-5fa6f592552b4a5ca87cb373fa01eb69'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='llama-3.1-405b', score=<MatchScore.Draw: 1>, id='e123d35630964e2ca5b7c2627a96e8bc-457fd124a32e48b1bd80ae4a6a80ee3e'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.B: 0>, id='c981ce58f35743f9a8878fbcdc053132-e138d61450ae4e5fa05b35c09818cf8c'),\n",
       " Match(model_a='phi-4', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.A: 2>, id='0766687f648b411cba0beb06a192a228-01c7d23de6254aa59e35fe66973f886b'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='claude-3-5-sonnet-v2', score=<MatchScore.A: 2>, id='b61ac56e23484f8db90486ba942ae4b1-c56b39339ef944c7800131b1cf355be0'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.Draw: 1>, id='9a89bb1a29964ffaab8c733fd32ea5b7-28031b6690e24194b54d42d6c650711d'),\n",
       " Match(model_a='mistral-small-3.1-24b', model_b='o3-mini', score=<MatchScore.Draw: 1>, id='66a6dda063ea49b389f1f1497ddb1bdd-5e05cf6121fa4549b1719b6cf34d2a62'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='claude-3-5-sonnet-v2', score=<MatchScore.A: 2>, id='5a514d70ec644b21a0672b11ea6c05c1-ba99b2b4a16345d9aab9878618088887'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='ministral-8b-instruct-2410', score=<MatchScore.B: 0>, id='874020cd7ee24175b994584a99400742-859f94cf5d6241ae84836960233dd6b7'),\n",
       " Match(model_a='llama-3.1-405b', model_b='mistral-nemo-2407', score=<MatchScore.A: 2>, id='f2dba51de1b044fa94a0a1ddd9923056-593b4b79ee8941329277e68307658f85'),\n",
       " Match(model_a='llama-3.1-405b', model_b='chocolatine-2-14b-instruct-v2.0.3-q8', score=<MatchScore.A: 2>, id='6801709d946a4734b8b29728981ca8ee-c02ca1caf3ba439d8fecd071e16b2de3'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='llama-3.1-70b', score=<MatchScore.B: 0>, id='fcb050300a104b7490245fb732613f91-63de2fa78b4f46a6aca4c12ca9adfc6b'),\n",
       " Match(model_a='llama-3.3-70b', model_b='gemini-1.5-pro-002', score=<MatchScore.A: 2>, id='08382c993a134689a9e1966c70b2dbbf-90872ed1c92f4bbba64d14584eb8dbbc'),\n",
       " Match(model_a='chocolatine-14b-instruct-dpo-v1.2-q4', model_b='mistral-nemo-2407', score=<MatchScore.A: 2>, id='bbc86c2fc6024bd0862095a449081f13-439c1e980ec84cf98b1833268a5a7e3e'),\n",
       " Match(model_a='lfm-40b', model_b='llama-3.1-405b', score=<MatchScore.B: 0>, id='891d476274574fecbadca2051570eb71-8cca04b0d21c4cdc94c4078f7bdbd7c9'),\n",
       " Match(model_a='phi-3.5-mini-instruct', model_b='mistral-nemo-2407', score=<MatchScore.Draw: 1>, id='04fcdce6e7c04412a987a38df2119d00-7b2716fd12e9426f92284fb1496e86d2'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='c4ai-command-r-08-2024', score=<MatchScore.A: 2>, id='d2d48d5ad37548fb82c9584921b0f2a1-4287796820114394899de46f87c598b2'),\n",
       " Match(model_a='deepseek-r1', model_b='deepseek-r1-distill-llama-70b', score=<MatchScore.Draw: 1>, id='4c0d842dce624a95b9bc923668452c97-757b45268078464ab0fcdb4136ca2e97'),\n",
       " Match(model_a='gemini-2.0-flash-001', model_b='llama-3.1-405b', score=<MatchScore.A: 2>, id='436ede8f9f054d31a787b7ce585b3086-5fbc95125323402583d806d1d66c5ea5'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='claude-3-5-sonnet-v2', score=<MatchScore.B: 0>, id='6b266c22a7844386ae61b71524b2365a-17ff7e3534d04afeb438dc1779c10ace'),\n",
       " Match(model_a='mistral-large-2411', model_b='deepseek-v3-chat', score=<MatchScore.Draw: 1>, id='688567a5e6ce47809688cfaccb69a6f4-f6c9d770aa6d406a908d82c899d454b1'),\n",
       " Match(model_a='gpt-4.1-nano', model_b='mistral-small-3.1-24b', score=<MatchScore.A: 2>, id='be4796424d634e89a79bbb8de04faf4a-0d65cd3ce1cf4cf68fc800af596fdab5'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.A: 2>, id='8002cbb17e224f099919ea0c879628d6-2751c624afe446ada39d827085f39547'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='llama-3.1-70b', score=<MatchScore.B: 0>, id='db0e0de714434da08e6d53539a2eff04-182fe25889a24a338a6895bd6125e2ea'),\n",
       " Match(model_a='llama-3.1-405b', model_b='mistral-nemo-2407', score=<MatchScore.B: 0>, id='9954ee4f7f7b43b7b7a95d08f8dd62af-d6c9b7d1b3fc47feb804fef3a9c92110'),\n",
       " Match(model_a='llama-3.1-nemotron-70b-instruct', model_b='phi-4', score=<MatchScore.A: 2>, id='553d192da223453ea0e2c4db28080a89-3e07e52f96e24872835b43d8e0553b66'),\n",
       " Match(model_a='gemma-3-12b', model_b='gemma-3-4b', score=<MatchScore.A: 2>, id='1f153fa47518470db4e681b7fa8d6d61-02e3b21beaac4c5ead90f9e7069c8610'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='llama-3.1-405b', score=<MatchScore.B: 0>, id='4b7499baecd94db3ae1b68af66825b05-c58798b93475445bb53693f2ca60826f'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='gpt-4o-2024-08-06', score=<MatchScore.B: 0>, id='c7ff48a285514795a3df905af09c8e18-1458ede7eec3453f8bc169a327855a17'),\n",
       " Match(model_a='mistral-large-2411', model_b='gemma-3-12b', score=<MatchScore.Draw: 1>, id='e807bad5e3f74bc7a961af91574b1711-366e444a8ebe46959c1f818c7c6c7109'),\n",
       " Match(model_a='deepseek-r1-distill-llama-70b', model_b='o3-mini', score=<MatchScore.A: 2>, id='73ca4a56d5694b669dd7523402ce4233-9e1f192566e145b08978af894265c356'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='mistral-large-2411', score=<MatchScore.B: 0>, id='50521adb26af4ba29891a60e0bb28347-f7aaffc3cecb4c3fa9e8021685a740d3'),\n",
       " Match(model_a='gemini-2.0-flash-exp', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.A: 2>, id='0ea84ea5a1cd44ec8cc3ce7e368a816f-601e8577df8449b19b6a40619dde6833'),\n",
       " Match(model_a='gpt-4.1-nano', model_b='claude-3-7-sonnet', score=<MatchScore.B: 0>, id='91d94aa1a7aa4dd7855279f4aff3d61a-2305b470e7f140bf993bb4b99487b375'),\n",
       " Match(model_a='gemini-2.0-flash-001', model_b='llama-4-scout', score=<MatchScore.A: 2>, id='53aceb58ef4a44379cb2746b98d39d78-fb83b0999dbb45d082f549df65e6c01f'),\n",
       " Match(model_a='gemini-2.0-flash-001', model_b='chocolatine-2-14b-instruct-v2.0.3-q8', score=<MatchScore.A: 2>, id='ca1a1d3a4db847b385529748a1a10236-f9814403e7a347c38bc63ba53c6718c6'),\n",
       " Match(model_a='c4ai-command-r-08-2024', model_b='gemini-2.0-flash-001', score=<MatchScore.Draw: 1>, id='39847011635b4277bacb4cb593caa721-e75c40356039467090172cbf720173e4'),\n",
       " Match(model_a='c4ai-command-r-08-2024', model_b='gemma-3-4b', score=<MatchScore.A: 2>, id='002444714bfe42bd85d9f40e0354e67b-30511f50c808400897f17d950b776dcd'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='deepseek-r1-distill-llama-70b', score=<MatchScore.Draw: 1>, id='0369eecbea4d4904957ff66a302d0bab-d5457a5886e948df905f297e60a5d28e'),\n",
       " Match(model_a='mistral-large-2411', model_b='mistral-nemo-2407', score=<MatchScore.A: 2>, id='eede750b2dc3419aa1531c5fe15dc06f-6b8a1f573a744eadb135045b7e91fa8c'),\n",
       " Match(model_a='mistral-large-2411', model_b='gemini-1.5-pro-002', score=<MatchScore.B: 0>, id='5b792990a07041a48a270e945699d4e5-6978188b1b6c4d32859fcc749bf724ec'),\n",
       " Match(model_a='deepseek-r1', model_b='chocolatine-2-14b-instruct-v2.0.3-q8', score=<MatchScore.A: 2>, id='71b923905cc742c99a8cc6548e7d9c31-9ea78fb9d5e94fd7ab268b3025de0217'),\n",
       " Match(model_a='llama-4-scout', model_b='mistral-small-3.1-24b', score=<MatchScore.Draw: 1>, id='3f5a032381ea4b3db6a7ffa4bd61581a-9ad3f089a98a41a0b6ad6f670336f1a2'),\n",
       " Match(model_a='gemini-2.0-flash-exp', model_b='llama-3.3-70b', score=<MatchScore.Draw: 1>, id='4bdb948f3ef1444e9910a60e9ff29462-a7295a2ab41b48a899494e95ebfab87a'),\n",
       " Match(model_a='lfm-40b', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.Draw: 1>, id='d300e041452b4bfa89b8a8d6ab9a4a2e-96a1379e2b214c18b44355de7247dc6a'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='llama-3.1-nemotron-70b-instruct', score=<MatchScore.Draw: 1>, id='c87b93e949e6448bb61b263db40957e1-85c7cb1db91f41848690356c8e7f7ff9'),\n",
       " Match(model_a='lfm-40b', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.Draw: 1>, id='4481cb6b254240749ef024f000576eb7-6d40aeadc32c415eb9923940efde7e09'),\n",
       " Match(model_a='qwq-32b', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.A: 2>, id='16d318f9b09142fe9edf031afa3f2e65-7d075bccdf894cfa8283d87c6f669d8f'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.A: 2>, id='bdfde83982b0485085ec5bf0bd799493-d9e0c59446734488babf541b6a883fb4'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.A: 2>, id='7a6897331f004e20b332cbda7db47d06-6f4ff5284c734f3fb769a0ad701d8edf'),\n",
       " Match(model_a='mistral-small-24b-instruct-2501', model_b='c4ai-command-r-08-2024', score=<MatchScore.A: 2>, id='1dea048367da4ce7970069e47606b556-25c4ff7f7cb64349bc6719f63bb23546'),\n",
       " Match(model_a='deepseek-v3-0324', model_b='c4ai-command-r-08-2024', score=<MatchScore.A: 2>, id='ef1e78bd5b4a42ebafb7e7afd3fb3918-1366559a7777449abbef0039fbd05d17'),\n",
       " Match(model_a='phi-3.5-mini-instruct', model_b='llama-3.1-70b', score=<MatchScore.B: 0>, id='17c22b96b7d048e29ce4d9b8c8e6865e-8b7df3895ca64bb08d12803ccb873a43'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.Draw: 1>, id='49a8b2b935f6402aba1c7cee42d67ad4-ef5b4dd9ff704a46b8a6b6a132e4c2c0'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='gemini-2.0-flash-001', score=<MatchScore.A: 2>, id='e0a4afe42906427fb44dab8f7d8b66af-72f12096597742c494f0c2bd0aa7d8be'),\n",
       " Match(model_a='phi-4', model_b='llama-3.1-405b', score=<MatchScore.B: 0>, id='a325ad2a37c34a16b1c63bfd33f012c8-d033d243b84440538663b481c7642d98'),\n",
       " Match(model_a='mistral-small-3.1-24b', model_b='llama-3.1-nemotron-70b-instruct', score=<MatchScore.A: 2>, id='20cd3140a2d04ff7a3af9cebe622f7cc-52c762a1a910433196f9e1bf2f306a5b'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='llama-3.1-nemotron-70b-instruct', score=<MatchScore.A: 2>, id='12ccaa1a9a7d4ff690c745ad4b7fbf6d-1f8801ecf615452fa87f7a59f6e40273'),\n",
       " Match(model_a='gemma-3-4b', model_b='llama-3.1-405b', score=<MatchScore.A: 2>, id='eac857586e2c4807b326bcd3d9e930f9-4a34af80d5f446a99ea05896ac04d235'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='gemma-2-9b-it', score=<MatchScore.Draw: 1>, id='89e5fd4edd7c4bc1998836b5a500136f-bf29b18539d145919e92816cdafd0489'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='ministral-8b-instruct-2410', score=<MatchScore.Draw: 1>, id='8c1dfaa601854cdda3676ae80dee2446-b56dc64cea044ba4a86f017a2a8a65cb'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.A: 2>, id='635c572efb5c470e83023c4bb7438b04-6f518581ea414bb0b99737eae031a573'),\n",
       " Match(model_a='gemma-3-4b', model_b='command-a', score=<MatchScore.A: 2>, id='c69fa3ec94d141f281e3cf7f109c5ce5-b21ec97b5fd6401c91ba9c2257c514da'),\n",
       " Match(model_a='gemini-2.0-flash-exp', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.Draw: 1>, id='b96b5ba20a2444d696ac71babe13bacb-41d9879e08f741a798e0abf21f5dc165'),\n",
       " Match(model_a='llama-3.1-70b', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.Draw: 1>, id='b4ce5db4f00e4ea7b077c72d232aa285-ffde2c76d9d84efaaa2a2cc21bcb2e5b'),\n",
       " Match(model_a='deepseek-v3-0324', model_b='o4-mini', score=<MatchScore.A: 2>, id='9dff20cc0eb645f8a9aaa197129ee1f5-9c5cfdfa06a74fb2b37bdb270e3001d7'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='llama-3.1-nemotron-70b-instruct', score=<MatchScore.Draw: 1>, id='807c5344e0c5413182f3b100accdc704-a2304d9e88774f20a6abe22aedd34255'),\n",
       " Match(model_a='llama-3.1-8b', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.Draw: 1>, id='bd02e4056ace44a88cdbd75bd63d6ea1-346ca39752834761823bb43735afd3e3'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='phi-4', score=<MatchScore.Draw: 1>, id='be3eaa73251c49b08f745911e91289d7-a3183e0debb14521a0fbb2a2c70b8926'),\n",
       " Match(model_a='mixtral-8x7b-instruct-v0.1', model_b='gemma-2-9b-it', score=<MatchScore.Draw: 1>, id='5c14c505b28f41eb92a5af2b6c0cda51-e62deb80f25a4475964ec2a3c1580544'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.Draw: 1>, id='e5ae1b6efd9d4945a1b0db3253712063-626289a378144d5e9dbbc9977cdea3bf'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='gpt-4.1-mini', score=<MatchScore.Draw: 1>, id='99aa472b90fa4f24a79df8ec5fc53dca-41885f4f5463494aae9f77b40b65167e'),\n",
       " Match(model_a='gemma-3-12b', model_b='phi-4', score=<MatchScore.A: 2>, id='29e4c95eb2744288bbeaf7f4d172f278-f9e7932c0526419cb4d4692672f8e227'),\n",
       " Match(model_a='deepseek-r1', model_b='claude-3-7-sonnet', score=<MatchScore.B: 0>, id='ab3f1ced45aa419b99a861520f3dca2b-00950c4bc0c84bbaa20878473889824d'),\n",
       " Match(model_a='llama-4-scout', model_b='gemini-2.0-flash-001', score=<MatchScore.B: 0>, id='05f4ece192e04b2f83e9722a25acb6fd-297d6c20f80d4fd7b866a8e26dc9e6ea'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='llama-3.3-70b', score=<MatchScore.B: 0>, id='84d9c5cafebb48529dae0d2e8a9df66c-ff8d09bfc7ce43dea9a82b58379177fc'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='phi-3.5-mini-instruct', score=<MatchScore.A: 2>, id='469fbbdc5a7f4530b6643c2a89a511a7-3e69bbd23f314d0d906401e56f34817a'),\n",
       " Match(model_a='llama-3.1-nemotron-70b-instruct', model_b='c4ai-command-r-08-2024', score=<MatchScore.B: 0>, id='f04b39d85549475292f5e7a6cc180ec1-fee6f125a77b4ee9b89e09ed4af6173c'),\n",
       " Match(model_a='llama-3.1-70b', model_b='gemma-2-9b-it', score=<MatchScore.B: 0>, id='da1400741f4d47ef85c4f9a364ad9e71-237dd4b3a6934d579199df02f09b1c75'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.B: 0>, id='5c2ba6430adb456eb4fa3cdf1c10e811-822d23a5d9e8472ca4e8a7179821a0d6'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='gemini-2.0-flash-001', score=<MatchScore.Draw: 1>, id='0ff4016f0f7941bb84e057bea38511de-aac3f9b72387478dbb58796a0cea73b6'),\n",
       " Match(model_a='claude-3-7-sonnet', model_b='mistral-saba', score=<MatchScore.A: 2>, id='edf7471271c84be486496f086fe634d6-bcd48153cd454dd9a70b322a8a6706e3'),\n",
       " Match(model_a='mistral-large-2411', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.B: 0>, id='7a48b9660bb14bd1b7583888bf69f852-a2ef62e3bdfc4ffdb7f3a71343377e9e'),\n",
       " Match(model_a='llama-3.1-405b', model_b='qwen2.5-7b-instruct', score=<MatchScore.A: 2>, id='a465d10d840647a5a8679b12fa5e771a-1f233dec5adc4e5c92700924ff292d91'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='deepseek-v3-chat', score=<MatchScore.B: 0>, id='895cdceb3da241939b77675e2f8392c6-bfc26263a5444b869101ab2decedc66f'),\n",
       " Match(model_a='mixtral-8x7b-instruct-v0.1', model_b='mistral-nemo-2407', score=<MatchScore.A: 2>, id='304754bb98834032adffa347349208da-5d34e302e3c7461ea657ff5c9f0d3891'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='gpt-4o-2024-08-06', score=<MatchScore.A: 2>, id='05a6c858a7164bc1a4817af6365c4264-4b93d43405a24fbea81ded57a3458311'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.B: 0>, id='25f986fa794d4d4ab883b89c55a3f394-4e8d00b317004a87a0753e1fa83f0d0a'),\n",
       " Match(model_a='mistral-large-2411', model_b='c4ai-command-r-08-2024', score=<MatchScore.A: 2>, id='40d4405f17944ad2891e349cc5de1e47-ff682118f03b4501bbba1d648da90cc3'),\n",
       " Match(model_a='mistral-small-3.1-24b', model_b='llama-3.1-nemotron-70b-instruct', score=<MatchScore.A: 2>, id='c6af9c5f5026453c80b5d12c2b95a702-e19e9abeff524de68c5742bac1ba3a64'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='aya-expanse-8b', score=<MatchScore.Draw: 1>, id='9884a13d55a94ea9a0e88f1a89ebbfa6-4704d399dee74eea860b914e16ef4411'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='deepseek-v3-chat', score=<MatchScore.B: 0>, id='59b6109d348d4136944c7e74aa838acc-edc9821846ec4b95986863c43c44c99d'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='gemma-3-4b', score=<MatchScore.A: 2>, id='cd7df519441641f0a6c89c45a4a44592-d6a522b4d5844610a128300060b7aeb7'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='mistral-large-2411', score=<MatchScore.Draw: 1>, id='f1593a68738148678832b1e4202eddd3-2d6947f4f2004ed1b572b53a334e17dc'),\n",
       " Match(model_a='llama-3.1-nemotron-70b-instruct', model_b='o3-mini', score=<MatchScore.A: 2>, id='9423aa80c2154ae2befd58228e734ec4-181558c9b6cf424ead2e9aa1a36c886d'),\n",
       " Match(model_a='mixtral-8x7b-instruct-v0.1', model_b='llama-3.1-70b', score=<MatchScore.B: 0>, id='19d3c304f8f74391b5bf96259eeb5e9c-a67bbc0c59df4171a4a621862d09d6ba'),\n",
       " Match(model_a='llama-3.1-nemotron-70b-instruct', model_b='command-a', score=<MatchScore.Draw: 1>, id='9d637450e4c048469c7a5a532321456d-20de02c2dc7f40d39921da5add004536'),\n",
       " Match(model_a='phi-4', model_b='claude-3-5-sonnet-v2', score=<MatchScore.B: 0>, id='3a6f068dfde24a0fa3c0b4d9907537b6-cd78a426165547fcb8c9746da0884693'),\n",
       " Match(model_a='jamba-1.5-large', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.B: 0>, id='757c47810a7f4549ae4f0fff408f1899-f25ba118aaab484dbb50da7f2fa838a0'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='gemini-2.0-flash-001', score=<MatchScore.Draw: 1>, id='d8dc800b2e974f8fbc53d852ae4c8c2b-5194816f3c6648c19b9a6cdc581aad3a'),\n",
       " Match(model_a='mixtral-8x7b-instruct-v0.1', model_b='gemini-1.5-pro-001', score=<MatchScore.B: 0>, id='96dbfaefaf374b4dbb1ca0f94d3ea5ca-d8ac2ec151d347afbf77a6627e0eb2a0'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='llama-3.1-70b', score=<MatchScore.A: 2>, id='2534791742974f8fa12138b3cb67e719-8246cbaeb60d46f29ae5d33493a9450d'),\n",
       " Match(model_a='gemini-2.0-flash-001', model_b='c4ai-command-r-08-2024', score=<MatchScore.A: 2>, id='4088e424c3d848128b321f78507d1941-b57024988ab241c2926f677c1fff55eb'),\n",
       " Match(model_a='gpt-4.1-nano', model_b='deepseek-v3-0324', score=<MatchScore.B: 0>, id='a63b246c450c4968935779b22174b2b1-3b31c3b6c23b4746bdb21ed293c51015'),\n",
       " Match(model_a='mistral-small-3.1-24b', model_b='deepseek-r1', score=<MatchScore.A: 2>, id='aec2e46c734e49d6a45488292b4ed559-0f074e0c34c846dc9550393aa5f5e3e6'),\n",
       " Match(model_a='llama-3.3-70b', model_b='c4ai-command-r-08-2024', score=<MatchScore.B: 0>, id='1a7b12ce0f3f4099a7319a7f19f42e58-088a440317ef43c08b1fe44789bd33df'),\n",
       " Match(model_a='command-a', model_b='grok-3-mini-beta', score=<MatchScore.B: 0>, id='a6dda2e7c15445f295aea1334ed709bf-e036cafd8f3d494c8e63897a61217a5b'),\n",
       " Match(model_a='gemini-2.0-flash-001', model_b='ministral-8b-instruct-2410', score=<MatchScore.A: 2>, id='a2ec0c7423ad419298be3cc6cb43348b-e962231390934534a6901eb7de5e46bb'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.A: 2>, id='02fcff04fce8497ba65c54b51ac0a151-29724ec12d5e485984bd800559d922b7'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='gemma-2-9b-it', score=<MatchScore.B: 0>, id='5b59dbc4aa054500ace6d8448fca4ea6-7f7243c5d46446638ffbb2e311f1a0ac'),\n",
       " Match(model_a='deepseek-r1', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.B: 0>, id='47f233187fd5463181d87b5b3de0053b-98f48cffcedd4b4c8e67166072bd0149'),\n",
       " Match(model_a='aya-expanse-8b', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.A: 2>, id='0a23f7f52a6840d2ba0820139f97f384-2f655fa6ecbf42b3a635c8c42bd6c27c'),\n",
       " Match(model_a='llama-3.1-70b', model_b='mistral-large-2411', score=<MatchScore.B: 0>, id='367b7c8c4bfb47089cf8626f4e83fa41-10d64d9a060f4a328860efb8f7c319c3'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='llama-3.1-405b', score=<MatchScore.B: 0>, id='57ccd49e1eac42d2b7c80a85232f391b-2c7b45a1407949c0b76d14bcbc391006'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='mistral-large-2411', score=<MatchScore.A: 2>, id='57afdf7756b140df82df87e5b2202ca6-948cd232009048d083f2ed09ecb473db'),\n",
       " Match(model_a='mistral-large-2411', model_b='gpt-4.1-nano', score=<MatchScore.Draw: 1>, id='35e9043da05c4614876526d4fde1d6a2-6eb17242dc9d4addafb177cd4ca7a4e9'),\n",
       " Match(model_a='gemini-1.5-pro-001', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.A: 2>, id='8f48668b2e494e769f8259d3e654620e-0cb8a716d0b94a2083e7390160b02eda'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='gemini-1.5-pro-002', score=<MatchScore.B: 0>, id='abaf5faa082f46ceb21f53c3c7079d33-48dc1b38263f46fbb4eb8c3d7106ddee'),\n",
       " Match(model_a='llama-3.1-8b', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.B: 0>, id='e6793e53c8f94528959fb16a85858374-7183e62170a84dc9827720188ab92f4a'),\n",
       " Match(model_a='llama-3.1-405b', model_b='gemini-1.5-pro-001', score=<MatchScore.B: 0>, id='c7bccc8a660d4983b1e7de3c4390a62e-2509c8b9865d4a3c9cce4102361865c0'),\n",
       " Match(model_a='gemma-3-4b', model_b='gemini-2.0-flash-001', score=<MatchScore.B: 0>, id='fc670a99fdbd41c0abf47e79162b6814-0b18065f83824265bb91e9c6d385136b'),\n",
       " Match(model_a='llama-3.1-nemotron-70b-instruct', model_b='deepseek-v3-chat', score=<MatchScore.B: 0>, id='0df3eb1682d74bd1b1cc8b31918d6991-87adce197757415da6ba700256e0afa6'),\n",
       " Match(model_a='llama-3.3-70b', model_b='llama-3.1-405b', score=<MatchScore.A: 2>, id='3bc87bba1b4b4bf88ca1b256a85a4ab9-d319bb17bc784266b5fbc5a21817dcc9'),\n",
       " Match(model_a='llama-3.1-70b', model_b='gemini-2.0-flash-exp', score=<MatchScore.Draw: 1>, id='b76dd08f91fc466ebc028ca41d2aaf88-f534e80894904f73915cf31a3e8f22de'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.B: 0>, id='99761ee4ba5941c7a385c2f84af63503-2072ec9ebfe74cd690827c3232314a08'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='llama-3.1-70b', score=<MatchScore.A: 2>, id='3eaad23f18414240b7e9ca732afa7f22-62d4306e76c04a678e5d259a1f5b965b'),\n",
       " Match(model_a='phi-4', model_b='claude-3-5-sonnet-v2', score=<MatchScore.Draw: 1>, id='ca67767aad9643b78a092405524a2ee5-c9b164c902a04a879c25fdafee309f18'),\n",
       " Match(model_a='llama-3.1-nemotron-70b-instruct', model_b='claude-3-7-sonnet', score=<MatchScore.B: 0>, id='83671c615287463895fc5671f29165f4-4959a52fd0344a7cb04a6b5065584aca'),\n",
       " Match(model_a='mistral-small-24b-instruct-2501', model_b='deepseek-r1', score=<MatchScore.B: 0>, id='1da8059fa61c4b2495e7179f7f3b830b-d4e53f19129248c8981a2c3ca5701671'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='mistral-large-2411', score=<MatchScore.Draw: 1>, id='f41e626c5a9b46c6997e9fe4066b2045-bf03ef1e180d463894b04fd4936785ad'),\n",
       " Match(model_a='claude-3-7-sonnet', model_b='ministral-8b-instruct-2410', score=<MatchScore.A: 2>, id='ed815d8ae04f48de92174606eb1574e5-7795b3db0de94db8970e3df19f66c9c8'),\n",
       " Match(model_a='llama-3.1-70b', model_b='ministral-8b-instruct-2410', score=<MatchScore.Draw: 1>, id='7f410e3af54748f194b1f24d74f8dbbe-98724a3bcab142428659db94617e012a'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='phi-4', score=<MatchScore.B: 0>, id='2843056831784153b10d13e9af62dd0d-6b5fc42310ea4caabaad92d765c4a744'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='c4ai-command-r-08-2024', score=<MatchScore.A: 2>, id='c1c27f69a53847f69101814cbf29829b-e7fb62e9c6064740a5dbfca258fcb906'),\n",
       " Match(model_a='gemini-1.5-pro-001', model_b='llama-3.1-70b', score=<MatchScore.A: 2>, id='513e62fac5e546c7bd5fbf550d5681c5-d185cf6063cc4cdf9134f0690a41d0d4'),\n",
       " Match(model_a='chocolatine-2-14b-instruct-v2.0.3-q8', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.B: 0>, id='8a36524bce72483292bbace37074c7d7-a8f79bccabdf4f71941c5645db18fa4e'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.A: 2>, id='9e5bae9ef22d4080abf761dfccc22fb1-2424ff10b25f4e0c8314f082620f6ace'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='gemma-3-4b', score=<MatchScore.B: 0>, id='e881423e94fe41bb8673a58cb1859a93-765465415df64047aad6fb25549786c3'),\n",
       " Match(model_a='gemma-3-4b', model_b='gemma-3-27b', score=<MatchScore.B: 0>, id='dc20b8cf2cff4131916eb44bc30d9ed7-119f3f17a8584298bedb224d83f5b83f'),\n",
       " Match(model_a='llama-3.1-70b', model_b='claude-3-5-sonnet-v2', score=<MatchScore.Draw: 1>, id='5bbb4861c2824c4d8cbd13052282604d-97ec31ac36f4402bb869539e72d2e92e'),\n",
       " Match(model_a='gemma-3-27b', model_b='lfm-40b', score=<MatchScore.A: 2>, id='02fcfb0f40e14cf6bb152fc42561a681-f38cd303f3ea4126b8fdb2345b44f602'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='phi-3.5-mini-instruct', score=<MatchScore.A: 2>, id='e5932dae59b0422ba874706bff274ad4-84f5da7e23194d0bbce83291f1fd830d'),\n",
       " Match(model_a='llama-3.1-8b', model_b='c4ai-command-r-08-2024', score=<MatchScore.Draw: 1>, id='f3b2f86d459e4145a20259ddc8c09748-21a972ef94ec43a9ab491a998b807316'),\n",
       " Match(model_a='deepseek-r1', model_b='grok-3-mini-beta', score=<MatchScore.Draw: 1>, id='9f09788dc4ca4229bdba1319908239dc-2f024486e816415bb41e785fb012e94a'),\n",
       " Match(model_a='deepseek-v3-0324', model_b='gpt-4.1-mini', score=<MatchScore.A: 2>, id='7af28d27c2e74ffd9db47742d18f6172-550b9c91eca14b46be1e33b35a4a0ad0'),\n",
       " Match(model_a='lfm-40b', model_b='mistral-large-2411', score=<MatchScore.B: 0>, id='abcf04b3fb8a465d85a98d86066e2316-f29f250e04b64d1b8b41db194a9f95cc'),\n",
       " Match(model_a='c4ai-command-r-08-2024', model_b='phi-4', score=<MatchScore.Draw: 1>, id='8815d30744bb4c5aa75f00fc3e107fce-e67f61928fc34487b4a550ac3e23fb09'),\n",
       " Match(model_a='deepseek-r1-distill-llama-70b', model_b='llama-3.1-70b', score=<MatchScore.A: 2>, id='83f9574a15f742cd97218cc867b91a91-ba5d2473a37d40c399abe5ae3ff34fd9'),\n",
       " Match(model_a='gpt-4.1-mini', model_b='c4ai-command-r-08-2024', score=<MatchScore.B: 0>, id='8b1e0b2c55ec460bba3a359e712caa5a-93fe95102b8a4f808e68eb82ca1de627'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.B: 0>, id='a6bf0b68294643929c0d9c1ffb17dbec-1a7eea19b3084f0ab6cb0ef8777ccc6f'),\n",
       " Match(model_a='llama-3.1-nemotron-70b-instruct', model_b='mistral-small-3.1-24b', score=<MatchScore.B: 0>, id='8d7fcec9a16b415e852ea41267bbe606-ef9eb9c7132b42c88684ab1f92bd4554'),\n",
       " Match(model_a='deepseek-r1', model_b='o3-mini', score=<MatchScore.B: 0>, id='b4f3c8ef397343a789667932f56cc889-119465e8e0fe47e69de616d7a8739c59'),\n",
       " Match(model_a='phi-4', model_b='deepseek-v3-chat', score=<MatchScore.B: 0>, id='614917b6cff54755a5a55886671f295f-56730cd0a7b642c1948c69f58a9e408c'),\n",
       " Match(model_a='phi-4', model_b='gemma-3-12b', score=<MatchScore.B: 0>, id='146a730e1a2441a48b922e37185d012f-7098b10511864e1a84a3efa89c6698ad'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='claude-3-5-sonnet-v2', score=<MatchScore.B: 0>, id='31f96c68725a4b0bb3a7c3100dab6432-77501f44fd914320bbef909516c74850'),\n",
       " Match(model_a='llama-3.1-405b', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.Draw: 1>, id='5c784d4ebfe1451596d391c78888c5f1-829d1af937e149e6a8871177cb157cc0'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='claude-3-5-sonnet-v2', score=<MatchScore.B: 0>, id='de16bfde6cd8484993f166614a3601c4-eb1d348036ef4486b82cb57b799438be'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='phi-4', score=<MatchScore.Draw: 1>, id='eb3640c19e37451d932ddaab674bab2f-701571a85222497fb8654d4749c023a8'),\n",
       " Match(model_a='claude-3-7-sonnet', model_b='command-a', score=<MatchScore.Draw: 1>, id='44306ef7b22444f088e8e2575b56a7b5-8bfefc2bb6854973b28ef70b9244f0da'),\n",
       " Match(model_a='c4ai-command-r-08-2024', model_b='llama-3.1-405b', score=<MatchScore.B: 0>, id='ef810ec8777143e1b24b8e425b9dbef6-a97a9cd224a145a0abe9852d0b3be4c3'),\n",
       " Match(model_a='mistral-small-3.1-24b', model_b='mistral-large-2411', score=<MatchScore.A: 2>, id='22084a6d24f14d44af1770086c9a3117-2b3d252a43fe49bf920316febfea2db0'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='ministral-8b-instruct-2410', score=<MatchScore.A: 2>, id='aaf4a44a45c040e396df86ec76ab8a57-e526dd3d17624d40990278512e4b4a9a'),\n",
       " Match(model_a='mistral-small-24b-instruct-2501', model_b='claude-3-5-sonnet-v2', score=<MatchScore.Draw: 1>, id='06983bd775e04e56a7593db7aa465c68-b1d92eb7fe6746cbb69d42ff1fcab2d7'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='llama-3.1-405b', score=<MatchScore.B: 0>, id='d781d79d5f0b46fd993a217fcc3e6067-730d8376bb604b14988b8206c836174f'),\n",
       " Match(model_a='llama-3.1-nemotron-70b-instruct', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.A: 2>, id='59fbd4ee6f124b359a82857468dfceee-57d4f9cb1af4468f864bf03b75eafcdb'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='deepseek-v3-chat', score=<MatchScore.Draw: 1>, id='3bc4ac568c8d4a9eb0fe74f961bb5859-98f61da45e0f4df687e851c80158f660'),\n",
       " Match(model_a='mistral-large-2411', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.Draw: 1>, id='b21a8bef268a40cdbe2d4cbed4971245-0d914e8e0d7f45d294558b8558572a76'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.A: 2>, id='38c941016baf45d3a13b89bec2bc8034-98cbfdbd3e054b83a0954827db2c253e'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='mistral-large-2411', score=<MatchScore.Draw: 1>, id='33cc857fd2694a03bc10c2ef0932dbf1-d8f7487e24374290a853ac715e8586d1'),\n",
       " Match(model_a='llama-3.1-70b', model_b='claude-3-5-sonnet-v2', score=<MatchScore.A: 2>, id='f9b9863a9f434fb88a150551853c690d-07a5732ddf4f4fc7b48853fedc710125'),\n",
       " Match(model_a='gemini-1.5-pro-001', model_b='mistral-nemo-2407', score=<MatchScore.B: 0>, id='6b63983b12cc4959a9bd74b17690eebf-c5d58705c220402e9e4c713b37052add'),\n",
       " Match(model_a='gemini-1.5-pro-001', model_b='phi-3.5-mini-instruct', score=<MatchScore.A: 2>, id='b70917b9a65542fa8c61dfacf6266bbf-23c1bd7e1b374ccbb3c00acd5119ed39'),\n",
       " Match(model_a='gemini-2.0-flash-exp', model_b='llama-3.1-405b', score=<MatchScore.Draw: 1>, id='c645c98b3791431da295bd70f36e826b-2a3e9ea23e324eca9a330fa6271eb9a7'),\n",
       " Match(model_a='gemma-2-27b-it-q8', model_b='phi-3.5-mini-instruct', score=<MatchScore.A: 2>, id='1402463cbd094fd599edbb33ebad4863-a595f2520b694c20b67c1fcbc6707378'),\n",
       " Match(model_a='mistral-large-2411', model_b='lfm-40b', score=<MatchScore.A: 2>, id='2da8cb4385df42e58c966f2a1566a48e-7188fe6ecacb4b10b094b56f4701da2c'),\n",
       " Match(model_a='gemini-2.0-flash-exp', model_b='gemma-2-9b-it', score=<MatchScore.A: 2>, id='d8c5a31949bc47cc989bf05511e28bc6-79fb8e37a50841ed9fee3c40cf6ca236'),\n",
       " Match(model_a='llama-3.1-8b', model_b='phi-3.5-mini-instruct', score=<MatchScore.A: 2>, id='998f61d6f12c4ca7bc70975bac27ed02-5ef600a0d2b34e0ca8f052797ffb8356'),\n",
       " Match(model_a='mistral-large-2411', model_b='llama-3.1-405b', score=<MatchScore.Draw: 1>, id='6b45edc0c6434f26a40079993fa3a5de-4cd467e34157461f83023d18c36e5ee0'),\n",
       " Match(model_a='phi-4', model_b='qwq-32b', score=<MatchScore.B: 0>, id='3733e931be954622a7285611448531b0-6c7ca7ce404f473f97c75fd616b77da1'),\n",
       " Match(model_a='lfm-40b', model_b='mistral-large-2411', score=<MatchScore.B: 0>, id='3de069424ffe43cdb4d906ed9332d149-c3832d02de2841838e5045c7d9cdc79f'),\n",
       " Match(model_a='llama-3.1-405b', model_b='deepseek-r1-distill-llama-70b', score=<MatchScore.B: 0>, id='07f025e251e045b1aca0f9fb70c87706-ab41e37ce2724b7290a9b32905e5802d'),\n",
       " Match(model_a='llama-3.1-405b', model_b='gemma-3-4b', score=<MatchScore.B: 0>, id='c8bef4aa312d4c50b9bfa07e251c63ad-aa8408bfbb4b4c3ab28629a6d8c29da5'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='gpt-4o-2024-08-06', score=<MatchScore.B: 0>, id='338381f548cf44039a14536ecd543f9c-c60c309434cb480185c71fcabff38b0b'),\n",
       " Match(model_a='mistral-small-3.1-24b', model_b='claude-3-5-sonnet-v2', score=<MatchScore.A: 2>, id='d39559990d194335a71d3b2fc101e8ab-1c574ec4a09143f2bd0e539c39af04b9'),\n",
       " Match(model_a='llama-3.1-70b', model_b='gemini-2.0-flash-exp', score=<MatchScore.Draw: 1>, id='b77663413a9e49fa8c38577aef06b34a-a62037ac1fe04342a3bf70ed48fd6cf1'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='mistral-nemo-2407', score=<MatchScore.A: 2>, id='df073b38b11944ae9b43e710457a6c87-52d52a8c9cfb48ffb4510e8c6578dfbe'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='llama-3.3-70b', score=<MatchScore.Draw: 1>, id='02be31837e234e0aa7880953a2e87628-de01d6eb749249c59b4abb4ce3596e56'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='deepseek-v3-chat', score=<MatchScore.Draw: 1>, id='f8f211ee946b479dadc8d84d76b1fbdf-6247e2a08b804ff9b3b6723d05bc8312'),\n",
       " Match(model_a='llama-3.1-8b', model_b='qwq-32b', score=<MatchScore.Draw: 1>, id='74d930cb26bb419c89cdb99a451ede8b-0e0e6fdfff7444ca908fbf35e34852c9'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.B: 0>, id='407d1bcea942458c825ead1ed9efe0d0-1bcf82986d20463cb49a04522b941e66'),\n",
       " Match(model_a='mistral-large-2411', model_b='gpt-4.1-mini', score=<MatchScore.A: 2>, id='d027be9dbfc6424d810fc1780c4e11a0-b86c1d47a831484890576bfeec00203f'),\n",
       " Match(model_a='mistral-small-24b-instruct-2501', model_b='gemini-2.0-flash-001', score=<MatchScore.B: 0>, id='e7748c3e89dd4c1291fada6332e7b193-c096de7b06c94debb07cc8a3b127cce3'),\n",
       " Match(model_a='gemma-3-4b', model_b='llama-3.1-8b', score=<MatchScore.A: 2>, id='ab8297db944244a781d2d15eefa38236-0013fc31d11b4100ba826687e7448987'),\n",
       " Match(model_a='llama-3.1-405b', model_b='mistral-nemo-2407', score=<MatchScore.A: 2>, id='6dbabec9500e4afc8c314c70c4488985-3d9de3d9b1a243c086b049d822d85542'),\n",
       " Match(model_a='gemini-1.5-pro-001', model_b='llama-3.1-70b', score=<MatchScore.A: 2>, id='a124db8ee3ef4b8b91512576db71dc48-f6978c0352484fa2bba83de3f5209a93'),\n",
       " Match(model_a='gemma-2-27b-it-q8', model_b='gemini-1.5-pro-001', score=<MatchScore.B: 0>, id='a40fa6465d164810b6f8b2505145ef5b-39d3d04eb35e4409b7ddca3e7aa33f8c'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.Draw: 1>, id='d1c4a729413b4ef18f7c645547df9ca1-82174732328f4e238d4964cea28cd9c3'),\n",
       " Match(model_a='gemma-3-4b', model_b='gpt-4.1-nano', score=<MatchScore.B: 0>, id='15b891de537e43a6bfd4b3e2143b94dd-7fd40da824144f0388322cf47dcc0917'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.Draw: 1>, id='3cee31d9f0b3482eb2f3c9c6c3d8d09e-c9b004804f5f4f0d9bc4578df4431582'),\n",
       " Match(model_a='o4-mini', model_b='gemma-3-27b', score=<MatchScore.Draw: 1>, id='851526e79ecf434bbde318cba9d4917c-bab00043e6f347c99fa1e2681243212b'),\n",
       " Match(model_a='gemma-3-4b', model_b='gemini-2.0-flash-001', score=<MatchScore.A: 2>, id='c83cd05e2251400a97f55eadc8744ddb-06232962046a44c888790e135440e28c'),\n",
       " Match(model_a='llama-3.3-70b', model_b='llama-3.1-405b', score=<MatchScore.Draw: 1>, id='6fc24940befb4046bb2d34c4899b5cce-dac1b8cab5224580818fbc9b1a1c03dd'),\n",
       " Match(model_a='llama-3.1-70b', model_b='command-a', score=<MatchScore.Draw: 1>, id='c6af70987a9e41a6b953255dd3fa2c94-c180b0353d2f4496814a920d37011076'),\n",
       " Match(model_a='mistral-saba', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.A: 2>, id='8c4727ae78e3494e82e92be2db91009a-5099f2d23dae440386b2c618b5d7a716'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='deepseek-v3-chat', score=<MatchScore.A: 2>, id='cbb4a5160fe94804b4086e3afc1259f7-3ec785801a814cbd9dae377ead7e5a51'),\n",
       " Match(model_a='command-a', model_b='gpt-4.1-mini', score=<MatchScore.Draw: 1>, id='857ab38b11844a4980867647a98e3a79-4074f71b96004d91afd0bdc9fa4ef02c'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.B: 0>, id='22b8930710d241568ea31b39e33fe224-b06f3becc1dd4f7a93e842ebe0502c60'),\n",
       " Match(model_a='phi-4', model_b='deepseek-v3-chat', score=<MatchScore.A: 2>, id='449fd4a61dd44ac995dd928400c034d6-10ab4f45b8e240b68448ff6308d9e7d0'),\n",
       " Match(model_a='llama-3.1-405b', model_b='mistral-large-2411', score=<MatchScore.A: 2>, id='b6115dadc042482a87fc86cabfc830fb-13ff5daae0844ca0a2e977826ca66c50'),\n",
       " Match(model_a='llama-3.1-70b', model_b='gpt-4o-2024-08-06', score=<MatchScore.B: 0>, id='0fc9452d2de74f3393fec8395427e5c4-69add75484f54025bebac134546c925d'),\n",
       " Match(model_a='lfm-40b', model_b='llama-3.1-70b', score=<MatchScore.A: 2>, id='db363455f4224707a5d61111dcbbb793-a2c8b7b4f6314edc8b4543f265260563'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='gemini-1.5-pro-001', score=<MatchScore.A: 2>, id='651a6bbfd1ed4bcc84b1b30b0ca5061e-290416eb2bb54384a37ff0af7a420f30'),\n",
       " Match(model_a='deepseek-r1-distill-llama-70b', model_b='grok-3-mini-beta', score=<MatchScore.A: 2>, id='801b91ee99df4895889e72c2e3fbf582-dcb5e03191bd44f1bcc9ba42bec1fcce'),\n",
       " Match(model_a='chocolatine-2-14b-instruct-v2.0.3-q8', model_b='llama-3.1-405b', score=<MatchScore.B: 0>, id='f99bd6466dee408fbbe64f5e1f60518f-28c8c1c579164437b1984e5cf8886280'),\n",
       " Match(model_a='llama-3.1-70b', model_b='llama-3.1-8b', score=<MatchScore.B: 0>, id='7d40501161c64dcab27375df050d6736-acfb3eb7b43743afa103858334c63f99'),\n",
       " Match(model_a='chocolatine-2-14b-instruct-v2.0.3-q8', model_b='gemma-2-9b-it', score=<MatchScore.A: 2>, id='e01dfbcc4ed84d63bb0ba31031f9a873-4661b182f5a4420c8649b3991b593f98'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='gemini-2.0-flash-001', score=<MatchScore.Draw: 1>, id='d6d84cfe01fe4f8f8e1ba43afea26da1-3c25bc72fbd24439bb4c85121312c09c'),\n",
       " Match(model_a='qwen2.5-7b-instruct', model_b='phi-3.5-mini-instruct', score=<MatchScore.A: 2>, id='7b85d25aacab45c5a6d3b040f7302aa4-43cb43337be44ceaab3c567b610cd037'),\n",
       " Match(model_a='mistral-small-3.1-24b', model_b='gemini-2.0-flash-001', score=<MatchScore.A: 2>, id='49dc1c0957cb4591b6e75f12e2034e34-d7b19c80546147dd97bb4a991d09b38f'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='deepseek-v3-chat', score=<MatchScore.A: 2>, id='21c8e0719da0433ebdb7305a9f69486c-f05b3ddf8f8d4c09925379341bda2ea6'),\n",
       " Match(model_a='llama-3.1-nemotron-70b-instruct', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.A: 2>, id='d79a0d7952164f80afa54dc730b1cd6d-8d18b1664f664371b76cefe070511db9'),\n",
       " Match(model_a='gpt-4.1-mini', model_b='c4ai-command-r-08-2024', score=<MatchScore.Draw: 1>, id='3acb7916fdf944a2bb188ba8ded148c1-982aa0a6e4704516b64d4b41e9383d26'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='gemini-2.0-flash-001', score=<MatchScore.B: 0>, id='c7c91ec9a85746f4b8774a2c88b6821d-05e218d207764cfd9394dc506137f095'),\n",
       " Match(model_a='jamba-1.5-large', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.Draw: 1>, id='43d4c94de2f54351a57e38bdbadc4d53-0216dac99eed4b32b746044128e9610c'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='gpt-4o-2024-08-06', score=<MatchScore.A: 2>, id='0f6c77f6cbf24f4bacff4929c9f846d9-c139a5329c28472588015ff07b8af713'),\n",
       " Match(model_a='llama-4-scout', model_b='mistral-small-3.1-24b', score=<MatchScore.B: 0>, id='26978f15a316420ca91051fd528f298c-e42ab31c14dd4c8d94ca29ec02ea32c5'),\n",
       " Match(model_a='gpt-4.1-nano', model_b='grok-3-mini-beta', score=<MatchScore.Draw: 1>, id='4512fe16c956463ca6c50e996b00f1ec-18c3a8abec564426a0643a66b42f866d'),\n",
       " Match(model_a='command-a', model_b='mistral-large-2411', score=<MatchScore.B: 0>, id='906cf8e8ac294660abc3a198314deddf-5ed54133d6ba47a989d09e3f30ae91d1'),\n",
       " Match(model_a='gemma-3-27b', model_b='mistral-nemo-2407', score=<MatchScore.A: 2>, id='d642007e8afc4d8fadc8596cc555b6b5-e33f5bd121bb44d298dbffe2fae87f08'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='mixtral-8x7b-instruct-v0.1', score=<MatchScore.B: 0>, id='54278799046e4c1d8ea8b6a7793afc81-1ddb78e038134d2c84f47a9a049c1cd9'),\n",
       " Match(model_a='llama-3.1-405b', model_b='gemma-2-9b-it', score=<MatchScore.A: 2>, id='4a0bf8d1c7074c60bcf1237866345e78-2e29e2bd858e443a8419252e0bf16516'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='mistral-large-2411', score=<MatchScore.B: 0>, id='2e243a595d5543b5ba3b0d2fee8186e8-e3edf5d999154361bc70081239269c91'),\n",
       " Match(model_a='llama-3.1-405b', model_b='llama-3.1-70b', score=<MatchScore.B: 0>, id='27777c37a0c04b8daf86794bbf262f5a-8b72921c73f4415fb77533009c2f55a5'),\n",
       " Match(model_a='o3-mini', model_b='mistral-small-3.1-24b', score=<MatchScore.Draw: 1>, id='f3755644289e41c09a679c78f1b2f445-2d74116440c44046b9db119e26a17992'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='gpt-4o-2024-08-06', score=<MatchScore.A: 2>, id='7b5fb0ded1d94e86b9cf1df5e8eb58ec-f4d82af40ff644e4918c591f2fbc3040'),\n",
       " Match(model_a='llama-3.1-8b', model_b='ministral-8b-instruct-2410', score=<MatchScore.Draw: 1>, id='475daec5e4ab4ec6a43426e3380ad988-4363e7ebb99a4241bc37b7a990d6c345'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='llama-3.1-70b', score=<MatchScore.Draw: 1>, id='330ee4c3218045eba1c173e14b126241-f4ebb88b8fc844b68806d744455efe85'),\n",
       " Match(model_a='phi-3.5-mini-instruct', model_b='llama-3.1-405b', score=<MatchScore.B: 0>, id='5493719a42c44020978f2590ccc34bc9-d2596e0d71b74ba4b40ca4a655442b6c'),\n",
       " Match(model_a='gemini-2.0-flash-exp', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.A: 2>, id='6c6ad1dda1b04edb8c7a791fbd427f17-43630507986e45f7aad1198eeb6abd78'),\n",
       " Match(model_a='llama-3.1-405b', model_b='gemini-1.5-pro-002', score=<MatchScore.B: 0>, id='660433ee518c44d0937df143e97e0425-11ce96ee1d754880ab197a017983ac7a'),\n",
       " Match(model_a='command-a', model_b='gpt-4.1-nano', score=<MatchScore.A: 2>, id='21842b511792401b8ece0748117cc8d2-fdc4455820634e258a74a63f9696716d'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='c4ai-command-r-08-2024', score=<MatchScore.B: 0>, id='1eacbabb31fa4e39ae511a256b870bf3-942fd717767544e7a4a0d8ce6afcae0c'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='deepseek-v3-chat', score=<MatchScore.Draw: 1>, id='953a8548b5df4a68b7ddf737207180a2-e66b369463744f6e92ae21258e39d744'),\n",
       " Match(model_a='llama-3.3-70b', model_b='llama-3.1-8b', score=<MatchScore.Draw: 1>, id='46028c02a5174d11af9176ec702b6aa6-38e58be3ac694045bfe8da7ab75c57b2'),\n",
       " Match(model_a='qwen2.5-32b-instruct', model_b='lfm-40b', score=<MatchScore.A: 2>, id='eb771fbc84c94f8ea225db3fd106822c-f2399547c2384f11aef536b89cb3c6f3'),\n",
       " Match(model_a='mistral-large-2411', model_b='phi-4', score=<MatchScore.A: 2>, id='a406c4b9901c4d05b21741b3e0ab5a55-75cf819da1784feb83e7d22c16470288'),\n",
       " Match(model_a='llama-3.1-nemotron-70b-instruct', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.B: 0>, id='35cd6eeebefd453cbf18cf671ee27db6-77918ca764eb42d084cb198e881870f6'),\n",
       " Match(model_a='c4ai-command-r-08-2024', model_b='deepseek-r1-distill-llama-70b', score=<MatchScore.B: 0>, id='5f9b4ffa800f42d2a7355d02267005d2-7b858b881d24430998ec1bb09e5c7457'),\n",
       " Match(model_a='gpt-4.1-mini', model_b='phi-4', score=<MatchScore.Draw: 1>, id='e719ec98d76b43b39a5204224a70bbdc-8696d54436ea49648d5ff5f8bbd30027'),\n",
       " Match(model_a='mistral-large-2411', model_b='llama-3.1-nemotron-70b-instruct', score=<MatchScore.B: 0>, id='750dc7f6c2eb4de6986381f8be57c2d9-0d5ded6b3a8f46c5a7bfca2e6868bca2'),\n",
       " Match(model_a='llama-3.1-nemotron-70b-instruct', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.B: 0>, id='1ac9606133054d97b5dd83af80a9ce3f-afae02c710bb49cba5ba673c9886fbf0'),\n",
       " Match(model_a='mistral-small-3.1-24b', model_b='lfm-40b', score=<MatchScore.Draw: 1>, id='22505445d9f449db94194808d77fcb8d-18db29e40d494c2f8d593281197e1d73'),\n",
       " Match(model_a='llama-3.1-8b', model_b='command-a', score=<MatchScore.Draw: 1>, id='d26aceeb980b4a808a90a885d24ffaaf-3cfca401cc294954a6d2ea54adc63930'),\n",
       " Match(model_a='mistral-large-2411', model_b='phi-4', score=<MatchScore.B: 0>, id='0d36ba388d6e4ded8f6577c24a7ea1aa-ece02b1eccd443018cb48db1e818d83a'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='claude-3-5-sonnet-v2', score=<MatchScore.B: 0>, id='40c97e6270f94d198ce553a29b6eaad8-60e661f263bc4d7bbe314cfc767efe0c'),\n",
       " Match(model_a='c4ai-command-r-08-2024', model_b='gpt-4.1-mini', score=<MatchScore.Draw: 1>, id='1f221813a27349a8888f510dbd585b2a-8118cf4d777f4c398284346ae45923c5'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='gemini-2.0-flash-001', score=<MatchScore.A: 2>, id='27a06981c4e5498493cf99c457f25a6f-afdd207c997c4220af9433b6e5f42b56'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='gpt-4o-2024-08-06', score=<MatchScore.Draw: 1>, id='7cedc2573d6948f7aafe90efed527e73-3afebd85c5e34cd0a21035aef26ede7a'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='llama-3.1-70b', score=<MatchScore.B: 0>, id='f77260994f8348b9a694b0cc2487ecde-6c1513f7d6f74e709774e7bbe09fa843'),\n",
       " Match(model_a='llama-3.3-70b', model_b='mistral-large-2411', score=<MatchScore.B: 0>, id='1fc0c884b64d4e08a41cbd1917b6bd6e-87e87db1a935450fbce8fea34056c832'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='gpt-4.1-mini', score=<MatchScore.A: 2>, id='77489737f5c6469aad3566a8ecf7c355-71abb39948dc422c846f1613a759b33f'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='claude-3-5-sonnet-v2', score=<MatchScore.B: 0>, id='c0477751bdf0492fa5e9259a1f32a3c7-f38f7b3519794dfbb138665e0d6d540f'),\n",
       " Match(model_a='mistral-large-2411', model_b='mistral-large-2411', score=<MatchScore.A: 2>, id='892ec275b9924d78adecf2aa9198f4ec-9e94a7e8a3ab43dcb538e50b9eaf6c3f'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='mixtral-8x7b-instruct-v0.1', score=<MatchScore.B: 0>, id='28caf252a256410382ddacdb1294d16b-56a933d89d694e04b72aba4277ddcf49'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='ministral-8b-instruct-2410', score=<MatchScore.B: 0>, id='9a29e0c7b9994eb5ad2d918fa87f7893-d972a50e45184360824d6fd9170fe104'),\n",
       " Match(model_a='gemini-1.5-pro-001', model_b='gemma-2-9b-it', score=<MatchScore.A: 2>, id='103c0a48efd445deb09ef565897a3409-832a101c5a8840a9b74cdc5f3eccefc5'),\n",
       " Match(model_a='mistral-saba', model_b='llama-4-scout', score=<MatchScore.A: 2>, id='cfb0954432494980b951dc4703abc406-9da98d2282ae45dd861446746c11f30c'),\n",
       " Match(model_a='llama-3.1-70b', model_b='llama-3.1-8b', score=<MatchScore.A: 2>, id='2fa6c922639c4ba8b409afba339ef92b-f08e7d4cceee4971b2e5ab067713210a'),\n",
       " Match(model_a='qwen2.5-7b-instruct', model_b='llama-3.1-70b', score=<MatchScore.A: 2>, id='f8d6ab89228b4a00a72e5410babde0ab-e03749bee9b2481eb87aa76df3a031c0'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.A: 2>, id='2356a3799ddb4987b32e019715ca6ae4-bd59ed0ec8d94185abb99281a0fa7463'),\n",
       " Match(model_a='mistral-small-24b-instruct-2501', model_b='gemma-3-4b', score=<MatchScore.B: 0>, id='caf387c815794f878f57a87af576fb2d-6430ab4083144f05b63d41356491ef40'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='deepseek-v3-chat', score=<MatchScore.A: 2>, id='3ee513cd78f04b4f8c559ce5abb4e435-6e8052e0d33a4edc8efa5b09523efc69'),\n",
       " Match(model_a='mistral-large-2411', model_b='llama-3.1-405b', score=<MatchScore.A: 2>, id='f77da74c537642eb9605cc68b43a9165-a5b6b4d8ded942469cea7b6b75ee57ab'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='claude-3-5-sonnet-v2', score=<MatchScore.Draw: 1>, id='f4349f6f79a345a78f18fe0159acebd9-4d633cd80142469aac0e37d8e0225e2b'),\n",
       " Match(model_a='gemma-3-4b', model_b='gpt-4.1-mini', score=<MatchScore.Draw: 1>, id='840fea57650441d0a09a16c4591bfd2d-b3b7f13a486b4c379d6d1bf67e4d0b5f'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='deepseek-v3-chat', score=<MatchScore.B: 0>, id='c427572ac41e4d2d82124da22d9940cf-2aeff8da2f8048998540e15d0bf6d0cd'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.A: 2>, id='8487c802f55b46a69ed96efe61cb27d5-b79957bfeb034535b152e1dd9fcf8a52'),\n",
       " Match(model_a='mistral-large-2411', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.Draw: 1>, id='5d130c3ee52644818ff0716f60acd90f-0f19070ae68f45e49befd2442b7d542f'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='gemini-1.5-pro-001', score=<MatchScore.B: 0>, id='dc57b272d08f47058ffe06c987298fef-8b4037a72d57475f93813f9100e750b3'),\n",
       " Match(model_a='gemma-3-4b', model_b='llama-3.1-70b', score=<MatchScore.Draw: 1>, id='854e329d88a44dc89ecf16d70519d024-fd8a81cd512441b3892d127722c1ee72'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='c4ai-command-r-08-2024', score=<MatchScore.A: 2>, id='c3aea5dbea0f42b0b7975ead5178c233-3a6f1492e44d443d8519a68a8cb9ab2d'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='chocolatine-2-14b-instruct-v2.0.3-q8', score=<MatchScore.Draw: 1>, id='e098608e93f440ed866d88ad9017c373-9b3416727d5a4d47b9fcda63d714f856'),\n",
       " Match(model_a='command-a', model_b='llama-3.1-nemotron-70b-instruct', score=<MatchScore.B: 0>, id='834d4839184a40a69a7e4ca0acd82ad0-086f34fdbd4d47128cc7b2d454a25aef'),\n",
       " Match(model_a='mistral-large-2411', model_b='gemini-2.0-flash-exp', score=<MatchScore.B: 0>, id='131a715f98b84618a76fc53981187e95-cea27f4a84a9470b975efd0d705b0b74'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='mixtral-8x7b-instruct-v0.1', score=<MatchScore.A: 2>, id='e96b65de629b47c89a64ee99ce77be4d-630c19e81ba0493dae5b11a4486c5d9c'),\n",
       " Match(model_a='aya-expanse-8b', model_b='llama-3.1-405b', score=<MatchScore.Draw: 1>, id='63443a7750164eaa9fd2bda1c36b5459-3c9b1eb2478546b9b11bb555f3f8ef9f'),\n",
       " Match(model_a='deepseek-r1-distill-llama-70b', model_b='c4ai-command-r-08-2024', score=<MatchScore.Draw: 1>, id='be130c8c4f2c470d87d98d8f564976be-c6d7574273084708907e7aab213af9c9'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='gpt-4o-2024-08-06', score=<MatchScore.Draw: 1>, id='2cd38e00bc014d7e96b49b3a45869aba-131226bbed6f4e32be633b2999d37e3b'),\n",
       " Match(model_a='llama-3.1-70b', model_b='chocolatine-2-14b-instruct-v2.0.3-q8', score=<MatchScore.A: 2>, id='cc91316e3b9c4fb98f583b4944abfe4a-7dedbbc068c74aa898f3e3dc1e7c9a9a'),\n",
       " Match(model_a='qwq-32b', model_b='phi-4', score=<MatchScore.B: 0>, id='ccc66dbdf44944189687c37908a5392e-29ad049ba33a463285fcd3a9c3c04439'),\n",
       " Match(model_a='mistral-small-24b-instruct-2501', model_b='llama-3.1-8b', score=<MatchScore.A: 2>, id='2c6fd64a304540ceb8e085a0bd00c12c-9abc70f45bad45dda5c62450ea436a56'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='claude-3-5-sonnet-v2', score=<MatchScore.Draw: 1>, id='92c00e78d0d64cc9a7d7795938be0f93-c6297cc3615046cea2ef452f647471b1'),\n",
       " Match(model_a='mistral-small-24b-instruct-2501', model_b='llama-3.3-70b', score=<MatchScore.A: 2>, id='9557e7b3ebff40318262876d171281cc-a46e3aa8e6d3414d9be30d89e269d698'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='mistral-large-2411', score=<MatchScore.A: 2>, id='65075d4d52954793a38a755929d84434-090059a5e59544feb3e5fd30ba43c360'),\n",
       " Match(model_a='llama-3.1-nemotron-70b-instruct', model_b='gemini-2.0-flash-exp', score=<MatchScore.Draw: 1>, id='f379fe0cd53044208796f27c52a64eb2-ee045d24916a4af49eb4718f08e721c5'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='c4ai-command-r-08-2024', score=<MatchScore.A: 2>, id='47bb0f7780d843218546ac7ae7d40815-40aec45eda564732922408edacf65526'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.A: 2>, id='e6bd09384e6947d28f966a2dd4445ed1-760a2fd66ea64be1a7730156566f1400'),\n",
       " Match(model_a='llama-3.1-405b', model_b='ministral-8b-instruct-2410', score=<MatchScore.B: 0>, id='ea1efe7cc7344026bfe3ac5dcd7b940e-2cd4fe6215af44cea3d4fe235b355c68'),\n",
       " Match(model_a='llama-3.1-8b', model_b='gemini-1.5-pro-001', score=<MatchScore.B: 0>, id='f79ceba422e34277b3db7a2e87aeca54-17b024970396471487c029e3831572d8'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='claude-3-5-sonnet-v2', score=<MatchScore.A: 2>, id='717c0bfcd59f47519b9c04b2602c83d7-b58fd147746d478e9af50ef29a2a41bd'),\n",
       " Match(model_a='qwq-32b', model_b='llama-3.3-70b', score=<MatchScore.A: 2>, id='39f3f2db44e04c679a5ff53a86fb3853-97a07f552e3449d18e0cc1df4dccf672'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='gpt-4o-2024-08-06', score=<MatchScore.A: 2>, id='cf577b2b7de04c87b7f288d6b5c34fdb-773e468a04784694a30131c61adaa4c2'),\n",
       " Match(model_a='llama-3.1-70b', model_b='gemini-2.0-flash-exp', score=<MatchScore.B: 0>, id='2939422a20e64a8c9190597b89f6453d-fd873c541ded4bd194009ecebbe9f0f9'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='ministral-8b-instruct-2410', score=<MatchScore.B: 0>, id='ed0a18802a5d4ecba5bb38dedb054efe-00d40727100a4709b106230125c12190'),\n",
       " Match(model_a='llama-3.1-8b', model_b='llama-3.1-nemotron-70b-instruct', score=<MatchScore.Draw: 1>, id='366abcb06e8145fba8d39c8bf3cfdc3b-c75571b3a7e74eefa959b371a1aa90df'),\n",
       " Match(model_a='llama-3.1-8b', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.B: 0>, id='7e8c8f49a4d540518734a6f01f567949-fb4ca55493ad4b688650ecf3a95a30da'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='ministral-8b-instruct-2410', score=<MatchScore.A: 2>, id='680be226316e474dae4db18596a0b6cd-c2703d16da594ef48607a6ba353eb0b1'),\n",
       " Match(model_a='phi-4', model_b='ministral-8b-instruct-2410', score=<MatchScore.Draw: 1>, id='5cd167b03b414e158babdd6986699dab-1dfe80defebf4bba96489d88c284baa8'),\n",
       " Match(model_a='deepseek-r1-distill-llama-70b', model_b='deepseek-r1', score=<MatchScore.Draw: 1>, id='996674a120254463b166e5fba49d91c7-4b0f0730bfd24389a1fdfc8d6a5325d7'),\n",
       " Match(model_a='llama-3.1-405b', model_b='mistral-nemo-2407', score=<MatchScore.B: 0>, id='2d65b937cdf84197b4e4b446bbc38ac9-287bd6c5be8e465d82a9eb81d5341322'),\n",
       " Match(model_a='llama-3.1-405b', model_b='phi-3.5-mini-instruct', score=<MatchScore.A: 2>, id='efc120b923d44b2ea593925c6d9f21d7-c5e53d8538154577802c75a34a9e1643'),\n",
       " Match(model_a='o3-mini', model_b='llama-3.3-70b', score=<MatchScore.A: 2>, id='aacda165448a4c7d8c147ea4586825d6-6e511e8b6b604c45bb3ead0ae701abca'),\n",
       " Match(model_a='llama-3.1-70b', model_b='gemini-1.5-pro-002', score=<MatchScore.B: 0>, id='48d5979b212644c88b7cd2d32e96e794-ee479841fa0946948e18857ebcce4bf7'),\n",
       " Match(model_a='lfm-40b', model_b='claude-3-5-sonnet-v2', score=<MatchScore.A: 2>, id='05a203b9ea1b49c1a39d23aa7a44bfd0-2e25b76b7bf742999428ab3c50c91c55'),\n",
       " Match(model_a='llama-3.1-405b', model_b='lfm-40b', score=<MatchScore.A: 2>, id='c1f1fafcb44d4b20bfe6b162b32e584f-44a0fcaf79f942c08393d718693712a7'),\n",
       " Match(model_a='llama-3.1-405b', model_b='gemini-1.5-pro-001', score=<MatchScore.B: 0>, id='1945e651a2c44c43a01fb4b3faae49ad-a814e99476b44a9088b55d419b4323f5'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='phi-3.5-mini-instruct', score=<MatchScore.B: 0>, id='ad989e3e57a2478798fc4ff2fc6ba832-4b44e8a6099b4091848351ffd05b252a'),\n",
       " Match(model_a='aya-expanse-8b', model_b='mistral-nemo-2407', score=<MatchScore.A: 2>, id='f077b2b4519743dabd66a48030b5fb19-9cbf77609fe64bc48b328c1fddaf93a4'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='mistral-nemo-2407', score=<MatchScore.B: 0>, id='3b38994d6a18440ea7e58727f68d34f9-3b45cf4225bd42159500166c8352c87a'),\n",
       " Match(model_a='mistral-large-2411', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.Draw: 1>, id='20d1a5184f1f441694d453e4c7a6a4e1-cf71c1cc76a74213b83c080d7b1feff7'),\n",
       " Match(model_a='llama-3.1-70b', model_b='chocolatine-14b-instruct-dpo-v1.2-q4', score=<MatchScore.A: 2>, id='d75cdae1e0cb41f89c73b47a736913ce-ed013cd205ad405ea135fdc2cf816c6f'),\n",
       " Match(model_a='aya-expanse-8b', model_b='llama-3.1-nemotron-70b-instruct', score=<MatchScore.B: 0>, id='f3696d4e09d142fbb03327f1c54821ad-841f6dc462824a93839eff793d4722bd'),\n",
       " Match(model_a='phi-4', model_b='gpt-4o-2024-08-06', score=<MatchScore.Draw: 1>, id='f58934f80bf944f78e02e9c9e066d1d9-54976d5361ba471fa54e147baccc0010'),\n",
       " Match(model_a='command-a', model_b='ministral-8b-instruct-2410', score=<MatchScore.A: 2>, id='a4d7c81178994b8e9fa4c6428180c37e-0e78dc4a77a441c09d65ac6557b951f5'),\n",
       " Match(model_a='gpt-4.1-nano', model_b='mistral-saba', score=<MatchScore.A: 2>, id='725d5da35c7946e0b967e412c3e79fcf-191b3dac9ddd4051a0e159a703fd05d4'),\n",
       " Match(model_a='phi-3.5-mini-instruct', model_b='mixtral-8x7b-instruct-v0.1', score=<MatchScore.A: 2>, id='59bcd16dcc84424487fdb378bba8ce15-ec2c2bbdb9494272b3c9f4c341d5aefe'),\n",
       " Match(model_a='phi-4', model_b='llama-4-scout', score=<MatchScore.B: 0>, id='ef21aaa9c28c4c49a1f45f043c61e3a2-32fdb8fc2ede4ea7b8bb9d449b22253e'),\n",
       " Match(model_a='deepseek-r1-distill-llama-70b', model_b='llama-3.1-405b', score=<MatchScore.Draw: 1>, id='ffd05a98cc8a479a96cc2da389c4177c-daf2d4ea69b941ac87c203e23a1e3da0'),\n",
       " Match(model_a='gemini-1.5-pro-001', model_b='gemma-2-9b-it', score=<MatchScore.B: 0>, id='98f9a033f4544416af71c89e24287f1c-cbbcc2a94d92449d8da775117b37ff3d'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='gemma-2-9b-it', score=<MatchScore.B: 0>, id='cbd57d4af98348569488fae4bbb43529-84c21acb9ca441b0848df04001a9ea44'),\n",
       " Match(model_a='aya-expanse-8b', model_b='gemini-2.0-flash-exp', score=<MatchScore.B: 0>, id='899d82760f134e0ca163a6699d1cbb1c-9baf13ee7a634f3bac2a3d0043b310d8'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='gemma-2-9b-it', score=<MatchScore.Draw: 1>, id='163deb012f28476fa771f74ca09cc8c8-2e0873f46d944bfeb417c72e3b627939'),\n",
       " Match(model_a='deepseek-r1-distill-llama-70b', model_b='deepseek-r1', score=<MatchScore.A: 2>, id='7b1d11437bec4cab9f3fc956ef1265e5-ec8cad2f50064985bc383a05f179a5d6'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='command-a', score=<MatchScore.B: 0>, id='95f8185bafb6432d9bf1b54f0173174a-ca68ca0f43664a0ab48c841cdf2e86df'),\n",
       " Match(model_a='phi-3.5-mini-instruct', model_b='chocolatine-14b-instruct-dpo-v1.2-q4', score=<MatchScore.A: 2>, id='603a0166a1cf4b5d99d4a1cdc377d77d-32bae8f261f3419c816f2c18ec43f58a'),\n",
       " Match(model_a='llama-3.1-8b', model_b='gemma-2-9b-it', score=<MatchScore.B: 0>, id='b894ac46b5404bc4acb0893555ff8095-8ddaacd2cbb242828c3205c8b25bb51a'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='gpt-4o-2024-08-06', score=<MatchScore.B: 0>, id='f94640cdf0854c5fb8e6a47e97c6ac45-3a6dd54c996046bc851b6780ec63a74f'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='phi-4', score=<MatchScore.Draw: 1>, id='53092fc8c467426fa90795a525683b01-1efe1d44e41c4debaca6355fd95b0db9'),\n",
       " Match(model_a='phi-4', model_b='llama-3.1-8b', score=<MatchScore.Draw: 1>, id='d9e3195f0b524c52bbbd14389f53b15c-35dec6ff9f804d50a3c2631dce6833ee'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='llama-3.1-405b', score=<MatchScore.A: 2>, id='f30878aa9e4d452a87d8fe70f3e722e9-2d42ee2ae2144a54bbb54174ad0df283'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='llama-3.1-405b', score=<MatchScore.A: 2>, id='c2905f5ae7b44a4d93b886a1a968c848-df5361d3294540e185d32d540196155f'),\n",
       " Match(model_a='mixtral-8x7b-instruct-v0.1', model_b='phi-3.5-mini-instruct', score=<MatchScore.B: 0>, id='efbca808ae0d49589ae52f09d300a66c-0584a82dd02a4870a4e6f3588b6ef91f'),\n",
       " Match(model_a='mistral-small-3.1-24b', model_b='llama-3.1-8b', score=<MatchScore.Draw: 1>, id='2c09e0980bdf40b79c9ff88774b7b76f-85541a329766428184e01eab2f5288bc'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='llama-3.1-70b', score=<MatchScore.Draw: 1>, id='5ee1258d6b5543468af51fd6868839fb-36aa050f164f4ffb98db976387ce81f7'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='mistral-large-2411', score=<MatchScore.Draw: 1>, id='b30065d717d84117a045e3418887f772-04e98d02c32a4a69bb5ae788fe6c80a2'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='deepseek-v3-chat', score=<MatchScore.Draw: 1>, id='067d43a4c7d8452f8814929408727c9a-c7ab4d2eadd049caaa591dbbda5d630e'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='llama-3.1-405b', score=<MatchScore.B: 0>, id='ca7a9c8f159c425a81318df9650f3bff-93a43d82f3564617a3197bc6810343fb'),\n",
       " Match(model_a='llama-3.3-70b', model_b='claude-3-5-sonnet-v2', score=<MatchScore.A: 2>, id='f6724a15aeda4886a15140c731b07aa7-1efd8daa6474408a93b02a594ea1dc2c'),\n",
       " Match(model_a='gpt-4.1-nano', model_b='deepseek-r1-distill-llama-70b', score=<MatchScore.A: 2>, id='7270283613ea43a3b7cfe6f0081765c9-7baeeb230f3640e186d9b94b2c2ebb4b'),\n",
       " Match(model_a='phi-4', model_b='gemini-1.5-pro-002', score=<MatchScore.B: 0>, id='234d7883c190447ca060508f7c93f628-ef5e8647528644ae9576aaf203d60d71'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='gemini-1.5-pro-002', score=<MatchScore.Draw: 1>, id='4878112a10e544789990507850667f13-746192f84cc54801a9da46d2f7aeb288'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='mixtral-8x7b-instruct-v0.1', score=<MatchScore.B: 0>, id='64f30e1c23f2445786523afd5d6f6487-06d8c7d329e544b794615968efecb543'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='llama-3.1-8b', score=<MatchScore.Draw: 1>, id='99ea120405cb4f6087a2fa1fb795dbab-e48c389b02cf4675ab8aaabd41694b9d'),\n",
       " Match(model_a='phi-4', model_b='llama-3.3-70b', score=<MatchScore.Draw: 1>, id='ba4d1887820f494caefbae12d509461c-ff7a735d1b49473c937e48b5af004fa7'),\n",
       " Match(model_a='llama-3.1-8b', model_b='llama-3.1-nemotron-70b-instruct', score=<MatchScore.A: 2>, id='e5a652cfe95b4f98b22d1110f7358cd7-35ad85947a234f5a98d33a70450050cb'),\n",
       " Match(model_a='llama-3.1-nemotron-70b-instruct', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.A: 2>, id='e1ca5b8556074adc978dc4f47f4d977c-b62bae43d19b4e0eb6e316d4fac6381d'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='chocolatine-2-14b-instruct-v2.0.3-q8', score=<MatchScore.A: 2>, id='d8af59e5d2964f97bd247ad5142cb884-2f20aca6bb664c06be021be89709a8a7'),\n",
       " Match(model_a='llama-3.1-8b', model_b='mistral-small-3.1-24b', score=<MatchScore.A: 2>, id='a8b1e0a0cbbd483483729810b92a4f2d-73e8f2680feb427b8e0afa5b61c7c138'),\n",
       " Match(model_a='llama-4-scout', model_b='gemini-2.0-flash-001', score=<MatchScore.B: 0>, id='45f020fb12ea47dbb948b1700c04a676-f869a13654844cf8b77456fa2a42ac26'),\n",
       " Match(model_a='command-a', model_b='llama-3.1-8b', score=<MatchScore.A: 2>, id='6e4a215a5ce64c32a6962b37b30aa0dc-61627c9ecde3429d990933c694e39907'),\n",
       " Match(model_a='llama-3.1-8b', model_b='gpt-4o-2024-08-06', score=<MatchScore.B: 0>, id='f6eb4512d3124ae8ae043f5023b374c6-3cb587a4bdb64cd191e709cf4a5404af'),\n",
       " Match(model_a='mistral-small-3.1-24b', model_b='llama-3.3-70b', score=<MatchScore.A: 2>, id='d3259ed29ea643e4b522ca3349640023-517a17ebfa0742508653ed0778b55381'),\n",
       " Match(model_a='gpt-4.1-nano', model_b='mistral-saba', score=<MatchScore.A: 2>, id='aef9afe42ae844248b0080279e2fdb81-994bf9fa9866462fa009aeb42048213b'),\n",
       " Match(model_a='command-a', model_b='mistral-small-3.1-24b', score=<MatchScore.B: 0>, id='1721b5d7733a4288abb5595c11da7850-0238984ad4524ac5876c78af7a8d3c4f'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='command-a', score=<MatchScore.B: 0>, id='db8e3512473b45d68f845b5403dd3246-ead10c030c82469994113e30faefd2c3'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='gemini-1.5-pro-002', score=<MatchScore.Draw: 1>, id='fc1d53f3f84a4c21af491ae1c06146a1-1d111bb3379949be96ccce8bc318eb88'),\n",
       " Match(model_a='aya-expanse-8b', model_b='mistral-nemo-2407', score=<MatchScore.B: 0>, id='4c213f0510a04c28a5a63b3cfc52e0f4-5e5a40856d31446ba786bbac444b1763'),\n",
       " Match(model_a='mistral-small-3.1-24b', model_b='gemini-2.0-flash-001', score=<MatchScore.B: 0>, id='6d863b54d0194d6498eb2b9223a7e375-3359a47bf41945e49a6cb48ff3ca30fd'),\n",
       " Match(model_a='llama-3.1-nemotron-70b-instruct', model_b='gemma-3-27b', score=<MatchScore.A: 2>, id='12e0f0d1d7464217b3b6ae0b32d28870-f61e0febdd4544bbadb6ef16193a9061'),\n",
       " Match(model_a='gemma-3-27b', model_b='llama-3.1-405b', score=<MatchScore.A: 2>, id='ea614bc20fd548528f160f7abeec5ec1-dea291b9fbf44ee4a72e1ea4387841ff'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='llama-3.1-70b', score=<MatchScore.A: 2>, id='d8100a8bf9e64c9daec6e375a4e360ea-abf47d8710ad4d4fa18d1ba5aca6c9b4'),\n",
       " Match(model_a='claude-3-7-sonnet', model_b='gpt-4.1-mini', score=<MatchScore.Draw: 1>, id='e5323f8dd50d4bf9a9e8173d85f5f6dc-5e140cb8254d4b839142c5e9be68371d'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='gpt-4o-2024-08-06', score=<MatchScore.B: 0>, id='2e7da1e6b2aa4e35943cfff771bf3f19-b5fbb5df25314dd1bd50322bc37a42b1'),\n",
       " Match(model_a='llama-3.1-70b', model_b='gpt-4o-2024-08-06', score=<MatchScore.B: 0>, id='b6be067bdfb040c9a1042ce3c1c14751-ac43abe0d90648a6b698b785ddaad03e'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='gpt-4o-2024-08-06', score=<MatchScore.A: 2>, id='6b3267d9048040d8aa348d83f317bf5a-ee09d98fa6024919a113c6d6e032b10d'),\n",
       " Match(model_a='llama-3.1-8b', model_b='lfm-40b', score=<MatchScore.B: 0>, id='8554bed0c3ba4779adba9b9d907660f6-04bc841985884e7cb0fe0da022020194'),\n",
       " Match(model_a='gemma-3-12b', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.Draw: 1>, id='6003e63ff3914cfa9828fe2a46802ec3-123a7cc024194d0a8fd75d6db28b2dd4'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='deepseek-r1', score=<MatchScore.B: 0>, id='72f0a9c456bd402889523d654a57be96-0e3aab78ae1547d08e6989b45d8b193c'),\n",
       " Match(model_a='llama-3.3-70b', model_b='llama-3.1-405b', score=<MatchScore.A: 2>, id='143335dd795a4d6cbf230beae163439b-31a545e4749149b09fd383849f3621d4'),\n",
       " Match(model_a='mistral-small-3.1-24b', model_b='claude-3-7-sonnet', score=<MatchScore.Draw: 1>, id='d2234733cdbb4de585c083908a68b79f-8c5f7abdc3c24c529d5380f6a52edd3f'),\n",
       " Match(model_a='llama-3.1-70b', model_b='mixtral-8x7b-instruct-v0.1', score=<MatchScore.B: 0>, id='dd4c6df6ef1d461e970a22374e1afa25-1bb7d8be53864df08a94fb5d665ed7e5'),\n",
       " Match(model_a='mistral-small-24b-instruct-2501', model_b='gemini-2.0-flash-exp', score=<MatchScore.A: 2>, id='eb938124719c444098abfbb9663af1c0-a29a09867ac84dbe92550809dcc1ed10'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='phi-4', score=<MatchScore.A: 2>, id='ad67aeda5da04b2eb6c843b96adcc7e9-c387fa87c443416f8aad741e26c8a88a'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.B: 0>, id='9e82715abd9d4c1495d30b79aa649d75-29bec8d99d1a4568818dc3bd881fed8f'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='llama-3.1-70b', score=<MatchScore.A: 2>, id='d6bd3a12c2fd4900a270269afd822608-7a9a470d477a4f65bc0e4df329df3c65'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='mistral-nemo-2407', score=<MatchScore.A: 2>, id='c156df835c6d4925b0e61d83e6e08911-babe25aabd6443bc80c1a6d94b32b0ae'),\n",
       " Match(model_a='llama-3.1-8b', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.B: 0>, id='52d991f25e6147ba8afdac7c6136f486-08e8720fb66142a580705e2091b857fb'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='gemma-3-12b', score=<MatchScore.A: 2>, id='49b82e9d33da4fe684c19b0b97bab11a-21d9a4f2ad1b4fe2a4fb6269152395e7'),\n",
       " Match(model_a='llama-3.1-70b', model_b='gemini-1.5-pro-002', score=<MatchScore.Draw: 1>, id='f160767840404f159ab67c61399a789a-8bdfcda5966c4b4abf283d07f797d5f7'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='gpt-4o-2024-08-06', score=<MatchScore.B: 0>, id='78c87a66b9d848898ff723e57558600e-fd29710936ed461ab4b7a6384207a71c'),\n",
       " Match(model_a='mixtral-8x7b-instruct-v0.1', model_b='mistral-nemo-2407', score=<MatchScore.A: 2>, id='018d2b825c654c6db9ebfb987f478fa6-83a53458eeb14460845c6b66d38b1bcb'),\n",
       " Match(model_a='deepseek-r1', model_b='qwq-32b', score=<MatchScore.A: 2>, id='8323954aabb44189a5ea7fcbf0cfa8c2-362f5057de4143bd8e60911468e66aba'),\n",
       " Match(model_a='qwq-32b', model_b='gemini-1.5-pro-002', score=<MatchScore.B: 0>, id='8d9b79ed1ed54d7ea76f7b6c8a16cf5e-ddde148aa2394969a6b2c5d0af07b4b0'),\n",
       " Match(model_a='gemma-3-27b', model_b='llama-3.1-8b', score=<MatchScore.A: 2>, id='143a0c3336d24776a3c9102ef0d4f6db-eb6018a027d74bfb83bce61ac7803c50'),\n",
       " Match(model_a='o3-mini', model_b='c4ai-command-r-08-2024', score=<MatchScore.A: 2>, id='26faa5347ae544b1acbe573a941f9de6-f589e3846a3a4d2eb3f089a10e732498'),\n",
       " Match(model_a='phi-4', model_b='gemma-2-9b-it', score=<MatchScore.Draw: 1>, id='04f8c2d9e4aa4b11a73af061ddb25840-6ce71a2a4d6e4f95bdda2eb4c1ceeeca'),\n",
       " Match(model_a='mixtral-8x7b-instruct-v0.1', model_b='gpt-4o-2024-08-06', score=<MatchScore.Draw: 1>, id='261711fa1c9f48f9b42e64e7a3328034-e3eccf6d267d4415a2eb17c1cfbd2105'),\n",
       " Match(model_a='c4ai-command-r-08-2024', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.A: 2>, id='77ee98cd64d343e194810348d5a6e32e-db7aa27b37bd4f2b88bc504dcf6b8df3'),\n",
       " Match(model_a='llama-3.1-405b', model_b='chocolatine-14b-instruct-dpo-v1.2-q4', score=<MatchScore.B: 0>, id='5fabe16507f84f8fbcbd7cdab3cf5fa7-3a1a203abd624df3960c0720f4a8dabf'),\n",
       " Match(model_a='lfm-40b', model_b='llama-3.1-8b', score=<MatchScore.B: 0>, id='828d2e710a3343539590275801b1c2a8-731ff0dd035b4ad384ee22138106bc65'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='phi-3.5-mini-instruct', score=<MatchScore.A: 2>, id='7c2343eeb7894a7f8b49b39d40b7b255-736abc1f02f747369e13acc1d8a6bf58'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='llama-3.1-405b', score=<MatchScore.B: 0>, id='cdc2e150634d43bcb12f4a7595181821-3cc14f1a7f854b0196df9490ba62a698'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='llama-3.1-nemotron-70b-instruct', score=<MatchScore.B: 0>, id='fa80331c23b64ed3b5f76537c1106a18-00dc65f5120d4fc0ab3df2f94e41c51e'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.Draw: 1>, id='8a5de46073ee46d99693772c1fda85fa-2e617602274442f59cc30b16325a9767'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='claude-3-5-sonnet-v2', score=<MatchScore.A: 2>, id='d3d3be3c92e1435c9c8c4165789fb01b-2656cd1dd3704c2292d8d89ec7060db5'),\n",
       " Match(model_a='gemma-3-27b', model_b='c4ai-command-r-08-2024', score=<MatchScore.A: 2>, id='039cfb99e4db4bcb9131176105d89538-4e47ba0c6d274ffab3cf794994978841'),\n",
       " Match(model_a='grok-3-mini-beta', model_b='gpt-4.1-mini', score=<MatchScore.Draw: 1>, id='e635b785caa34afbba16672836102983-f9a1aef1897e47389672ca62e110964f'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='llama-3.1-405b', score=<MatchScore.B: 0>, id='8f1ee81ad14a42aab42f44a72483171b-874289cfd4a141ae8f669982b9028b58'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.A: 2>, id='2c920343b9704e2bb46f8da6660754fd-8523111f479647da8873a0f169b425ae'),\n",
       " Match(model_a='llama-3.1-8b', model_b='gpt-4.1-mini', score=<MatchScore.B: 0>, id='9d7e4301753648389fc8e548a911a58b-f37b00c9944d40098755fc7f25a9ae77'),\n",
       " Match(model_a='lfm-40b', model_b='gemini-1.5-pro-001', score=<MatchScore.B: 0>, id='cb26dff94d9f4ef3bcb521a99a4d2cd0-73e115ea29f046c68080058bf4ba8e3e'),\n",
       " Match(model_a='mistral-large-2411', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.A: 2>, id='9f253ab1c4c44635a95c42b6832ab052-386cc7e1db744e0989fe6c0792e8d45c'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.B: 0>, id='baa3098c1e5d45fd8bffb991b092ff4e-23410dd8ae4344fea0621b070fa23bbe'),\n",
       " Match(model_a='mistral-large-2411', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.A: 2>, id='27159b0732b64338be6abec43bd7b2da-94c8a8b334b844bf97ceac6c3e1376cc'),\n",
       " Match(model_a='gemma-3-12b', model_b='llama-3.1-70b', score=<MatchScore.Draw: 1>, id='ee71f1b695fe4bf1bcc0721d5d075b15-057b8d9c909448bf91b088221ddcc5b8'),\n",
       " Match(model_a='mistral-large-2411', model_b='deepseek-r1-distill-llama-70b', score=<MatchScore.B: 0>, id='a2473defb5c94e6185981d5322dad0b6-6be617513670464cb1a740a140695819'),\n",
       " Match(model_a='deepseek-r1-distill-llama-70b', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.A: 2>, id='3c4a3e2e9ab34b8d97743dfa497cfcb7-aeafc45909f64ce3b76cc39f4dcb778f'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='aya-expanse-8b', score=<MatchScore.B: 0>, id='d1b00e6ba82f46bf9b6687094457ebc1-54d0a0c7d5de4c3dad503464a961afb9'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='llama-3.1-8b', score=<MatchScore.Draw: 1>, id='1bdad26a84844ba4808befcc35cf0759-08ca5194bf3648c19910edc8b4cb8cf0'),\n",
       " Match(model_a='llama-3.1-8b', model_b='mistral-small-3.1-24b', score=<MatchScore.B: 0>, id='f0ad9efdd08246c19b9f0220a67ee0f1-cf766318bec845d5b015f685bd930215'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='gemini-1.5-pro-002', score=<MatchScore.B: 0>, id='985c30d9b5244a5ca842b8f998c30055-fe658eccb9844b26a0e7e514cc784dfd'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.A: 2>, id='b40db98c8f5946c8b7484054be2f93e2-1c32162b5f734c6a967b5e23a0aa3c7e'),\n",
       " Match(model_a='llama-3.1-70b', model_b='gemma-2-27b-it-q8', score=<MatchScore.A: 2>, id='b1aca40387044e1681a2990d727fc248-89df4fb67d2147deae304240fa443e38'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='aya-expanse-8b', score=<MatchScore.Draw: 1>, id='c869afb5760b4bbeb96b22a672121014-4f441c5239ff48de9f8f82d864943fdb'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.A: 2>, id='8b739dbaab77437cad49d15557915dc9-836ae79a0c1c4ff7b3bfd6b0add72ae6'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='mistral-small-3.1-24b', score=<MatchScore.B: 0>, id='36fedc48d56149889a637735945561be-e4b9bced96204cf391591fbca83acb3b'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='llama-3.1-70b', score=<MatchScore.A: 2>, id='95f7534bc0ad436698a0866a94a3e3c2-c73f891cf75b442a88a3c559c136df51'),\n",
       " Match(model_a='phi-4', model_b='llama-3.1-405b', score=<MatchScore.A: 2>, id='3eeb6b2109a24672989794d68d5a7980-4627bde71d3e45a38af4e0e95496b724'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.A: 2>, id='2d2612a5591548199d42a4615e3fa21b-6daa7b79b5d14ed1a09fce6fe1303e77'),\n",
       " Match(model_a='llama-3.1-405b', model_b='gemini-1.5-pro-002', score=<MatchScore.B: 0>, id='abd41a13ba8c4c288186fa9fe2c9a919-095f4372fac946b6b0ccb80daaa08377'),\n",
       " Match(model_a='llama-3.1-70b', model_b='llama-3.3-70b', score=<MatchScore.B: 0>, id='f50e866f5ec94b92b023658e5703d749-bffa06b5b13348059da2bcf8ca82ba15'),\n",
       " Match(model_a='gemini-1.5-pro-001', model_b='llama-3.1-70b', score=<MatchScore.B: 0>, id='bd56348c3bc5488595f2fecd8c9b9891-c5dc067408b84fdfa71d35331ca0c9ba'),\n",
       " Match(model_a='o3-mini', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.Draw: 1>, id='9a6036dd61fd4991a65c6b36d14500e6-bf72dc5a463845d7bd7ea64cca62e737'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='llama-3.1-8b', score=<MatchScore.Draw: 1>, id='31effbe529964126bd702590b0ad9b20-6966800eb0694470b73d19ea431b0aea'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='ministral-8b-instruct-2410', score=<MatchScore.B: 0>, id='b12595e04ff54becbc7f2507325b901c-7681f2c2d4c44e5697543d7a172ffa89'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='gemini-1.5-pro-002', score=<MatchScore.A: 2>, id='7489c4a187b94400a8d1964fd7fd9773-501591b1900a4f28a5507bf9a1433584'),\n",
       " Match(model_a='llama-3.1-70b', model_b='phi-3.5-mini-instruct', score=<MatchScore.B: 0>, id='be79543d92654f09b0aa3161f2cac2fb-d94d69b31840480b88b889d01d473aeb'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.B: 0>, id='605ac4a5996e4ffc861f9705007b928d-d23c5238cabe4ec388dbf0877ac6bd55'),\n",
       " Match(model_a='llama-3.3-70b', model_b='ministral-8b-instruct-2410', score=<MatchScore.Draw: 1>, id='4f4f5cd96a564364abf5465e9a8a2916-c75d0875e06a4c2f925531858a0ef382'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='llama-3.1-405b', score=<MatchScore.B: 0>, id='aa74710f4cba4c52a2f0cf3f03f0f9bb-1345c34de4f1496ab4f546f94e87db40'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='qwq-32b', score=<MatchScore.B: 0>, id='7cb32abbc27d4b32b6a8161f25a6f27e-e3d78bb876e2411bb08d5839f6c3b5d8'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='qwq-32b', score=<MatchScore.A: 2>, id='beaaaecde3794426b2968485c4f97729-d086c8e1465a44c08534d7010e8986b6'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='deepseek-r1', score=<MatchScore.B: 0>, id='0cecb4c2560b4fd88045d24934a40b8b-d919ced7f4844970a64761a2bc4bb21b'),\n",
       " Match(model_a='gemma-3-12b', model_b='command-a', score=<MatchScore.Draw: 1>, id='529ccd09a95b4caeae168248a95b21df-74286b297e8f41d0926c02b4478433ba'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='llama-3.1-70b', score=<MatchScore.A: 2>, id='9a4c206f979046b98c416a7ad57b6e3b-cd46eb13bd664f42a808cadb998f5c70'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='gemma-2-9b-it', score=<MatchScore.A: 2>, id='cb26f79785ca4599a7cdeaaac2fd2042-ce98eafdece041ae8cbdc4288ef2b9a6'),\n",
       " Match(model_a='lfm-40b', model_b='gemini-2.0-flash-001', score=<MatchScore.B: 0>, id='f8bdc9431f2e4cfa83f942b68ab731dc-bd74ae3766a7417e9dd751c05ca7fbef'),\n",
       " Match(model_a='llama-3.1-8b', model_b='mistral-small-3.1-24b', score=<MatchScore.B: 0>, id='8c2f48b4a7334a67991d9ea1529eb421-16f809c4e7db4e7898a8773997ece13f'),\n",
       " Match(model_a='claude-3-7-sonnet', model_b='phi-4', score=<MatchScore.Draw: 1>, id='92f46f1bba854f1393606ccddf0babea-dd3332946aaf4e219351d2898ab2ae0c'),\n",
       " Match(model_a='mistral-saba', model_b='command-a', score=<MatchScore.B: 0>, id='1dc48819fe36496babe45ad1e658cef2-eb3ba432ac5841ba9a724c699d060e19'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='gemma-2-9b-it', score=<MatchScore.A: 2>, id='ec67c42f4e234a10a53e38acc26b1ab7-2bbb63aa89334ddeb470642664ac33a9'),\n",
       " Match(model_a='gemini-2.0-flash-exp', model_b='ministral-8b-instruct-2410', score=<MatchScore.A: 2>, id='f719fa98a189450c8aaa99391156953b-50897d3be2c94dce9f1d9862fca2a1b8'),\n",
       " Match(model_a='llama-3.1-405b', model_b='ministral-8b-instruct-2410', score=<MatchScore.A: 2>, id='61b38503e36f4b6aaf26c7a4a5ca55d0-8b2ec7a0d90346aa9a404f37340747a1'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='llama-3.1-70b', score=<MatchScore.B: 0>, id='9775d89e45fa4186b5399e5c86a6704a-aab19bdb6590425097eab67bc40835d5'),\n",
       " Match(model_a='deepseek-r1', model_b='claude-3-7-sonnet', score=<MatchScore.B: 0>, id='a1e5b9409a5942ce8424b628987290d1-e217914e132e4026b22ebaf8dd7f03ef'),\n",
       " Match(model_a='lfm-40b', model_b='llama-3.1-405b', score=<MatchScore.B: 0>, id='f791be64adfd4cbb85bc2f6b5b66d571-c3393cdcafe74c4aa1e31b3a241bb89a'),\n",
       " Match(model_a='mistral-saba', model_b='llama-3.3-70b', score=<MatchScore.A: 2>, id='c8ed974a2d8740afb325262c844001d0-05b5b81673ea45ca8205873acbfc647b'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='gemma-3-4b', score=<MatchScore.B: 0>, id='651b690a34b04f5c96218d69d1d19db2-61642686b19e4f68853d0c18cfd1555b'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='llama-3.1-70b', score=<MatchScore.A: 2>, id='8b0fbbe14b0b43a4879e12a4883eb382-8d14f36690a547db9e4f2b7254b7272a'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.A: 2>, id='b0b60536e27f4c28afad2d14a60f28d3-741a5e439b694f189d309a494d94e098'),\n",
       " Match(model_a='deepseek-v3-0324', model_b='o4-mini', score=<MatchScore.Draw: 1>, id='6a28b0439f094ae7a69ba111ade0e799-5b14494ccea2478cb71bce7492216dc7'),\n",
       " Match(model_a='mistral-large-2411', model_b='claude-3-5-sonnet-v2', score=<MatchScore.B: 0>, id='fd997e566e6444e48a4a18b792b6c897-da69ea24d0a94fd89a2a063c82749d05'),\n",
       " Match(model_a='mistral-small-24b-instruct-2501', model_b='llama-3.3-70b', score=<MatchScore.B: 0>, id='29cb6db0a1214915b30a99f1a40b621a-6e99642b438e4da49311f73de65039c7'),\n",
       " Match(model_a='llama-3.1-405b', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.B: 0>, id='626ebec8499b4375aeff96dac06fa9d5-aac017091e144730bfcf9d3dbc8d6a54'),\n",
       " Match(model_a='gemma-3-27b', model_b='mistral-small-3.1-24b', score=<MatchScore.B: 0>, id='314e102a96c34e088f746d0cf0d3b2d6-56cf4cc1f296498695173d0f8cdc3993'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='llama-3.1-8b', score=<MatchScore.B: 0>, id='4822571e4a93402390742e1ea7973b19-43ec53ebbbc9430fb29b2649ded16887'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='mistral-saba', score=<MatchScore.B: 0>, id='9e9b9a2324b846509c85f08765c99337-0a1483030e304c959c4817838bdc57eb'),\n",
       " Match(model_a='mistral-large-2411', model_b='mistral-nemo-2407', score=<MatchScore.Draw: 1>, id='e5ac40440cd940d8a38be2c75dda2bcd-29be1386fc10489a801ba0e442f9ad4d'),\n",
       " Match(model_a='command-a', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.A: 2>, id='53a6284f01364e2cbb2beea3b4231171-99505bfda8cc44049453f1939cd5b176'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='mistral-large-2411', score=<MatchScore.Draw: 1>, id='d056f7b649de46bf85a91a08ce3523e1-3bea4d64107147a5ac1c0a0ded02498a'),\n",
       " Match(model_a='mistral-large-2411', model_b='gpt-4.1-nano', score=<MatchScore.B: 0>, id='f7cd20c57ce7468da54d9b704b66e8c7-145cdc6498f140068f83b618866f0459'),\n",
       " Match(model_a='gemma-3-4b', model_b='deepseek-v3-0324', score=<MatchScore.A: 2>, id='17ec42a004814a4892f8b2daafec3e17-f7305002198b49c7bef174ba9619a70f'),\n",
       " Match(model_a='phi-4', model_b='gemini-1.5-pro-002', score=<MatchScore.Draw: 1>, id='0f513004625e4bdea73c3228c7940133-5b3e9b1101214ee0a3adccc2fc048b0f'),\n",
       " Match(model_a='phi-3.5-mini-instruct', model_b='llama-3.1-405b', score=<MatchScore.A: 2>, id='53023cce98274e828af2e66666fa7020-caf660d0475141b8b75d97d1e8854156'),\n",
       " Match(model_a='aya-expanse-8b', model_b='gemma-2-9b-it', score=<MatchScore.Draw: 1>, id='c894d05aee8d477f8ef0ccfb3cd06387-c35667bb335b445bb8651362eb4289b8'),\n",
       " Match(model_a='phi-4', model_b='lfm-40b', score=<MatchScore.A: 2>, id='047fb0299dfc4af3b0f07d75edc0f6bd-826ae11a5fbd483daf7c3a1e46c86cab'),\n",
       " Match(model_a='phi-4', model_b='qwq-32b', score=<MatchScore.A: 2>, id='a4ce0f4157f24b8f819059a5f8401500-5d92657382bd462987df2eb801953fe7'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='llama-3.1-nemotron-70b-instruct', score=<MatchScore.A: 2>, id='b735414c942949e095c74190d0227213-0051ddac252a4ec894a0ee587cfaaeb2'),\n",
       " Match(model_a='gpt-4.1-mini', model_b='ministral-8b-instruct-2410', score=<MatchScore.Draw: 1>, id='e5eefeac8a9f433bb9a66d46384f461f-acded1544b6c41c88fea092335ac7632'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.Draw: 1>, id='d2b943a501ed43d9a2088adb3cb2a84f-a1d1f6a5d1b24c8f805b7c6df314dce8'),\n",
       " Match(model_a='qwq-32b', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.B: 0>, id='8058b5c536994f47a55af7b76226f8e4-faeb093f89d24f84a20e5775f1fccd2d'),\n",
       " Match(model_a='llama-3.1-70b', model_b='llama-3.3-70b', score=<MatchScore.Draw: 1>, id='aa0b47ac7659443c86099b909765e501-e013e47039044d889682e4f2d3d3e4a9'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='gemma-2-9b-it', score=<MatchScore.A: 2>, id='5a9f85eef1b44785ac85a803f609ef48-f912989b67e5418f8d38cfa53fa358eb'),\n",
       " Match(model_a='gemma-3-27b', model_b='deepseek-v3-chat', score=<MatchScore.B: 0>, id='688654d7dd7e4e42977369a5619eb168-321e837a1e0c4fd384010d8d6b274256'),\n",
       " Match(model_a='gemini-1.5-pro-001', model_b='ministral-8b-instruct-2410', score=<MatchScore.A: 2>, id='40857a495fc8499590e606f6589b0388-cd6eaefd346b428cae2e3d8e5284166b'),\n",
       " Match(model_a='llama-3.1-nemotron-70b-instruct', model_b='deepseek-v3-chat', score=<MatchScore.B: 0>, id='f1ac82a687ea44ddae9e4a1c92a559e0-c4e0560e8bd640e2ab99bae412171551'),\n",
       " Match(model_a='c4ai-command-r-08-2024', model_b='mistral-small-3.1-24b', score=<MatchScore.B: 0>, id='3c44aee3dc9547b58263d82f54f7bf54-04d74d94f7044d08a59bc136cec9b422'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='deepseek-v3-chat', score=<MatchScore.B: 0>, id='6f744372a71248b48c73184b95c8b2a1-4e13883b417942b99275fb2a1c73b4a8'),\n",
       " Match(model_a='llama-3.1-8b', model_b='mistral-large-2411', score=<MatchScore.Draw: 1>, id='00be5dab5fed4f9daf118129ca9e4683-ae59bf71631844cdb429d0540dca6be1'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='llama-3.1-8b', score=<MatchScore.B: 0>, id='b7c941fcaf524d6ba4850b2ab2850750-b2f6bacb2d2e4ba2b8d372074241e85d'),\n",
       " Match(model_a='gemini-2.0-flash-exp', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.A: 2>, id='688f1b71f06643be8630cc8a0a38fc16-2898c0b9b993400998f71d41f9edcbcc'),\n",
       " Match(model_a='qwq-32b', model_b='command-a', score=<MatchScore.Draw: 1>, id='02c20fd25b2b49fb97a1363c136ce9b4-4e507d28367d4e80b9eec1f10b7e10c3'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='claude-3-5-sonnet-v2', score=<MatchScore.Draw: 1>, id='6fda084912a94995ba6c391b1ca24740-2b8276225e404e98870cff9eb830d540'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='gemini-2.0-flash-exp', score=<MatchScore.B: 0>, id='6f27987908b84220a0b168acbeead396-1c92798b4be442f7ba0479f4e21273e6'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='phi-4', score=<MatchScore.A: 2>, id='d508c2f2b2f14981a5b0e54f88a26b22-34aa8d91fcae458c89198cbe59452dbb'),\n",
       " Match(model_a='mixtral-8x7b-instruct-v0.1', model_b='qwen2.5-7b-instruct', score=<MatchScore.B: 0>, id='8619ee5232264754b2b5f5377431266e-ab27aa00309e4ca8a9beb9f000ae57b6'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='gpt-4o-2024-08-06', score=<MatchScore.B: 0>, id='903afd88ada8405f83b617e493f117cb-059d48a61df84a74b8535b9245043a02'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.B: 0>, id='335093b813dc471b8b89dd6a3dd2dbdb-e74d23c9fd4c4d5e86adfdd4dc1b278a'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='gemini-2.0-flash-001', score=<MatchScore.B: 0>, id='a3e4f526924c43b7b11b622525a43dd0-0a7c5d9b5c19493b84801c70345f2692'),\n",
       " Match(model_a='gemma-3-27b', model_b='gemini-1.5-pro-002', score=<MatchScore.A: 2>, id='6e06d04b87974826881eb6ddbc252fb9-8cd5ce444aff4e4c8d6de1d903e3b1dc'),\n",
       " Match(model_a='deepseek-r1-distill-llama-70b', model_b='o3-mini', score=<MatchScore.A: 2>, id='3b0ff228f9e54a448b37467b384d52f8-5d3652064f5046428a8b389b4350d5bf'),\n",
       " Match(model_a='llama-3.3-70b', model_b='c4ai-command-r-08-2024', score=<MatchScore.Draw: 1>, id='d740dbb1f695412eb7ee45239d2e9ade-0c2e72c7e85648d7b0f1e005fa8f4f73'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='claude-3-5-sonnet-v2', score=<MatchScore.B: 0>, id='40f36a0c030a4c72b45461f69cd0d639-9b53fec7879c4ca492235c2bd7f43fe6'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='gemini-2.0-flash-001', score=<MatchScore.A: 2>, id='23cb293feb6c471f8c3175ac08de137e-9c121c1ccd7e4f0bb70af83158c3c3d6'),\n",
       " Match(model_a='phi-4', model_b='mistral-saba', score=<MatchScore.B: 0>, id='ed0e45c472f747caaa8fd984e1ba964d-0bb37ea1ebae429a97641a9824d085ed'),\n",
       " Match(model_a='chocolatine-14b-instruct-dpo-v1.2-q4', model_b='llama-3.1-70b', score=<MatchScore.B: 0>, id='227ba80c9dd94e7f8cb497e4be7583d8-a68a7d1a667d4a4e9f2c89187fa9cf4d'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='gemini-2.0-flash-exp', score=<MatchScore.Draw: 1>, id='68b282b3caa94c0aa2edeb0b3a83bf72-c77b788812724ff08c51550f1ed80e68'),\n",
       " Match(model_a='llama-3.1-405b', model_b='mistral-nemo-2407', score=<MatchScore.A: 2>, id='f1cd29890ee6488c8fc6df3d40d2ed79-e53df44839234378a83d0a8713b1f9a1'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='gemini-2.0-flash-exp', score=<MatchScore.B: 0>, id='98474888ec7d4c05a088e7271403b46f-cef70cc0aa1d491abbad53c25ad0d75b'),\n",
       " Match(model_a='aya-expanse-8b', model_b='llama-3.1-70b', score=<MatchScore.Draw: 1>, id='aa7538f0c6d14baca7ad141ca642dbc5-6f3c6d953d84430aa4e3ee94fc8d68cf'),\n",
       " Match(model_a='aya-expanse-8b', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.A: 2>, id='bf9f431abdc14e65848404bffd706d4d-126b974049a34d59bbb940329ca8eb43'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='mistral-nemo-2407', score=<MatchScore.A: 2>, id='00a4bca2b0164023b2ea463791881f86-06acde51b0c74a44934ad7973458e60e'),\n",
       " Match(model_a='gemini-2.0-flash-001', model_b='phi-4', score=<MatchScore.A: 2>, id='d3f44f4f55b743f190db7856889875f4-28cd58b70aa44b828226cc87f5aa79ad'),\n",
       " Match(model_a='llama-3.1-70b', model_b='mistral-nemo-2407', score=<MatchScore.A: 2>, id='0e780da190384003b5b1b195393d6004-2845fa375197419fbf16d0402fb87d32'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.Draw: 1>, id='69e9a6a165c0445fb43f7154e553e5b1-d18f6eb1a1534414a51e82512a6fb8b9'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='gpt-4o-2024-08-06', score=<MatchScore.A: 2>, id='b0634fb187be4b7cb7be792d7680d472-06fe3d6cd7714b9b86fb81dfa42cdc81'),\n",
       " Match(model_a='lfm-40b', model_b='gemini-1.5-pro-002', score=<MatchScore.Draw: 1>, id='dcab1ed65e2d4f948e7217c725420dcc-337fad4c45984e19b23eafa2819b9513'),\n",
       " Match(model_a='mixtral-8x7b-instruct-v0.1', model_b='gemma-2-9b-it', score=<MatchScore.Draw: 1>, id='60b4636c1eef445aaa2973505cc4e4c5-54203339827e409eaeab35df0835cd54'),\n",
       " Match(model_a='llama-3.1-nemotron-70b-instruct', model_b='phi-4', score=<MatchScore.A: 2>, id='3ac7c0a931ed47a29dbba88cc1326d8f-c443c94aaffb4849a3bba5c5312e4566'),\n",
       " Match(model_a='llama-3.1-405b', model_b='phi-3.5-mini-instruct', score=<MatchScore.A: 2>, id='6ffb844eddf94e1ab37cb0c0b763cb47-ca1374c38ef244638c7b518ef880d1a2'),\n",
       " Match(model_a='gemini-2.0-flash-001', model_b='claude-3-5-sonnet-v2', score=<MatchScore.A: 2>, id='a011059e312c442d8a406b307f70b250-b7581cc8fee1425ebf67a0632cb6c91e'),\n",
       " Match(model_a='llama-3.3-70b', model_b='c4ai-command-r-08-2024', score=<MatchScore.Draw: 1>, id='2569835254154858a732cdcef31a0bd1-3942b947dfc7438081c9559fe104bab5'),\n",
       " Match(model_a='llama-3.1-nemotron-70b-instruct', model_b='gemini-1.5-pro-002', score=<MatchScore.B: 0>, id='a8f1d61152684d688112c656ea477ccf-8c30e43d3ae64ad4975422d457e6ae2d'),\n",
       " Match(model_a='deepseek-r1-distill-llama-70b', model_b='lfm-40b', score=<MatchScore.A: 2>, id='3add9fbd2f30444a836c9784f3224c5f-9a82320c52f9429c966950ddd4eae023'),\n",
       " Match(model_a='qwq-32b', model_b='o3-mini', score=<MatchScore.B: 0>, id='96a5361012a747fc8ada469308bef5cd-97ee4ab983e94c6f9c5359d5629f19b7'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='claude-3-7-sonnet', score=<MatchScore.B: 0>, id='c8af80c6d1854ab7a16af3ddecc9c85d-2f9d6308487649bd9992cc8b2c9de73e'),\n",
       " Match(model_a='mistral-large-2411', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.A: 2>, id='d3cfa18bd5ed4887a32b6182d23ddb6c-8eeacb91a0d04ac6b1416c041f0d311d'),\n",
       " Match(model_a='gemma-3-27b', model_b='llama-3.1-405b', score=<MatchScore.Draw: 1>, id='d16f60c3b95b42dd94ae99af698d7a92-665e95886df642559c9e34c78254b35b'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='llama-3.1-405b', score=<MatchScore.A: 2>, id='b5d40d8df3f244f8b38b2da0a525225e-20701be30175422eaac3dba9e4b8a187'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='llama-3.1-70b', score=<MatchScore.B: 0>, id='ad0f84f6a1c04776847877537855e970-2759cc4fd89e45f3b25c3f035c977c20'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='gemma-2-27b-it-q8', score=<MatchScore.B: 0>, id='b1747a10855a4fc7bf2ad13de7753432-8aa02e138e8241938638ab5600650b1d'),\n",
       " Match(model_a='deepseek-r1-distill-llama-70b', model_b='qwq-32b', score=<MatchScore.Draw: 1>, id='fb5d1b8c8fd543a195f40755a660772a-f6252434d76a4caf9902729d2c8a7193'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='qwen2.5-7b-instruct', score=<MatchScore.A: 2>, id='b6b5537e44574d69a99c9481c39e5b2c-1b358d641cb74510b943f53763f1158d'),\n",
       " Match(model_a='llama-3.1-8b', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.B: 0>, id='cdb67d90de52490ab936e32ad8e8db14-cbb5dc1718b943068760f764534f2666'),\n",
       " Match(model_a='deepseek-r1', model_b='qwq-32b', score=<MatchScore.A: 2>, id='8e376165d9844c178357d3f180774fa3-f10d1d16361548a29346b595b8327cdd'),\n",
       " Match(model_a='gemma-3-12b', model_b='gemini-2.0-flash-001', score=<MatchScore.B: 0>, id='0fc2fc1ef3074facae36f9b6f5d6c1c0-521916860705478b934ee0349f07a514'),\n",
       " Match(model_a='llama-3.1-70b', model_b='llama-3.1-70b', score=<MatchScore.A: 2>, id='a28a12a1aa3e46588c89b05aa6772779-fa3b32140176468ca256867f5abcfbd3'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.B: 0>, id='cdd48164ff3d47e7836e2851a4e53f9f-1790add5253b4d4dbb1965299ce1f3c5'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.B: 0>, id='ec81c67638fd4d3ea59c304bf1a56a0e-251cc25de8b041f089327361761a5016'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.A: 2>, id='f3b0fcd3c33045899dfde3ae632c75a6-6420e65ca3e5422ab2b82d9dbb641035'),\n",
       " Match(model_a='command-a', model_b='qwq-32b', score=<MatchScore.Draw: 1>, id='95e9b2ba3c8340268fd98c8475c9a328-92853aa240c1446c81858b90cd5a2368'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='llama-3.1-8b', score=<MatchScore.A: 2>, id='224b927893a74da3972106078892bf39-215afaa85f134897a6c6fc883bfbc7e8'),\n",
       " Match(model_a='command-a', model_b='deepseek-r1-distill-llama-70b', score=<MatchScore.B: 0>, id='06322a61f99546f998989675b910f5b5-0695e496844242b0885c8c9e44eed2ae'),\n",
       " Match(model_a='llama-3.3-70b', model_b='phi-4', score=<MatchScore.Draw: 1>, id='61d91119493f4d3cb037f4c4ebc3e3ef-e9ce39b8e8c54ca1b4faab47312eb093'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='claude-3-5-sonnet-v2', score=<MatchScore.Draw: 1>, id='88fccbc6412a460aa9335a2a1df104cb-3425131dd16848b18bd713ab96f1354f'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='claude-3-5-sonnet-v2', score=<MatchScore.A: 2>, id='28dedd7cc65b4469b829afa660eecb66-12717b9b32424ec985f5e96c813fc9d6'),\n",
       " Match(model_a='llama-3.3-70b', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.Draw: 1>, id='99317437fd5343188ed12bd76a0e1bb4-7a556dced28b423d9a73a9c257dd3e0e'),\n",
       " Match(model_a='llama-3.1-405b', model_b='gemini-1.5-pro-002', score=<MatchScore.Draw: 1>, id='4a7012b3e8b44ab88635a95aa7738d0d-991d6b2f5be74c37930744d5a440fedb'),\n",
       " Match(model_a='llama-3.1-405b', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.A: 2>, id='ad0c77e250514338a273cee23627d7e7-6ef1241ebb274ab5aa8bf43ba7c2d4ab'),\n",
       " Match(model_a='gemini-2.0-flash-001', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.B: 0>, id='f9f0adf07b1f4864a185b75e63a307ff-f77fc7f319c04b95a72870020ff7ad90'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='deepseek-v3-chat', score=<MatchScore.B: 0>, id='e0ae3034e1e946dcb0f85d6020ab0f27-25344b235b354547a989e9168c70a951'),\n",
       " Match(model_a='llama-3.1-405b', model_b='gemini-1.5-pro-001', score=<MatchScore.B: 0>, id='ed5970627302480982a19e5b37c576a6-85819b62969d4a6ba4a78806102f63fe'),\n",
       " Match(model_a='o3-mini', model_b='gemma-3-27b', score=<MatchScore.A: 2>, id='cbd82fbd0ebb4062b9b484c77ed9de03-d327b74b34474645a74cdbd0cb7cdf74'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='gpt-4o-2024-08-06', score=<MatchScore.Draw: 1>, id='c0d3662a2cbf48feb2fe190419fc788e-39b09a11044f494592517e37f319a5f0'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='claude-3-7-sonnet', score=<MatchScore.Draw: 1>, id='d3ab10854e97494ea79b9a1a6b1df4ee-8a49bc8ba9194a3d89e2345ea650124e'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='llama-3.1-405b', score=<MatchScore.Draw: 1>, id='807bc5859f5449049290968c6a782eb6-b12228e7af3a459798cf621ab935d195'),\n",
       " Match(model_a='command-a', model_b='claude-3-5-sonnet-v2', score=<MatchScore.B: 0>, id='3838556ba7ab4e028092f45bf3a197cd-ecce75c15a774ea7994a5a419c111be2'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='gemma-2-9b-it', score=<MatchScore.A: 2>, id='bf96bcfe4aa147289c070e2613756554-e8cdcc584bed41b48b35b5e6e98ca515'),\n",
       " Match(model_a='mistral-small-24b-instruct-2501', model_b='mistral-large-2411', score=<MatchScore.Draw: 1>, id='1e950fad7ccb445c9c2982f8d70a47f5-88aa84fc151649efaaeb28553efa1b59'),\n",
       " Match(model_a='llama-3.1-70b', model_b='gemini-2.0-flash-001', score=<MatchScore.B: 0>, id='393d080bf9dc4b1dbb418d6291147723-fcdb53609deb427b9afcfe1ff16405e1'),\n",
       " Match(model_a='command-a', model_b='ministral-8b-instruct-2410', score=<MatchScore.A: 2>, id='101cdd4f48b84eab87135e88dc271c97-df0e3547e0f24f41843990a40ab33fb2'),\n",
       " Match(model_a='llama-3.1-8b', model_b='qwen2.5-7b-instruct', score=<MatchScore.B: 0>, id='a631db7aa4a74e44b664998245e69339-cc3b77b369dc4531bac8e24f5871529b'),\n",
       " Match(model_a='mistral-small-24b-instruct-2501', model_b='gemini-2.0-flash-exp', score=<MatchScore.Draw: 1>, id='616309ae5dd54e5dbd80a3968a7377b3-aba9121c07be41a791100a8f8b458e80'),\n",
       " Match(model_a='gemma-2-27b-it-q8', model_b='lfm-40b', score=<MatchScore.B: 0>, id='1f5947889f214fecbb8ee62f1072d821-8a81153a5b9f4552b28429d72668e851'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.Draw: 1>, id='03bf6718095a41838ec444ffa0022f0c-78e1183ee65b41ba98d9ab32308d7997'),\n",
       " Match(model_a='llama-3.1-405b', model_b='llama-3.1-8b', score=<MatchScore.B: 0>, id='5e978893e66742b08ef9d5a80f0a440d-b250030a41ea4111868c0bf916ccf001'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='claude-3-5-sonnet-v2', score=<MatchScore.A: 2>, id='363a7383c7cc49cdbe042191a926d721-5294762652d34d1f961e0d8f2f56adad'),\n",
       " Match(model_a='llama-3.1-8b', model_b='gemma-2-9b-it', score=<MatchScore.Draw: 1>, id='a3b43677e7c2433eba942cb737554423-a3b78756564a4dda9648eb1f66919ef0'),\n",
       " Match(model_a='aya-expanse-8b', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.B: 0>, id='0bad6c91a70b439ebf416dbf432e548c-074bfb5f8e0e41ce82674b687c041f4c'),\n",
       " Match(model_a='mistral-large-2411', model_b='mistral-small-3.1-24b', score=<MatchScore.A: 2>, id='bbf4224dd23b43598fb19dcde68956e7-b2acd625baed45e5ab88ab78092a34cc'),\n",
       " Match(model_a='llama-3.1-8b', model_b='lfm-40b', score=<MatchScore.B: 0>, id='f0159809164f4767927c7c8db19d55cd-fcf4a817842b47f5b99025c9fbfca933'),\n",
       " Match(model_a='phi-4', model_b='mistral-large-2411', score=<MatchScore.Draw: 1>, id='955ecb3dc58b40acbb6dcb3f16b3b472-dfd1ebbcde38442680037ed0ae7cee42'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='deepseek-v3-chat', score=<MatchScore.B: 0>, id='c786cadcbd4f4eedb26ab81aa0980848-3cab69730df94fc69845162d4e459642'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.B: 0>, id='0716d66a0015404782c161600d6ec49c-16e3430a35fe44cfaa0e6b5ee6bedeac'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.A: 2>, id='8a4b189c186a49d8ad4864879208cf69-bb58491e2e99477f8be923911fbf40c7'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.B: 0>, id='8e9426e2e3f145c9ac5c991875b5ee3f-f46019c215a6422baee08b0ec4f7a19e'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='mixtral-8x7b-instruct-v0.1', score=<MatchScore.B: 0>, id='86e6e61d55dd425c86b843f0e6a6e87b-ed4a1d0da19946e8a43d3c5d950d186a'),\n",
       " Match(model_a='llama-3.3-70b', model_b='c4ai-command-r-08-2024', score=<MatchScore.Draw: 1>, id='be014c3316c74a5786136acf0ead8f13-607409ca8ac04d779678bd883cdb91ab'),\n",
       " Match(model_a='mistral-saba', model_b='command-a', score=<MatchScore.A: 2>, id='cbcc4be324f84adfa12743f704d7cb76-8649603249224945b593e028e1ba5d4f'),\n",
       " Match(model_a='grok-3-mini-beta', model_b='o4-mini', score=<MatchScore.B: 0>, id='0e911d0633054d6885591691c850ea1b-7660c2ba7d7444f2bac66c3283b2e78b'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.Draw: 1>, id='40777d8f38da4eb498a5e4502eb194d8-ffd0db3f24034752a96f1c1430c45564'),\n",
       " Match(model_a='llama-3.1-8b', model_b='gemma-2-9b-it', score=<MatchScore.Draw: 1>, id='de976f182480412fa3eb5ca5b8b80766-815d6a8df8db4e4ea66de64971cf27a4'),\n",
       " Match(model_a='qwq-32b', model_b='deepseek-r1', score=<MatchScore.B: 0>, id='ae85453c54c642ae805afad617d6485b-70cfa4e75c054a75ae8eb3ee500fb074'),\n",
       " Match(model_a='mistral-small-3.1-24b', model_b='mistral-large-2411', score=<MatchScore.Draw: 1>, id='e3472bfeeaab4e2fb317a5533fb9dbfd-000f4216674a48c780d0072f7cbbeeb8'),\n",
       " Match(model_a='c4ai-command-r-08-2024', model_b='command-a', score=<MatchScore.Draw: 1>, id='6d8e1c0d34514a059380c4f16af512f6-ead4933060204fd0a2d1944f169903f7'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.Draw: 1>, id='87f078eb38fa4228bdd7aacda43023d2-f22bb3e1bc2342c5af40861bbd7e7c06'),\n",
       " Match(model_a='phi-3.5-mini-instruct', model_b='gemma-2-9b-it', score=<MatchScore.A: 2>, id='3a44f54b0b424830b3ec40bae7b1a07d-a9009f93e8004038993391aa132aacfa'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='gemini-1.5-pro-002', score=<MatchScore.A: 2>, id='51a77f7a4cde472dae7ff869af65ba7a-9e439285a5d8419881fe1488371ecba6'),\n",
       " Match(model_a='o4-mini', model_b='grok-3-mini-beta', score=<MatchScore.B: 0>, id='6be80b0c60ed495781453960380e0676-463b43e8acd74cfda1439a947efe1e49'),\n",
       " Match(model_a='deepseek-r1-distill-llama-70b', model_b='o3-mini', score=<MatchScore.A: 2>, id='ba2201491d864bf291c9cf99f6eb6ee4-9d52aaa36cef482aa9ce1f345ba9a9df'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.B: 0>, id='6c3f7948cb124b37bcb14e19119a0ade-6d1da6d2298c4906b9a99d6b7d37efaf'),\n",
       " Match(model_a='claude-3-7-sonnet', model_b='c4ai-command-r-08-2024', score=<MatchScore.A: 2>, id='384de20b19d44e8bacf55e0bd141d646-0dd8868e0ac84fdea2108867aa2a19ce'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='gemini-1.5-pro-002', score=<MatchScore.A: 2>, id='75171393ae9844a0baa7147de453cda0-75e799e0d0874bcb8898671dac6cc55b'),\n",
       " Match(model_a='llama-3.1-8b', model_b='gemini-2.0-flash-exp', score=<MatchScore.A: 2>, id='5c0136b20aac400f9f7bcad229eebdc9-e2ca0b99e2894672be0cf04559e27e21'),\n",
       " Match(model_a='deepseek-r1-distill-llama-70b', model_b='o4-mini', score=<MatchScore.A: 2>, id='d24f26f44d4e439498975b6dfb4c70b0-ccb1d7c5f60b4c81a368c12aa103afd7'),\n",
       " Match(model_a='llama-3.1-405b', model_b='phi-4', score=<MatchScore.B: 0>, id='6d7de8bd942c4c21ad6b261a492eaa73-77d28769b2834fdaa277cab3b551826b'),\n",
       " Match(model_a='gemini-2.0-flash-001', model_b='deepseek-v3-chat', score=<MatchScore.A: 2>, id='7396083b63444933ab7fb058ab919f56-e499941d1ccc419ba0d8afa895344d71'),\n",
       " Match(model_a='phi-3.5-mini-instruct', model_b='llama-3.1-405b', score=<MatchScore.B: 0>, id='abb4167fd69d441493e2919e692131fe-62ce07780ed6413b95bdec170c9ded6e'),\n",
       " Match(model_a='lfm-40b', model_b='llama-3.1-70b', score=<MatchScore.Draw: 1>, id='67d32141d3754a91bbed073f00f15455-efa565847f76491c83f62925cff8b52c'),\n",
       " Match(model_a='phi-3.5-mini-instruct', model_b='gemma-2-9b-it', score=<MatchScore.B: 0>, id='8a0fc24f4d3a4d8b85558ebde031355e-cd6336f4690b4c91bc88550ba3d3dfd9'),\n",
       " Match(model_a='llama-3.1-8b', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.B: 0>, id='c26d6ed3c8c04d489266fb6975929a23-daf298f1e85e4b11b645b6d7c171d710'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='gemini-1.5-pro-001', score=<MatchScore.A: 2>, id='47e6204a4d314a199a14929880196832-4b7084367bf94644babe19dc59b5913b'),\n",
       " Match(model_a='llama-3.1-nemotron-70b-instruct', model_b='gemini-1.5-pro-001', score=<MatchScore.A: 2>, id='aad4c26d96e64c2182687dea6407bbae-85cdc149151448acb24ff9141db314ca'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='phi-4', score=<MatchScore.A: 2>, id='7ed32a6e7f244803954f302a38a9f560-db1de04645484d73ba9405a010d5c050'),\n",
       " Match(model_a='c4ai-command-r-08-2024', model_b='llama-3.3-70b', score=<MatchScore.Draw: 1>, id='3909954e7632489f84da381e50dde358-85d1ff6e7f5e409db4933a61efe0fa18'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='gemini-1.5-pro-002', score=<MatchScore.B: 0>, id='983e56cc3e914b8aa20480d9f1d3598c-d271bd761e104d23960fb3585472708e'),\n",
       " Match(model_a='llama-3.1-405b', model_b='mistral-large-2411', score=<MatchScore.A: 2>, id='4c235be1a70349a28425715a540059cd-5bf4280e75724469829128815fb5f3d3'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='gpt-4o-2024-08-06', score=<MatchScore.A: 2>, id='5cd11faa9eb549489d809c6c8604ec8d-1b3a12a611264e8ba9dae0b961b5accb'),\n",
       " Match(model_a='llama-3.1-405b', model_b='gemma-2-9b-it', score=<MatchScore.B: 0>, id='e1fe165e532e45c8bb917fe27cf6321e-9d3e44d55294437c9bb580c0ba74ea7b'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.A: 2>, id='ed1f1d2d4a744881b7c535a2f9d035dc-27319c00fca241269704a518108790bb'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='gemma-2-9b-it', score=<MatchScore.A: 2>, id='839c917e32fb43a685e9aaf9d5da0dd4-760df38e80f741ea89aafffc54f23c1c'),\n",
       " Match(model_a='mistral-large-2411', model_b='llama-3.1-8b', score=<MatchScore.A: 2>, id='bd60a4b3d20f4598a2015ad7eac14df9-4d257462d4e847b88f53744287c60fc4'),\n",
       " Match(model_a='gemini-2.0-flash-001', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.A: 2>, id='469f45f1998746be8dc54b12c64e6611-5db29b09445045b1a56567d886422a93'),\n",
       " Match(model_a='llama-3.1-405b', model_b='ministral-8b-instruct-2410', score=<MatchScore.A: 2>, id='a9ab96b676fd4bec8811d098187bd014-22e4235a661e43ed9496043029305c21'),\n",
       " Match(model_a='mistral-large-2411', model_b='deepseek-v3-0324', score=<MatchScore.Draw: 1>, id='d5a9d783a8984299b1aeb0e720e5b577-5bd812e977d848fe893f0bbca196b029'),\n",
       " Match(model_a='gemma-3-27b', model_b='gemma-3-12b', score=<MatchScore.B: 0>, id='a733088cd2c94f0f97e494ed694f6848-d77306e7bf544c70974485171a4e8ff8'),\n",
       " Match(model_a='mistral-small-24b-instruct-2501', model_b='llama-3.1-8b', score=<MatchScore.Draw: 1>, id='6248023d09d84616af58f5d2d82ea763-780a45873d994a00a35563a16d840265'),\n",
       " Match(model_a='llama-3.3-70b', model_b='c4ai-command-r-08-2024', score=<MatchScore.A: 2>, id='80c5e9b2d62e4faea0ef9600e13f92dc-05c11fde9c6c44fcbf6ee6fc3990a7d6'),\n",
       " Match(model_a='lfm-40b', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.Draw: 1>, id='ed8a68a1c6b2476797975b3d3b6c9d3c-c14142efabb5404882842df0fceb55de'),\n",
       " Match(model_a='o3-mini', model_b='deepseek-r1', score=<MatchScore.A: 2>, id='2cf712dd296842d49fc4b83420b6cfcf-004257a847e94de992afeec65ecb58f9'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='claude-3-5-sonnet-v2', score=<MatchScore.Draw: 1>, id='e6875d41dc2646779fb9c938bf5608e8-c9252baee9d042f78cd3cbc3c3540fcb'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='claude-3-5-sonnet-v2', score=<MatchScore.A: 2>, id='381ade78ce7e4de4a05dc144087eb85b-7674d1c6656745fbaaafcfa649d5f1d9'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='llama-3.1-405b', score=<MatchScore.B: 0>, id='618a584f961745af810cf78f8495fe5d-bf4e8d60406f40eaa55e76eaa210f6c4'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='gemini-1.5-pro-002', score=<MatchScore.Draw: 1>, id='dba43a6253bd4312b9282a3bf1a15ac1-974d3fd9526c4d67acb13d6dcb0bf90a'),\n",
       " Match(model_a='gemma-3-27b', model_b='llama-3.3-70b', score=<MatchScore.A: 2>, id='cc3fa0de7abc40ed9ac91b22ac3071a1-4b18c495174243beb510702cf51d3313'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='llama-3.1-405b', score=<MatchScore.A: 2>, id='6d7ef1d5f8ac43afb9943436aca90d98-c31ddf25bc764ae59149cfcbd20d0034'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='llama-3.1-8b', score=<MatchScore.B: 0>, id='0bfd345dd20c4a8fbb153fb15a0f1ac9-51b3a0a3f91249c8ababe2b0d320275c'),\n",
       " Match(model_a='mistral-large-2411', model_b='llama-3.1-nemotron-70b-instruct', score=<MatchScore.B: 0>, id='70ab9c9f74f34542a9e48ec3eeef3ef3-197ff307a734433a8bbb38fe105ac72c'),\n",
       " Match(model_a='mistral-large-2411', model_b='claude-3-5-sonnet-v2', score=<MatchScore.Draw: 1>, id='ecdad9b44c634cc7b8602c5ce33e0d49-604db25515c84c36bbf281dd5ca04b6b'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='llama-3.1-70b', score=<MatchScore.A: 2>, id='f57fd4e6b54a4095a22708875ca4b3e9-803b68ce737047fa87f0ad5d4ade61fc'),\n",
       " Match(model_a='gemini-2.0-flash-exp', model_b='gemma-2-9b-it', score=<MatchScore.A: 2>, id='1ea673d121464ec387754e0285b5b716-a5933f9c678b4f63b20fcafb15793720'),\n",
       " Match(model_a='c4ai-command-r-08-2024', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.Draw: 1>, id='dd234d952bc44aac8fbb4840ec093f89-43d6f27e0cdf415ea71fa80832b7fb4b'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.A: 2>, id='e44560cece2e4daaab24bf454b2b8e96-4bb8f49194ea474b89febe0b63900bc2'),\n",
       " Match(model_a='gemma-3-12b', model_b='llama-3.1-8b', score=<MatchScore.B: 0>, id='df2c39589ad744028073fec5bb41a8f4-0641736576774a9585b466f0da4e87ac'),\n",
       " Match(model_a='llama-3.1-8b', model_b='phi-3.5-mini-instruct', score=<MatchScore.B: 0>, id='532d543c22ad40648b23d3e2131c0f29-f9f476c5beab40e49c573fb825074ec2'),\n",
       " Match(model_a='llama-3.1-405b', model_b='lfm-40b', score=<MatchScore.B: 0>, id='66328240372240f5b3f9feab43e820f3-a880d2dbdaf34703be83c8c6240c1fc4'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='gpt-4o-2024-08-06', score=<MatchScore.A: 2>, id='6d3d72aafd8f40f1b51d34a0b50a2db6-5d8fbae9566946dd9f2eb9cda09bb518'),\n",
       " Match(model_a='mistral-large-2411', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.B: 0>, id='61bf80ffbb5841fda5d787ed53541119-6008681a4e59466b880549e255be54dc'),\n",
       " Match(model_a='gpt-4.1-mini', model_b='gemini-2.0-flash-001', score=<MatchScore.B: 0>, id='3cde5dc2039f49998870fa32bf407592-4912d94fd77d4c6c8680a7d58cf99995'),\n",
       " Match(model_a='mistral-small-3.1-24b', model_b='phi-4', score=<MatchScore.Draw: 1>, id='25975dbc7a18476086e576b3712c8f21-782b1dd256a9456191bd61b03573ef4f'),\n",
       " Match(model_a='gemini-2.0-flash-exp', model_b='gemini-1.5-pro-002', score=<MatchScore.A: 2>, id='2ce1a9166c894b2883da303b2261a9ee-a875b42a540046faaa37099514625d87'),\n",
       " Match(model_a='llama-3.1-405b', model_b='claude-3-5-sonnet-v2', score=<MatchScore.A: 2>, id='d5365ce4fdc845f98be4eb32ebad17d6-2b25a965545c4beaae70939a6cc83906'),\n",
       " Match(model_a='aya-expanse-8b', model_b='phi-4', score=<MatchScore.Draw: 1>, id='0784b69db7be4d4e80c51f8f066dc67a-656ce70b6fc34ee79b6c9a2d05bcbff6'),\n",
       " Match(model_a='gemini-1.5-pro-001', model_b='llama-3.1-8b', score=<MatchScore.B: 0>, id='38c221df208847b88cfa7a3add4b3d32-65548b7e09b54d9bb8c07b78134a9634'),\n",
       " Match(model_a='o3-mini', model_b='qwq-32b', score=<MatchScore.B: 0>, id='aaf85bc4edc44c378330a68dbefdaa7a-b0403b578dc742cd91e263de70696639'),\n",
       " Match(model_a='mistral-small-3.1-24b', model_b='phi-4', score=<MatchScore.A: 2>, id='3c15baa8c8f24e39bc8d5922afcb9332-20de0112dc07481f850881c8d8b1123f'),\n",
       " Match(model_a='llama-3.3-70b', model_b='deepseek-v3-chat', score=<MatchScore.B: 0>, id='58be42dc59e5472e86d9f1b0e8b32962-cc5f9aef0856460ca4018c0baaf386f8'),\n",
       " Match(model_a='llama-3.3-70b', model_b='ministral-8b-instruct-2410', score=<MatchScore.A: 2>, id='ddefe7824a4146e28c7c2d64ec33fd2b-cb058bf5a31846a7af782aa0a9eec63e'),\n",
       " Match(model_a='mistral-large-2411', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.A: 2>, id='2c66ee00a69843ebb4a417c297a42e0d-0dff074b31634cdfb7261bd6402d901e'),\n",
       " Match(model_a='llama-3.1-70b', model_b='llama-3.1-405b', score=<MatchScore.B: 0>, id='762dc29c1a8e46b8bc3ad1c31e168c2d-ff0636e12fba40e8acd10c82803c6605'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='gemma-2-27b-it-q8', score=<MatchScore.B: 0>, id='408972117266490a9868097081d6ebdb-b77b50925b8c49df974eb48b4979e3d0'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='deepseek-v3-chat', score=<MatchScore.B: 0>, id='5f54055759d6435b94c48a36ae8537e7-24981a900f7d4436bba0a3cf6ced6a91'),\n",
       " Match(model_a='gemini-2.0-flash-exp', model_b='llama-3.1-405b', score=<MatchScore.A: 2>, id='793601c59a2b4aa5b0dbaa4cad7a870e-9837cebc99584a7a80db2a2cfc7a330d'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='mistral-nemo-2407', score=<MatchScore.A: 2>, id='ddad55996e064717b9c72d660a5527c7-4895508c3a9048c08d4d6f3c6c1e51f8'),\n",
       " Match(model_a='aya-expanse-8b', model_b='llama-3.3-70b', score=<MatchScore.Draw: 1>, id='1d0b98bb0592454b8994c3521aa40585-352ea359cedd43a5a21b0b22eb7bf378'),\n",
       " Match(model_a='llama-3.3-70b', model_b='ministral-8b-instruct-2410', score=<MatchScore.A: 2>, id='748053994de24e228f6c2b2e09833a90-a6ccc7b3f700492d948bedff747a7dc7'),\n",
       " Match(model_a='gemma-3-27b', model_b='deepseek-v3-0324', score=<MatchScore.Draw: 1>, id='c8768f9102214ed4afd5106f8c52b204-a15124374d524f2faa381286ea661ee0'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='mistral-nemo-2407', score=<MatchScore.A: 2>, id='2cef746ca5c448988ff3fe2ae6c99f2d-e55fdc42ce5c48b1a178f18e87ddd9d8'),\n",
       " Match(model_a='llama-3.3-70b', model_b='llama-3.1-nemotron-70b-instruct', score=<MatchScore.Draw: 1>, id='40d7f48ee91f4d6aae0319f952d87675-9bb9e059bc84412ebc9b7b8026206f2e'),\n",
       " Match(model_a='phi-3.5-mini-instruct', model_b='gemma-2-27b-it-q8', score=<MatchScore.A: 2>, id='4b6b5180421f449c9b9bd065e6f43247-9fe083bb36d447f0a430680fc15ea7aa'),\n",
       " Match(model_a='llama-3.1-8b', model_b='deepseek-v3-chat', score=<MatchScore.B: 0>, id='666ccb9ac60b421c8aac36aaa30efdae-3a63466510c74d378cbadb87ebd12d2d'),\n",
       " Match(model_a='mistral-large-2411', model_b='llama-3.1-8b', score=<MatchScore.Draw: 1>, id='de0c5fbdb7794d689a29df7b036a86e5-2d7b3787762f49c398b00eefa6e4ce87'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='gemini-1.5-pro-001', score=<MatchScore.A: 2>, id='ad71d3e9b48f4034bafcf5c9a3141299-0e4b355d06ec47f38eb6a5f111f12a2c'),\n",
       " Match(model_a='gemini-1.5-pro-001', model_b='gemma-2-27b-it-q8', score=<MatchScore.A: 2>, id='8b2f02efceea4303b45fdabd35023637-44a877c990a04c9da1f65acf92cfdb0d'),\n",
       " Match(model_a='llama-3.1-nemotron-70b-instruct', model_b='llama-3.1-8b', score=<MatchScore.A: 2>, id='da511efb65594e10bfd013c1f3936ab1-b2bec07ddb364b70a3588767d19e1cd3'),\n",
       " Match(model_a='mistral-small-3.1-24b', model_b='grok-3-mini-beta', score=<MatchScore.A: 2>, id='1df94f4323a14aabb36c2d260bdad7e4-223c16dd7b7443b0a1f272752ea0fb36'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='claude-3-5-sonnet-v2', score=<MatchScore.B: 0>, id='2f813b998819491fae55db4f80c6f0e4-60e9d3002e344bdea71b690ce6f1cff7'),\n",
       " Match(model_a='lfm-40b', model_b='qwen2.5-7b-instruct', score=<MatchScore.B: 0>, id='902772200c074d6e99cae4a261d5c7f1-1992632f0e0a4f378a195b52d0760f0e'),\n",
       " Match(model_a='mistral-small-3.1-24b', model_b='llama-3.1-70b', score=<MatchScore.Draw: 1>, id='89beaf7e606b431ba04c076a4a9d6ad8-a21b1b6dff9d46a1a4b05210d7c2c357'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='gemini-2.0-flash-exp', score=<MatchScore.A: 2>, id='818c726c9bee48e8a3f5f5436a43ab5f-572e85acd8234dd59d0ac16c15900874'),\n",
       " Match(model_a='gemini-2.0-flash-exp', model_b='llama-3.1-8b', score=<MatchScore.A: 2>, id='4ea24985570e4a37b893d0e17a727748-3fd027b9c6a945b1862aec6e691853ab'),\n",
       " Match(model_a='gemma-3-27b', model_b='qwq-32b', score=<MatchScore.A: 2>, id='c4b88ce97a1e4c9ba0ea90d54dab2e0f-085612ca340f4d559715b952879a98c6'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='gemini-1.5-pro-002', score=<MatchScore.A: 2>, id='c1a23361c2fd4f02976441ae497527f2-4009e3dd97874b19befe006bfe00c76a'),\n",
       " Match(model_a='chocolatine-2-14b-instruct-v2.0.3-q8', model_b='gpt-4o-2024-08-06', score=<MatchScore.B: 0>, id='8fc6b404bba8497ba14fd2ace15b1b96-dca92ca7fe2b4eedbb083dde2a859768'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.B: 0>, id='0e912715c873425a902c65deb5b46c9e-0e8c29ab997b43efbe2b357dd67ec455'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.B: 0>, id='c748a0c8f4d744f8b617f93b49089917-9f690fe472f04fd5adb9286335c63a3c'),\n",
       " Match(model_a='phi-4', model_b='gemini-1.5-pro-002', score=<MatchScore.B: 0>, id='05a1d6119a824729a5c30f468e01da37-822c340d4a9845519229c5d0209c5329'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='llama-3.3-70b', score=<MatchScore.A: 2>, id='4bb58315d60b4b72b5227ab34f5f3a3e-859fc104afdf4679851e6cf630a0fb0a'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='llama-3.3-70b', score=<MatchScore.A: 2>, id='5ce99ed6ec3949cd90222d3b58449384-239fa5daf31c4076ab6f49198425ca75'),\n",
       " Match(model_a='o3-mini', model_b='deepseek-v3-chat', score=<MatchScore.A: 2>, id='fc2ba13f28d741e08fb2f1d907265669-6a29d0d8c2584a0aa37e487dab6841e4'),\n",
       " Match(model_a='qwq-32b', model_b='deepseek-r1-distill-llama-70b', score=<MatchScore.A: 2>, id='b06a012f4aa54cbab84ce426d493a5ee-978d9cb6c1a74ec19ca167859333c238'),\n",
       " Match(model_a='llama-3.1-8b', model_b='mistral-nemo-2407', score=<MatchScore.B: 0>, id='57e50c74883c440e8ed7d956a51472c8-215cb1da83a849889e04b5b763abcd62'),\n",
       " Match(model_a='gemma-3-12b', model_b='llama-3.1-405b', score=<MatchScore.A: 2>, id='28a946cf3d0742e289f82ad376439d30-62535c2ae4c74e59b6ffa45ceca788c5'),\n",
       " Match(model_a='gemma-3-12b', model_b='lfm-40b', score=<MatchScore.A: 2>, id='4a347bda075240d983d866d5017483b6-7b129b7b593146e3bfb8e9951731fb71'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.B: 0>, id='f68473d3dcaa4d97bbfd73a478ad4e05-618023be22114604aa32d89b0f3a79a8'),\n",
       " Match(model_a='phi-4', model_b='llama-3.1-70b', score=<MatchScore.B: 0>, id='d2fdf7ad1ea64aeabd282d178f30d1df-bcec49c6ac83428ca97f442d5c7f75b0'),\n",
       " Match(model_a='deepseek-r1', model_b='o3-mini', score=<MatchScore.Draw: 1>, id='cbe546bc07ce455c913724ae1219df14-39f117e2611e4a78b9207d472bcc0e8e'),\n",
       " Match(model_a='llama-3.3-70b', model_b='llama-3.1-405b', score=<MatchScore.Draw: 1>, id='2f1189fc6ba14c7cb1713bc50edd39ba-00bb08d11a2548e68966120e4533f927'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='gemini-1.5-pro-002', score=<MatchScore.B: 0>, id='629e16a699104c26961a008563d5884f-4336f515b1cf4eab84f1de7a556b1841'),\n",
       " Match(model_a='deepseek-r1', model_b='gemini-2.0-flash-001', score=<MatchScore.B: 0>, id='06d38b0716e74b379209a682304bbc0c-f687e0da56634f4cbaa73018fa26d906'),\n",
       " Match(model_a='llama-3.1-405b', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.A: 2>, id='7cd1200406ba4ed589d84629957bface-78c6b9cf3ec54afabe4270e62e0d943a'),\n",
       " Match(model_a='llama-3.1-405b', model_b='gemma-3-12b', score=<MatchScore.Draw: 1>, id='2591da5caa6f48afab5910ae0f3aebfc-b5bef20d41674c30bae9838f41644582'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='gemini-2.0-flash-001', score=<MatchScore.B: 0>, id='55e843379a114191b98ab441aafdc464-aeef80c84eb048ee896a2c70476114a4'),\n",
       " Match(model_a='command-a', model_b='llama-3.1-nemotron-70b-instruct', score=<MatchScore.A: 2>, id='fba15a11901b479e8203847f631deae2-dc2f929266ee4966ba96f7d1d134ebc0'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='mistral-large-2411', score=<MatchScore.B: 0>, id='d8db3943b7b74b38a4149c3c23eb5387-88d8f491ebad4637a4b81b36274cee9e'),\n",
       " Match(model_a='gpt-4.1-nano', model_b='gpt-4.1-mini', score=<MatchScore.A: 2>, id='5f7fbdbb4ffc4c5b86a15a057cb7b0a3-36d75677c3b04287a526765e62ddb0db'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.Draw: 1>, id='359c4a91dba44336b0a8be041c134795-a68595d2b9a24112a5e5de4d8cf0814f'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='jamba-1.5-large', score=<MatchScore.B: 0>, id='6088a74bead5478cbd0a8c28899553d1-4e09b2c31e8e47548f222f43d12d6b3a'),\n",
       " Match(model_a='llama-3.3-70b', model_b='o3-mini', score=<MatchScore.B: 0>, id='c87379283b1a4c468ef6fd4dfc45695f-f21fedfcc7524a218b311d47813312e1'),\n",
       " Match(model_a='lfm-40b', model_b='llama-3.1-nemotron-70b-instruct', score=<MatchScore.B: 0>, id='4130b4558c35407c97493d1e0625b2d2-a8c8d0a1174e4e359194025360c97469'),\n",
       " Match(model_a='llama-3.1-70b', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.B: 0>, id='3e0652d662544afbb76d7ce5f973eb88-14b92860f7a247b68cc3aaf78167fad0'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='llama-3.1-8b', score=<MatchScore.B: 0>, id='0c35597407804e2196f654c72bd357ea-332937ff245c43ac84bdaf85f5430770'),\n",
       " Match(model_a='qwen2.5-7b-instruct', model_b='llama-3.1-70b', score=<MatchScore.A: 2>, id='e9f739a6111a4b03a6924f84b8214030-974503cf67104b9c80849b14a709ada8'),\n",
       " Match(model_a='gemma-3-27b', model_b='deepseek-r1-distill-llama-70b', score=<MatchScore.Draw: 1>, id='84a8fefea6d24301985a2a83d0eb3a2f-7bd7581aca4e48c9b70dfb82f992126e'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='gemini-1.5-pro-001', score=<MatchScore.B: 0>, id='11c90416b5cf430a961dd108776be1fb-5095d72b1fb3491487624474db78fa8e'),\n",
       " Match(model_a='mixtral-8x7b-instruct-v0.1', model_b='phi-3.5-mini-instruct', score=<MatchScore.B: 0>, id='eff11007fb024f50968f23333772b4b8-09d138e5b1aa4dcca0316aa39b3df28f'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='llama-3.1-405b', score=<MatchScore.A: 2>, id='ff4a1642662f4aae8b7171c8bc649134-fd57423f21a34f6ea11cad0350783163'),\n",
       " Match(model_a='c4ai-command-r-08-2024', model_b='deepseek-v3-chat', score=<MatchScore.A: 2>, id='f16081f6088c4b2c86c14f97ee794a06-ccd8f85473a3421585f78c323e7af8ea'),\n",
       " Match(model_a='llama-3.1-8b', model_b='gemma-2-9b-it', score=<MatchScore.A: 2>, id='ddc28b0974164be6a3b46fdbd0543dd2-fed85b8733004fd48b136bca4067f171'),\n",
       " Match(model_a='llama-3.1-70b', model_b='llama-3.1-405b', score=<MatchScore.A: 2>, id='7229cc483d3b4392b29db09eadf49a72-476078e2b92944d99e6e8865b433461c'),\n",
       " Match(model_a='gemini-2.0-flash-001', model_b='llama-3.1-70b', score=<MatchScore.A: 2>, id='84a2077bf8a746159e1805e6920f2fed-5047b969688a46c8acea3970ed4d1c1e'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='llama-3.1-8b', score=<MatchScore.Draw: 1>, id='10701169dd2e4a0a92143939375d7ad4-0675caf083cf408ca824fa3f71ad6d72'),\n",
       " Match(model_a='llama-3.1-405b', model_b='gemma-3-27b', score=<MatchScore.B: 0>, id='01e5fc941103416dbd1be7f304caf15e-34eee1967c674aa6ab8cf493dfcab802'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='mistral-large-2411', score=<MatchScore.B: 0>, id='c0a67c24437041f29c54a6860603b297-9484b6aa96c24610aca6bfbbbaaa3821'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.B: 0>, id='d269678696084f5ca9b1855e2683ec92-c7c81645c4644fb1a72821ca5efd0dc4'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='gemini-1.5-pro-002', score=<MatchScore.Draw: 1>, id='2abebecb83304c3e82191795ae13811c-6c5e1f5eca29460084012abc14411286'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='gemma-2-9b-it', score=<MatchScore.Draw: 1>, id='da4a9b37911344488a671145cca69c8e-0b8303c656ca478dbadcc72af5e61318'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='llama-3.3-70b', score=<MatchScore.Draw: 1>, id='3af2653923ec4f5d91fe00aee1b9eb13-109ada900cfc44908b419670df456197'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='mistral-large-2411', score=<MatchScore.B: 0>, id='49f08c88df6946babe57195d11567510-3fe5764d077a4fcea15152f8b81a8dca'),\n",
       " Match(model_a='lfm-40b', model_b='llama-3.1-405b', score=<MatchScore.B: 0>, id='c667aeaaddf84e9ebc332eea7d566816-ad49803c1bbb45ce961c0b34262c5d6c'),\n",
       " Match(model_a='c4ai-command-r-08-2024', model_b='llama-3.3-70b', score=<MatchScore.A: 2>, id='8be5689f41414f67b20f299f63892cb2-4b43f84ee3eb46b986482a939b21f192'),\n",
       " Match(model_a='llama-3.1-8b', model_b='phi-3.5-mini-instruct', score=<MatchScore.A: 2>, id='1750c154b8b042d8ad35d9211a1a6a35-ed8f7ce92de0406db7513ec458071eb1'),\n",
       " Match(model_a='llama-3.1-70b', model_b='gemma-3-4b', score=<MatchScore.Draw: 1>, id='f87dec799a1a4f04aa5383b3332c92b0-99fe230126e744b5983a65e65b4524c0'),\n",
       " Match(model_a='deepseek-r1-distill-llama-70b', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.A: 2>, id='412a30a0d6504a96802d4c362d3c8a82-76b0d73bf693496386f266a6804fe3e4'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.B: 0>, id='d0979e7defce4ec8a0b4f11a68804d15-6d51eefae6b140bcbe538f64ebcdaa5f'),\n",
       " Match(model_a='gpt-4.1-mini', model_b='mistral-small-3.1-24b', score=<MatchScore.Draw: 1>, id='831faae9a0004b7591d6d0100280ac3d-201f72d8a97d4c76be2a3a999a6e3da9'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='llama-3.1-405b', score=<MatchScore.A: 2>, id='3a9ad185ccd44aa3a46bae7cc3f66484-3e87483b5129493aaccfc875ae301543'),\n",
       " Match(model_a='llama-3.1-8b', model_b='command-a', score=<MatchScore.Draw: 1>, id='1da974a4e682431f80f12df3bcd44342-8cb4dc3904ae4eef883bbb5fbec5e4df'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='mistral-large-2411', score=<MatchScore.B: 0>, id='22da8d711e994e6dbafb301173cebc8f-a736f5739ba74affb60f4c69011af7c1'),\n",
       " Match(model_a='llama-3.1-8b', model_b='gemma-3-12b', score=<MatchScore.B: 0>, id='9ee97d54c1a14489b64980950591a89a-93eddb6930e448dda34daa7d077bc5d4'),\n",
       " Match(model_a='llama-3.1-70b', model_b='mistral-nemo-2407', score=<MatchScore.A: 2>, id='ec5ceb8abb7f49d08a67eb51044b52b3-fde70e09dd1741a09eafe9cbbeb3492b'),\n",
       " Match(model_a='command-a', model_b='c4ai-command-r-08-2024', score=<MatchScore.B: 0>, id='8bc0cb66d8ff4f50a650996607a5c539-ca7665dbbb4e451daf2d3ff96e505a7e'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='c4ai-command-r-08-2024', score=<MatchScore.B: 0>, id='da2fd6a0bd5849b6999a1f1c01921809-3e2cd883d4144c4c892abb8019e99f2e'),\n",
       " Match(model_a='llama-3.1-70b', model_b='gemini-2.0-flash-exp', score=<MatchScore.A: 2>, id='09d7a28e7b4747fe90fcd4579674bcc7-efce0f7b014042b68f4c7a4e75b1ff17'),\n",
       " Match(model_a='llama-3.1-8b', model_b='ministral-8b-instruct-2410', score=<MatchScore.Draw: 1>, id='055ed96321644a8f88949dd028065590-cea580408aad485690480ec1ffa90a71'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='mistral-nemo-2407', score=<MatchScore.B: 0>, id='d00996fd547d49488b1f7bcd407834e0-6526fc0658304b42a4d06a040f6a0f08'),\n",
       " Match(model_a='phi-4', model_b='llama-3.1-405b', score=<MatchScore.A: 2>, id='2a6fb832f5ab4d5a9dedeb5ee9605f67-4e020e79d83249fca37ad87022d561b5'),\n",
       " Match(model_a='mistral-small-3.1-24b', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.B: 0>, id='d094f0b4323f4466bc89d6bbd9a58ab4-e9c6f07455634217a6c11954c8ffa673'),\n",
       " Match(model_a='mistral-large-2411', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.A: 2>, id='9ab789d5a5fb4700ae22e3ec116a3ce4-256c421c4cc54322902a3434668d8b6f'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='phi-4', score=<MatchScore.B: 0>, id='3449cb9c7ac443acaca05dedca68d8c2-4671ddb6a3f845bbaaa1bd69fb53df5d'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='gemini-1.5-pro-001', score=<MatchScore.B: 0>, id='40e16e047cd249269a05050e9722508d-b4514934e0c44bc090390925eb87ab5d'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.A: 2>, id='f4af17422fbc4d9cb566e9cce56af7bb-6ae538b1cde5471c882b960bd1fe191e'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='llama-3.1-8b', score=<MatchScore.A: 2>, id='9276116991074178b37895ca4f3c3500-3a81791060764b19b32ebca146fbb82c'),\n",
       " Match(model_a='llama-3.3-70b', model_b='chocolatine-2-14b-instruct-v2.0.3-q8', score=<MatchScore.B: 0>, id='e592e844072841d79af1611539a46793-e0f3899519a447038373f91217e1dd49'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='gemma-2-9b-it', score=<MatchScore.A: 2>, id='3b5c33333d574dafa5e702cb342f1d4a-77ad9d93d4e34173beec6d5d5ddcaa17'),\n",
       " Match(model_a='gemma-3-27b', model_b='command-a', score=<MatchScore.A: 2>, id='7178a7aea816426786ac619187606aed-36a139d8a7ce4ad694a384c1870c1127'),\n",
       " Match(model_a='llama-3.1-8b', model_b='claude-3-5-sonnet-v2', score=<MatchScore.A: 2>, id='f888569655e84d47be11b0f58ce346c4-9063a1ab387944629a5b8f8ab5ddd6b2'),\n",
       " Match(model_a='qwen2.5-7b-instruct', model_b='ministral-8b-instruct-2410', score=<MatchScore.B: 0>, id='3a2069fc24bb46d08e1d3e7f4162906f-743d558aeb254830938f63ceda0321ae'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.B: 0>, id='67c6c22074a646c29bdc12f1ac7871bc-fe65cc69efe240dfb00f3cee8e978002'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='gemma-2-9b-it', score=<MatchScore.Draw: 1>, id='fd3d8c39a80e40988b8236ecc50d2429-4470545b8fb247098276b81310c534ad'),\n",
       " Match(model_a='gemini-2.0-flash-exp', model_b='mistral-nemo-2407', score=<MatchScore.A: 2>, id='fb3d36c437ee4724aa7862fed8cedd59-22f4791926d046baae448a20c5c39dfc'),\n",
       " Match(model_a='c4ai-command-r-08-2024', model_b='gemma-3-27b', score=<MatchScore.B: 0>, id='8e0eab861e7e4a50898d03e673c6bfb4-403ea4cf32e64c43ba05c48f3493dba0'),\n",
       " Match(model_a='mistral-saba', model_b='llama-3.3-70b', score=<MatchScore.B: 0>, id='a1a3bc3458c040a98077965d2be48636-0af1dabea1174160bab1ab47701571ef'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.B: 0>, id='604d9dec94ac45c5a754ad8205e612b4-66c2dd43d8b143fa87424a7521faab65'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='phi-4', score=<MatchScore.B: 0>, id='08a13c78c2a84c6ba9ebebcb2e9e079d-67d3d42dd1e941b8a6fdee00c6752398'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='claude-3-5-sonnet-v2', score=<MatchScore.B: 0>, id='9ae579ed176d40f799b10b06c615ba6d-b692c89ae753430ba6e33566f13de6a8'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='llama-3.3-70b', score=<MatchScore.A: 2>, id='bf4d8c038e5d4799bae30ee132bd226c-bccbe31e5de6462ab235f6c37aa8b248'),\n",
       " Match(model_a='lfm-40b', model_b='gemini-1.5-pro-001', score=<MatchScore.B: 0>, id='14a4f55bd7434f2f92be73c27d630a90-32f22b37957d47deaa7cc4f4217f06c6'),\n",
       " Match(model_a='llama-3.3-70b', model_b='llama-3.1-nemotron-70b-instruct', score=<MatchScore.Draw: 1>, id='400a6a95744240dbad2b4ca1764db16b-872055a45d2c41f19726a07a71da7ec2'),\n",
       " Match(model_a='mistral-small-3.1-24b', model_b='o3-mini', score=<MatchScore.Draw: 1>, id='e6caf82be7bd4bc397053b112acbca5a-01369e62f25e455583a770f24d75104c'),\n",
       " Match(model_a='phi-4', model_b='c4ai-command-r-08-2024', score=<MatchScore.Draw: 1>, id='8c2a7148ef89487d986106b6a581a86d-9a62128fea67427da50cd6b5362082c5'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='mixtral-8x7b-instruct-v0.1', score=<MatchScore.B: 0>, id='cbcef95e350e4e2b826a76d999b77c09-6eee27d1606b4518b65590ec1ff2d932'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='mistral-small-3.1-24b', score=<MatchScore.B: 0>, id='67145ac608af4bff8514dea626a03699-3057cd7248ec4cbeabc898f15c7ee439'),\n",
       " Match(model_a='llama-3.1-8b', model_b='mistral-nemo-2407', score=<MatchScore.Draw: 1>, id='a14c9b80be6a406b9b921e4f588e60eb-436d6a817e414560baf7b79a986445fd'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='gemma-2-9b-it', score=<MatchScore.B: 0>, id='57330ba2b4b34630a2547c38aba66127-0a790af5c6e04ec587ed36944fd3fafa'),\n",
       " Match(model_a='gemini-2.0-flash-exp', model_b='llama-3.1-8b', score=<MatchScore.A: 2>, id='7cacba74216444b4ad461c0eb7cf9a36-7463efd4747b4755ba772357cb84fad6'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='mixtral-8x7b-instruct-v0.1', score=<MatchScore.B: 0>, id='bd3642b6b5854b47972048d261c1aa80-3755fefecd4741f0a0a0f6c22cd0b382'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='llama-3.1-405b', score=<MatchScore.B: 0>, id='a2b84cead296400393b1622790143afa-ee7ac41c392e4238b3283cce87a8fefa'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='c4ai-command-r-08-2024', score=<MatchScore.B: 0>, id='89009d827a37462987ff0e160716b7f4-92c5e0e5ea38456981558f8c603edac7'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='claude-3-5-sonnet-v2', score=<MatchScore.A: 2>, id='ebde47a6d2c5489e9daf4ce67682e65a-fe6215f2a7fb4f45b81a81822d7d9fac'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.A: 2>, id='c13d48aecf10479493e6203d27a2e1d5-c95939005d8b4364934585e96dfc5ecb'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.Draw: 1>, id='7029a2eb2cd149caa3826b6d2ffa08f1-65828f5d66234a67a48447814d0b390b'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='gemini-2.0-flash-001', score=<MatchScore.B: 0>, id='33eef35209c24599aada67f21c8c18dd-3dcb6abb3f794d50b1563b5eea014e6e'),\n",
       " Match(model_a='llama-3.1-405b', model_b='gemma-3-12b', score=<MatchScore.B: 0>, id='ce9853bc820e4f8c872d1ec5c2c7f9e5-471a9304c3874edebf4b5856fe16315f'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='claude-3-5-sonnet-v2', score=<MatchScore.Draw: 1>, id='5714b96c00d944bc97bfb8188ba487a9-c824a5e26e3749c7ae032baa2c9491a4'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='ministral-8b-instruct-2410', score=<MatchScore.A: 2>, id='5c68b27358c04c7a80cdd88798454ce4-6d4d410a03cc468d8392836ec5bac2ba'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='ministral-8b-instruct-2410', score=<MatchScore.Draw: 1>, id='1c42fdcf56e34e7e96b66b4ca1fca3bb-0aadfd2db4e541ce8c2a8fc99d3172d5'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='gpt-4o-2024-08-06', score=<MatchScore.B: 0>, id='087cea1dc54e4c358554fa29d6fb9f2f-4abcc169ab274e69978939729e0df3bf'),\n",
       " Match(model_a='deepseek-r1', model_b='claude-3-5-sonnet-v2', score=<MatchScore.A: 2>, id='6f21931160494fcf923b0d8b843d1824-f790f966f80d46eeb8de4f580db6158e'),\n",
       " Match(model_a='mistral-large-2411', model_b='claude-3-7-sonnet', score=<MatchScore.Draw: 1>, id='1f76f0e773704cc1ae6a296d7e81a282-7bf42d929ae9419bb2dd596b4f986ab3'),\n",
       " Match(model_a='gemini-2.0-flash-001', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.A: 2>, id='f12c260ccf3f45fb8336a43c36324734-bd0e35494c3b4a5fb6baac70ff73bbfd'),\n",
       " Match(model_a='qwq-32b', model_b='command-a', score=<MatchScore.B: 0>, id='7d61ad89a49e495d92de698b6323f7ca-65acbc276468404d90dc0d507b31f4fa'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='chocolatine-2-14b-instruct-v2.0.3-q8', score=<MatchScore.A: 2>, id='ffe7bebc7acf4a8fa96c63197c4e8b68-71da449aca4a424ca15af476291104b2'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='llama-3.1-405b', score=<MatchScore.B: 0>, id='0b1c7c225f7c4a43a9854ef0957ed821-181be23f9ccb47eb9ef5224a50d6f802'),\n",
       " Match(model_a='mistral-large-2411', model_b='phi-4', score=<MatchScore.A: 2>, id='dcdf56c4c8224fe09c335da7fe5e5918-47f6b374f6e7490b804d88b259d35030'),\n",
       " Match(model_a='llama-3.1-405b', model_b='deepseek-r1', score=<MatchScore.B: 0>, id='8488d14323e9452b879cdafc36dfb9c6-3ae4620238814cc088d4c52297704220'),\n",
       " Match(model_a='gemma-3-27b', model_b='ministral-8b-instruct-2410', score=<MatchScore.A: 2>, id='3586030d1c46489cba9919644be1db14-949e5f84e0994d56bafa7421a4669a40'),\n",
       " Match(model_a='deepseek-r1', model_b='claude-3-5-sonnet-v2', score=<MatchScore.Draw: 1>, id='311af9fd1f684ab9b01953568ed333b0-e7a70fbf4fac4dc2b10ab636b709389d'),\n",
       " Match(model_a='phi-3.5-mini-instruct', model_b='gemma-2-9b-it', score=<MatchScore.B: 0>, id='7a9a86738c50475dadd2e65ad1657f03-8870b8c3f14d4ca19c811882ff65d52e'),\n",
       " Match(model_a='gemini-2.0-flash-exp', model_b='phi-4', score=<MatchScore.B: 0>, id='c36c315af46d46f2a900b82f42d3a68c-51197f648b7d4de8a333f58fcbf43a9c'),\n",
       " Match(model_a='mixtral-8x7b-instruct-v0.1', model_b='llama-3.1-405b', score=<MatchScore.B: 0>, id='b39e070f93c84b58b33d68738afb0f31-58c3d41c104b40a39ca21251ca63cc59'),\n",
       " Match(model_a='lfm-40b', model_b='gemini-1.5-pro-002', score=<MatchScore.B: 0>, id='ba8d824e100c46bcad5461034f0ed18c-b2c0777197d04e7d89b9469632e73e5a'),\n",
       " Match(model_a='gemini-2.0-flash-exp', model_b='llama-3.1-nemotron-70b-instruct', score=<MatchScore.Draw: 1>, id='646c938e3d844dc99c796b517e8d68e0-8ec15961295f4df2be97cdb2ba2b51e7'),\n",
       " Match(model_a='gemma-3-4b', model_b='chocolatine-2-14b-instruct-v2.0.3-q8', score=<MatchScore.A: 2>, id='7654d0f1e0a443f8b4e5714f37020d46-85fd8ec6ec2d48449b2336bd9bedcd6c'),\n",
       " Match(model_a='gemini-2.0-flash-exp', model_b='gemini-1.5-pro-002', score=<MatchScore.A: 2>, id='19f2da16c7234ea7950261d533715c73-8bff64c996eb45c6bb7c2233afc953a8'),\n",
       " Match(model_a='mixtral-8x7b-instruct-v0.1', model_b='gemini-1.5-pro-001', score=<MatchScore.B: 0>, id='9dc3662731914193961cb6b4c4d4abd0-026775ed71b64d88a141504aac0462af'),\n",
       " Match(model_a='llama-3.1-8b', model_b='gemini-1.5-pro-001', score=<MatchScore.A: 2>, id='cb2a2a3962e14794a5b2db94d76b6d88-c5445d112e154af3aa7d705a518e09ce'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='llama-3.1-405b', score=<MatchScore.A: 2>, id='80046c8e96ed445daf44214a044fe704-badfdff05fad440c82c8eeb888dbc0f9'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.Draw: 1>, id='c34f39ae890e4c20ae4886bed4bf0ae2-c529e0d06011492cba01bbf3fa9f7bfe'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.Draw: 1>, id='891aa230f9b04678b9c7aaa349a6cfb1-d5470a5d161c4b948a1d6b0cda354dc7'),\n",
       " Match(model_a='llama-3.3-70b', model_b='llama-3.1-nemotron-70b-instruct', score=<MatchScore.Draw: 1>, id='70669aadfc2f4a4abc6266bdde41b323-978d999bedbe4dfa82c6eb1e819ef12f'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='phi-3.5-mini-instruct', score=<MatchScore.B: 0>, id='b8a48cce84f241cbb9643f9e6faa602a-d43e9bbed5af45318401aa1c1b434453'),\n",
       " Match(model_a='llama-3.1-8b', model_b='llama-3.1-405b', score=<MatchScore.A: 2>, id='be919ac593b14a3bb9d38c03dfe0a3ff-b8b9e2935b994d709352bf7d91b4c8e7'),\n",
       " Match(model_a='llama-3.1-8b', model_b='phi-3.5-mini-instruct', score=<MatchScore.B: 0>, id='d52adcf3fc6041ba96f9c880c929777a-23d008ea0e794f09a8f0ae2e4a9247f3'),\n",
       " Match(model_a='chocolatine-2-14b-instruct-v2.0.3-q8', model_b='gemma-3-4b', score=<MatchScore.B: 0>, id='cfb0ad88866a435e96f07b2f7bc6ff3c-191d3c5249ad484b8323e5ec39efad2e'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='claude-3-5-sonnet-v2', score=<MatchScore.B: 0>, id='1c25b9f6887348c2906cc77625350cc7-6f47daf7c4a94c3c8211175d9351c15b'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='claude-3-5-sonnet-v2', score=<MatchScore.Draw: 1>, id='4c10d62a31d848a7bc39c7102de2731b-80397c8cb4864a8ba6c3177dae6c7f08'),\n",
       " Match(model_a='aya-expanse-8b', model_b='ministral-8b-instruct-2410', score=<MatchScore.A: 2>, id='b2cd1e1b701349ceb5ff8d5a79652f0d-f66e3746d5f54a9eb653b847dc5483aa'),\n",
       " Match(model_a='gemini-2.0-flash-exp', model_b='gemma-2-9b-it', score=<MatchScore.A: 2>, id='75708c10aa1f49a0bc0cf23a539e91e2-e04293de7bbc485d9935b74e878ae958'),\n",
       " Match(model_a='chocolatine-2-14b-instruct-v2.0.3-q8', model_b='claude-3-5-sonnet-v2', score=<MatchScore.B: 0>, id='9bcfa11b0c004d50a04126b22ae94b18-b63e0292b58c4b8abaea2b21b0a2d502'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='gemini-2.0-flash-exp', score=<MatchScore.B: 0>, id='4f0a3af09d694f12b85a23fc3d190e84-1cbf800911114c28b448a6a5f1c9f251'),\n",
       " Match(model_a='command-a', model_b='mistral-nemo-2407', score=<MatchScore.A: 2>, id='33f089d8b6af4a3b8170114b9bdbc4c8-5b07b11801934e3a8cbe0a935e243feb'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='mistral-nemo-2407', score=<MatchScore.A: 2>, id='b16a9c3567c24f0fbd4642fdea82ab78-559a141c954c47dbb50a19f60d9d15a2'),\n",
       " Match(model_a='o3-mini', model_b='mistral-small-3.1-24b', score=<MatchScore.B: 0>, id='3a9c148b4e9c46b39628d76885515903-44f02174123f4be799e4c644c47616d8'),\n",
       " Match(model_a='deepseek-r1', model_b='gemma-3-27b', score=<MatchScore.B: 0>, id='71a220852327405f899e589859b3f016-ba084f70954642fcb5edb1eaf6db7631'),\n",
       " Match(model_a='mistral-saba', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.A: 2>, id='f49af9241c4e47b3afafed7c11564786-dff3c10b1dc143108a39f61943a0f297'),\n",
       " Match(model_a='mistral-small-24b-instruct-2501', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.A: 2>, id='ce31eeafc25642ca91fed9130c761425-75cf3d974e03412fb1d87c1b2ca43ad4'),\n",
       " Match(model_a='deepseek-r1', model_b='claude-3-5-sonnet-v2', score=<MatchScore.B: 0>, id='022a0d20d5bd4df685cbc0e867f9c3be-9785d652829e4751923b43e147f121b0'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='c4ai-command-r-08-2024', score=<MatchScore.Draw: 1>, id='c17227d0c63746d28597c4d44262ff22-261dc084972c47dc8ddfac8337f919f1'),\n",
       " Match(model_a='phi-4', model_b='chocolatine-2-14b-instruct-v2.0.3-q8', score=<MatchScore.A: 2>, id='8d1cfd28a8e2414db4fa77e2dfdea9fc-e1d7c44fe9d94de0adfb975c3a2c4fb4'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='mixtral-8x7b-instruct-v0.1', score=<MatchScore.B: 0>, id='d3702da6192e49b889c6d398037f458d-15a67ee1bd054eacab3a48ac4b2a5cbb'),\n",
       " Match(model_a='llama-3.3-70b', model_b='deepseek-r1', score=<MatchScore.A: 2>, id='9ec056c2794746a2b9b6bb31b0149fdc-c23ae2fb7dc04306b8d0f2761cc8cfbc'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='gemma-2-9b-it', score=<MatchScore.B: 0>, id='19e4ec8ae62540ebb2d775d5ee1485c7-62910073250b4c2989f12e5f76fb4a05'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='mistral-small-3.1-24b', score=<MatchScore.Draw: 1>, id='ff75dc8919534bacbaadc8d8fa5bbfc8-02f7ad5f84a54ce78b86becffcd6ee47'),\n",
       " Match(model_a='gemma-2-27b-it-q8', model_b='ministral-8b-instruct-2410', score=<MatchScore.A: 2>, id='b0ee614a7eba42f58c77f244e912bbd5-efebcce0c08d457b971dc55c8db0dd7e'),\n",
       " Match(model_a='llama-3.1-70b', model_b='gpt-4o-2024-08-06', score=<MatchScore.B: 0>, id='ef304a44c3c04d399c65bc9d17aa8379-e42205244d2e40b7a79220aeaf069a8b'),\n",
       " Match(model_a='mistral-small-24b-instruct-2501', model_b='gemma-2-9b-it', score=<MatchScore.Draw: 1>, id='ffe5889c66eb44f2ad5425583b6dd5a4-b34a16b810684a1390f9760787beeb87'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='llama-3.1-70b', score=<MatchScore.B: 0>, id='32b2f1b82f034b50af9d693bca4d9bfe-c15fc37e0b644e3f824e64028c3fd3b0'),\n",
       " Match(model_a='gemini-1.5-pro-001', model_b='mistral-nemo-2407', score=<MatchScore.A: 2>, id='e6aa7bb302064ed1ae7c59c093cb2345-b171c754c2d048eb9ee7d1f4687344e8'),\n",
       " Match(model_a='qwen2.5-7b-instruct', model_b='mistral-nemo-2407', score=<MatchScore.B: 0>, id='a16366aff67b4ad38738cb1874e9f036-3fd1931109ca40d1bf0b31a7b1cf763e'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.A: 2>, id='6db7ee848d884eb3805f472df89b42aa-f9c1b0d43ea84021857b0362c75e174d'),\n",
       " Match(model_a='gemma-2-27b-it-q8', model_b='gemini-1.5-pro-001', score=<MatchScore.B: 0>, id='77464d785a0e43e4b1ed98bf95f28e4d-5b8398b9b9624e06bdde4b7a542b96d8'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='claude-3-5-sonnet-v2', score=<MatchScore.Draw: 1>, id='04207795b45444aca62324828d285a1d-d94acaa3de894a94b5f4d2f47d6266ce'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.Draw: 1>, id='1c66108a57d24ab286a62776684d0a8b-bc7e65289339415dae0cec1943cccc20'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='gemma-2-9b-it', score=<MatchScore.B: 0>, id='87b6745711af4283843e2cefb88385a8-fe845b1c598148e6a4a4881e26ccb39e'),\n",
       " Match(model_a='mixtral-8x7b-instruct-v0.1', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.B: 0>, id='ef89bd94494e4dbdb2454b2b88b9c117-dfc3383a0c8e49e8a46c885f2e34bc9b'),\n",
       " Match(model_a='chocolatine-2-14b-instruct-v2.0.3-q8', model_b='gemini-2.0-flash-exp', score=<MatchScore.B: 0>, id='6f3d1405ef1844a28474938cfe12c307-a510b69665ac4fbf841b211dca06738b'),\n",
       " Match(model_a='gpt-4.1-mini', model_b='phi-4', score=<MatchScore.B: 0>, id='c6b5f0426e3c45bba5683882d248aa92-2ce13088a16f468dab3f8238d702e6c9'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='gpt-4o-2024-08-06', score=<MatchScore.A: 2>, id='b1fdee5bcfa64bf784a9e90f82311ec7-92c2058af1364de081e71833a8104286'),\n",
       " Match(model_a='llama-4-scout', model_b='gemini-2.0-flash-001', score=<MatchScore.B: 0>, id='a7be0d87e1284c048c6a5b96d1603ac0-5d85490e1a574da3a56588d86d6289d2'),\n",
       " Match(model_a='mistral-small-24b-instruct-2501', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.Draw: 1>, id='c50d0049ccc141feac70c187d706c471-fc0f143f28ea438e91053a6b71a9c887'),\n",
       " Match(model_a='llama-3.3-70b', model_b='ministral-8b-instruct-2410', score=<MatchScore.A: 2>, id='f02b414c2d0c4bc1967a30ad83060eae-31703c0c477e4544acfa8f8f720fbe40'),\n",
       " Match(model_a='command-a', model_b='deepseek-v3-chat', score=<MatchScore.A: 2>, id='d76663e9081a4fec824655677cb63c1d-ad86582d7fb14ed888c80de2da2c2d57'),\n",
       " Match(model_a='mistral-large-2411', model_b='deepseek-r1', score=<MatchScore.A: 2>, id='ac6e9953f579465ab8cb4eaa17977a72-c02f435cbad94d2a82333b8c492fab8b'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.B: 0>, id='bb0c8bcfe150415faa5f9ff69da9bce5-ba652eb93f1b47b89995394eb249857d'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='mistral-nemo-2407', score=<MatchScore.B: 0>, id='0c644d052345439f9e34f37568faf816-c2e60b3874c9437d9a1ced9e58ac7d5c'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='c4ai-command-r-08-2024', score=<MatchScore.B: 0>, id='1d1fd787e2a04368b7a0c9a8128cffd4-f6478b7a5a3944b78a33ee1e9a4d9f1a'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='gemma-2-9b-it', score=<MatchScore.A: 2>, id='46c16c956cb342d8ac3acc1c043866bf-db146acecc8749ff9e34c1ca7f0f1bc8'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='deepseek-v3-chat', score=<MatchScore.B: 0>, id='98aa794d15e0453cae4ea240fdd8319f-54ee161efb6d46de8b472abc41498229'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.A: 2>, id='b096e41b91f44cef9cc1a562f08c5781-5a03feac7f3c4986aff75f128f2afbb0'),\n",
       " Match(model_a='llama-3.1-nemotron-70b-instruct', model_b='ministral-8b-instruct-2410', score=<MatchScore.A: 2>, id='3dcc2bb3df8e4dce833b312bcd573fc8-7f157610bb0647d1b6a7e341f6d8a6cb'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='ministral-8b-instruct-2410', score=<MatchScore.A: 2>, id='03cafa3cc944410a9b65009fa9125e21-0f3ee9a5a5574c78a707b15e20bfa472'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='qwen2.5-7b-instruct', score=<MatchScore.B: 0>, id='199eaa9258a04ec8bf3cda83cb454015-b2b293b48d7f47b4b6236d4a9bd46be8'),\n",
       " Match(model_a='gemini-2.0-flash-001', model_b='llama-3.1-405b', score=<MatchScore.A: 2>, id='fefeb619d76641a9ab764aa361d4bccf-f94caaebed0b4173b7f3599880592617'),\n",
       " Match(model_a='lfm-40b', model_b='c4ai-command-r-08-2024', score=<MatchScore.Draw: 1>, id='472646ec10224253aded87c860323f48-f713f461e2144ee4aec440f34f638743'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='llama-3.1-70b', score=<MatchScore.B: 0>, id='d4fa72bc2e23470fb287c2968ad975b4-c64906b0a1b440d792b77382751a1d38'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='gemini-1.5-pro-002', score=<MatchScore.A: 2>, id='940715b00a064d7a84a21de8c67ec802-6fe172df38574ea892bd45722dc554ca'),\n",
       " Match(model_a='llama-3.1-8b', model_b='ministral-8b-instruct-2410', score=<MatchScore.A: 2>, id='4bf7650b3fdb4a7dada6e9c07a68fbe7-0ec95ee05c0642469fd59161c78b0074'),\n",
       " Match(model_a='phi-4', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.A: 2>, id='90ae0384e1b343daad527779641d6838-b6ea0e47bc8e43d9a1871927a1c36d73'),\n",
       " Match(model_a='llama-3.1-405b', model_b='llama-3.1-70b', score=<MatchScore.B: 0>, id='315245d700054d3680fc4c09a059e735-3d1673041fa7443fa83de2eaf5cb4450'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='llama-3.1-8b', score=<MatchScore.Draw: 1>, id='e3f5065323fc40b2a6b2acc87c397aca-ad8ef55559c34d90b753ace05ed915ef'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='llama-3.1-70b', score=<MatchScore.A: 2>, id='44732ec492a34b5e88b155cb61be6c2a-6711406fab7e4729b5e237e8510abf8d'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='gpt-4o-2024-08-06', score=<MatchScore.B: 0>, id='7915ed801b464043a57b95fb56e57e0d-49eaffaaae764de2abcee708447c19b4'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='gpt-4o-2024-08-06', score=<MatchScore.A: 2>, id='62a54be216da485a97c8a5cbacad9742-8b82dacefe2a488fa563b49c7330de39'),\n",
       " Match(model_a='llama-3.1-70b', model_b='mixtral-8x22b-instruct-v0.1', score=<MatchScore.B: 0>, id='998709c3193f4526af2e658b61ec01c5-c369fcb131494c2eb563a8dba2495fa3'),\n",
       " Match(model_a='mistral-large-2411', model_b='phi-4', score=<MatchScore.A: 2>, id='1bc96ffc2244422f8c8b048c67c6fa69-de99dbb8aecd40ef96050e6dbcb8e331'),\n",
       " Match(model_a='llama-3.1-405b', model_b='gemma-2-9b-it', score=<MatchScore.A: 2>, id='76f3639ebb0e484393ef6b55251724b8-5c9941e387334c6f9185ed210e9d7617'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='lfm-40b', score=<MatchScore.Draw: 1>, id='c209bc74aabd4d72b5464603776f48ff-1da49dd132d049e3beb1065de62a1317'),\n",
       " Match(model_a='claude-3-7-sonnet', model_b='llama-3.1-405b', score=<MatchScore.B: 0>, id='ebd11cbf282b4b88864b95c092ff129d-a9beaf830a594ecfa3e4514d35d0692a'),\n",
       " Match(model_a='llama-3.3-70b', model_b='llama-3.1-8b', score=<MatchScore.A: 2>, id='79035eb6eb96426b9a9a8872d8e4a5f4-de3075606e7942d08b79da7ac2f8b57b'),\n",
       " Match(model_a='deepseek-r1', model_b='deepseek-r1-distill-llama-70b', score=<MatchScore.A: 2>, id='425564c099d84348b17365ca4a8032bc-25ba6f8ff45442478724a287e56b4796'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='mistral-nemo-2407', score=<MatchScore.A: 2>, id='165c2f4158de48b79d54b7c74475468b-9bbe7f22a66349d1b3904ada0d1e919d'),\n",
       " Match(model_a='chocolatine-2-14b-instruct-v2.0.3-q8', model_b='deepseek-v3-chat', score=<MatchScore.Draw: 1>, id='a363e9448ede45f790ba64e08f4fa34b-a5cf4747eb0140be826dbb264ced3b5f'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='mistral-large-2411', score=<MatchScore.A: 2>, id='6aaf2d68536d45109a985f5749157e5a-8c2bda2a24cd48529528d1fdb9507d6f'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='gemini-2.0-flash-exp', score=<MatchScore.B: 0>, id='0c3c68d844f34b2fa9a6cf529d974edb-bb17624aea6b496b95df4e451bad0e7e'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.A: 2>, id='6931d04ba46841918c631fd758f379b1-623f9cb79675471594d0635a7ce1c362'),\n",
       " Match(model_a='gemma-3-27b', model_b='deepseek-r1', score=<MatchScore.Draw: 1>, id='391bba8dc1e648718b274876ed508b5b-b0adade45df144dfbeaf1ec63cc819c3'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='gemini-2.0-flash-exp', score=<MatchScore.B: 0>, id='36484b8573b04a5fb1ea9f5ae1d90aa1-6433de92994a415f90ec2fe0e41ac668'),\n",
       " Match(model_a='llama-3.3-70b', model_b='mistral-large-2411', score=<MatchScore.B: 0>, id='d53ef1b6649a49aeb67f1609b443f1ee-25be5622e0ef43aaae904d2f43289c13'),\n",
       " Match(model_a='gemini-2.0-flash-001', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.A: 2>, id='86663c2190a7431a8cc19f8de686970a-9bb1b74a2a064ba58d8210687a721711'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='mistral-large-2411', score=<MatchScore.Draw: 1>, id='94ffcbeaf8744c26a395b3d3136c0b21-99cff4624d9c4c8ea464428db1606877'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='claude-3-5-sonnet-v2', score=<MatchScore.A: 2>, id='86b5b74bf77a49c28fd31a50a57dbfdf-8f81b320b66b4f079b4a3b765aa1dea0'),\n",
       " Match(model_a='mistral-large-2411', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.Draw: 1>, id='c9e14c94a3344fc3a51334a66d02a3f6-03369b3949294bbc897a28e9b61b4a67'),\n",
       " Match(model_a='gemma-3-12b', model_b='deepseek-r1', score=<MatchScore.A: 2>, id='80c4c8ccf251459c9a6d3aab1bc1c46e-fdc143d3e4774666bba4c95a015686d1'),\n",
       " Match(model_a='llama-3.1-70b', model_b='phi-3.5-mini-instruct', score=<MatchScore.A: 2>, id='8017dc0079754bc1b7f2ce8c89aa31e8-8cbb82486f1e40cebac3dfe02d18e996'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='llama-3.1-405b', score=<MatchScore.A: 2>, id='7e721cf1091e42799efd474dd72f9960-ef255c9b7d064f91a266e834d997d5e0'),\n",
       " Match(model_a='gemma-3-27b', model_b='llama-3.3-70b', score=<MatchScore.A: 2>, id='eae96a54267b43518c427fe92fabe2cd-252c7f2f323d42d0abc65079f809b240'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='llama-3.1-8b', score=<MatchScore.Draw: 1>, id='ee466698e7d049bf89591717c938c8b8-8d0e50d134554a2fa46294cda49a08c9'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='gemini-2.0-flash-001', score=<MatchScore.B: 0>, id='91b508c1cc9745c69c4323075a0dfba4-7ac5a019358b4dbcab4e444902a2279c'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.Draw: 1>, id='714c72d3548f4e2393550da21e1b05f4-7ab96911beb74e9aa12c069c273fba34'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='llama-3.3-70b', score=<MatchScore.Draw: 1>, id='a6c6ec5dd525483092678c25c595313e-0a0b4856e1e54fc1b3cc31b1339f84cb'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='llama-3.1-405b', score=<MatchScore.A: 2>, id='6fc08312cf004f45a9c5d91c6399e4ed-58b799c8a9434f22b617443a33cdd114'),\n",
       " Match(model_a='gemini-1.5-pro-001', model_b='llama-3.1-8b', score=<MatchScore.A: 2>, id='4e44177e6d104223818c279ff025bc9d-d0c4c6f35bc54aa6bc5a0075f37a81ca'),\n",
       " Match(model_a='gpt-4o-2024-08-06', model_b='mistral-nemo-2407', score=<MatchScore.Draw: 1>, id='1e3a8d070dab4ac0b413ba2cd6387a5f-03219aee6cec4cd99b4a5b8c0207f198'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='gpt-4o-2024-08-06', score=<MatchScore.Draw: 1>, id='0dc3fc0150e845ce88c8051e4f60b830-6ebe462072f44559987ac5aa0b2b5ca9'),\n",
       " Match(model_a='c4ai-command-r-08-2024', model_b='o3-mini', score=<MatchScore.B: 0>, id='2a524c2085d3416e92f11794eae694f8-1acb9231cae2486a8a147b84a7c65fd6'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='gemini-2.0-flash-exp', score=<MatchScore.B: 0>, id='563c033d49bd4700a0533f441c08fa2f-dee6a7988e4948be923608244a4e5d2a'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='gemini-2.0-flash-001', score=<MatchScore.Draw: 1>, id='d1cce74e15624d67bd7bb1482da8e160-6d3c962dcbbd486b9eb1c327f3aa7d4c'),\n",
       " Match(model_a='llama-3.1-70b', model_b='mistral-large-2411', score=<MatchScore.B: 0>, id='c924f25ce16847c48e7e6fd66ec6462b-8efe3223136a40b7a4e47682531290f8'),\n",
       " Match(model_a='phi-4', model_b='gemma-2-9b-it', score=<MatchScore.Draw: 1>, id='0c6714486bb245009c94be5a9081967b-eb30a1c629ef49d0949faae75a757a7a'),\n",
       " Match(model_a='gemini-1.5-pro-002', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.A: 2>, id='8de44a42ecf14bcd819f23c1f72dbfb4-b90b938615ed4aeb9e5ada9e1f6e651f'),\n",
       " Match(model_a='mistral-nemo-2407', model_b='gemini-1.5-pro-001', score=<MatchScore.B: 0>, id='deaa44f4b0a744b9ac587352c5afa420-5cae848ccd9b4846a2738343d6400493'),\n",
       " Match(model_a='gemma-2-9b-it', model_b='gemini-1.5-pro-001', score=<MatchScore.A: 2>, id='6061834c6c0c416e8318c023c3f35bb1-01f37d3a256e429daef653dda38d906d'),\n",
       " Match(model_a='llama-3.3-70b', model_b='qwen2.5-coder-32b-instruct', score=<MatchScore.A: 2>, id='c725f6140c9d4ca786b0732e44564217-eb0c059dc07440e2ae4f670af623cba6'),\n",
       " Match(model_a='phi-3.5-mini-instruct', model_b='mistral-nemo-2407', score=<MatchScore.B: 0>, id='abc1b8127dd2458b9848b9308a21f3a2-da7fe0498ed04ed4b4f72414d03fef0b'),\n",
       " Match(model_a='c4ai-command-r-08-2024', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.A: 2>, id='ef977a5eeff74337afb21277ae02554e-b08706a0a40a43f4b9d12ec658f51ac8'),\n",
       " Match(model_a='gemma-3-4b', model_b='mistral-large-2411', score=<MatchScore.Draw: 1>, id='82c5ddf1d10646b689831d5e16f04644-1d44d59dd60b44b6a6d54619cbaf0f0b'),\n",
       " Match(model_a='deepseek-v3-chat', model_b='c4ai-command-r-08-2024', score=<MatchScore.A: 2>, id='3f5f9c018730435091046f9867a6de0d-b642d92055e24a20942795ddfe37db01'),\n",
       " Match(model_a='mistral-small-24b-instruct-2501', model_b='gemini-1.5-pro-002', score=<MatchScore.B: 0>, id='5faf61cda7ba4f088f4ed2fea0f7d13b-f2a736fbfb8444d8b6b59c090ad120c4'),\n",
       " Match(model_a='phi-3.5-mini-instruct', model_b='mistral-nemo-2407', score=<MatchScore.A: 2>, id='58ce523528784be0adf796d4ae203bbf-5f985365f12841bc94b03600d6895fd7'),\n",
       " Match(model_a='deepseek-r1', model_b='o3-mini', score=<MatchScore.Draw: 1>, id='bd987f7be30b48bca1bd98c40e89462e-6be173ffdd7f467db71acc93298c0db3'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='llama-3.1-70b', score=<MatchScore.B: 0>, id='1ee1635f062b420aad9c0e8b067cff0a-3503689587c943a3866c1cce02afb3fd'),\n",
       " Match(model_a='llama-3.1-8b', model_b='mistral-nemo-2407', score=<MatchScore.A: 2>, id='236740e7af8440fd86456d278d3f78e8-48210a95357f4b6ea04276ce4ed3c314'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='llama-3.1-nemotron-70b-instruct', score=<MatchScore.Draw: 1>, id='cd0bbbd2e56841cea434485fb878a1fa-bc2c37c210624dd18be5c2bd762df6c4'),\n",
       " Match(model_a='gpt-4.1-nano', model_b='gemini-2.0-flash-001', score=<MatchScore.B: 0>, id='be6022db3289484182a050f50d22bbb2-0830e089f30940a8b252083bdb07b33d'),\n",
       " Match(model_a='mistral-small-3.1-24b', model_b='llama-4-scout', score=<MatchScore.Draw: 1>, id='ae4e79fd10ae4586b03f15b6abea9456-50d75779d74d49d19fedb4eaae05398c'),\n",
       " Match(model_a='mistral-small-3.1-24b', model_b='gemma-3-27b', score=<MatchScore.A: 2>, id='579447df0f3746058b37d89dd9e7a26b-af22705e93554dc2bbbf6a5e910034ea'),\n",
       " Match(model_a='gemini-2.0-flash-001', model_b='hermes-3-llama-3.1-405b', score=<MatchScore.A: 2>, id='f23d52ed652743a0b0bf6b45589acb8c-60a6adf8b040453e8753e2a2db0db4e9'),\n",
       " Match(model_a='ministral-8b-instruct-2410', model_b='gemma-3-27b', score=<MatchScore.B: 0>, id='357decbd248f4dc98fb2736e0d9c7307-6fb6241d66b640648c1ddd55aa5bbfb3'),\n",
       " Match(model_a='mistral-small-24b-instruct-2501', model_b='command-a', score=<MatchScore.B: 0>, id='60873bef62fb4a619df6aeb196c41472-494953861e4f4309a817a9ffbf0c8e09'),\n",
       " Match(model_a='llama-3.1-70b', model_b='lfm-40b', score=<MatchScore.B: 0>, id='37bda10125dc4af2b9cf3915a7451dbd-8925d68797f34dedbc3c85304220ce1e'),\n",
       " Match(model_a='llama-3.3-70b', model_b='mistral-large-2411', score=<MatchScore.B: 0>, id='5d4212eaa5b74715ae0b4c3c3a81b0bc-c7b1b9a21e9342c49dd0c81b96d99e53'),\n",
       " Match(model_a='gemma-3-12b', model_b='llama-3.1-nemotron-70b-instruct', score=<MatchScore.B: 0>, id='1c4ec65f23594fa987cad59a59bf38b4-03f40021fdff4c25b463d0d680a7426b'),\n",
       " Match(model_a='gemini-2.0-flash-001', model_b='mistral-saba', score=<MatchScore.A: 2>, id='0c7e61869389490da2df48ba7f55b454-a2c2eaf9400743dd9afa7c7c1b473051'),\n",
       " Match(model_a='mistral-small-3.1-24b', model_b='command-a', score=<MatchScore.B: 0>, id='1e5252643435479e8184dddb102d88db-df4656085ebf446e94692e97778918bd'),\n",
       " Match(model_a='phi-4', model_b='aya-expanse-8b', score=<MatchScore.A: 2>, id='ef74545141a44627b6d4b043e400d1e3-f079c48a255b48ccaab30dafb5bc6632'),\n",
       " Match(model_a='phi-4', model_b='mistral-large-2411', score=<MatchScore.B: 0>, id='17073ac7dfb0469e9843b622997e5d93-aa18fb2aeb5e4944bbab4f62b422a13c'),\n",
       " Match(model_a='hermes-3-llama-3.1-405b', model_b='llama-3.1-nemotron-70b-instruct', score=<MatchScore.A: 2>, id='36a257573ef5466f8f3b9de129161563-ec27537c8a934c7a9b943613e4cf6609'),\n",
       " Match(model_a='llama-3.1-405b', model_b='mixtral-8x7b-instruct-v0.1', score=<MatchScore.A: 2>, id='e66e5e78483e4009900b4f647e7413bc-3b21128d2fef4d929cbd9e20ed93d2a5'),\n",
       " Match(model_a='mistral-small-3.1-24b', model_b='llama-3.3-70b', score=<MatchScore.Draw: 1>, id='09d419058b514a6485ad36835af958a5-d20753bec88c4fb2bd818cbac53c7350'),\n",
       " Match(model_a='c4ai-command-r-08-2024', model_b='mistral-small-3.1-24b', score=<MatchScore.B: 0>, id='829b818814ec43219429c82a70bcaaf3-1a50dd87c8a249e3b82ab9aa0cfd8757'),\n",
       " Match(model_a='lfm-40b', model_b='mistral-small-24b-instruct-2501', score=<MatchScore.B: 0>, id='0a70e58d7ed74b629b51c5db08abc1c3-c0d2bc44809349d28ee4be6d7434269a'),\n",
       " Match(model_a='deepseek-r1-distill-llama-70b', model_b='mistral-small-3.1-24b', score=<MatchScore.Draw: 1>, id='31bf0ee48c2f4cafbaaa8c9d74381222-a7bb72090f0f4081ae28a1bbfb7fa414'),\n",
       " Match(model_a='gemini-1.5-pro-001', model_b='llama-3.1-8b', score=<MatchScore.A: 2>, id='834b645b45c64b2db37066ab0d43b645-b0642cc384434094baeebb3e4e0eb39b'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='gemini-2.0-flash-001', score=<MatchScore.A: 2>, id='e1223fed29584e09abb2cab61ac20631-52dea715449f4e23a0bdf87133e62f9e'),\n",
       " Match(model_a='gemini-1.5-pro-001', model_b='phi-3.5-mini-instruct', score=<MatchScore.A: 2>, id='7b07766bd7754445b0d4af018f0f76f8-2e6769c98e164c90a58df3d0afe8f4ca'),\n",
       " Match(model_a='gemini-2.0-flash-001', model_b='gemini-1.5-pro-002', score=<MatchScore.A: 2>, id='e3dc05b2648a4a1d8734a78d20560a62-26d9cab807cc442ebbeb9cbafef4e40c'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='gemma-2-9b-it', score=<MatchScore.B: 0>, id='a82745fdba7b418ab78e49c34361c8db-e83d757a6ba041aa9f0f83599ebbf627'),\n",
       " Match(model_a='claude-3-7-sonnet', model_b='command-a', score=<MatchScore.Draw: 1>, id='133b58f9001d4d8da93441a39707e228-be540d6c53184a5eb07ea8e302f24510'),\n",
       " Match(model_a='gemini-1.5-pro-001', model_b='mixtral-8x7b-instruct-v0.1', score=<MatchScore.A: 2>, id='c20334a9de124a4fa6e4085df9e019fa-37e0a1d664174996b9c3c2c1f8866a82'),\n",
       " Match(model_a='claude-3-5-sonnet-v2', model_b='gpt-4o-2024-08-06', score=<MatchScore.A: 2>, id='d305fe9cd4694964b9a82a7acbb6dfe0-d77d73ff35084c6589e312c124b132c8'),\n",
       " Match(model_a='llama-3.1-8b', model_b='gemini-2.0-flash-001', score=<MatchScore.B: 0>, id='17fac43a89b342b6bd089a9080471c5f-89ea8ad48866488e949a7cb3246c0154'),\n",
       " Match(model_a='gemma-3-12b', model_b='llama-3.1-8b', score=<MatchScore.Draw: 1>, id='c37596425c284d5aae3aebce05b1ca0d-613c95ca900b4358b94ff05433a72dec'),\n",
       " Match(model_a='mixtral-8x22b-instruct-v0.1', model_b='llama-3.1-70b', score=<MatchScore.B: 0>, id='9d7bf0846f344855bffa2e3c1fcd3285-aa395b7e3f4545e3afeac75f8b557600'),\n",
       " Match(model_a='phi-4', model_b='gpt-4.1-mini', score=<MatchScore.A: 2>, id='e8ef589959444599a76ca1957b87d25b-db669f6025804cfdadf1edefcf48158d'),\n",
       " Match(model_a='llama-3.1-70b', model_b='gemini-1.5-pro-001', score=<MatchScore.B: 0>, id='77650d6534ff4af6bb9f30d72a5474df-3c3a395265e547179a2e39cbcad3b7d4'),\n",
       " Match(model_a='phi-4', model_b='mixtral-8x7b-instruct-v0.1', score=<MatchScore.Draw: 1>, id='f462db1cdda14795b934946e94a33f4e-e45f24d7f6ea464db5f81da68370a8f5'),\n",
       " Match(model_a='mistral-large-2411', model_b='gpt-4o-2024-08-06', score=<MatchScore.Draw: 1>, id='db1b2b7afbca4614af0f5456244b5da5-68b52eadf0494a8591822c41ba3072e2'),\n",
       " Match(model_a='mistral-small-3.1-24b', model_b='gpt-4o-mini-2024-07-18', score=<MatchScore.Draw: 1>, id='11439058402e43d9997980a3f642dbe3-62d7f8182b9e42c9a7470251b84598ee'),\n",
       " Match(model_a='qwen2.5-coder-32b-instruct', model_b='mistral-nemo-2407', score=<MatchScore.Draw: 1>, id='2895a9ee8ca24403a7a5a81acb8f676c-0275d1444c6149c3a3c4c5de86bc7330'),\n",
       " Match(model_a='gemini-2.0-flash-001', model_b='llama-4-scout', score=<MatchScore.Draw: 1>, id='0b8ffa0d166e4460ae854055181e81d6-3b43515519f9422e8dd67db10eba31cc'),\n",
       " Match(model_a='gpt-4o-mini-2024-07-18', model_b='phi-3.5-mini-instruct', score=<MatchScore.A: 2>, id='b99a87b3816c4eb181ec3b1cb157a603-bb4aebe3c7b542f49045e71e44defb04'),\n",
       " Match(model_a='llama-3.1-70b', model_b='llama-3.3-70b', score=<MatchScore.A: 2>, id='e16760f67ab14960b80e323eabb3e19c-39f2324b73c9436a9fb96af247bd7388'),\n",
       " Match(model_a='mistral-large-2411', model_b='gemini-2.0-flash-exp', score=<MatchScore.B: 0>, id='c6becd1666f14742bac13cba5876c6e0-dc1ab19ba0374de995905d9df1f08d3c'),\n",
       " ...]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.match_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1574044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing bootstrap scores from a sample of 76861 matches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing bootstrap samples: 100%|██████████| 5/5 [00:00<00:00,  5.70it/s]\n"
     ]
    }
   ],
   "source": [
    "scores = pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bcac115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (52, 9)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model_name</th><th>median</th><th>p2.5</th><th>p97.5</th><th>total_output_tokens</th><th>conso_all_conv</th><th>n_match</th><th>mean_conso_per_match</th><th>mean_conso_per_token</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>u32</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;Yi-1.5-9B-Chat&quot;</td><td>788.44272</td><td>773.710339</td><td>860.997884</td><td>47531.0</td><td>0.182743</td><td>65</td><td>0.002811</td><td>0.000004</td></tr><tr><td>&quot;aya-expanse-8b&quot;</td><td>1000.68942</td><td>939.692118</td><td>1081.730745</td><td>1.05781e6</td><td>3.98568</td><td>1302</td><td>0.003061</td><td>0.000004</td></tr><tr><td>&quot;c4ai-command-r-08-2024&quot;</td><td>923.687526</td><td>882.29904</td><td>991.157838</td><td>2.747666e6</td><td>20.763975</td><td>3598</td><td>0.005771</td><td>0.000008</td></tr><tr><td>&quot;chocolatine-14b-instruct-dpo-v…</td><td>769.806287</td><td>743.103763</td><td>796.193166</td><td>131187.0</td><td>0.602249</td><td>309</td><td>0.001949</td><td>0.000005</td></tr><tr><td>&quot;chocolatine-2-14b-instruct-v2.…</td><td>810.537544</td><td>742.694296</td><td>867.813721</td><td>533384.0</td><td>1.934863</td><td>1796</td><td>0.001077</td><td>0.000004</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;qwen2-7b-instruct&quot;</td><td>793.96601</td><td>716.713321</td><td>864.338403</td><td>43550.0</td><td>0.153078</td><td>80</td><td>0.001913</td><td>0.000004</td></tr><tr><td>&quot;qwen2.5-32b-instruct&quot;</td><td>984.43552</td><td>956.114822</td><td>1082.716717</td><td>75812.0</td><td>0.531085</td><td>142</td><td>0.00374</td><td>0.000007</td></tr><tr><td>&quot;qwen2.5-7b-instruct&quot;</td><td>954.56483</td><td>884.771634</td><td>989.927913</td><td>1.186919e6</td><td>4.305576</td><td>1420</td><td>0.003032</td><td>0.000004</td></tr><tr><td>&quot;qwen2.5-coder-32b-instruct&quot;</td><td>989.596408</td><td>889.646566</td><td>1096.73325</td><td>4.0819e6</td><td>29.128193</td><td>4954</td><td>0.00588</td><td>0.000007</td></tr><tr><td>&quot;qwq-32b&quot;</td><td>932.448506</td><td>880.345535</td><td>998.8053</td><td>1.757717e6</td><td>12.542963</td><td>1479</td><td>0.008481</td><td>0.000007</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (52, 9)\n",
       "┌────────────┬───────────┬───────────┬───────────┬───┬───────────┬─────────┬───────────┬───────────┐\n",
       "│ model_name ┆ median    ┆ p2.5      ┆ p97.5     ┆ … ┆ conso_all ┆ n_match ┆ mean_cons ┆ mean_cons │\n",
       "│ ---        ┆ ---       ┆ ---       ┆ ---       ┆   ┆ _conv     ┆ ---     ┆ o_per_mat ┆ o_per_tok │\n",
       "│ str        ┆ f64       ┆ f64       ┆ f64       ┆   ┆ ---       ┆ u32     ┆ ch        ┆ en        │\n",
       "│            ┆           ┆           ┆           ┆   ┆ f64       ┆         ┆ ---       ┆ ---       │\n",
       "│            ┆           ┆           ┆           ┆   ┆           ┆         ┆ f64       ┆ f64       │\n",
       "╞════════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═════════╪═══════════╪═══════════╡\n",
       "│ Yi-1.5-9B- ┆ 788.44272 ┆ 773.71033 ┆ 860.99788 ┆ … ┆ 0.182743  ┆ 65      ┆ 0.002811  ┆ 0.000004  │\n",
       "│ Chat       ┆           ┆ 9         ┆ 4         ┆   ┆           ┆         ┆           ┆           │\n",
       "│ aya-expans ┆ 1000.6894 ┆ 939.69211 ┆ 1081.7307 ┆ … ┆ 3.98568   ┆ 1302    ┆ 0.003061  ┆ 0.000004  │\n",
       "│ e-8b       ┆ 2         ┆ 8         ┆ 45        ┆   ┆           ┆         ┆           ┆           │\n",
       "│ c4ai-comma ┆ 923.68752 ┆ 882.29904 ┆ 991.15783 ┆ … ┆ 20.763975 ┆ 3598    ┆ 0.005771  ┆ 0.000008  │\n",
       "│ nd-r-08-20 ┆ 6         ┆           ┆ 8         ┆   ┆           ┆         ┆           ┆           │\n",
       "│ 24         ┆           ┆           ┆           ┆   ┆           ┆         ┆           ┆           │\n",
       "│ chocolatin ┆ 769.80628 ┆ 743.10376 ┆ 796.19316 ┆ … ┆ 0.602249  ┆ 309     ┆ 0.001949  ┆ 0.000005  │\n",
       "│ e-14b-inst ┆ 7         ┆ 3         ┆ 6         ┆   ┆           ┆         ┆           ┆           │\n",
       "│ ruct-dpo-v ┆           ┆           ┆           ┆   ┆           ┆         ┆           ┆           │\n",
       "│ …          ┆           ┆           ┆           ┆   ┆           ┆         ┆           ┆           │\n",
       "│ chocolatin ┆ 810.53754 ┆ 742.69429 ┆ 867.81372 ┆ … ┆ 1.934863  ┆ 1796    ┆ 0.001077  ┆ 0.000004  │\n",
       "│ e-2-14b-in ┆ 4         ┆ 6         ┆ 1         ┆   ┆           ┆         ┆           ┆           │\n",
       "│ struct-v2. ┆           ┆           ┆           ┆   ┆           ┆         ┆           ┆           │\n",
       "│ …          ┆           ┆           ┆           ┆   ┆           ┆         ┆           ┆           │\n",
       "│ …          ┆ …         ┆ …         ┆ …         ┆ … ┆ …         ┆ …       ┆ …         ┆ …         │\n",
       "│ qwen2-7b-i ┆ 793.96601 ┆ 716.71332 ┆ 864.33840 ┆ … ┆ 0.153078  ┆ 80      ┆ 0.001913  ┆ 0.000004  │\n",
       "│ nstruct    ┆           ┆ 1         ┆ 3         ┆   ┆           ┆         ┆           ┆           │\n",
       "│ qwen2.5-32 ┆ 984.43552 ┆ 956.11482 ┆ 1082.7167 ┆ … ┆ 0.531085  ┆ 142     ┆ 0.00374   ┆ 0.000007  │\n",
       "│ b-instruct ┆           ┆ 2         ┆ 17        ┆   ┆           ┆         ┆           ┆           │\n",
       "│ qwen2.5-7b ┆ 954.56483 ┆ 884.77163 ┆ 989.92791 ┆ … ┆ 4.305576  ┆ 1420    ┆ 0.003032  ┆ 0.000004  │\n",
       "│ -instruct  ┆           ┆ 4         ┆ 3         ┆   ┆           ┆         ┆           ┆           │\n",
       "│ qwen2.5-co ┆ 989.59640 ┆ 889.64656 ┆ 1096.7332 ┆ … ┆ 29.128193 ┆ 4954    ┆ 0.00588   ┆ 0.000007  │\n",
       "│ der-32b-in ┆ 8         ┆ 6         ┆ 5         ┆   ┆           ┆         ┆           ┆           │\n",
       "│ struct     ┆           ┆           ┆           ┆   ┆           ┆         ┆           ┆           │\n",
       "│ qwq-32b    ┆ 932.44850 ┆ 880.34553 ┆ 998.8053  ┆ … ┆ 12.542963 ┆ 1479    ┆ 0.008481  ┆ 0.000007  │\n",
       "│            ┆ 6         ┆ 5         ┆           ┆   ┆           ┆         ┆           ┆           │\n",
       "└────────────┴───────────┴───────────┴───────────┴───┴───────────┴─────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140dac27",
   "metadata": {},
   "source": [
    "### Une autre méthode de calcul \n",
    "\n",
    "Ici on utilise uniquement les données de votes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e971e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since ministere-culture/comparia-reactions couldn't be found on the Hugging Face Hub (offline mode is enabled).\n",
      "Found the latest cached dataset configuration 'default' at /home/jupyterhub-users/shared/projet_comparia/huggingface_hub/ministere-culture___comparia-reactions/default/0.0.0/80befa851337d9f295096cef3d100b40d220dc07 (last modified on Mon Jul 28 10:06:54 2025).\n",
      "Using the latest cached version of the dataset since ministere-culture/comparia-conversations couldn't be found on the Hugging Face Hub (offline mode is enabled).\n",
      "Found the latest cached dataset configuration 'default' at /home/jupyterhub-users/shared/projet_comparia/huggingface_hub/ministere-culture___comparia-conversations/default/0.0.0/dc40af6af1c14e68bf39d55f6e1573d2d6582f19 (last modified on Wed Jun  4 17:40:30 2025).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reactions data originally contains 22993 conversations pairs.\n",
      "Final reactions dataset contains 21244 conversations pairs.\n",
      "Computing bootstrap scores from a sample of 21244 matches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing bootstrap samples: 100%|██████████| 5/5 [00:00<00:00, 24.87it/s]\n"
     ]
    }
   ],
   "source": [
    "pipeline = RankingPipeline(\n",
    "    method=\"elo_random\",\n",
    "    include_votes=False,\n",
    "    include_reactions=True,\n",
    "    bootstrap_samples=5,\n",
    "    mean_how=\"token\",\n",
    "    export_path=None,  # Path(\"output\"),\n",
    ")\n",
    "scores_votes = pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c91a29d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (48, 9)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model_name</th><th>median</th><th>p2.5</th><th>p97.5</th><th>total_output_tokens</th><th>conso_all_conv</th><th>n_match</th><th>mean_conso_per_match</th><th>mean_conso_per_token</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>u32</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;aya-expanse-8b&quot;</td><td>1019.477569</td><td>949.836442</td><td>1040.227478</td><td>327851.0</td><td>1.235297</td><td>467</td><td>0.002645</td><td>0.000004</td></tr><tr><td>&quot;c4ai-command-r-08-2024&quot;</td><td>939.774937</td><td>928.81374</td><td>1000.487767</td><td>741453.0</td><td>5.603123</td><td>1079</td><td>0.005193</td><td>0.000008</td></tr><tr><td>&quot;chocolatine-2-14b-instruct-v2.…</td><td>759.705486</td><td>684.747706</td><td>942.699169</td><td>167003.0</td><td>0.605807</td><td>556</td><td>0.00109</td><td>0.000004</td></tr><tr><td>&quot;claude-3-5-sonnet-v2&quot;</td><td>992.536398</td><td>946.97924</td><td>1071.004452</td><td>992729.0</td><td>133.262452</td><td>1834</td><td>0.072662</td><td>0.000134</td></tr><tr><td>&quot;claude-3-7-sonnet&quot;</td><td>1063.784625</td><td>1032.96022</td><td>1163.142276</td><td>287583.0</td><td>38.604711</td><td>296</td><td>0.130421</td><td>0.000134</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;phi-3.5-mini-instruct&quot;</td><td>896.58118</td><td>821.1154</td><td>976.019231</td><td>343212.0</td><td>1.052349</td><td>430</td><td>0.002447</td><td>0.000003</td></tr><tr><td>&quot;phi-4&quot;</td><td>983.898322</td><td>942.589566</td><td>1014.433007</td><td>1.149348e6</td><td>5.298356</td><td>1498</td><td>0.003537</td><td>0.000005</td></tr><tr><td>&quot;qwen2.5-7b-instruct&quot;</td><td>899.580331</td><td>850.126551</td><td>915.839325</td><td>313742.0</td><td>1.138106</td><td>392</td><td>0.002903</td><td>0.000004</td></tr><tr><td>&quot;qwen2.5-coder-32b-instruct&quot;</td><td>925.558969</td><td>896.082695</td><td>937.705889</td><td>1.168947e6</td><td>8.341536</td><td>1490</td><td>0.005598</td><td>0.000007</td></tr><tr><td>&quot;qwq-32b&quot;</td><td>989.794172</td><td>864.810423</td><td>1004.312183</td><td>353398.0</td><td>2.521827</td><td>298</td><td>0.008463</td><td>0.000007</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (48, 9)\n",
       "┌────────────┬───────────┬───────────┬───────────┬───┬───────────┬─────────┬───────────┬───────────┐\n",
       "│ model_name ┆ median    ┆ p2.5      ┆ p97.5     ┆ … ┆ conso_all ┆ n_match ┆ mean_cons ┆ mean_cons │\n",
       "│ ---        ┆ ---       ┆ ---       ┆ ---       ┆   ┆ _conv     ┆ ---     ┆ o_per_mat ┆ o_per_tok │\n",
       "│ str        ┆ f64       ┆ f64       ┆ f64       ┆   ┆ ---       ┆ u32     ┆ ch        ┆ en        │\n",
       "│            ┆           ┆           ┆           ┆   ┆ f64       ┆         ┆ ---       ┆ ---       │\n",
       "│            ┆           ┆           ┆           ┆   ┆           ┆         ┆ f64       ┆ f64       │\n",
       "╞════════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═════════╪═══════════╪═══════════╡\n",
       "│ aya-expans ┆ 1019.4775 ┆ 949.83644 ┆ 1040.2274 ┆ … ┆ 1.235297  ┆ 467     ┆ 0.002645  ┆ 0.000004  │\n",
       "│ e-8b       ┆ 69        ┆ 2         ┆ 78        ┆   ┆           ┆         ┆           ┆           │\n",
       "│ c4ai-comma ┆ 939.77493 ┆ 928.81374 ┆ 1000.4877 ┆ … ┆ 5.603123  ┆ 1079    ┆ 0.005193  ┆ 0.000008  │\n",
       "│ nd-r-08-20 ┆ 7         ┆           ┆ 67        ┆   ┆           ┆         ┆           ┆           │\n",
       "│ 24         ┆           ┆           ┆           ┆   ┆           ┆         ┆           ┆           │\n",
       "│ chocolatin ┆ 759.70548 ┆ 684.74770 ┆ 942.69916 ┆ … ┆ 0.605807  ┆ 556     ┆ 0.00109   ┆ 0.000004  │\n",
       "│ e-2-14b-in ┆ 6         ┆ 6         ┆ 9         ┆   ┆           ┆         ┆           ┆           │\n",
       "│ struct-v2. ┆           ┆           ┆           ┆   ┆           ┆         ┆           ┆           │\n",
       "│ …          ┆           ┆           ┆           ┆   ┆           ┆         ┆           ┆           │\n",
       "│ claude-3-5 ┆ 992.53639 ┆ 946.97924 ┆ 1071.0044 ┆ … ┆ 133.26245 ┆ 1834    ┆ 0.072662  ┆ 0.000134  │\n",
       "│ -sonnet-v2 ┆ 8         ┆           ┆ 52        ┆   ┆ 2         ┆         ┆           ┆           │\n",
       "│ claude-3-7 ┆ 1063.7846 ┆ 1032.9602 ┆ 1163.1422 ┆ … ┆ 38.604711 ┆ 296     ┆ 0.130421  ┆ 0.000134  │\n",
       "│ -sonnet    ┆ 25        ┆ 2         ┆ 76        ┆   ┆           ┆         ┆           ┆           │\n",
       "│ …          ┆ …         ┆ …         ┆ …         ┆ … ┆ …         ┆ …       ┆ …         ┆ …         │\n",
       "│ phi-3.5-mi ┆ 896.58118 ┆ 821.1154  ┆ 976.01923 ┆ … ┆ 1.052349  ┆ 430     ┆ 0.002447  ┆ 0.000003  │\n",
       "│ ni-instruc ┆           ┆           ┆ 1         ┆   ┆           ┆         ┆           ┆           │\n",
       "│ t          ┆           ┆           ┆           ┆   ┆           ┆         ┆           ┆           │\n",
       "│ phi-4      ┆ 983.89832 ┆ 942.58956 ┆ 1014.4330 ┆ … ┆ 5.298356  ┆ 1498    ┆ 0.003537  ┆ 0.000005  │\n",
       "│            ┆ 2         ┆ 6         ┆ 07        ┆   ┆           ┆         ┆           ┆           │\n",
       "│ qwen2.5-7b ┆ 899.58033 ┆ 850.12655 ┆ 915.83932 ┆ … ┆ 1.138106  ┆ 392     ┆ 0.002903  ┆ 0.000004  │\n",
       "│ -instruct  ┆ 1         ┆ 1         ┆ 5         ┆   ┆           ┆         ┆           ┆           │\n",
       "│ qwen2.5-co ┆ 925.55896 ┆ 896.08269 ┆ 937.70588 ┆ … ┆ 8.341536  ┆ 1490    ┆ 0.005598  ┆ 0.000007  │\n",
       "│ der-32b-in ┆ 9         ┆ 5         ┆ 9         ┆   ┆           ┆         ┆           ┆           │\n",
       "│ struct     ┆           ┆           ┆           ┆   ┆           ┆         ┆           ┆           │\n",
       "│ qwq-32b    ┆ 989.79417 ┆ 864.81042 ┆ 1004.3121 ┆ … ┆ 2.521827  ┆ 298     ┆ 0.008463  ┆ 0.000007  │\n",
       "│            ┆ 2         ┆ 3         ┆ 83        ┆   ┆           ┆         ┆           ┆           │\n",
       "└────────────┴───────────┴───────────┴───────────┴───┴───────────┴─────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_votes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914dc5de",
   "metadata": {},
   "source": [
    "## Pipeline avec un ranker alternatif\n",
    "\n",
    "Utilisation du Ranker `MaximumLikelihood`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33484b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since ministere-culture/comparia-votes couldn't be found on the Hugging Face Hub (offline mode is enabled).\n",
      "Found the latest cached dataset configuration 'default' at /home/jupyterhub-users/shared/projet_comparia/huggingface_hub/ministere-culture___comparia-votes/default/0.0.0/679f56e14f413546403b3468d717c4417e394326 (last modified on Mon Jul 28 10:06:44 2025).\n",
      "Using the latest cached version of the dataset since ministere-culture/comparia-conversations couldn't be found on the Hugging Face Hub (offline mode is enabled).\n",
      "Found the latest cached dataset configuration 'default' at /home/jupyterhub-users/shared/projet_comparia/huggingface_hub/ministere-culture___comparia-conversations/default/0.0.0/dc40af6af1c14e68bf39d55f6e1573d2d6582f19 (last modified on Wed Jun  4 17:40:30 2025).\n",
      "Using the latest cached version of the dataset since ministere-culture/comparia-reactions couldn't be found on the Hugging Face Hub (offline mode is enabled).\n",
      "Found the latest cached dataset configuration 'default' at /home/jupyterhub-users/shared/projet_comparia/huggingface_hub/ministere-culture___comparia-reactions/default/0.0.0/80befa851337d9f295096cef3d100b40d220dc07 (last modified on Mon Jul 28 10:06:54 2025).\n",
      "Using the latest cached version of the dataset since ministere-culture/comparia-conversations couldn't be found on the Hugging Face Hub (offline mode is enabled).\n",
      "Found the latest cached dataset configuration 'default' at /home/jupyterhub-users/shared/projet_comparia/huggingface_hub/ministere-culture___comparia-conversations/default/0.0.0/dc40af6af1c14e68bf39d55f6e1573d2d6582f19 (last modified on Wed Jun  4 17:40:30 2025).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final votes dataset contains 55617 conversations pairs.\n",
      "Reactions data originally contains 22993 conversations pairs.\n",
      "Final reactions dataset contains 21244 conversations pairs.\n"
     ]
    }
   ],
   "source": [
    "pipeline = RankingPipeline(\n",
    "    method=\"ml\",\n",
    "    include_votes=True,\n",
    "    include_reactions=True,\n",
    "    mean_how=\"token\",\n",
    "    bootstrap_samples=5,\n",
    "    export_path=Path(\"output\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19d46e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing bootstrap scores from a sample of 76861 matches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing bootstrap samples: 100%|██████████| 5/5 [00:00<00:00,  5.40it/s]\n"
     ]
    }
   ],
   "source": [
    "scores_ml = pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f76592e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since ministere-culture/comparia-votes couldn't be found on the Hugging Face Hub (offline mode is enabled).\n",
      "Found the latest cached dataset configuration 'default' at /home/jupyterhub-users/shared/projet_comparia/huggingface_hub/ministere-culture___comparia-votes/default/0.0.0/679f56e14f413546403b3468d717c4417e394326 (last modified on Mon Jul 28 10:06:44 2025).\n",
      "Using the latest cached version of the dataset since ministere-culture/comparia-conversations couldn't be found on the Hugging Face Hub (offline mode is enabled).\n",
      "Found the latest cached dataset configuration 'default' at /home/jupyterhub-users/shared/projet_comparia/huggingface_hub/ministere-culture___comparia-conversations/default/0.0.0/dc40af6af1c14e68bf39d55f6e1573d2d6582f19 (last modified on Wed Jun  4 17:40:30 2025).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final votes dataset contains 55617 conversations pairs.\n",
      "Computing bootstrap scores from a sample of 55617 matches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing bootstrap samples: 100%|██████████| 5/5 [00:00<00:00,  7.05it/s]\n"
     ]
    }
   ],
   "source": [
    "pipeline = RankingPipeline(\n",
    "    method=\"ml\",\n",
    "    include_votes=True,\n",
    "    include_reactions=False,\n",
    "    mean_how=\"token\",\n",
    "    bootstrap_samples=5,\n",
    ")\n",
    "\n",
    "scores_ml_votes = pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66711d3",
   "metadata": {},
   "source": [
    "## Comparaison des différentes méthodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "159fa36a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (52, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model_name</th><th>score_elo</th><th>score_elo_votes</th><th>score_ml</th><th>score_ml_votes</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;Yi-1.5-9B-Chat&quot;</td><td>788.44272</td><td>null</td><td>841.898492</td><td>789.478267</td></tr><tr><td>&quot;aya-expanse-8b&quot;</td><td>1000.68942</td><td>1019.477569</td><td>1001.36097</td><td>1011.732923</td></tr><tr><td>&quot;c4ai-command-r-08-2024&quot;</td><td>923.687526</td><td>939.774937</td><td>961.203015</td><td>961.982304</td></tr><tr><td>&quot;chocolatine-14b-instruct-dpo-v…</td><td>769.806287</td><td>null</td><td>803.965521</td><td>783.213805</td></tr><tr><td>&quot;chocolatine-2-14b-instruct-v2.…</td><td>810.537544</td><td>759.705486</td><td>847.275605</td><td>853.874869</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;qwen2-7b-instruct&quot;</td><td>793.96601</td><td>null</td><td>795.690607</td><td>768.937374</td></tr><tr><td>&quot;qwen2.5-32b-instruct&quot;</td><td>984.43552</td><td>null</td><td>1002.386072</td><td>1012.044339</td></tr><tr><td>&quot;qwen2.5-7b-instruct&quot;</td><td>954.56483</td><td>899.580331</td><td>958.416572</td><td>976.563204</td></tr><tr><td>&quot;qwen2.5-coder-32b-instruct&quot;</td><td>989.596408</td><td>925.558969</td><td>952.229222</td><td>959.008077</td></tr><tr><td>&quot;qwq-32b&quot;</td><td>932.448506</td><td>989.794172</td><td>973.987791</td><td>980.335982</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (52, 5)\n",
       "┌─────────────────────────────────┬────────────┬─────────────────┬─────────────┬────────────────┐\n",
       "│ model_name                      ┆ score_elo  ┆ score_elo_votes ┆ score_ml    ┆ score_ml_votes │\n",
       "│ ---                             ┆ ---        ┆ ---             ┆ ---         ┆ ---            │\n",
       "│ str                             ┆ f64        ┆ f64             ┆ f64         ┆ f64            │\n",
       "╞═════════════════════════════════╪════════════╪═════════════════╪═════════════╪════════════════╡\n",
       "│ Yi-1.5-9B-Chat                  ┆ 788.44272  ┆ null            ┆ 841.898492  ┆ 789.478267     │\n",
       "│ aya-expanse-8b                  ┆ 1000.68942 ┆ 1019.477569     ┆ 1001.36097  ┆ 1011.732923    │\n",
       "│ c4ai-command-r-08-2024          ┆ 923.687526 ┆ 939.774937      ┆ 961.203015  ┆ 961.982304     │\n",
       "│ chocolatine-14b-instruct-dpo-v… ┆ 769.806287 ┆ null            ┆ 803.965521  ┆ 783.213805     │\n",
       "│ chocolatine-2-14b-instruct-v2.… ┆ 810.537544 ┆ 759.705486      ┆ 847.275605  ┆ 853.874869     │\n",
       "│ …                               ┆ …          ┆ …               ┆ …           ┆ …              │\n",
       "│ qwen2-7b-instruct               ┆ 793.96601  ┆ null            ┆ 795.690607  ┆ 768.937374     │\n",
       "│ qwen2.5-32b-instruct            ┆ 984.43552  ┆ null            ┆ 1002.386072 ┆ 1012.044339    │\n",
       "│ qwen2.5-7b-instruct             ┆ 954.56483  ┆ 899.580331      ┆ 958.416572  ┆ 976.563204     │\n",
       "│ qwen2.5-coder-32b-instruct      ┆ 989.596408 ┆ 925.558969      ┆ 952.229222  ┆ 959.008077     │\n",
       "│ qwq-32b                         ┆ 932.448506 ┆ 989.794172      ┆ 973.987791  ┆ 980.335982     │\n",
       "└─────────────────────────────────┴────────────┴─────────────────┴─────────────┴────────────────┘"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "pl.concat(\n",
    "    [\n",
    "        scores.select(\"model_name\", \"median\").rename(mapping={\"median\": \"score_elo\"}),\n",
    "        scores_votes.select(\"model_name\", \"median\").rename(mapping={\"median\": \"score_elo_votes\"}),\n",
    "        scores_ml.select(\"model_name\", \"median\").rename(mapping={\"median\": \"score_ml\"}),\n",
    "        scores_ml_votes.select(\"model_name\", \"median\").rename(mapping={\"median\": \"score_ml_votes\"}),\n",
    "    ],\n",
    "    how=\"align\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "953a2437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-7ac71999854d444f8c303827369ed7da.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-7ac71999854d444f8c303827369ed7da.vega-embed details,\n",
       "  #altair-viz-7ac71999854d444f8c303827369ed7da.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-7ac71999854d444f8c303827369ed7da\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-7ac71999854d444f8c303827369ed7da\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-7ac71999854d444f8c303827369ed7da\");\n",
       "    }\n",
       "\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      let deps = [\"vega-embed\"];\n",
       "      require(deps, displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-86c4d392c61ddded6e19471ec49574b3\"}, \"mark\": {\"type\": \"circle\", \"size\": 80}, \"encoding\": {\"color\": {\"field\": \"score_type\", \"title\": \"Score Type\", \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"model_name\", \"type\": \"nominal\"}, {\"field\": \"score\", \"type\": \"quantitative\"}, {\"field\": \"score_type\", \"type\": \"nominal\"}], \"x\": {\"field\": \"model_name\", \"sort\": [\"gemini-1.5-pro-001\", \"deepseek-v3-chat\", \"gemini-2.0-flash-exp\", \"gemini-2.0-flash-001\", \"gemma-3-12b\", \"gemma-3-27b\", \"claude-3-7-sonnet\", \"gemini-1.5-pro-002\", \"command-a\", \"grok-3-mini-beta\", \"llama-3.1-nemotron-70b-instruct\", \"gemma-3-4b\", \"gemma-2-9b-it\", \"deepseek-v3-0324\", \"mistral-saba\", \"gpt-4.1-mini\", \"llama-3.1-405b\", \"phi-4\", \"o4-mini\", \"mistral-large-2411\", \"gemma-2-27b-it-q8\", \"mistral-small-3.1-24b\", \"deepseek-r1\", \"llama-4-scout\", \"gpt-4o-2024-08-06\", \"aya-expanse-8b\", \"o3-mini\", \"claude-3-5-sonnet-v2\", \"mistral-small-24b-instruct-2501\", \"qwen2.5-coder-32b-instruct\", \"gpt-4.1-nano\", \"qwen2.5-32b-instruct\", \"gpt-4o-mini-2024-07-18\", \"jamba-1.5-large\", \"llama-3.1-70b\", \"llama-3.3-70b\", \"hermes-3-llama-3.1-405b\", \"qwen2.5-7b-instruct\", \"ministral-8b-instruct-2410\", \"qwq-32b\", \"deepseek-r1-distill-llama-70b\", \"c4ai-command-r-08-2024\", \"phi-3.5-mini-instruct\", \"mistral-nemo-2407\", \"llama-3.1-8b\", \"lfm-40b\", \"mixtral-8x7b-instruct-v0.1\", \"mixtral-8x22b-instruct-v0.1\", \"chocolatine-2-14b-instruct-v2.0.3-q8\", \"qwen2-7b-instruct\", \"Yi-1.5-9B-Chat\", \"chocolatine-14b-instruct-dpo-v1.2-q4\"], \"title\": \"model_name\", \"type\": \"nominal\"}, \"y\": {\"field\": \"score\", \"scale\": {\"domain\": [500, 1300]}, \"title\": \"Score\", \"type\": \"quantitative\"}}, \"height\": 400, \"width\": 600, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-86c4d392c61ddded6e19471ec49574b3\": [{\"model_name\": \"gemini-1.5-pro-001\", \"score_type\": \"Elo score (all data)\", \"score\": 1165.145829315568}, {\"model_name\": \"deepseek-v3-chat\", \"score_type\": \"Elo score (all data)\", \"score\": 1154.8038107239192}, {\"model_name\": \"gemini-2.0-flash-exp\", \"score_type\": \"Elo score (all data)\", \"score\": 1148.448823540513}, {\"model_name\": \"gemini-2.0-flash-001\", \"score_type\": \"Elo score (all data)\", \"score\": 1147.0488539855235}, {\"model_name\": \"gemma-3-12b\", \"score_type\": \"Elo score (all data)\", \"score\": 1125.638051913515}, {\"model_name\": \"gemma-3-27b\", \"score_type\": \"Elo score (all data)\", \"score\": 1123.22070772581}, {\"model_name\": \"claude-3-7-sonnet\", \"score_type\": \"Elo score (all data)\", \"score\": 1099.6708392526816}, {\"model_name\": \"gemini-1.5-pro-002\", \"score_type\": \"Elo score (all data)\", \"score\": 1096.1635727414296}, {\"model_name\": \"command-a\", \"score_type\": \"Elo score (all data)\", \"score\": 1086.8034952218366}, {\"model_name\": \"grok-3-mini-beta\", \"score_type\": \"Elo score (all data)\", \"score\": 1082.2739384580993}, {\"model_name\": \"llama-3.1-nemotron-70b-instruct\", \"score_type\": \"Elo score (all data)\", \"score\": 1081.01427474604}, {\"model_name\": \"gemma-3-4b\", \"score_type\": \"Elo score (all data)\", \"score\": 1078.8589751381537}, {\"model_name\": \"gemma-2-9b-it\", \"score_type\": \"Elo score (all data)\", \"score\": 1065.862074169808}, {\"model_name\": \"deepseek-v3-0324\", \"score_type\": \"Elo score (all data)\", \"score\": 1063.940292265836}, {\"model_name\": \"mistral-saba\", \"score_type\": \"Elo score (all data)\", \"score\": 1057.7399949021717}, {\"model_name\": \"gpt-4.1-mini\", \"score_type\": \"Elo score (all data)\", \"score\": 1052.311198577507}, {\"model_name\": \"llama-3.1-405b\", \"score_type\": \"Elo score (all data)\", \"score\": 1037.939631736325}, {\"model_name\": \"phi-4\", \"score_type\": \"Elo score (all data)\", \"score\": 1037.1152148729786}, {\"model_name\": \"o4-mini\", \"score_type\": \"Elo score (all data)\", \"score\": 1034.7282318539526}, {\"model_name\": \"mistral-large-2411\", \"score_type\": \"Elo score (all data)\", \"score\": 1034.4612496143768}, {\"model_name\": \"gemma-2-27b-it-q8\", \"score_type\": \"Elo score (all data)\", \"score\": 1027.5518958746604}, {\"model_name\": \"mistral-small-3.1-24b\", \"score_type\": \"Elo score (all data)\", \"score\": 1024.6020604977289}, {\"model_name\": \"deepseek-r1\", \"score_type\": \"Elo score (all data)\", \"score\": 1013.9159498827795}, {\"model_name\": \"llama-4-scout\", \"score_type\": \"Elo score (all data)\", \"score\": 1013.3428863173503}, {\"model_name\": \"gpt-4o-2024-08-06\", \"score_type\": \"Elo score (all data)\", \"score\": 1003.4792050064724}, {\"model_name\": \"aya-expanse-8b\", \"score_type\": \"Elo score (all data)\", \"score\": 1000.6894201761406}, {\"model_name\": \"o3-mini\", \"score_type\": \"Elo score (all data)\", \"score\": 999.1686430754431}, {\"model_name\": \"claude-3-5-sonnet-v2\", \"score_type\": \"Elo score (all data)\", \"score\": 994.2140943220253}, {\"model_name\": \"mistral-small-24b-instruct-2501\", \"score_type\": \"Elo score (all data)\", \"score\": 990.1693245072939}, {\"model_name\": \"qwen2.5-coder-32b-instruct\", \"score_type\": \"Elo score (all data)\", \"score\": 989.5964077672102}, {\"model_name\": \"gpt-4.1-nano\", \"score_type\": \"Elo score (all data)\", \"score\": 984.8621844905064}, {\"model_name\": \"qwen2.5-32b-instruct\", \"score_type\": \"Elo score (all data)\", \"score\": 984.4355201172713}, {\"model_name\": \"gpt-4o-mini-2024-07-18\", \"score_type\": \"Elo score (all data)\", \"score\": 979.9659562304929}, {\"model_name\": \"jamba-1.5-large\", \"score_type\": \"Elo score (all data)\", \"score\": 978.8690099946675}, {\"model_name\": \"llama-3.1-70b\", \"score_type\": \"Elo score (all data)\", \"score\": 973.9876855989933}, {\"model_name\": \"llama-3.3-70b\", \"score_type\": \"Elo score (all data)\", \"score\": 972.845497698505}, {\"model_name\": \"hermes-3-llama-3.1-405b\", \"score_type\": \"Elo score (all data)\", \"score\": 972.2181709263415}, {\"model_name\": \"qwen2.5-7b-instruct\", \"score_type\": \"Elo score (all data)\", \"score\": 954.5648301819358}, {\"model_name\": \"ministral-8b-instruct-2410\", \"score_type\": \"Elo score (all data)\", \"score\": 940.0446575279897}, {\"model_name\": \"qwq-32b\", \"score_type\": \"Elo score (all data)\", \"score\": 932.4485059393405}, {\"model_name\": \"deepseek-r1-distill-llama-70b\", \"score_type\": \"Elo score (all data)\", \"score\": 930.8883495350076}, {\"model_name\": \"c4ai-command-r-08-2024\", \"score_type\": \"Elo score (all data)\", \"score\": 923.6875262427285}, {\"model_name\": \"phi-3.5-mini-instruct\", \"score_type\": \"Elo score (all data)\", \"score\": 916.6120026081678}, {\"model_name\": \"mistral-nemo-2407\", \"score_type\": \"Elo score (all data)\", \"score\": 912.6065881444837}, {\"model_name\": \"llama-3.1-8b\", \"score_type\": \"Elo score (all data)\", \"score\": 906.987654559974}, {\"model_name\": \"lfm-40b\", \"score_type\": \"Elo score (all data)\", \"score\": 896.5515598422662}, {\"model_name\": \"mixtral-8x7b-instruct-v0.1\", \"score_type\": \"Elo score (all data)\", \"score\": 884.4925479969706}, {\"model_name\": \"mixtral-8x22b-instruct-v0.1\", \"score_type\": \"Elo score (all data)\", \"score\": 880.3730838178105}, {\"model_name\": \"chocolatine-2-14b-instruct-v2.0.3-q8\", \"score_type\": \"Elo score (all data)\", \"score\": 810.5375441022825}, {\"model_name\": \"qwen2-7b-instruct\", \"score_type\": \"Elo score (all data)\", \"score\": 793.9660102975005}, {\"model_name\": \"Yi-1.5-9B-Chat\", \"score_type\": \"Elo score (all data)\", \"score\": 788.4427197437343}, {\"model_name\": \"chocolatine-14b-instruct-dpo-v1.2-q4\", \"score_type\": \"Elo score (all data)\", \"score\": 769.8062866276616}, {\"model_name\": \"gemini-1.5-pro-001\", \"score_type\": \"Elo score (votes data)\", \"score\": 1022.5220446691438}, {\"model_name\": \"deepseek-v3-chat\", \"score_type\": \"Elo score (votes data)\", \"score\": 1078.9988577519396}, {\"model_name\": \"gemini-2.0-flash-exp\", \"score_type\": \"Elo score (votes data)\", \"score\": 1116.5332949885808}, {\"model_name\": \"gemini-2.0-flash-001\", \"score_type\": \"Elo score (votes data)\", \"score\": 1130.5193650667152}, {\"model_name\": \"gemma-3-12b\", \"score_type\": \"Elo score (votes data)\", \"score\": 1068.4593795016915}, {\"model_name\": \"gemma-3-27b\", \"score_type\": \"Elo score (votes data)\", \"score\": 1185.0074404938673}, {\"model_name\": \"claude-3-7-sonnet\", \"score_type\": \"Elo score (votes data)\", \"score\": 1063.7846251496644}, {\"model_name\": \"gemini-1.5-pro-002\", \"score_type\": \"Elo score (votes data)\", \"score\": 1021.928115618113}, {\"model_name\": \"command-a\", \"score_type\": \"Elo score (votes data)\", \"score\": 1104.5133499124781}, {\"model_name\": \"grok-3-mini-beta\", \"score_type\": \"Elo score (votes data)\", \"score\": 1091.5127880254106}, {\"model_name\": \"llama-3.1-nemotron-70b-instruct\", \"score_type\": \"Elo score (votes data)\", \"score\": 1081.6282891370504}, {\"model_name\": \"gemma-3-4b\", \"score_type\": \"Elo score (votes data)\", \"score\": 1086.437526500525}, {\"model_name\": \"gemma-2-9b-it\", \"score_type\": \"Elo score (votes data)\", \"score\": 954.9363544063065}, {\"model_name\": \"deepseek-v3-0324\", \"score_type\": \"Elo score (votes data)\", \"score\": 1076.4723068333992}, {\"model_name\": \"mistral-saba\", \"score_type\": \"Elo score (votes data)\", \"score\": 1003.2650811608823}, {\"model_name\": \"gpt-4.1-mini\", \"score_type\": \"Elo score (votes data)\", \"score\": 1082.3615209659422}, {\"model_name\": \"llama-3.1-405b\", \"score_type\": \"Elo score (votes data)\", \"score\": 1011.1129657489153}, {\"model_name\": \"phi-4\", \"score_type\": \"Elo score (votes data)\", \"score\": 983.8983216583988}, {\"model_name\": \"o4-mini\", \"score_type\": \"Elo score (votes data)\", \"score\": 1018.0441075508456}, {\"model_name\": \"mistral-large-2411\", \"score_type\": \"Elo score (votes data)\", \"score\": 1069.393603861344}, {\"model_name\": \"gemma-2-27b-it-q8\", \"score_type\": \"Elo score (votes data)\", \"score\": 978.6245698953214}, {\"model_name\": \"mistral-small-3.1-24b\", \"score_type\": \"Elo score (votes data)\", \"score\": 1007.8520085355455}, {\"model_name\": \"deepseek-r1\", \"score_type\": \"Elo score (votes data)\", \"score\": 1058.8671423091969}, {\"model_name\": \"llama-4-scout\", \"score_type\": \"Elo score (votes data)\", \"score\": 998.0087250927222}, {\"model_name\": \"gpt-4o-2024-08-06\", \"score_type\": \"Elo score (votes data)\", \"score\": 1044.4008594537963}, {\"model_name\": \"aya-expanse-8b\", \"score_type\": \"Elo score (votes data)\", \"score\": 1019.477568719501}, {\"model_name\": \"o3-mini\", \"score_type\": \"Elo score (votes data)\", \"score\": 1019.5932190037588}, {\"model_name\": \"claude-3-5-sonnet-v2\", \"score_type\": \"Elo score (votes data)\", \"score\": 992.5363984837742}, {\"model_name\": \"mistral-small-24b-instruct-2501\", \"score_type\": \"Elo score (votes data)\", \"score\": 982.9431293271185}, {\"model_name\": \"qwen2.5-coder-32b-instruct\", \"score_type\": \"Elo score (votes data)\", \"score\": 925.5589686295814}, {\"model_name\": \"gpt-4.1-nano\", \"score_type\": \"Elo score (votes data)\", \"score\": 978.5889693686878}, {\"model_name\": \"qwen2.5-32b-instruct\", \"score_type\": \"Elo score (votes data)\", \"score\": null}, {\"model_name\": \"gpt-4o-mini-2024-07-18\", \"score_type\": \"Elo score (votes data)\", \"score\": 1055.7748735803973}, {\"model_name\": \"jamba-1.5-large\", \"score_type\": \"Elo score (votes data)\", \"score\": 1008.8504715921201}, {\"model_name\": \"llama-3.1-70b\", \"score_type\": \"Elo score (votes data)\", \"score\": 967.4060878993265}, {\"model_name\": \"llama-3.3-70b\", \"score_type\": \"Elo score (votes data)\", \"score\": 1012.2402250056342}, {\"model_name\": \"hermes-3-llama-3.1-405b\", \"score_type\": \"Elo score (votes data)\", \"score\": 965.7538066738816}, {\"model_name\": \"qwen2.5-7b-instruct\", \"score_type\": \"Elo score (votes data)\", \"score\": 899.5803313823051}, {\"model_name\": \"ministral-8b-instruct-2410\", \"score_type\": \"Elo score (votes data)\", \"score\": 917.2887576766248}, {\"model_name\": \"qwq-32b\", \"score_type\": \"Elo score (votes data)\", \"score\": 989.7941722222909}, {\"model_name\": \"deepseek-r1-distill-llama-70b\", \"score_type\": \"Elo score (votes data)\", \"score\": 965.2693971163828}, {\"model_name\": \"c4ai-command-r-08-2024\", \"score_type\": \"Elo score (votes data)\", \"score\": 939.7749366174612}, {\"model_name\": \"phi-3.5-mini-instruct\", \"score_type\": \"Elo score (votes data)\", \"score\": 896.5811797985187}, {\"model_name\": \"mistral-nemo-2407\", \"score_type\": \"Elo score (votes data)\", \"score\": 817.2082745276598}, {\"model_name\": \"llama-3.1-8b\", \"score_type\": \"Elo score (votes data)\", \"score\": 929.4558443410401}, {\"model_name\": \"lfm-40b\", \"score_type\": \"Elo score (votes data)\", \"score\": 884.9197585465708}, {\"model_name\": \"mixtral-8x7b-instruct-v0.1\", \"score_type\": \"Elo score (votes data)\", \"score\": 891.1942378377901}, {\"model_name\": \"mixtral-8x22b-instruct-v0.1\", \"score_type\": \"Elo score (votes data)\", \"score\": 859.7658422379452}, {\"model_name\": \"chocolatine-2-14b-instruct-v2.0.3-q8\", \"score_type\": \"Elo score (votes data)\", \"score\": 759.7054857660129}, {\"model_name\": \"qwen2-7b-instruct\", \"score_type\": \"Elo score (votes data)\", \"score\": null}, {\"model_name\": \"Yi-1.5-9B-Chat\", \"score_type\": \"Elo score (votes data)\", \"score\": null}, {\"model_name\": \"chocolatine-14b-instruct-dpo-v1.2-q4\", \"score_type\": \"Elo score (votes data)\", \"score\": null}, {\"model_name\": \"gemini-1.5-pro-001\", \"score_type\": \"BT score (all data)\", \"score\": 1089.151934986496}, {\"model_name\": \"deepseek-v3-chat\", \"score_type\": \"BT score (all data)\", \"score\": 1111.7792903269399}, {\"model_name\": \"gemini-2.0-flash-exp\", \"score_type\": \"BT score (all data)\", \"score\": 1139.4038838917065}, {\"model_name\": \"gemini-2.0-flash-001\", \"score_type\": \"BT score (all data)\", \"score\": 1118.8159777607136}, {\"model_name\": \"gemma-3-12b\", \"score_type\": \"BT score (all data)\", \"score\": 1105.5682027347889}, {\"model_name\": \"gemma-3-27b\", \"score_type\": \"BT score (all data)\", \"score\": 1128.274944079453}, {\"model_name\": \"claude-3-7-sonnet\", \"score_type\": \"BT score (all data)\", \"score\": 1082.3484413886474}, {\"model_name\": \"gemini-1.5-pro-002\", \"score_type\": \"BT score (all data)\", \"score\": 1050.1524707426295}, {\"model_name\": \"command-a\", \"score_type\": \"BT score (all data)\", \"score\": 1108.4264535933967}, {\"model_name\": \"grok-3-mini-beta\", \"score_type\": \"BT score (all data)\", \"score\": 1068.2765292549525}, {\"model_name\": \"llama-3.1-nemotron-70b-instruct\", \"score_type\": \"BT score (all data)\", \"score\": 1080.7438104382227}, {\"model_name\": \"gemma-3-4b\", \"score_type\": \"BT score (all data)\", \"score\": 1070.5389866742403}, {\"model_name\": \"gemma-2-9b-it\", \"score_type\": \"BT score (all data)\", \"score\": 980.8317982740031}, {\"model_name\": \"deepseek-v3-0324\", \"score_type\": \"BT score (all data)\", \"score\": 1094.4555682538762}, {\"model_name\": \"mistral-saba\", \"score_type\": \"BT score (all data)\", \"score\": 1007.7332226633957}, {\"model_name\": \"gpt-4.1-mini\", \"score_type\": \"BT score (all data)\", \"score\": 1067.2231798482123}, {\"model_name\": \"llama-3.1-405b\", \"score_type\": \"BT score (all data)\", \"score\": 1012.4819789692933}, {\"model_name\": \"phi-4\", \"score_type\": \"BT score (all data)\", \"score\": 994.5268145555418}, {\"model_name\": \"o4-mini\", \"score_type\": \"BT score (all data)\", \"score\": 1013.4488599985904}, {\"model_name\": \"mistral-large-2411\", \"score_type\": \"BT score (all data)\", \"score\": 1044.2843786303831}, {\"model_name\": \"gemma-2-27b-it-q8\", \"score_type\": \"BT score (all data)\", \"score\": 1022.6197623848554}, {\"model_name\": \"mistral-small-3.1-24b\", \"score_type\": \"BT score (all data)\", \"score\": 1033.3895143071784}, {\"model_name\": \"deepseek-r1\", \"score_type\": \"BT score (all data)\", \"score\": 1037.586442682137}, {\"model_name\": \"llama-4-scout\", \"score_type\": \"BT score (all data)\", \"score\": 1039.1113066565672}, {\"model_name\": \"gpt-4o-2024-08-06\", \"score_type\": \"BT score (all data)\", \"score\": 989.1573223419075}, {\"model_name\": \"aya-expanse-8b\", \"score_type\": \"BT score (all data)\", \"score\": 1001.3609699428375}, {\"model_name\": \"o3-mini\", \"score_type\": \"BT score (all data)\", \"score\": 1007.2507024034351}, {\"model_name\": \"claude-3-5-sonnet-v2\", \"score_type\": \"BT score (all data)\", \"score\": 1000.9385447262873}, {\"model_name\": \"mistral-small-24b-instruct-2501\", \"score_type\": \"BT score (all data)\", \"score\": 1013.443097858051}, {\"model_name\": \"qwen2.5-coder-32b-instruct\", \"score_type\": \"BT score (all data)\", \"score\": 952.2292218722444}, {\"model_name\": \"gpt-4.1-nano\", \"score_type\": \"BT score (all data)\", \"score\": 999.2567164896299}, {\"model_name\": \"qwen2.5-32b-instruct\", \"score_type\": \"BT score (all data)\", \"score\": 1002.3860720812439}, {\"model_name\": \"gpt-4o-mini-2024-07-18\", \"score_type\": \"BT score (all data)\", \"score\": 1012.6919603606395}, {\"model_name\": \"jamba-1.5-large\", \"score_type\": \"BT score (all data)\", \"score\": 988.9595296635875}, {\"model_name\": \"llama-3.1-70b\", \"score_type\": \"BT score (all data)\", \"score\": 1006.1432191708827}, {\"model_name\": \"llama-3.3-70b\", \"score_type\": \"BT score (all data)\", \"score\": 1015.6156793258821}, {\"model_name\": \"hermes-3-llama-3.1-405b\", \"score_type\": \"BT score (all data)\", \"score\": 967.5055384256398}, {\"model_name\": \"qwen2.5-7b-instruct\", \"score_type\": \"BT score (all data)\", \"score\": 958.4165722751271}, {\"model_name\": \"ministral-8b-instruct-2410\", \"score_type\": \"BT score (all data)\", \"score\": 985.887533142297}, {\"model_name\": \"qwq-32b\", \"score_type\": \"BT score (all data)\", \"score\": 973.9877909360398}, {\"model_name\": \"deepseek-r1-distill-llama-70b\", \"score_type\": \"BT score (all data)\", \"score\": 980.3353110251728}, {\"model_name\": \"c4ai-command-r-08-2024\", \"score_type\": \"BT score (all data)\", \"score\": 961.2030154967761}, {\"model_name\": \"phi-3.5-mini-instruct\", \"score_type\": \"BT score (all data)\", \"score\": 894.2736498472226}, {\"model_name\": \"mistral-nemo-2407\", \"score_type\": \"BT score (all data)\", \"score\": 882.4068578860116}, {\"model_name\": \"llama-3.1-8b\", \"score_type\": \"BT score (all data)\", \"score\": 934.5972007971983}, {\"model_name\": \"lfm-40b\", \"score_type\": \"BT score (all data)\", \"score\": 912.1389385172266}, {\"model_name\": \"mixtral-8x7b-instruct-v0.1\", \"score_type\": \"BT score (all data)\", \"score\": 918.5775547187259}, {\"model_name\": \"mixtral-8x22b-instruct-v0.1\", \"score_type\": \"BT score (all data)\", \"score\": 870.2820708698323}, {\"model_name\": \"chocolatine-2-14b-instruct-v2.0.3-q8\", \"score_type\": \"BT score (all data)\", \"score\": 847.2756051896877}, {\"model_name\": \"qwen2-7b-instruct\", \"score_type\": \"BT score (all data)\", \"score\": 795.6906065899664}, {\"model_name\": \"Yi-1.5-9B-Chat\", \"score_type\": \"BT score (all data)\", \"score\": 841.8984920758721}, {\"model_name\": \"chocolatine-14b-instruct-dpo-v1.2-q4\", \"score_type\": \"BT score (all data)\", \"score\": 803.965520623141}, {\"model_name\": \"gemini-1.5-pro-001\", \"score_type\": \"BT score (votes data)\", \"score\": 1098.8019619362797}, {\"model_name\": \"deepseek-v3-chat\", \"score_type\": \"BT score (votes data)\", \"score\": 1106.2446025032557}, {\"model_name\": \"gemini-2.0-flash-exp\", \"score_type\": \"BT score (votes data)\", \"score\": 1125.4168870510994}, {\"model_name\": \"gemini-2.0-flash-001\", \"score_type\": \"BT score (votes data)\", \"score\": 1122.597561579147}, {\"model_name\": \"gemma-3-12b\", \"score_type\": \"BT score (votes data)\", \"score\": 1104.707254012555}, {\"model_name\": \"gemma-3-27b\", \"score_type\": \"BT score (votes data)\", \"score\": 1112.9125584062267}, {\"model_name\": \"claude-3-7-sonnet\", \"score_type\": \"BT score (votes data)\", \"score\": 1082.6107448576408}, {\"model_name\": \"gemini-1.5-pro-002\", \"score_type\": \"BT score (votes data)\", \"score\": 1047.2877288235127}, {\"model_name\": \"command-a\", \"score_type\": \"BT score (votes data)\", \"score\": 1108.908603654176}, {\"model_name\": \"grok-3-mini-beta\", \"score_type\": \"BT score (votes data)\", \"score\": 1077.2300957325099}, {\"model_name\": \"llama-3.1-nemotron-70b-instruct\", \"score_type\": \"BT score (votes data)\", \"score\": 1082.814768198994}, {\"model_name\": \"gemma-3-4b\", \"score_type\": \"BT score (votes data)\", \"score\": 1074.7244128385125}, {\"model_name\": \"gemma-2-9b-it\", \"score_type\": \"BT score (votes data)\", \"score\": 986.1277920839724}, {\"model_name\": \"deepseek-v3-0324\", \"score_type\": \"BT score (votes data)\", \"score\": 1095.8318732538428}, {\"model_name\": \"mistral-saba\", \"score_type\": \"BT score (votes data)\", \"score\": 1016.5864364787712}, {\"model_name\": \"gpt-4.1-mini\", \"score_type\": \"BT score (votes data)\", \"score\": 1062.6208999076684}, {\"model_name\": \"llama-3.1-405b\", \"score_type\": \"BT score (votes data)\", \"score\": 1018.9952035706028}, {\"model_name\": \"phi-4\", \"score_type\": \"BT score (votes data)\", \"score\": 1000.9810381583644}, {\"model_name\": \"o4-mini\", \"score_type\": \"BT score (votes data)\", \"score\": 1018.1088062218026}, {\"model_name\": \"mistral-large-2411\", \"score_type\": \"BT score (votes data)\", \"score\": 1044.287603337956}, {\"model_name\": \"gemma-2-27b-it-q8\", \"score_type\": \"BT score (votes data)\", \"score\": 1046.8736938763673}, {\"model_name\": \"mistral-small-3.1-24b\", \"score_type\": \"BT score (votes data)\", \"score\": 1038.3713106947737}, {\"model_name\": \"deepseek-r1\", \"score_type\": \"BT score (votes data)\", \"score\": 1030.0240269614003}, {\"model_name\": \"llama-4-scout\", \"score_type\": \"BT score (votes data)\", \"score\": 1031.9672821097272}, {\"model_name\": \"gpt-4o-2024-08-06\", \"score_type\": \"BT score (votes data)\", \"score\": 987.0280050381936}, {\"model_name\": \"aya-expanse-8b\", \"score_type\": \"BT score (votes data)\", \"score\": 1011.7329234101444}, {\"model_name\": \"o3-mini\", \"score_type\": \"BT score (votes data)\", \"score\": 1005.1982235526634}, {\"model_name\": \"claude-3-5-sonnet-v2\", \"score_type\": \"BT score (votes data)\", \"score\": 995.4278068445501}, {\"model_name\": \"mistral-small-24b-instruct-2501\", \"score_type\": \"BT score (votes data)\", \"score\": 1020.3116692204665}, {\"model_name\": \"qwen2.5-coder-32b-instruct\", \"score_type\": \"BT score (votes data)\", \"score\": 959.0080769506818}, {\"model_name\": \"gpt-4.1-nano\", \"score_type\": \"BT score (votes data)\", \"score\": 1004.2158424602135}, {\"model_name\": \"qwen2.5-32b-instruct\", \"score_type\": \"BT score (votes data)\", \"score\": 1012.0443393659826}, {\"model_name\": \"gpt-4o-mini-2024-07-18\", \"score_type\": \"BT score (votes data)\", \"score\": 1010.0005985611606}, {\"model_name\": \"jamba-1.5-large\", \"score_type\": \"BT score (votes data)\", \"score\": 998.649210909432}, {\"model_name\": \"llama-3.1-70b\", \"score_type\": \"BT score (votes data)\", \"score\": 1011.3479951990882}, {\"model_name\": \"llama-3.3-70b\", \"score_type\": \"BT score (votes data)\", \"score\": 1017.7264826320096}, {\"model_name\": \"hermes-3-llama-3.1-405b\", \"score_type\": \"BT score (votes data)\", \"score\": 969.3208757155694}, {\"model_name\": \"qwen2.5-7b-instruct\", \"score_type\": \"BT score (votes data)\", \"score\": 976.5632038809694}, {\"model_name\": \"ministral-8b-instruct-2410\", \"score_type\": \"BT score (votes data)\", \"score\": 991.5161070315477}, {\"model_name\": \"qwq-32b\", \"score_type\": \"BT score (votes data)\", \"score\": 980.3359820979189}, {\"model_name\": \"deepseek-r1-distill-llama-70b\", \"score_type\": \"BT score (votes data)\", \"score\": 980.2268110026903}, {\"model_name\": \"c4ai-command-r-08-2024\", \"score_type\": \"BT score (votes data)\", \"score\": 961.9823041957017}, {\"model_name\": \"phi-3.5-mini-instruct\", \"score_type\": \"BT score (votes data)\", \"score\": 893.2467623040066}, {\"model_name\": \"mistral-nemo-2407\", \"score_type\": \"BT score (votes data)\", \"score\": 885.9304483506976}, {\"model_name\": \"llama-3.1-8b\", \"score_type\": \"BT score (votes data)\", \"score\": 934.1440966545429}, {\"model_name\": \"lfm-40b\", \"score_type\": \"BT score (votes data)\", \"score\": 906.5975725034583}, {\"model_name\": \"mixtral-8x7b-instruct-v0.1\", \"score_type\": \"BT score (votes data)\", \"score\": 929.3385227041758}, {\"model_name\": \"mixtral-8x22b-instruct-v0.1\", \"score_type\": \"BT score (votes data)\", \"score\": 874.8858754222784}, {\"model_name\": \"chocolatine-2-14b-instruct-v2.0.3-q8\", \"score_type\": \"BT score (votes data)\", \"score\": 853.8748688916579}, {\"model_name\": \"qwen2-7b-instruct\", \"score_type\": \"BT score (votes data)\", \"score\": 768.9373739000314}, {\"model_name\": \"Yi-1.5-9B-Chat\", \"score_type\": \"BT score (votes data)\", \"score\": 789.4782666301487}, {\"model_name\": \"chocolatine-14b-instruct-dpo-v1.2-q4\", \"score_type\": \"BT score (votes data)\", \"score\": 783.2138053004281}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import polars as pl\n",
    "import altair as alt\n",
    "\n",
    "df_pl = pl.concat(\n",
    "    [\n",
    "        scores.select(\"model_name\", \"median\").rename(mapping={\"median\": \"score_elo\"}),\n",
    "        scores_votes.select(\"model_name\", \"median\").rename(mapping={\"median\": \"score_elo_votes\"}),\n",
    "        scores_ml.select(\"model_name\", \"median\").rename(mapping={\"median\": \"score_ml\"}),\n",
    "        scores_ml_votes.select(\"model_name\", \"median\").rename(mapping={\"median\": \"score_ml_votes\"}),\n",
    "    ],\n",
    "    how=\"align\",\n",
    ").sort(\"score_elo\", descending=True)\n",
    "\n",
    "df = df_pl.to_pandas()\n",
    "df_long = df.melt(\n",
    "    id_vars=[\"model_name\"],\n",
    "    value_vars=[\"score_elo\", \"score_elo_votes\", \"score_ml\", \"score_ml_votes\"],\n",
    "    var_name=\"score_type\",\n",
    "    value_name=\"score\",\n",
    ")\n",
    "legend_labels = {\n",
    "    \"score_elo\": \"Elo score (all data)\",\n",
    "    \"score_elo_votes\": \"Elo score (votes data)\",\n",
    "    \"score_ml\": \"BT score (all data)\",\n",
    "    \"score_ml_votes\": \"BT score (votes data)\",\n",
    "}\n",
    "df_long[\"score_type\"] = df_long[\"score_type\"].map(legend_labels)\n",
    "\n",
    "chart = (\n",
    "    alt.Chart(df_long)\n",
    "    .mark_circle(size=80)\n",
    "    .encode(\n",
    "        x=alt.X(\"model_name:N\", sort=df[\"model_name\"].tolist(), title=\"model_name\"),\n",
    "        y=alt.Y(\"score:Q\", title=\"Score\", scale=alt.Scale(domain=[500, 1300])),\n",
    "        color=alt.Color(\"score_type:N\", title=\"Score Type\"),\n",
    "        tooltip=[\"model_name\", \"score\", \"score_type\"],\n",
    "    )\n",
    "    .properties(width=600, height=400)\n",
    ")\n",
    "\n",
    "chart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbd13bf",
   "metadata": {},
   "source": [
    "## Scores par catégorie\n",
    "\n",
    "Les méthodes `run_category` et `run_all_categories` permettent de calculer des scores pour une catégorie spécifiée ou pour toutes les catégories (avec un nombre de matchs total supérieur à un seuil)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f335bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since ministere-culture/comparia-votes couldn't be found on the Hugging Face Hub (offline mode is enabled).\n",
      "Found the latest cached dataset configuration 'default' at /home/jupyterhub-users/shared/projet_comparia/huggingface_hub/ministere-culture___comparia-votes/default/0.0.0/679f56e14f413546403b3468d717c4417e394326 (last modified on Mon Jul 28 10:06:44 2025).\n",
      "Using the latest cached version of the dataset since ministere-culture/comparia-conversations couldn't be found on the Hugging Face Hub (offline mode is enabled).\n",
      "Found the latest cached dataset configuration 'default' at /home/jupyterhub-users/shared/projet_comparia/huggingface_hub/ministere-culture___comparia-conversations/default/0.0.0/dc40af6af1c14e68bf39d55f6e1573d2d6582f19 (last modified on Wed Jun  4 17:40:30 2025).\n",
      "Using the latest cached version of the dataset since ministere-culture/comparia-reactions couldn't be found on the Hugging Face Hub (offline mode is enabled).\n",
      "Found the latest cached dataset configuration 'default' at /home/jupyterhub-users/shared/projet_comparia/huggingface_hub/ministere-culture___comparia-reactions/default/0.0.0/80befa851337d9f295096cef3d100b40d220dc07 (last modified on Mon Jul 28 10:06:54 2025).\n",
      "Using the latest cached version of the dataset since ministere-culture/comparia-conversations couldn't be found on the Hugging Face Hub (offline mode is enabled).\n",
      "Found the latest cached dataset configuration 'default' at /home/jupyterhub-users/shared/projet_comparia/huggingface_hub/ministere-culture___comparia-conversations/default/0.0.0/dc40af6af1c14e68bf39d55f6e1573d2d6582f19 (last modified on Wed Jun  4 17:40:30 2025).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final votes dataset contains 55617 conversations pairs.\n",
      "Reactions data originally contains 22993 conversations pairs.\n",
      "Final reactions dataset contains 21244 conversations pairs.\n"
     ]
    }
   ],
   "source": [
    "pipeline = RankingPipeline(\n",
    "    method=\"elo_random\",\n",
    "    include_votes=True,\n",
    "    include_reactions=True,\n",
    "    mean_how=\"token\",\n",
    "    bootstrap_samples=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ccbcb453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing bootstrap scores from a sample of 23033 matches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing bootstrap samples: 100%|██████████| 5/5 [00:00<00:00, 22.10it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (52, 9)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model_name</th><th>median</th><th>p2.5</th><th>p97.5</th><th>total_output_tokens</th><th>conso_all_conv</th><th>n_match</th><th>mean_conso_per_match</th><th>mean_conso_per_token</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>u32</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;Yi-1.5-9B-Chat&quot;</td><td>845.029746</td><td>819.738541</td><td>995.596645</td><td>47531.0</td><td>0.182743</td><td>65</td><td>0.002811</td><td>0.000004</td></tr><tr><td>&quot;aya-expanse-8b&quot;</td><td>978.048693</td><td>944.560125</td><td>1062.887188</td><td>1.05781e6</td><td>3.98568</td><td>1302</td><td>0.003061</td><td>0.000004</td></tr><tr><td>&quot;c4ai-command-r-08-2024&quot;</td><td>969.916261</td><td>909.269552</td><td>1011.042408</td><td>2.747666e6</td><td>20.763975</td><td>3598</td><td>0.005771</td><td>0.000008</td></tr><tr><td>&quot;chocolatine-14b-instruct-dpo-v…</td><td>724.486575</td><td>688.256109</td><td>836.671107</td><td>131187.0</td><td>0.602249</td><td>309</td><td>0.001949</td><td>0.000005</td></tr><tr><td>&quot;chocolatine-2-14b-instruct-v2.…</td><td>799.843006</td><td>792.431724</td><td>879.278491</td><td>533384.0</td><td>1.934863</td><td>1796</td><td>0.001077</td><td>0.000004</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;qwen2-7b-instruct&quot;</td><td>783.37499</td><td>712.293222</td><td>822.76696</td><td>43550.0</td><td>0.153078</td><td>80</td><td>0.001913</td><td>0.000004</td></tr><tr><td>&quot;qwen2.5-32b-instruct&quot;</td><td>1075.661903</td><td>1041.802669</td><td>1130.784114</td><td>75812.0</td><td>0.531085</td><td>142</td><td>0.00374</td><td>0.000007</td></tr><tr><td>&quot;qwen2.5-7b-instruct&quot;</td><td>961.101464</td><td>950.03489</td><td>1111.110201</td><td>1.186919e6</td><td>4.305576</td><td>1420</td><td>0.003032</td><td>0.000004</td></tr><tr><td>&quot;qwen2.5-coder-32b-instruct&quot;</td><td>938.235591</td><td>910.737202</td><td>959.567243</td><td>4.0819e6</td><td>29.128193</td><td>4954</td><td>0.00588</td><td>0.000007</td></tr><tr><td>&quot;qwq-32b&quot;</td><td>930.721073</td><td>839.96028</td><td>1015.565118</td><td>1.757717e6</td><td>12.542963</td><td>1479</td><td>0.008481</td><td>0.000007</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (52, 9)\n",
       "┌────────────┬───────────┬───────────┬───────────┬───┬───────────┬─────────┬───────────┬───────────┐\n",
       "│ model_name ┆ median    ┆ p2.5      ┆ p97.5     ┆ … ┆ conso_all ┆ n_match ┆ mean_cons ┆ mean_cons │\n",
       "│ ---        ┆ ---       ┆ ---       ┆ ---       ┆   ┆ _conv     ┆ ---     ┆ o_per_mat ┆ o_per_tok │\n",
       "│ str        ┆ f64       ┆ f64       ┆ f64       ┆   ┆ ---       ┆ u32     ┆ ch        ┆ en        │\n",
       "│            ┆           ┆           ┆           ┆   ┆ f64       ┆         ┆ ---       ┆ ---       │\n",
       "│            ┆           ┆           ┆           ┆   ┆           ┆         ┆ f64       ┆ f64       │\n",
       "╞════════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═════════╪═══════════╪═══════════╡\n",
       "│ Yi-1.5-9B- ┆ 845.02974 ┆ 819.73854 ┆ 995.59664 ┆ … ┆ 0.182743  ┆ 65      ┆ 0.002811  ┆ 0.000004  │\n",
       "│ Chat       ┆ 6         ┆ 1         ┆ 5         ┆   ┆           ┆         ┆           ┆           │\n",
       "│ aya-expans ┆ 978.04869 ┆ 944.56012 ┆ 1062.8871 ┆ … ┆ 3.98568   ┆ 1302    ┆ 0.003061  ┆ 0.000004  │\n",
       "│ e-8b       ┆ 3         ┆ 5         ┆ 88        ┆   ┆           ┆         ┆           ┆           │\n",
       "│ c4ai-comma ┆ 969.91626 ┆ 909.26955 ┆ 1011.0424 ┆ … ┆ 20.763975 ┆ 3598    ┆ 0.005771  ┆ 0.000008  │\n",
       "│ nd-r-08-20 ┆ 1         ┆ 2         ┆ 08        ┆   ┆           ┆         ┆           ┆           │\n",
       "│ 24         ┆           ┆           ┆           ┆   ┆           ┆         ┆           ┆           │\n",
       "│ chocolatin ┆ 724.48657 ┆ 688.25610 ┆ 836.67110 ┆ … ┆ 0.602249  ┆ 309     ┆ 0.001949  ┆ 0.000005  │\n",
       "│ e-14b-inst ┆ 5         ┆ 9         ┆ 7         ┆   ┆           ┆         ┆           ┆           │\n",
       "│ ruct-dpo-v ┆           ┆           ┆           ┆   ┆           ┆         ┆           ┆           │\n",
       "│ …          ┆           ┆           ┆           ┆   ┆           ┆         ┆           ┆           │\n",
       "│ chocolatin ┆ 799.84300 ┆ 792.43172 ┆ 879.27849 ┆ … ┆ 1.934863  ┆ 1796    ┆ 0.001077  ┆ 0.000004  │\n",
       "│ e-2-14b-in ┆ 6         ┆ 4         ┆ 1         ┆   ┆           ┆         ┆           ┆           │\n",
       "│ struct-v2. ┆           ┆           ┆           ┆   ┆           ┆         ┆           ┆           │\n",
       "│ …          ┆           ┆           ┆           ┆   ┆           ┆         ┆           ┆           │\n",
       "│ …          ┆ …         ┆ …         ┆ …         ┆ … ┆ …         ┆ …       ┆ …         ┆ …         │\n",
       "│ qwen2-7b-i ┆ 783.37499 ┆ 712.29322 ┆ 822.76696 ┆ … ┆ 0.153078  ┆ 80      ┆ 0.001913  ┆ 0.000004  │\n",
       "│ nstruct    ┆           ┆ 2         ┆           ┆   ┆           ┆         ┆           ┆           │\n",
       "│ qwen2.5-32 ┆ 1075.6619 ┆ 1041.8026 ┆ 1130.7841 ┆ … ┆ 0.531085  ┆ 142     ┆ 0.00374   ┆ 0.000007  │\n",
       "│ b-instruct ┆ 03        ┆ 69        ┆ 14        ┆   ┆           ┆         ┆           ┆           │\n",
       "│ qwen2.5-7b ┆ 961.10146 ┆ 950.03489 ┆ 1111.1102 ┆ … ┆ 4.305576  ┆ 1420    ┆ 0.003032  ┆ 0.000004  │\n",
       "│ -instruct  ┆ 4         ┆           ┆ 01        ┆   ┆           ┆         ┆           ┆           │\n",
       "│ qwen2.5-co ┆ 938.23559 ┆ 910.73720 ┆ 959.56724 ┆ … ┆ 29.128193 ┆ 4954    ┆ 0.00588   ┆ 0.000007  │\n",
       "│ der-32b-in ┆ 1         ┆ 2         ┆ 3         ┆   ┆           ┆         ┆           ┆           │\n",
       "│ struct     ┆           ┆           ┆           ┆   ┆           ┆         ┆           ┆           │\n",
       "│ qwq-32b    ┆ 930.72107 ┆ 839.96028 ┆ 1015.5651 ┆ … ┆ 12.542963 ┆ 1479    ┆ 0.008481  ┆ 0.000007  │\n",
       "│            ┆ 3         ┆           ┆ 18        ┆   ┆           ┆         ┆           ┆           │\n",
       "└────────────┴───────────┴───────────┴───────────┴───┴───────────┴─────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.run_category(\"Education\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "efc06527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing bootstrap scores from a sample of 23033 matches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing bootstrap samples:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing bootstrap samples: 100%|██████████| 5/5 [00:00<00:00, 22.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing bootstrap scores from a sample of 8046 matches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing bootstrap samples: 100%|██████████| 5/5 [00:00<00:00, 68.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing bootstrap scores from a sample of 12297 matches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing bootstrap samples: 100%|██████████| 5/5 [00:00<00:00, 42.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing bootstrap scores from a sample of 10069 matches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing bootstrap samples: 100%|██████████| 5/5 [00:00<00:00, 54.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing bootstrap scores from a sample of 11206 matches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing bootstrap samples: 100%|██████████| 5/5 [00:00<00:00, 47.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing bootstrap scores from a sample of 5281 matches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing bootstrap samples: 100%|██████████| 5/5 [00:00<00:00, 107.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing bootstrap scores from a sample of 5714 matches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing bootstrap samples: 100%|██████████| 5/5 [00:00<00:00, 87.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing bootstrap scores from a sample of 31303 matches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing bootstrap samples: 100%|██████████| 5/5 [00:00<00:00, 14.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing bootstrap scores from a sample of 17013 matches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing bootstrap samples: 100%|██████████| 5/5 [00:00<00:00, 29.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing bootstrap scores from a sample of 13220 matches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing bootstrap samples: 100%|██████████| 5/5 [00:00<00:00, 38.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping Other which has less than 1000 matches.\n",
      "Computing bootstrap scores from a sample of 7920 matches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing bootstrap samples: 100%|██████████| 5/5 [00:00<00:00, 60.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing bootstrap scores from a sample of 5642 matches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing bootstrap samples: 100%|██████████| 5/5 [00:00<00:00, 98.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing bootstrap scores from a sample of 5913 matches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing bootstrap samples: 100%|██████████| 5/5 [00:00<00:00, 87.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping Shopping & Commodity which has less than 1000 matches.\n",
      "Skipping Daily Life & Home & Lifestyle which has less than 1000 matches.\n",
      "Skipping Religion & Spirituality which has less than 1000 matches.\n",
      "Skipping Sports which has less than 1000 matches.\n",
      "Skipping History which has less than 1000 matches.\n",
      "Skipping Real Estate which has less than 1000 matches.\n",
      "Skipping Philosophy which has less than 1000 matches.\n",
      "Skipping International which has less than 1000 matches.\n",
      "Skipping Psychology which has less than 1000 matches.\n",
      "Skipping Security which has less than 1000 matches.\n",
      "Skipping Philosophy & Spirituality which has less than 1000 matches.\n",
      "Skipping Fashion which has less than 1000 matches.\n",
      "Skipping Music which has less than 1000 matches.\n",
      "Skipping Marketing which has less than 1000 matches.\n",
      "Skipping Ethics & Debate which has less than 1000 matches.\n",
      "Skipping Philosophy & logic which has less than 1000 matches.\n",
      "Skipping Philosophy & Ethics which has less than 1000 matches.\n",
      "Skipping Industry which has less than 1000 matches.\n",
      "Skipping Robotics which has less than 1000 matches.\n",
      "Skipping Travel which has less than 1000 matches.\n",
      "Skipping Technology which has less than 1000 matches.\n",
      "Skipping Travel & Hobby which has less than 1000 matches.\n",
      "Skipping Philosophy and Ethics which has less than 1000 matches.\n",
      "Skipping Theology which has less than 1000 matches.\n",
      "Skipping Anthropology which has less than 1000 matches.\n",
      "Skipping Philosophy & Religion which has less than 1000 matches.\n",
      "Skipping Urban Planning which has less than 1000 matches.\n",
      "Skipping Agriculture which has less than 1000 matches.\n",
      "Skipping Linguistics which has less than 1000 matches.\n",
      "Skipping Philosophy & Metaphysics which has less than 1000 matches.\n",
      "Skipping Psychology & Mental Health which has less than 1000 matches.\n",
      "Skipping Sociology which has less than 1000 matches.\n",
      "Skipping Architecture and construction which has less than 1000 matches.\n",
      "Skipping Industry and artisanat which has less than 1000 matches.\n",
      "Skipping Biotechnology which has less than 1000 matches.\n",
      "Skipping Marketing & Sales which has less than 1000 matches.\n",
      "Skipping Mathematics which has less than 1000 matches.\n",
      "Skipping Engineering which has less than 1000 matches.\n",
      "Skipping Ethics which has less than 1000 matches.\n"
     ]
    }
   ],
   "source": [
    "results = pipeline.run_all_categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3972e690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Education': shape: (52, 4)\n",
       " ┌─────────────────────────────────┬─────────────┬─────────────┬─────────────┐\n",
       " │ model_name                      ┆ median      ┆ p2.5        ┆ p97.5       │\n",
       " │ ---                             ┆ ---         ┆ ---         ┆ ---         │\n",
       " │ str                             ┆ f64         ┆ f64         ┆ f64         │\n",
       " ╞═════════════════════════════════╪═════════════╪═════════════╪═════════════╡\n",
       " │ gemini-2.0-flash-exp            ┆ 1174.830014 ┆ 1119.283824 ┆ 1197.937658 │\n",
       " │ gemini-1.5-pro-001              ┆ 1172.805222 ┆ 1147.142513 ┆ 1187.500813 │\n",
       " │ gemma-3-12b                     ┆ 1143.561398 ┆ 1082.717014 ┆ 1199.230465 │\n",
       " │ deepseek-v3-chat                ┆ 1133.434964 ┆ 1040.648862 ┆ 1173.601508 │\n",
       " │ deepseek-v3-0324                ┆ 1127.382791 ┆ 1085.700847 ┆ 1164.296908 │\n",
       " │ …                               ┆ …           ┆ …           ┆ …           │\n",
       " │ chocolatine-2-14b-instruct-v2.… ┆ 879.282051  ┆ 834.151667  ┆ 940.335141  │\n",
       " │ mistral-nemo-2407               ┆ 870.410157  ┆ 808.023709  ┆ 892.286118  │\n",
       " │ mixtral-8x22b-instruct-v0.1     ┆ 814.252367  ┆ 778.418067  ┆ 888.260089  │\n",
       " │ chocolatine-14b-instruct-dpo-v… ┆ 768.908172  ┆ 726.840966  ┆ 858.188179  │\n",
       " │ qwen2-7b-instruct               ┆ 759.11961   ┆ 686.883884  ┆ 804.528705  │\n",
       " └─────────────────────────────────┴─────────────┴─────────────┴─────────────┘,\n",
       " 'Arts': shape: (52, 4)\n",
       " ┌─────────────────────────────────┬─────────────┬─────────────┬─────────────┐\n",
       " │ model_name                      ┆ median      ┆ p2.5        ┆ p97.5       │\n",
       " │ ---                             ┆ ---         ┆ ---         ┆ ---         │\n",
       " │ str                             ┆ f64         ┆ f64         ┆ f64         │\n",
       " ╞═════════════════════════════════╪═════════════╪═════════════╪═════════════╡\n",
       " │ gemini-2.0-flash-001            ┆ 1131.483866 ┆ 1104.418072 ┆ 1185.327491 │\n",
       " │ command-a                       ┆ 1128.04828  ┆ 1039.923696 ┆ 1167.632511 │\n",
       " │ gemma-3-27b                     ┆ 1126.859669 ┆ 1057.822853 ┆ 1148.090431 │\n",
       " │ gemini-2.0-flash-exp            ┆ 1126.00574  ┆ 1031.869213 ┆ 1134.97131  │\n",
       " │ gemma-3-12b                     ┆ 1120.947652 ┆ 1063.330842 ┆ 1161.511251 │\n",
       " │ …                               ┆ …           ┆ …           ┆ …           │\n",
       " │ phi-3.5-mini-instruct           ┆ 863.572536  ┆ 746.761391  ┆ 940.091667  │\n",
       " │ lfm-40b                         ┆ 859.409713  ┆ 810.398555  ┆ 874.821965  │\n",
       " │ chocolatine-2-14b-instruct-v2.… ┆ 803.524255  ┆ 751.603602  ┆ 850.783132  │\n",
       " │ chocolatine-14b-instruct-dpo-v… ┆ 794.76552   ┆ 769.193918  ┆ 848.60757   │\n",
       " │ Yi-1.5-9B-Chat                  ┆ 769.693792  ┆ 763.679192  ┆ 858.091721  │\n",
       " └─────────────────────────────────┴─────────────┴─────────────┴─────────────┘,\n",
       " 'Entertainment & Travel & Hobby': shape: (52, 4)\n",
       " ┌─────────────────────────────────┬─────────────┬─────────────┬─────────────┐\n",
       " │ model_name                      ┆ median      ┆ p2.5        ┆ p97.5       │\n",
       " │ ---                             ┆ ---         ┆ ---         ┆ ---         │\n",
       " │ str                             ┆ f64         ┆ f64         ┆ f64         │\n",
       " ╞═════════════════════════════════╪═════════════╪═════════════╪═════════════╡\n",
       " │ gemini-2.0-flash-exp            ┆ 1156.265916 ┆ 1108.933478 ┆ 1210.470737 │\n",
       " │ command-a                       ┆ 1148.509331 ┆ 1128.046816 ┆ 1218.751641 │\n",
       " │ gemma-3-27b                     ┆ 1142.175751 ┆ 1051.949761 ┆ 1155.831804 │\n",
       " │ llama-3.1-nemotron-70b-instruc… ┆ 1134.356292 ┆ 1013.967998 ┆ 1163.639832 │\n",
       " │ deepseek-v3-0324                ┆ 1126.752275 ┆ 1071.818724 ┆ 1167.609342 │\n",
       " │ …                               ┆ …           ┆ …           ┆ …           │\n",
       " │ mistral-nemo-2407               ┆ 864.200909  ┆ 810.409902  ┆ 891.963834  │\n",
       " │ phi-3.5-mini-instruct           ┆ 854.690477  ┆ 829.012126  ┆ 979.959923  │\n",
       " │ qwen2-7b-instruct               ┆ 852.112746  ┆ 817.455589  ┆ 906.164281  │\n",
       " │ chocolatine-14b-instruct-dpo-v… ┆ 836.850758  ┆ 752.120018  ┆ 902.265678  │\n",
       " │ chocolatine-2-14b-instruct-v2.… ┆ 833.412061  ┆ 722.11997   ┆ 865.888951  │\n",
       " └─────────────────────────────────┴─────────────┴─────────────┴─────────────┘,\n",
       " 'Culture & Cultural geography': shape: (52, 4)\n",
       " ┌─────────────────────────────────┬─────────────┬─────────────┬─────────────┐\n",
       " │ model_name                      ┆ median      ┆ p2.5        ┆ p97.5       │\n",
       " │ ---                             ┆ ---         ┆ ---         ┆ ---         │\n",
       " │ str                             ┆ f64         ┆ f64         ┆ f64         │\n",
       " ╞═════════════════════════════════╪═════════════╪═════════════╪═════════════╡\n",
       " │ command-a                       ┆ 1173.532094 ┆ 1056.273693 ┆ 1203.362035 │\n",
       " │ gemma-3-27b                     ┆ 1140.43915  ┆ 1100.233533 ┆ 1162.399378 │\n",
       " │ gemini-2.0-flash-001            ┆ 1125.514229 ┆ 1055.927633 ┆ 1175.051714 │\n",
       " │ gemini-2.0-flash-exp            ┆ 1122.56253  ┆ 1060.609511 ┆ 1160.993574 │\n",
       " │ deepseek-v3-chat                ┆ 1106.708265 ┆ 1058.27244  ┆ 1152.45078  │\n",
       " │ …                               ┆ …           ┆ …           ┆ …           │\n",
       " │ qwen2.5-7b-instruct             ┆ 865.794122  ┆ 823.386982  ┆ 950.101511  │\n",
       " │ mistral-nemo-2407               ┆ 857.827587  ┆ 814.600142  ┆ 896.169453  │\n",
       " │ qwen2-7b-instruct               ┆ 847.978988  ┆ 805.497398  ┆ 868.521499  │\n",
       " │ mixtral-8x22b-instruct-v0.1     ┆ 835.225933  ┆ 795.718546  ┆ 954.6039    │\n",
       " │ chocolatine-14b-instruct-dpo-v… ┆ 773.679698  ┆ 606.05246   ┆ 805.242109  │\n",
       " └─────────────────────────────────┴─────────────┴─────────────┴─────────────┘,\n",
       " 'Politics & Government': shape: (52, 4)\n",
       " ┌─────────────────────────────────┬─────────────┬─────────────┬─────────────┐\n",
       " │ model_name                      ┆ median      ┆ p2.5        ┆ p97.5       │\n",
       " │ ---                             ┆ ---         ┆ ---         ┆ ---         │\n",
       " │ str                             ┆ f64         ┆ f64         ┆ f64         │\n",
       " ╞═════════════════════════════════╪═════════════╪═════════════╪═════════════╡\n",
       " │ gemini-2.0-flash-exp            ┆ 1141.218536 ┆ 1100.367597 ┆ 1144.87065  │\n",
       " │ gemini-1.5-pro-001              ┆ 1129.460824 ┆ 1040.793837 ┆ 1139.249298 │\n",
       " │ gemma-3-27b                     ┆ 1129.006909 ┆ 1082.494548 ┆ 1158.205311 │\n",
       " │ gemini-2.0-flash-001            ┆ 1123.060969 ┆ 1052.991134 ┆ 1184.781381 │\n",
       " │ deepseek-v3-chat                ┆ 1118.574649 ┆ 1000.230132 ┆ 1153.413361 │\n",
       " │ …                               ┆ …           ┆ …           ┆ …           │\n",
       " │ mistral-nemo-2407               ┆ 875.633093  ┆ 843.984207  ┆ 997.790949  │\n",
       " │ phi-3.5-mini-instruct           ┆ 842.042706  ┆ 820.701863  ┆ 924.737122  │\n",
       " │ chocolatine-2-14b-instruct-v2.… ┆ 835.677278  ┆ 783.636357  ┆ 972.857839  │\n",
       " │ mixtral-8x22b-instruct-v0.1     ┆ 826.70544   ┆ 681.447768  ┆ 875.988873  │\n",
       " │ chocolatine-14b-instruct-dpo-v… ┆ 661.933668  ┆ 625.952901  ┆ 684.578361  │\n",
       " └─────────────────────────────────┴─────────────┴─────────────┴─────────────┘,\n",
       " 'Food & Drink & Cooking': shape: (52, 4)\n",
       " ┌─────────────────────────────────┬─────────────┬─────────────┬─────────────┐\n",
       " │ model_name                      ┆ median      ┆ p2.5        ┆ p97.5       │\n",
       " │ ---                             ┆ ---         ┆ ---         ┆ ---         │\n",
       " │ str                             ┆ f64         ┆ f64         ┆ f64         │\n",
       " ╞═════════════════════════════════╪═════════════╪═════════════╪═════════════╡\n",
       " │ gemma-3-27b                     ┆ 1164.356458 ┆ 1115.372663 ┆ 1216.766881 │\n",
       " │ gemini-2.0-flash-exp            ┆ 1159.101414 ┆ 1134.519043 ┆ 1193.696663 │\n",
       " │ gemini-2.0-flash-001            ┆ 1131.545937 ┆ 1021.104502 ┆ 1231.574409 │\n",
       " │ command-a                       ┆ 1116.324323 ┆ 1084.938265 ┆ 1131.557403 │\n",
       " │ gemini-1.5-pro-001              ┆ 1115.187063 ┆ 1110.886096 ┆ 1209.967499 │\n",
       " │ …                               ┆ …           ┆ …           ┆ …           │\n",
       " │ qwen2.5-coder-32b-instruct      ┆ 852.681552  ┆ 813.263106  ┆ 952.824377  │\n",
       " │ mixtral-8x22b-instruct-v0.1     ┆ 811.140126  ┆ 792.887929  ┆ 980.023003  │\n",
       " │ chocolatine-14b-instruct-dpo-v… ┆ 804.013105  ┆ 734.258339  ┆ 948.865152  │\n",
       " │ chocolatine-2-14b-instruct-v2.… ┆ 801.339817  ┆ 644.308904  ┆ 830.437854  │\n",
       " │ mistral-nemo-2407               ┆ 790.0984    ┆ 745.434673  ┆ 883.731119  │\n",
       " └─────────────────────────────────┴─────────────┴─────────────┴─────────────┘,\n",
       " 'Law & Justice': shape: (52, 4)\n",
       " ┌─────────────────────────────────┬─────────────┬─────────────┬─────────────┐\n",
       " │ model_name                      ┆ median      ┆ p2.5        ┆ p97.5       │\n",
       " │ ---                             ┆ ---         ┆ ---         ┆ ---         │\n",
       " │ str                             ┆ f64         ┆ f64         ┆ f64         │\n",
       " ╞═════════════════════════════════╪═════════════╪═════════════╪═════════════╡\n",
       " │ gemini-2.0-flash-exp            ┆ 1205.711393 ┆ 1122.888327 ┆ 1217.429183 │\n",
       " │ deepseek-v3-chat                ┆ 1189.866264 ┆ 1151.264828 ┆ 1206.13703  │\n",
       " │ gemma-3-27b                     ┆ 1142.621045 ┆ 1003.751474 ┆ 1296.200482 │\n",
       " │ gpt-4.1-mini                    ┆ 1111.838636 ┆ 1053.483422 ┆ 1196.617846 │\n",
       " │ gemma-3-12b                     ┆ 1111.040133 ┆ 974.382336  ┆ 1159.76751  │\n",
       " │ …                               ┆ …           ┆ …           ┆ …           │\n",
       " │ qwen2-7b-instruct               ┆ 873.401036  ┆ 842.872496  ┆ 924.645779  │\n",
       " │ mixtral-8x22b-instruct-v0.1     ┆ 871.730786  ┆ 805.989064  ┆ 915.538032  │\n",
       " │ lfm-40b                         ┆ 832.467871  ┆ 795.588276  ┆ 910.786211  │\n",
       " │ chocolatine-2-14b-instruct-v2.… ┆ 809.070283  ┆ 725.459265  ┆ 869.553563  │\n",
       " │ chocolatine-14b-instruct-dpo-v… ┆ 774.752646  ┆ 702.770424  ┆ 836.949809  │\n",
       " └─────────────────────────────────┴─────────────┴─────────────┴─────────────┘,\n",
       " 'Natural Science & Formal Science & Technology': shape: (52, 4)\n",
       " ┌─────────────────────────────────┬─────────────┬─────────────┬─────────────┐\n",
       " │ model_name                      ┆ median      ┆ p2.5        ┆ p97.5       │\n",
       " │ ---                             ┆ ---         ┆ ---         ┆ ---         │\n",
       " │ str                             ┆ f64         ┆ f64         ┆ f64         │\n",
       " ╞═════════════════════════════════╪═════════════╪═════════════╪═════════════╡\n",
       " │ gemini-2.0-flash-001            ┆ 1159.220977 ┆ 1089.385621 ┆ 1220.50457  │\n",
       " │ grok-3-mini-beta                ┆ 1149.757436 ┆ 1053.200666 ┆ 1153.630566 │\n",
       " │ gemma-3-4b                      ┆ 1142.922962 ┆ 1111.63804  ┆ 1159.184669 │\n",
       " │ gemma-3-27b                     ┆ 1125.494574 ┆ 1079.32383  ┆ 1215.370766 │\n",
       " │ gemma-3-12b                     ┆ 1122.572239 ┆ 1118.805362 ┆ 1199.906394 │\n",
       " │ …                               ┆ …           ┆ …           ┆ …           │\n",
       " │ chocolatine-2-14b-instruct-v2.… ┆ 847.142914  ┆ 799.555904  ┆ 873.453815  │\n",
       " │ qwen2-7b-instruct               ┆ 824.275324  ┆ 791.708033  ┆ 899.063989  │\n",
       " │ mixtral-8x22b-instruct-v0.1     ┆ 783.119613  ┆ 746.384408  ┆ 852.704422  │\n",
       " │ Yi-1.5-9B-Chat                  ┆ 778.144745  ┆ 679.295395  ┆ 812.293198  │\n",
       " │ chocolatine-14b-instruct-dpo-v… ┆ 777.759801  ┆ 687.316705  ┆ 823.989967  │\n",
       " └─────────────────────────────────┴─────────────┴─────────────┴─────────────┘,\n",
       " 'Business & Economics & Finance': shape: (52, 4)\n",
       " ┌─────────────────────────────────┬─────────────┬─────────────┬─────────────┐\n",
       " │ model_name                      ┆ median      ┆ p2.5        ┆ p97.5       │\n",
       " │ ---                             ┆ ---         ┆ ---         ┆ ---         │\n",
       " │ str                             ┆ f64         ┆ f64         ┆ f64         │\n",
       " ╞═════════════════════════════════╪═════════════╪═════════════╪═════════════╡\n",
       " │ gemma-3-27b                     ┆ 1151.593775 ┆ 1125.974468 ┆ 1187.861561 │\n",
       " │ command-a                       ┆ 1143.584603 ┆ 1091.293516 ┆ 1157.884774 │\n",
       " │ gemini-2.0-flash-001            ┆ 1141.608766 ┆ 1079.516708 ┆ 1197.826125 │\n",
       " │ gemma-3-12b                     ┆ 1127.211685 ┆ 1027.499224 ┆ 1145.649304 │\n",
       " │ deepseek-v3-chat                ┆ 1117.989382 ┆ 1002.07215  ┆ 1208.588686 │\n",
       " │ …                               ┆ …           ┆ …           ┆ …           │\n",
       " │ hermes-3-llama-3.1-405b         ┆ 875.416129  ┆ 866.763542  ┆ 1034.084397 │\n",
       " │ phi-3.5-mini-instruct           ┆ 846.22712   ┆ 788.387079  ┆ 916.676843  │\n",
       " │ chocolatine-2-14b-instruct-v2.… ┆ 816.899501  ┆ 776.302419  ┆ 919.698117  │\n",
       " │ mixtral-8x22b-instruct-v0.1     ┆ 780.512183  ┆ 734.817667  ┆ 878.076395  │\n",
       " │ chocolatine-14b-instruct-dpo-v… ┆ 759.086642  ┆ 730.891954  ┆ 801.587636  │\n",
       " └─────────────────────────────────┴─────────────┴─────────────┴─────────────┘,\n",
       " 'Society & Social Issues & Human Rights': shape: (52, 4)\n",
       " ┌─────────────────────────────────┬─────────────┬─────────────┬─────────────┐\n",
       " │ model_name                      ┆ median      ┆ p2.5        ┆ p97.5       │\n",
       " │ ---                             ┆ ---         ┆ ---         ┆ ---         │\n",
       " │ str                             ┆ f64         ┆ f64         ┆ f64         │\n",
       " ╞═════════════════════════════════╪═════════════╪═════════════╪═════════════╡\n",
       " │ gemini-2.0-flash-exp            ┆ 1185.214734 ┆ 1157.239351 ┆ 1247.501817 │\n",
       " │ gemma-3-12b                     ┆ 1127.858647 ┆ 1029.549596 ┆ 1223.937184 │\n",
       " │ gemini-2.0-flash-001            ┆ 1102.323166 ┆ 1045.932732 ┆ 1171.013025 │\n",
       " │ gemma-3-27b                     ┆ 1101.07933  ┆ 1025.737342 ┆ 1138.645094 │\n",
       " │ command-a                       ┆ 1099.55609  ┆ 1039.758539 ┆ 1170.671837 │\n",
       " │ …                               ┆ …           ┆ …           ┆ …           │\n",
       " │ mixtral-8x22b-instruct-v0.1     ┆ 837.908283  ┆ 773.656685  ┆ 937.486495  │\n",
       " │ mistral-nemo-2407               ┆ 816.474253  ┆ 740.407324  ┆ 963.059972  │\n",
       " │ chocolatine-2-14b-instruct-v2.… ┆ 780.844586  ┆ 742.357071  ┆ 872.998895  │\n",
       " │ qwen2-7b-instruct               ┆ 762.595326  ┆ 700.780628  ┆ 807.14118   │\n",
       " │ chocolatine-14b-instruct-dpo-v… ┆ 720.497255  ┆ 657.213006  ┆ 798.926014  │\n",
       " └─────────────────────────────────┴─────────────┴─────────────┴─────────────┘,\n",
       " 'Personal Development & Human Resources & Career': shape: (52, 4)\n",
       " ┌─────────────────────────────────┬─────────────┬─────────────┬─────────────┐\n",
       " │ model_name                      ┆ median      ┆ p2.5        ┆ p97.5       │\n",
       " │ ---                             ┆ ---         ┆ ---         ┆ ---         │\n",
       " │ str                             ┆ f64         ┆ f64         ┆ f64         │\n",
       " ╞═════════════════════════════════╪═════════════╪═════════════╪═════════════╡\n",
       " │ command-a                       ┆ 1180.288483 ┆ 1117.376193 ┆ 1215.053761 │\n",
       " │ gemini-2.0-flash-exp            ┆ 1162.099344 ┆ 1108.755328 ┆ 1209.038205 │\n",
       " │ gemini-2.0-flash-001            ┆ 1161.161841 ┆ 1100.012563 ┆ 1173.578647 │\n",
       " │ claude-3-7-sonnet               ┆ 1142.580322 ┆ 1100.186459 ┆ 1153.489736 │\n",
       " │ deepseek-r1                     ┆ 1113.200883 ┆ 1013.580205 ┆ 1142.838056 │\n",
       " │ …                               ┆ …           ┆ …           ┆ …           │\n",
       " │ mixtral-8x7b-instruct-v0.1      ┆ 860.189568  ┆ 689.446228  ┆ 932.517103  │\n",
       " │ mixtral-8x22b-instruct-v0.1     ┆ 859.87316   ┆ 807.610854  ┆ 926.220896  │\n",
       " │ chocolatine-14b-instruct-dpo-v… ┆ 852.80881   ┆ 822.435897  ┆ 905.861546  │\n",
       " │ phi-3.5-mini-instruct           ┆ 841.639445  ┆ 792.191     ┆ 947.277445  │\n",
       " │ chocolatine-2-14b-instruct-v2.… ┆ 789.897654  ┆ 705.562971  ┆ 845.717035  │\n",
       " └─────────────────────────────────┴─────────────┴─────────────┴─────────────┘,\n",
       " 'Environment': shape: (52, 4)\n",
       " ┌─────────────────────────────────┬─────────────┬─────────────┬─────────────┐\n",
       " │ model_name                      ┆ median      ┆ p2.5        ┆ p97.5       │\n",
       " │ ---                             ┆ ---         ┆ ---         ┆ ---         │\n",
       " │ str                             ┆ f64         ┆ f64         ┆ f64         │\n",
       " ╞═════════════════════════════════╪═════════════╪═════════════╪═════════════╡\n",
       " │ deepseek-v3-chat                ┆ 1165.8095   ┆ 1076.955813 ┆ 1190.184967 │\n",
       " │ gemma-3-27b                     ┆ 1139.096606 ┆ 1081.727335 ┆ 1216.521854 │\n",
       " │ gemini-1.5-pro-001              ┆ 1134.340869 ┆ 996.717088  ┆ 1178.786653 │\n",
       " │ gemma-3-4b                      ┆ 1133.882048 ┆ 1107.127245 ┆ 1234.14489  │\n",
       " │ llama-3.1-nemotron-70b-instruc… ┆ 1133.087879 ┆ 983.86134   ┆ 1186.42499  │\n",
       " │ …                               ┆ …           ┆ …           ┆ …           │\n",
       " │ chocolatine-14b-instruct-dpo-v… ┆ 891.061129  ┆ 795.788231  ┆ 908.32278   │\n",
       " │ mistral-nemo-2407               ┆ 881.539751  ┆ 808.150608  ┆ 939.251128  │\n",
       " │ mixtral-8x7b-instruct-v0.1      ┆ 877.160355  ┆ 753.061285  ┆ 961.915515  │\n",
       " │ mixtral-8x22b-instruct-v0.1     ┆ 844.1004    ┆ 805.724958  ┆ 948.870227  │\n",
       " │ chocolatine-2-14b-instruct-v2.… ┆ 834.580587  ┆ 792.942723  ┆ 903.660609  │\n",
       " └─────────────────────────────────┴─────────────┴─────────────┴─────────────┘,\n",
       " 'Health & Wellness & Medicine': shape: (52, 4)\n",
       " ┌─────────────────────────────────┬─────────────┬─────────────┬─────────────┐\n",
       " │ model_name                      ┆ median      ┆ p2.5        ┆ p97.5       │\n",
       " │ ---                             ┆ ---         ┆ ---         ┆ ---         │\n",
       " │ str                             ┆ f64         ┆ f64         ┆ f64         │\n",
       " ╞═════════════════════════════════╪═════════════╪═════════════╪═════════════╡\n",
       " │ gemini-2.0-flash-exp            ┆ 1149.746171 ┆ 1097.975386 ┆ 1177.322373 │\n",
       " │ gemma-3-12b                     ┆ 1142.828452 ┆ 1135.486968 ┆ 1189.637969 │\n",
       " │ gemma-3-27b                     ┆ 1130.831009 ┆ 1091.119061 ┆ 1158.509725 │\n",
       " │ deepseek-v3-0324                ┆ 1117.867067 ┆ 1035.967981 ┆ 1141.772825 │\n",
       " │ command-a                       ┆ 1116.166165 ┆ 1053.958037 ┆ 1202.514157 │\n",
       " │ …                               ┆ …           ┆ …           ┆ …           │\n",
       " │ mixtral-8x22b-instruct-v0.1     ┆ 861.578043  ┆ 813.26641   ┆ 909.286811  │\n",
       " │ lfm-40b                         ┆ 861.282724  ┆ 834.767578  ┆ 913.060859  │\n",
       " │ mixtral-8x7b-instruct-v0.1      ┆ 841.872277  ┆ 822.230273  ┆ 911.105447  │\n",
       " │ chocolatine-2-14b-instruct-v2.… ┆ 819.567062  ┆ 786.597538  ┆ 947.986945  │\n",
       " │ chocolatine-14b-instruct-dpo-v… ┆ 796.818391  ┆ 778.189484  ┆ 885.366835  │\n",
       " └─────────────────────────────────┴─────────────┴─────────────┴─────────────┘}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04843dbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
