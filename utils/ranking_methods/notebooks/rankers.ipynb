{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calcul de scores à partir du jeu de données `comparia`\n",
    "\n",
    "Dans ce notebook nous illustrons l'utilisation des classes `Ranker` pour calculer des scores à partir des données `comparia`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "cache_dir = input(\"Indicate path to all Hugging Face caches:\")\n",
    "os.environ[\"HF_DATASETS_CACHE\"] = cache_dir\n",
    "os.environ[\"HF_HUB_CACHE\"] = cache_dir\n",
    "os.environ[\"HF_TOKEN\"] = getpass(\"Enter your HuggingFace token:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since ministere-culture/comparia-reactions couldn't be found on the Hugging Face Hub (offline mode is enabled).\n",
      "Found the latest cached dataset configuration 'default' at /home/jupyterhub-users/shared/projet_comparia/huggingface_hub/ministere-culture___comparia-reactions/default/0.0.0/80befa851337d9f295096cef3d100b40d220dc07 (last modified on Mon Jul 28 10:06:54 2025).\n",
      "Using the latest cached version of the dataset since ministere-culture/comparia-conversations couldn't be found on the Hugging Face Hub (offline mode is enabled).\n",
      "Found the latest cached dataset configuration 'default' at /home/jupyterhub-users/shared/projet_comparia/huggingface_hub/ministere-culture___comparia-conversations/default/0.0.0/dc40af6af1c14e68bf39d55f6e1573d2d6582f19 (last modified on Wed Jun  4 17:40:30 2025).\n"
     ]
    }
   ],
   "source": [
    "from rank_comparia.utils import load_comparia\n",
    "\n",
    "reactions = load_comparia(\"ministere-culture/comparia-reactions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mise en forme des données\n",
    "\n",
    "Ici nous utilisons des fonctions *legacy* avec une heuristique simple pour déterminer le résultat d'un *match* (une paire de conversation) à partir des réactions associées. On soustrait le nombre de réactions négatives au nombre de réactions positives pour chaque modèle. Le modèle avec la différence la plus élevée est vainqueur du match. Si les différences sont identiques pour les deux modèle, le *match* est une égalité (on filtre les égalités dans la fonction `get_winners`).   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model_a_name</th><th>model_b_name</th><th>conversation_pair_id</th><th>score_a</th><th>score_b</th></tr><tr><td>str</td><td>str</td><td>str</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>&quot;gpt-4o-2024-08-06&quot;</td><td>&quot;gemini-2.0-flash-exp&quot;</td><td>&quot;a9d7ba9f60914ca3807fb9534834b9…</td><td>-2</td><td>2</td></tr><tr><td>&quot;llama-3.3-70b&quot;</td><td>&quot;c4ai-command-r-08-2024&quot;</td><td>&quot;778cd8622030442db5a52c82a8ce35…</td><td>-2</td><td>-2</td></tr><tr><td>&quot;gemma-2-9b-it&quot;</td><td>&quot;llama-3.3-70b&quot;</td><td>&quot;dad8a77a13754042994d06dab41b11…</td><td>2</td><td>-1</td></tr><tr><td>&quot;deepseek-v3-chat&quot;</td><td>&quot;claude-3-5-sonnet-v2&quot;</td><td>&quot;26accee6499848d599d152723533d8…</td><td>2</td><td>0</td></tr><tr><td>&quot;gemini-2.0-flash-exp&quot;</td><td>&quot;mistral-large-2411&quot;</td><td>&quot;ea434cd5413c4b2ea5c00acb5bc133…</td><td>1</td><td>-1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 5)\n",
       "┌──────────────────────┬────────────────────────┬──────────────────────────────┬─────────┬─────────┐\n",
       "│ model_a_name         ┆ model_b_name           ┆ conversation_pair_id         ┆ score_a ┆ score_b │\n",
       "│ ---                  ┆ ---                    ┆ ---                          ┆ ---     ┆ ---     │\n",
       "│ str                  ┆ str                    ┆ str                          ┆ i64     ┆ i64     │\n",
       "╞══════════════════════╪════════════════════════╪══════════════════════════════╪═════════╪═════════╡\n",
       "│ gpt-4o-2024-08-06    ┆ gemini-2.0-flash-exp   ┆ a9d7ba9f60914ca3807fb9534834 ┆ -2      ┆ 2       │\n",
       "│                      ┆                        ┆ b9…                          ┆         ┆         │\n",
       "│ llama-3.3-70b        ┆ c4ai-command-r-08-2024 ┆ 778cd8622030442db5a52c82a8ce ┆ -2      ┆ -2      │\n",
       "│                      ┆                        ┆ 35…                          ┆         ┆         │\n",
       "│ gemma-2-9b-it        ┆ llama-3.3-70b          ┆ dad8a77a13754042994d06dab41b ┆ 2       ┆ -1      │\n",
       "│                      ┆                        ┆ 11…                          ┆         ┆         │\n",
       "│ deepseek-v3-chat     ┆ claude-3-5-sonnet-v2   ┆ 26accee6499848d599d152723533 ┆ 2       ┆ 0       │\n",
       "│                      ┆                        ┆ d8…                          ┆         ┆         │\n",
       "│ gemini-2.0-flash-exp ┆ mistral-large-2411     ┆ ea434cd5413c4b2ea5c00acb5bc1 ┆ 1       ┆ -1      │\n",
       "│                      ┆                        ┆ 33…                          ┆         ┆         │\n",
       "└──────────────────────┴────────────────────────┴──────────────────────────────┴─────────┴─────────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rank_comparia.data_transformation import get_matches_with_score, get_winners, get_winrates\n",
    "\n",
    "matches = get_matches_with_score(reactions)\n",
    "\n",
    "matches.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "winners = get_winners(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On calcule des taux de victoire par modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (48, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model_name</th><th>len</th><th>wins</th><th>winrate</th></tr><tr><td>str</td><td>u32</td><td>u32</td><td>f64</td></tr></thead><tbody><tr><td>&quot;gemini-2.0-flash-exp&quot;</td><td>856</td><td>647</td><td>75.584112</td></tr><tr><td>&quot;deepseek-v3-chat&quot;</td><td>1530</td><td>1080</td><td>70.588235</td></tr><tr><td>&quot;gemma-3-27b&quot;</td><td>495</td><td>348</td><td>70.30303</td></tr><tr><td>&quot;gemini-2.0-flash-001&quot;</td><td>688</td><td>480</td><td>69.767442</td></tr><tr><td>&quot;gemini-1.5-pro-001&quot;</td><td>328</td><td>222</td><td>67.682927</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;mixtral-8x7b-instruct-v0.1&quot;</td><td>585</td><td>222</td><td>37.948718</td></tr><tr><td>&quot;lfm-40b&quot;</td><td>887</td><td>321</td><td>36.189402</td></tr><tr><td>&quot;mixtral-8x22b-instruct-v0.1&quot;</td><td>1459</td><td>445</td><td>30.500343</td></tr><tr><td>&quot;mistral-nemo-2407&quot;</td><td>1461</td><td>435</td><td>29.774127</td></tr><tr><td>&quot;chocolatine-2-14b-instruct-v2.…</td><td>499</td><td>127</td><td>25.450902</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (48, 4)\n",
       "┌─────────────────────────────────┬──────┬──────┬───────────┐\n",
       "│ model_name                      ┆ len  ┆ wins ┆ winrate   │\n",
       "│ ---                             ┆ ---  ┆ ---  ┆ ---       │\n",
       "│ str                             ┆ u32  ┆ u32  ┆ f64       │\n",
       "╞═════════════════════════════════╪══════╪══════╪═══════════╡\n",
       "│ gemini-2.0-flash-exp            ┆ 856  ┆ 647  ┆ 75.584112 │\n",
       "│ deepseek-v3-chat                ┆ 1530 ┆ 1080 ┆ 70.588235 │\n",
       "│ gemma-3-27b                     ┆ 495  ┆ 348  ┆ 70.30303  │\n",
       "│ gemini-2.0-flash-001            ┆ 688  ┆ 480  ┆ 69.767442 │\n",
       "│ gemini-1.5-pro-001              ┆ 328  ┆ 222  ┆ 67.682927 │\n",
       "│ …                               ┆ …    ┆ …    ┆ …         │\n",
       "│ mixtral-8x7b-instruct-v0.1      ┆ 585  ┆ 222  ┆ 37.948718 │\n",
       "│ lfm-40b                         ┆ 887  ┆ 321  ┆ 36.189402 │\n",
       "│ mixtral-8x22b-instruct-v0.1     ┆ 1459 ┆ 445  ┆ 30.500343 │\n",
       "│ mistral-nemo-2407               ┆ 1461 ┆ 435  ┆ 29.774127 │\n",
       "│ chocolatine-2-14b-instruct-v2.… ┆ 499  ┆ 127  ┆ 25.450902 │\n",
       "└─────────────────────────────────┴──────┴──────┴───────────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "winrates = get_winrates(winners)\n",
    "winrates.sort(\"winrate\", descending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcul des scores\n",
    "\n",
    "Pour chaque *match* on calcule un score, on mélange les matchs et on les ajoute un par un à un `ELORanker` qui met à jour les scores à chaque ajout de match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_comparia.elo import ELORanker\n",
    "from rank_comparia.ranker import Match, MatchScore\n",
    "import random\n",
    "\n",
    "\n",
    "def compute_match_score(score_a: int, score_b: int) -> MatchScore:\n",
    "    final_score = score_b - score_a\n",
    "    if final_score > 0:\n",
    "        return MatchScore.B\n",
    "    elif final_score < 0:\n",
    "        return MatchScore.A\n",
    "    else:\n",
    "        return MatchScore.Draw\n",
    "\n",
    "\n",
    "def get_shuffled_results(matches: list[Match], model_names: list[str], seed: int = 0):\n",
    "    random.seed(seed)\n",
    "    ranker_shuffle = ELORanker(K=40)\n",
    "    matches_shuffle = random.sample(matches, k=len(matches))\n",
    "    ranker_shuffle.add_players(model_names)\n",
    "    ranker_shuffle.compute_scores(matches=matches_shuffle)\n",
    "    return ranker_shuffle.players"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "100 sets de scores sont calculés avec des ordres d'ajout des matchs différents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = set(matches[\"model_a_name\"].unique()) | set(matches[\"model_b_name\"].unique())\n",
    "matches = [\n",
    "    Match(\n",
    "        match_dict[\"model_a_name\"],\n",
    "        match_dict[\"model_b_name\"],\n",
    "        compute_match_score(match_dict[\"score_a\"], match_dict[\"score_b\"]),\n",
    "    )\n",
    "    for match_dict in matches.to_dicts()\n",
    "]\n",
    "\n",
    "player_results = {\n",
    "    seed: get_shuffled_results(matches=matches, model_names=model_names, seed=seed) for seed in range(100)  # type: ignore\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les scores moyens sont calculés:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_avg_ranking = {\n",
    "    player_name: sum(results[player_name] for results in player_results.values()) / 100 for player_name in model_names\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gemini-2.0-flash-exp : 1147.9599849089927\n",
      "gemini-2.0-flash-001 : 1143.8844295922418\n",
      "gemma-3-27b : 1143.6980445411996\n",
      "deepseek-v3-chat : 1118.4919941658666\n",
      "deepseek-v3-0324 : 1117.7935322007172\n",
      "claude-3-7-sonnet : 1109.6578565056934\n",
      "command-a : 1103.506541041654\n",
      "gpt-4.1-mini : 1089.0134217999946\n",
      "gemma-3-12b : 1087.4332177526528\n",
      "llama-3.1-nemotron-70b-instruct : 1082.8862324152165\n",
      "deepseek-r1 : 1067.707567154525\n",
      "grok-3-mini-beta : 1064.5175499116738\n",
      "gemini-1.5-pro-002 : 1059.2637543153353\n",
      "gemma-3-4b : 1051.2248313858229\n",
      "gemini-1.5-pro-001 : 1039.7767494567863\n",
      "llama-4-scout : 1038.538638236755\n",
      "mistral-small-3.1-24b : 1034.7727254076663\n",
      "mistral-large-2411 : 1031.9773440478325\n",
      "o4-mini : 1007.7047558790124\n",
      "claude-3-5-sonnet-v2 : 999.6028528708318\n",
      "o3-mini : 998.0999711625981\n",
      "gpt-4o-mini-2024-07-18 : 997.3395258174513\n",
      "mistral-saba : 996.1870618799895\n",
      "llama-3.1-405b : 993.7309560027419\n",
      "llama-3.3-70b : 989.636112392419\n",
      "jamba-1.5-large : 986.4594007385728\n",
      "gpt-4.1-nano : 983.3776018378088\n",
      "mistral-small-24b-instruct-2501 : 982.9616223037737\n",
      "gpt-4o-2024-08-06 : 981.1266766957326\n",
      "phi-4 : 977.8136224446964\n",
      "gemma-2-27b-it-q8 : 974.1055989595812\n",
      "llama-3.1-70b : 973.2780238449875\n",
      "gemma-2-9b-it : 968.3261716255413\n",
      "deepseek-r1-distill-llama-70b : 962.7050792114051\n",
      "qwq-32b : 962.0140499035485\n",
      "ministral-8b-instruct-2410 : 956.891594297965\n",
      "aya-expanse-8b : 952.2027814722511\n",
      "hermes-3-llama-3.1-405b : 936.5385138474585\n",
      "c4ai-command-r-08-2024 : 932.4539485847798\n",
      "qwen2.5-coder-32b-instruct : 927.882948649687\n",
      "llama-3.1-8b : 925.7919017021885\n",
      "qwen2.5-7b-instruct : 913.6410574894802\n",
      "lfm-40b : 896.0662711264247\n",
      "phi-3.5-mini-instruct : 887.9520930472265\n",
      "mixtral-8x7b-instruct-v0.1 : 875.1771554477399\n",
      "mixtral-8x22b-instruct-v0.1 : 855.4803804192389\n",
      "mistral-nemo-2407 : 849.0714300317132\n",
      "chocolatine-2-14b-instruct-v2.0.3-q8 : 824.2764254725338\n"
     ]
    }
   ],
   "source": [
    "for player, ranking in sorted(players_avg_ranking.items(), key=lambda x: -x[1]):\n",
    "    print(f\"{player} : {ranking}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deux calculs des scores avec des ordres de matchs différents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'deepseek-v3-chat': 1222.3659076645158,\n",
       " 'deepseek-v3-0324': 1160.022327528974,\n",
       " 'gemma-3-27b': 1148.2471033702627,\n",
       " 'llama-3.1-nemotron-70b-instruct': 1129.19821147745,\n",
       " 'grok-3-mini-beta': 1129.1226774110612,\n",
       " 'claude-3-7-sonnet': 1110.4562506943903,\n",
       " 'gemini-2.0-flash-001': 1093.4435764629218,\n",
       " 'gemma-3-12b': 1093.4037570373907,\n",
       " 'llama-4-scout': 1080.9682101315454,\n",
       " 'llama-3.1-70b': 1073.1794687278423,\n",
       " 'gpt-4o-2024-08-06': 1066.928754250905,\n",
       " 'gpt-4o-mini-2024-07-18': 1054.3153814444802,\n",
       " 'o4-mini': 1052.2915707673058,\n",
       " 'deepseek-r1': 1042.1160324385348,\n",
       " 'gemini-2.0-flash-exp': 1040.7819248617755,\n",
       " 'gpt-4.1-mini': 1039.8891571909273,\n",
       " 'gemini-1.5-pro-002': 1030.0832258204975,\n",
       " 'gpt-4.1-nano': 1025.5068295180092,\n",
       " 'mistral-large-2411': 1010.2553504632021,\n",
       " 'o3-mini': 1008.0472387426064,\n",
       " 'gemma-3-4b': 1007.8624774286593,\n",
       " 'jamba-1.5-large': 1003.3622032217606,\n",
       " 'gemma-2-27b-it-q8': 1002.9330250557166,\n",
       " 'qwq-32b': 998.4497816797184,\n",
       " 'claude-3-5-sonnet-v2': 997.1559291576199,\n",
       " 'ministral-8b-instruct-2410': 995.7813264653023,\n",
       " 'command-a': 984.1623432208445,\n",
       " 'llama-3.1-405b': 978.0020750395363,\n",
       " 'gemma-2-9b-it': 977.9651843292951,\n",
       " 'mistral-small-3.1-24b': 975.7298679812984,\n",
       " 'qwen2.5-7b-instruct': 970.2075013060436,\n",
       " 'llama-3.3-70b': 969.1742413168711,\n",
       " 'mistral-small-24b-instruct-2501': 969.134822717865,\n",
       " 'mistral-saba': 966.6506673705385,\n",
       " 'c4ai-command-r-08-2024': 966.2334691505982,\n",
       " 'gemini-1.5-pro-001': 959.1019050120647,\n",
       " 'llama-3.1-8b': 957.9243220929125,\n",
       " 'phi-4': 956.4012533515511,\n",
       " 'phi-3.5-mini-instruct': 950.9531995566324,\n",
       " 'deepseek-r1-distill-llama-70b': 944.0597697560625,\n",
       " 'qwen2.5-coder-32b-instruct': 924.1634154726263,\n",
       " 'mixtral-8x22b-instruct-v0.1': 911.5202479363402,\n",
       " 'lfm-40b': 911.0412988825592,\n",
       " 'hermes-3-llama-3.1-405b': 904.7375365910876,\n",
       " 'chocolatine-2-14b-instruct-v2.0.3-q8': 875.5855190080798,\n",
       " 'mixtral-8x7b-instruct-v0.1': 824.4274366083478,\n",
       " 'aya-expanse-8b': 792.7188831267941,\n",
       " 'mistral-nemo-2407': 713.9373411586773}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranker_shuffle = ELORanker(K=40)\n",
    "\n",
    "random.seed(42)\n",
    "matches_shuffle = random.sample(matches, k=len(matches))\n",
    "ranker_shuffle.add_players(model_names)  # type: ignore\n",
    "ranker_shuffle.compute_scores(matches=matches_shuffle)\n",
    "ranker_shuffle.get_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gemini-2.0-flash-001': 1209.8342618515323,\n",
       " 'gemma-3-27b': 1195.8299467148802,\n",
       " 'deepseek-v3-chat': 1139.0750302684273,\n",
       " 'mistral-small-3.1-24b': 1138.0141516770327,\n",
       " 'deepseek-v3-0324': 1129.758660061055,\n",
       " 'gemini-2.0-flash-exp': 1118.4754331032336,\n",
       " 'claude-3-7-sonnet': 1116.0175756795334,\n",
       " 'deepseek-r1': 1114.1205449381769,\n",
       " 'llama-3.1-nemotron-70b-instruct': 1081.1405222523958,\n",
       " 'command-a': 1076.0820191004175,\n",
       " 'llama-3.3-70b': 1063.9149934964255,\n",
       " 'claude-3-5-sonnet-v2': 1059.8741758182616,\n",
       " 'llama-3.1-70b': 1054.1928910862732,\n",
       " 'grok-3-mini-beta': 1052.6146703291633,\n",
       " 'gemma-3-12b': 1046.9029354750498,\n",
       " 'mistral-small-24b-instruct-2501': 1046.6210369707717,\n",
       " 'llama-4-scout': 1028.7571908209454,\n",
       " 'gpt-4.1-nano': 1019.2522832667461,\n",
       " 'gpt-4.1-mini': 1015.7552936399269,\n",
       " 'gemini-1.5-pro-002': 1013.8739456511503,\n",
       " 'gemini-1.5-pro-001': 1008.0056676253727,\n",
       " 'gemma-3-4b': 1004.4250174730746,\n",
       " 'phi-4': 1002.1162429467676,\n",
       " 'o3-mini': 999.0945843715662,\n",
       " 'gpt-4o-mini-2024-07-18': 995.9347665452992,\n",
       " 'llama-3.1-8b': 994.6508169691466,\n",
       " 'deepseek-r1-distill-llama-70b': 986.6627099247204,\n",
       " 'gemma-2-27b-it-q8': 981.1827771111572,\n",
       " 'aya-expanse-8b': 977.0945430327089,\n",
       " 'qwen2.5-coder-32b-instruct': 974.3091536547606,\n",
       " 'o4-mini': 972.2460238803544,\n",
       " 'gpt-4o-2024-08-06': 971.5837148923201,\n",
       " 'llama-3.1-405b': 963.9641762158794,\n",
       " 'jamba-1.5-large': 952.9700285541841,\n",
       " 'qwq-32b': 944.5297817414141,\n",
       " 'mistral-large-2411': 942.5679439025953,\n",
       " 'mistral-saba': 935.3426072434145,\n",
       " 'c4ai-command-r-08-2024': 917.5923644171861,\n",
       " 'phi-3.5-mini-instruct': 915.180180347763,\n",
       " 'lfm-40b': 912.2240752955782,\n",
       " 'ministral-8b-instruct-2410': 901.3488428303233,\n",
       " 'gemma-2-9b-it': 889.4300892869919,\n",
       " 'mixtral-8x22b-instruct-v0.1': 868.0331184589245,\n",
       " 'qwen2.5-7b-instruct': 867.4347010520095,\n",
       " 'chocolatine-2-14b-instruct-v2.0.3-q8': 860.6595549514665,\n",
       " 'mixtral-8x7b-instruct-v0.1': 857.0433436660697,\n",
       " 'hermes-3-llama-3.1-405b': 856.0273898409255,\n",
       " 'mistral-nemo-2407': 828.2382215666299}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranker_shuffle = ELORanker(K=40)\n",
    "\n",
    "random.seed(1337)\n",
    "matches_shuffle = random.sample(matches, k=len(matches))\n",
    "ranker_shuffle.add_players(model_names)  # type: ignore\n",
    "ranker_shuffle.compute_scores(matches=matches_shuffle)\n",
    "ranker_shuffle.get_scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilisation d'un Ranker par maximum de vraisemblance\n",
    "\n",
    "Ici on calcule les scores avec un `Ranker` alternatif, défini dans `src/rank_comparia/maximum_likelihood.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gemini-2.0-flash-exp': np.float64(1143.1512358130012),\n",
       " 'gemma-3-27b': np.float64(1136.3184203836174),\n",
       " 'gemini-2.0-flash-001': np.float64(1133.400570032988),\n",
       " 'deepseek-v3-chat': np.float64(1114.0328789363393),\n",
       " 'deepseek-v3-0324': np.float64(1113.2067915235539),\n",
       " 'claude-3-7-sonnet': np.float64(1105.1612084450092),\n",
       " 'command-a': np.float64(1101.8786858020478),\n",
       " 'gpt-4.1-mini': np.float64(1093.6685242271394),\n",
       " 'gemma-3-12b': np.float64(1081.4653106195133),\n",
       " 'llama-3.1-nemotron-70b-instruct': np.float64(1078.196872612909),\n",
       " 'grok-3-mini-beta': np.float64(1071.2724072426324),\n",
       " 'deepseek-r1': np.float64(1064.2931624791943),\n",
       " 'gemma-3-4b': np.float64(1055.3168065207053),\n",
       " 'gemini-1.5-pro-002': np.float64(1047.884270532969),\n",
       " 'llama-4-scout': np.float64(1038.2019664020102),\n",
       " 'gemini-1.5-pro-001': np.float64(1037.4923002507746),\n",
       " 'mistral-small-3.1-24b': np.float64(1030.0445144875346),\n",
       " 'mistral-large-2411': np.float64(1028.6925455484807),\n",
       " 'o3-mini': np.float64(1006.2210001085826),\n",
       " 'claude-3-5-sonnet-v2': np.float64(1002.9586930415215),\n",
       " 'o4-mini': np.float64(1002.2210887330519),\n",
       " 'gpt-4o-mini-2024-07-18': np.float64(999.3491370088385),\n",
       " 'mistral-saba': np.float64(996.2399607255587),\n",
       " 'gpt-4o-2024-08-06': np.float64(993.5576631670547),\n",
       " 'llama-3.3-70b': np.float64(990.765165414004),\n",
       " 'llama-3.1-405b': np.float64(990.3338930578011),\n",
       " 'gpt-4.1-nano': np.float64(987.580492343384),\n",
       " 'jamba-1.5-large': np.float64(985.7386697199976),\n",
       " 'mistral-small-24b-instruct-2501': np.float64(985.0343495551712),\n",
       " 'phi-4': np.float64(980.6013968645213),\n",
       " 'gemma-2-27b-it-q8': np.float64(974.6081627145344),\n",
       " 'llama-3.1-70b': np.float64(968.6630865442116),\n",
       " 'gemma-2-9b-it': np.float64(967.0569404993886),\n",
       " 'deepseek-r1-distill-llama-70b': np.float64(961.7384805979112),\n",
       " 'aya-expanse-8b': np.float64(960.6598616976838),\n",
       " 'qwq-32b': np.float64(958.2356609829194),\n",
       " 'ministral-8b-instruct-2410': np.float64(957.8237000706683),\n",
       " 'hermes-3-llama-3.1-405b': np.float64(939.7716775444147),\n",
       " 'c4ai-command-r-08-2024': np.float64(934.8510999183768),\n",
       " 'llama-3.1-8b': np.float64(928.9460566541117),\n",
       " 'qwen2.5-coder-32b-instruct': np.float64(927.4127141222015),\n",
       " 'qwen2.5-7b-instruct': np.float64(912.2611208222494),\n",
       " 'lfm-40b': np.float64(896.5231395095763),\n",
       " 'phi-3.5-mini-instruct': np.float64(889.3352897771736),\n",
       " 'mixtral-8x7b-instruct-v0.1': np.float64(883.6849028582083),\n",
       " 'mixtral-8x22b-instruct-v0.1': np.float64(859.7838306178774),\n",
       " 'mistral-nemo-2407': np.float64(855.2771876657266),\n",
       " 'chocolatine-2-14b-instruct-v2.0.3-q8': np.float64(829.08710580286)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rank_comparia.maximum_likelihood import MaximumLikelihoodRanker\n",
    "\n",
    "ranker = MaximumLikelihoodRanker()\n",
    "ranker.compute_scores(matches=matches)\n",
    "ranker.get_scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les classes `Ranker` ont une méthode `compute_boostrap_scores` qui permettent de calculer des scores et intervalles de confiance bootstrap (les matchs qui servent au calcul des scores pour chaque échantillon bootstrap sont issus de ré-échantillonages avec remise de l'échantillon de matchs initial). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing bootstrap scores from a sample of 22993 matches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing bootstrap samples: 100%|██████████| 100/100 [00:04<00:00, 21.52it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (48, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model_name</th><th>median</th><th>p2.5</th><th>p97.5</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;gemini-2.0-flash-exp&quot;</td><td>1153.390147</td><td>1031.890169</td><td>1244.877391</td></tr><tr><td>&quot;gemini-2.0-flash-001&quot;</td><td>1152.431767</td><td>1052.093245</td><td>1251.837456</td></tr><tr><td>&quot;gemma-3-27b&quot;</td><td>1134.143863</td><td>1041.371622</td><td>1231.061902</td></tr><tr><td>&quot;deepseek-v3-chat&quot;</td><td>1123.290963</td><td>1018.621306</td><td>1233.623067</td></tr><tr><td>&quot;deepseek-v3-0324&quot;</td><td>1114.157011</td><td>1011.227499</td><td>1207.584693</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;mixtral-8x7b-instruct-v0.1&quot;</td><td>896.434294</td><td>771.549341</td><td>983.017173</td></tr><tr><td>&quot;phi-3.5-mini-instruct&quot;</td><td>871.098077</td><td>783.43975</td><td>996.576985</td></tr><tr><td>&quot;mixtral-8x22b-instruct-v0.1&quot;</td><td>847.277576</td><td>759.236246</td><td>984.498975</td></tr><tr><td>&quot;mistral-nemo-2407&quot;</td><td>846.145031</td><td>737.419622</td><td>963.055363</td></tr><tr><td>&quot;chocolatine-2-14b-instruct-v2.…</td><td>813.56509</td><td>735.185539</td><td>919.373315</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (48, 4)\n",
       "┌─────────────────────────────────┬─────────────┬─────────────┬─────────────┐\n",
       "│ model_name                      ┆ median      ┆ p2.5        ┆ p97.5       │\n",
       "│ ---                             ┆ ---         ┆ ---         ┆ ---         │\n",
       "│ str                             ┆ f64         ┆ f64         ┆ f64         │\n",
       "╞═════════════════════════════════╪═════════════╪═════════════╪═════════════╡\n",
       "│ gemini-2.0-flash-exp            ┆ 1153.390147 ┆ 1031.890169 ┆ 1244.877391 │\n",
       "│ gemini-2.0-flash-001            ┆ 1152.431767 ┆ 1052.093245 ┆ 1251.837456 │\n",
       "│ gemma-3-27b                     ┆ 1134.143863 ┆ 1041.371622 ┆ 1231.061902 │\n",
       "│ deepseek-v3-chat                ┆ 1123.290963 ┆ 1018.621306 ┆ 1233.623067 │\n",
       "│ deepseek-v3-0324                ┆ 1114.157011 ┆ 1011.227499 ┆ 1207.584693 │\n",
       "│ …                               ┆ …           ┆ …           ┆ …           │\n",
       "│ mixtral-8x7b-instruct-v0.1      ┆ 896.434294  ┆ 771.549341  ┆ 983.017173  │\n",
       "│ phi-3.5-mini-instruct           ┆ 871.098077  ┆ 783.43975   ┆ 996.576985  │\n",
       "│ mixtral-8x22b-instruct-v0.1     ┆ 847.277576  ┆ 759.236246  ┆ 984.498975  │\n",
       "│ mistral-nemo-2407               ┆ 846.145031  ┆ 737.419622  ┆ 963.055363  │\n",
       "│ chocolatine-2-14b-instruct-v2.… ┆ 813.56509   ┆ 735.185539  ┆ 919.373315  │\n",
       "└─────────────────────────────────┴─────────────┴─────────────┴─────────────┘"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranker = ELORanker(K=40)\n",
    "\n",
    "ranker.add_players(model_names)  # type: ignore\n",
    "scores = ranker.compute_bootstrap_scores(matches=matches)\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing bootstrap scores from a sample of 22993 matches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing bootstrap samples: 100%|██████████| 100/100 [00:06<00:00, 14.87it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (48, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model_name</th><th>median</th><th>p2.5</th><th>p97.5</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;gemini-2.0-flash-exp&quot;</td><td>1141.046782</td><td>1118.549819</td><td>1161.670632</td></tr><tr><td>&quot;gemma-3-27b&quot;</td><td>1137.791747</td><td>1110.83339</td><td>1168.632882</td></tr><tr><td>&quot;gemini-2.0-flash-001&quot;</td><td>1136.193398</td><td>1112.836702</td><td>1155.937855</td></tr><tr><td>&quot;deepseek-v3-chat&quot;</td><td>1115.718863</td><td>1097.233955</td><td>1131.381339</td></tr><tr><td>&quot;deepseek-v3-0324&quot;</td><td>1110.786993</td><td>1074.965941</td><td>1157.845912</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;phi-3.5-mini-instruct&quot;</td><td>890.608256</td><td>851.020407</td><td>915.327981</td></tr><tr><td>&quot;mixtral-8x7b-instruct-v0.1&quot;</td><td>886.7996</td><td>860.324786</td><td>910.511334</td></tr><tr><td>&quot;mixtral-8x22b-instruct-v0.1&quot;</td><td>858.512945</td><td>843.320127</td><td>875.31544</td></tr><tr><td>&quot;mistral-nemo-2407&quot;</td><td>854.711631</td><td>835.924169</td><td>869.653397</td></tr><tr><td>&quot;chocolatine-2-14b-instruct-v2.…</td><td>830.391766</td><td>798.721338</td><td>857.784509</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (48, 4)\n",
       "┌─────────────────────────────────┬─────────────┬─────────────┬─────────────┐\n",
       "│ model_name                      ┆ median      ┆ p2.5        ┆ p97.5       │\n",
       "│ ---                             ┆ ---         ┆ ---         ┆ ---         │\n",
       "│ str                             ┆ f64         ┆ f64         ┆ f64         │\n",
       "╞═════════════════════════════════╪═════════════╪═════════════╪═════════════╡\n",
       "│ gemini-2.0-flash-exp            ┆ 1141.046782 ┆ 1118.549819 ┆ 1161.670632 │\n",
       "│ gemma-3-27b                     ┆ 1137.791747 ┆ 1110.83339  ┆ 1168.632882 │\n",
       "│ gemini-2.0-flash-001            ┆ 1136.193398 ┆ 1112.836702 ┆ 1155.937855 │\n",
       "│ deepseek-v3-chat                ┆ 1115.718863 ┆ 1097.233955 ┆ 1131.381339 │\n",
       "│ deepseek-v3-0324                ┆ 1110.786993 ┆ 1074.965941 ┆ 1157.845912 │\n",
       "│ …                               ┆ …           ┆ …           ┆ …           │\n",
       "│ phi-3.5-mini-instruct           ┆ 890.608256  ┆ 851.020407  ┆ 915.327981  │\n",
       "│ mixtral-8x7b-instruct-v0.1      ┆ 886.7996    ┆ 860.324786  ┆ 910.511334  │\n",
       "│ mixtral-8x22b-instruct-v0.1     ┆ 858.512945  ┆ 843.320127  ┆ 875.31544   │\n",
       "│ mistral-nemo-2407               ┆ 854.711631  ┆ 835.924169  ┆ 869.653397  │\n",
       "│ chocolatine-2-14b-instruct-v2.… ┆ 830.391766  ┆ 798.721338  ┆ 857.784509  │\n",
       "└─────────────────────────────────┴─────────────┴─────────────┴─────────────┘"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranker = MaximumLikelihoodRanker()\n",
    "scores = ranker.compute_bootstrap_scores(matches=matches)\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ajout de la notion de frugalité dans le score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since ministere-culture/comparia-conversations couldn't be found on the Hugging Face Hub (offline mode is enabled).\n",
      "Found the latest cached dataset configuration 'default' at /home/jupyterhub-users/shared/projet_comparia/huggingface_hub/ministere-culture___comparia-conversations/default/0.0.0/dc40af6af1c14e68bf39d55f6e1573d2d6582f19 (last modified on Wed Jun  4 17:40:30 2025).\n",
      "Using the latest cached version of the dataset since ministere-culture/comparia-conversations couldn't be found on the Hugging Face Hub (offline mode is enabled).\n",
      "Found the latest cached dataset configuration 'default' at /home/jupyterhub-users/shared/projet_comparia/huggingface_hub/ministere-culture___comparia-conversations/default/0.0.0/dc40af6af1c14e68bf39d55f6e1573d2d6582f19 (last modified on Wed Jun  4 17:40:30 2025).\n"
     ]
    }
   ],
   "source": [
    "from rank_comparia.frugality import get_normalized_log_cost, calculate_frugality_score\n",
    "from rank_comparia.plot import plot_elo_against_frugal_elo\n",
    "\n",
    "conversations = load_comparia(\"ministere-culture/comparia-conversations\")\n",
    "conversations = conversations.rename({\"model_a_name\": \"model_a\", \"model_b_name\": \"model_b\"})\n",
    "\n",
    "frugality_score = calculate_frugality_score(conversations, None)\n",
    "graph = plot_elo_against_frugal_elo(\n",
    "    frugal_log_score=get_normalized_log_cost(frugality_score, mean=\"token\"), bootstraped_scores=scores\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-25f25eeb52c8476797c1bc7caf067de9.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-25f25eeb52c8476797c1bc7caf067de9.vega-embed details,\n",
       "  #altair-viz-25f25eeb52c8476797c1bc7caf067de9.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-25f25eeb52c8476797c1bc7caf067de9\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-25f25eeb52c8476797c1bc7caf067de9\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-25f25eeb52c8476797c1bc7caf067de9\");\n",
       "    }\n",
       "\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      let deps = [\"vega-embed\"];\n",
       "      require(deps, displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}, \"legend\": {\"labelLimit\": 300}}, \"data\": {\"name\": \"data-8f027ae78e239a3c12f67d1f7b708f0c\"}, \"mark\": {\"type\": \"point\", \"filled\": true}, \"encoding\": {\"color\": {\"field\": \"organization\", \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"model_name\", \"type\": \"nominal\"}, {\"field\": \"organization\", \"type\": \"nominal\"}, {\"field\": \"license\", \"type\": \"nominal\"}, {\"field\": \"median\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"median\", \"scale\": {\"domainMin\": 800.0, \"domainMax\": 1200.0}, \"title\": \"elo score\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"y\", \"scale\": {\"domainMin\": 300.0, \"domainMax\": 1200.0}, \"title\": \"frugality elo score\", \"type\": \"quantitative\"}}, \"height\": 450, \"params\": [{\"name\": \"param_1\", \"bind\": {\"input\": \"range\", \"max\": 1, \"min\": 0, \"name\": \"frugality coefficient:  \"}, \"value\": 1}], \"title\": \"frugality elo ranking\", \"transform\": [{\"calculate\": \"(datum.median - (param_1 * (datum.cost * 366)))\", \"as\": \"y\"}], \"width\": 800, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-8f027ae78e239a3c12f67d1f7b708f0c\": [{\"model_name\": \"aya-expanse-8b\", \"median\": 960.2356779096783, \"cost\": -0.30225179113580936, \"name\": \"Aya-Expanse-8B\", \"organization\": \"Cohere\", \"license\": \"CC-BY-NC-4.0\"}, {\"model_name\": \"c4ai-command-r-08-2024\", \"median\": 936.6521286429495, \"cost\": 8.881784197001252e-16, \"name\": \"Command R (08-2024)\", \"organization\": \"Cohere\", \"license\": \"CC-BY-NC-4.0\"}, {\"model_name\": \"chocolatine-2-14b-instruct-v2.0.3-q8\", \"median\": 830.3917658821791, \"cost\": -0.31873633411705704, \"name\": \"Chocolatine-2-14b Instruct\", \"organization\": \"jpacifico (individual)\", \"license\": \"Apache 2.0\"}, {\"model_name\": \"claude-3-5-sonnet-v2\", \"median\": 1003.4491292222262, \"cost\": 1.249530541893717, \"name\": \"Claude 3.5 Sonnet V2\", \"organization\": \"Anthropic\", \"license\": \"Proprietary\"}, {\"model_name\": \"command-a\", \"median\": 1102.1070908792417, \"cost\": 0.38226228402165496, \"name\": \"Command A\", \"organization\": \"Cohere\", \"license\": \"CC-BY-NC-4.0\"}, {\"model_name\": \"deepseek-r1\", \"median\": 1063.761615324878, \"cost\": 0.7939890896114417, \"name\": \"DeepSeek-R1\", \"organization\": \"DeepSeek\", \"license\": \"MIT\"}, {\"model_name\": \"deepseek-r1-distill-llama-70b\", \"median\": 961.3000981305797, \"cost\": 0.21747578810586177, \"name\": \"DeepSeek-R1 distiil\", \"organization\": \"DeepSeek\", \"license\": \"MIT\"}, {\"model_name\": \"deepseek-v3-chat\", \"median\": 1115.7188625734798, \"cost\": 0.7939890896114408, \"name\": \"DeepSeek-V3 Chat\", \"organization\": \"DeepSeek\", \"license\": \"DeepSeek\"}, {\"model_name\": \"gemini-1.5-pro-001\", \"median\": 1041.220675443369, \"cost\": 1.2466857817034938, \"name\": \"Gemini 1.5 pro 001\", \"organization\": \"Google\", \"license\": \"Proprietary\"}, {\"model_name\": \"gemini-1.5-pro-002\", \"median\": 1047.5139613251758, \"cost\": 1.24900751927514, \"name\": \"Gemini 1.5 pro 002\", \"organization\": \"Google\", \"license\": \"Proprietary\"}, {\"model_name\": \"gemini-2.0-flash-001\", \"median\": 1136.193397847913, \"cost\": 0.03856163599175755, \"name\": \"Gemini 2.0 Flash\", \"organization\": \"Google\", \"license\": \"Proprietary\"}, {\"model_name\": \"gemini-2.0-flash-exp\", \"median\": 1141.0467823963359, \"cost\": 0.03856163599175666, \"name\": \"Gemini 2.0 Flash\", \"organization\": \"Google\", \"license\": \"Proprietary\"}, {\"model_name\": \"gemma-2-27b-it-q8\", \"median\": 974.9144027592447, \"cost\": -0.06984816755028067, \"name\": \"Gemma 2 27B q8\", \"organization\": \"Google\", \"license\": \"Gemma license\"}, {\"model_name\": \"gemma-2-9b-it\", \"median\": 966.1348049540677, \"cost\": -0.28674553916989964, \"name\": \"Gemma 2 9B\", \"organization\": \"Google\", \"license\": \"Gemma license\"}, {\"model_name\": \"gemma-3-12b\", \"median\": 1085.043472644611, \"cost\": -0.24193823019243865, \"name\": \"Gemma 3 12B\", \"organization\": \"Google\", \"license\": \"Gemma license\"}, {\"model_name\": \"gemma-3-27b\", \"median\": 1137.7917471144947, \"cost\": -0.06984816755027978, \"name\": \"Gemma-3 27B\", \"organization\": \"Google\", \"license\": \"Gemma\"}, {\"model_name\": \"gemma-3-4b\", \"median\": 1057.476584929394, \"cost\": -0.37231349860838137, \"name\": \"Gemma 3 4B\", \"organization\": \"Google\", \"license\": \"Gemma license\"}, {\"model_name\": \"gpt-4o-mini-2024-07-18\", \"median\": 999.4632767938855, \"cost\": -3.5659937475784886e-05, \"name\": \"GPT-4o mini\", \"organization\": \"OpenAI\", \"license\": \"Proprietary\"}, {\"model_name\": \"hermes-3-llama-3.1-405b\", \"median\": 941.986007462127, \"cost\": 1.498095476260533, \"name\": \"Hermes 3\", \"organization\": \"Nous Research\", \"license\": \"llama3\"}, {\"model_name\": \"jamba-1.5-large\", \"median\": 986.301451110428, \"cost\": 0.7984425037421765, \"name\": \"Jamba Large\", \"organization\": \"AI21 Labs\", \"license\": \"Jamba Open Model License\"}, {\"model_name\": \"lfm-40b\", \"median\": 896.1440557618057, \"cost\": 0.03856163599175755, \"name\": \"Liquid Foundation Model\", \"organization\": \"Liquid\", \"license\": \"Unknown\"}, {\"model_name\": \"llama-3.1-405b\", \"median\": 991.8279507959028, \"cost\": 1.498095476260533, \"name\": \"Llama 3.1 405B\", \"organization\": \"Meta\", \"license\": \"Llama 3.1 Community\"}, {\"model_name\": \"llama-3.1-70b\", \"median\": 970.2538832398925, \"cost\": 0.21747578810586354, \"name\": \"Llama-3.1-70B\", \"organization\": \"Meta\", \"license\": \"Llama 3.1 Community\"}, {\"model_name\": \"llama-3.1-8b\", \"median\": 929.0593591186926, \"cost\": -0.3022517911358129, \"name\": \"Llama 3.1 8B\", \"organization\": \"Meta\", \"license\": \"Llama 3.1 Community\"}, {\"model_name\": \"llama-3.1-nemotron-70b-instruct\", \"median\": 1078.4682155768955, \"cost\": 0.21747578810586088, \"name\": \"Nemotron 70B Instruct\", \"organization\": \"Nvidia\", \"license\": \"Llama 3.1 Community\"}, {\"model_name\": \"llama-3.3-70b\", \"median\": 988.7670101051718, \"cost\": 0.21747578810586088, \"name\": \"Llama 3.3 70B\", \"organization\": \"Meta\", \"license\": \"Llama 3.3 Community\"}, {\"model_name\": \"ministral-8b-instruct-2410\", \"median\": 957.5275227866349, \"cost\": -0.3022517911358129, \"name\": \"Ministral 8B-Instruct\", \"organization\": \"Mistral\", \"license\": \"MRL\"}, {\"model_name\": \"mistral-large-2411\", \"median\": 1028.2848777475892, \"cost\": 0.4206500320907649, \"name\": \"Mistral-Large-2411\", \"organization\": \"Mistral\", \"license\": \"Mistral Research\"}, {\"model_name\": \"mistral-nemo-2407\", \"median\": 854.711631137231, \"cost\": -0.241938230192436, \"name\": \"Mistral Nemo Instruct\", \"organization\": \"Mistral AI\", \"license\": \"Apache 2.0\"}, {\"model_name\": \"mistral-small-24b-instruct-2501\", \"median\": 984.6976608743771, \"cost\": -0.09923752954196363, \"name\": \"Mistral-Small-24B-Instruct-2501\", \"organization\": \"Mistral\", \"license\": \"Apache 2.0\"}, {\"model_name\": \"mistral-small-3.1-24b\", \"median\": 1029.0840710412926, \"cost\": -0.09923752954196186, \"name\": \"Mistral Small-3.1 24B\", \"organization\": \"Mistral AI\", \"license\": \"Apache 2.0\"}, {\"model_name\": \"mixtral-8x22b-instruct-v0.1\", \"median\": 858.5129447632821, \"cost\": 0.36807215387247805, \"name\": \"Mixtral 8x22B Instruct\", \"organization\": \"Mistral AI\", \"license\": \"Apache 2.0\"}, {\"model_name\": \"mixtral-8x7b-instruct-v0.1\", \"median\": 886.7995996977154, \"cost\": -0.21472558478401726, \"name\": \"Mixtral 8x7B Instruct\", \"organization\": \"Mistral AI\", \"license\": \"Apache 2.0\"}, {\"model_name\": \"o3-mini\", \"median\": 1004.1080893619818, \"cost\": 0.9099986164021105, \"name\": \"o3-mini\", \"organization\": \"OpenAI\", \"license\": \"Proprietary\"}, {\"model_name\": \"phi-3.5-mini-instruct\", \"median\": 890.6082560032231, \"cost\": -0.3917493743738403, \"name\": \"Phi-3.5 Mini Instruct\", \"organization\": \"Microsoft\", \"license\": \"MIT\"}, {\"model_name\": \"phi-4\", \"median\": 979.7469847291021, \"cost\": -0.21465692835301375, \"name\": \"Phi 4\", \"organization\": \"Microsoft\", \"license\": \"MIT\"}, {\"model_name\": \"qwen2.5-7b-instruct\", \"median\": 911.970337581788, \"cost\": -0.31873633411705793, \"name\": \"Qwen2.5-7B\", \"organization\": \"Alibaba\", \"license\": \"Apache 2.0\"}, {\"model_name\": \"qwen2.5-coder-32b-instruct\", \"median\": 927.8666788561352, \"cost\": -0.02489535897645556, \"name\": \"Qwen2.5-Coder-32B-Instruct\", \"organization\": \"Alibaba\", \"license\": \"Apache 2.0\"}, {\"model_name\": \"qwq-32b\", \"median\": 959.5350507242528, \"cost\": -0.02489535897645645, \"name\": \"QwQ 32B\", \"organization\": \"Alibaba\", \"license\": \"Apache 2.0\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
