{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bef1cb70",
   "metadata": {},
   "source": [
    "## Chargement des donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211d2dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "cache_dir = input(\"Indicate path to all Hugging Face caches:\")\n",
    "os.environ[\"HF_DATASETS_CACHE\"] = cache_dir\n",
    "os.environ[\"HF_HUB_CACHE\"] = cache_dir\n",
    "os.environ[\"HF_TOKEN\"] = getpass(\"Enter your HuggingFace token:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d546cfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_comparia.utils import load_comparia\n",
    "\n",
    "votes = load_comparia(\"ministere-culture/comparia-votes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6133374f",
   "metadata": {},
   "source": [
    "## Import de librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe1c89d-709a-42fb-b801-68db56a5f307",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "# import torch\n",
    "from pathlib import Path\n",
    "\n",
    "import umap\n",
    "import hdbscan\n",
    "import nltk\n",
    "import pickle\n",
    "\n",
    "from bertopic import BERTopic\n",
    "from collections import defaultdict\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import stopwords\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3a9669-3e19-4b8f-9e3f-4cacb94046da",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa3c7e7-06e9-4182-b7e0-7674dd11a371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.is_available()\n",
    "# https://maartengr.github.io/BERTopic/getting_started/best_practices/best_practices.html#training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e0fa92-8b1e-4830-bdd1-99da0cbd7361",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53926acf-15ae-4417-8fc4-8a58b18cd792",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_model(docs, model_name, min_cluster_size):\n",
    "\n",
    "    sentence_model = SentenceTransformer(model_name)\n",
    "    embeddings = sentence_model.encode(docs, how_progress_bar=False)\n",
    "    vectorizer_model = CountVectorizer(stop_words=get_stop_words(), min_df=2, ngram_range=(1, 3))\n",
    "\n",
    "    # reduce embeddings dimension\n",
    "    umap_model = umap.UMAP(n_neighbors=20, n_components=10, min_dist=0.0, metric=\"cosine\", low_memory=False)\n",
    "\n",
    "    \"\"\"perform documents clustering\"\"\"\n",
    "    hdbscan_model = hdbscan.HDBSCAN(\n",
    "        min_cluster_size=min_cluster_size,\n",
    "        min_samples=1,\n",
    "        metric=\"euclidean\",\n",
    "        cluster_selection_method=\"eom\",\n",
    "        prediction_data=True,\n",
    "    )\n",
    "\n",
    "    topic_model = BERTopic(\n",
    "        # Pipeline models\n",
    "        embedding_model=sentence_model,\n",
    "        umap_model=umap_model,\n",
    "        hdbscan_model=hdbscan_model,\n",
    "        vectorizer_model=vectorizer_model,\n",
    "        # Hyperparameters\n",
    "        top_n_words=10,\n",
    "        verbose=True,\n",
    "    )\n",
    "    \"\"\"\n",
    "    if save:\n",
    "        topic_model.save(\n",
    "        model_title = model_title,\n",
    "        serialization=\"safetensors\",\n",
    "        save_ctfidf=True\n",
    "    )\n",
    "    #my_model = BERTopic.load(\"my_model\")\n",
    "    \"\"\"\n",
    "    \"\"\" Train model\"\"\"\n",
    "    topics, probs = topic_model.fit_transform(docs, embeddings)\n",
    "\n",
    "    return topic_model, embeddings, topics, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebd6705-ef60-420b-898d-2e19fc9f7272",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(df, var):\n",
    "\n",
    "    df = df.with_columns(foo_lower=pl.col(var).str.to_lowercase())\n",
    "    df1 = df.unique(subset=[var], keep=\"first\")\n",
    "\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3640bfbc-9f14-40a0-9f07-26cbd009a9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_words(phrase):\n",
    "\n",
    "    list_stop = [\n",
    "        \"ton\",\n",
    "        \"de\",\n",
    "        \"les\",\n",
    "        \"et\",\n",
    "        \"le\",\n",
    "        \"la\",\n",
    "        \"que\",\n",
    "        \"un\",\n",
    "        \"je\",\n",
    "        \"c'est\",\n",
    "        \"quand\",\n",
    "        \"cest\",\n",
    "        \"si\",\n",
    "        \"comme\",\n",
    "        \"bonjour\",\n",
    "        \"un\",\n",
    "        \"il\",\n",
    "        \"je\",\n",
    "        \"to\",\n",
    "        \"the\",\n",
    "        \"of\",\n",
    "        \"for\",\n",
    "        \"et\",\n",
    "        \"une\",\n",
    "        \"un\",\n",
    "        \"de\" \"est\",\n",
    "    ]\n",
    "\n",
    "    disallowed_wordlist = stopwords.words(\"french\") + list_stop\n",
    "\n",
    "    phrase_split = phrase.split()\n",
    "\n",
    "    allowed_words_list = []\n",
    "\n",
    "    for word in phrase_split:\n",
    "\n",
    "        if word not in disallowed_wordlist:\n",
    "\n",
    "            allowed_words_list.append(word)\n",
    "\n",
    "    new_phrase = \" \".join(allowed_words_list)\n",
    "\n",
    "    return new_phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eed4294-691f-422d-81ac-acc7c664f7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stop_words():\n",
    "    list_stop = [\n",
    "        \"ton\",\n",
    "        \"de\",\n",
    "        \"les\",\n",
    "        \"et\",\n",
    "        \"le\",\n",
    "        \"la\",\n",
    "        \"que\",\n",
    "        \"un\",\n",
    "        \"je\",\n",
    "        \"c'est\",\n",
    "        \"quand\",\n",
    "        \"cest\",\n",
    "        \"si\",\n",
    "        \"comme\",\n",
    "        \"bonjour\",\n",
    "        \"un\",\n",
    "        \"il\",\n",
    "        \"to\",\n",
    "        \"the\",\n",
    "        \"of\",\n",
    "        \"for\",\n",
    "        \"une\",\n",
    "        \"un\",\n",
    "        \"de\" \"est\",\n",
    "        \"ne\",\n",
    "    ]\n",
    "\n",
    "    list_stop_words = stopwords.words(\"french\") + list_stop\n",
    "\n",
    "    return list_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c028ba-9fb9-4e26-a93e-98cee6a4a72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_categories(df, topic_model, model_name, figure_name, save):\n",
    "\n",
    "    topics = topic_model.get_topic_info()\n",
    "\n",
    "    print(\"there are \", len(topics), \" topics, when I use the model \", model_name)\n",
    "    topics = topics[topics[\"Topic\"].isin(range(0, 100))]\n",
    "    N = len(topics)\n",
    "\n",
    "    legende = []\n",
    "    legende_dict = {}\n",
    "\n",
    "    for i in range(0, N):\n",
    "        legende.append(\"Topic \" + str(i) + \": \" + \", \".join(topics[\"Representation\"].iloc[i][:9]))\n",
    "        legende_dict[i] = \"Topic \" + str(i) + \": \" + \", \".join(topics[\"Representation\"].iloc[i][:9])\n",
    "\n",
    "    var1 = \"Topic\"\n",
    "    df_pl = df[[\"Topic\"]].sort_values(by=var1)\n",
    "    df_pl = df.groupby([var1], as_index=False)[var1].count().fillna(0)\n",
    "    df_pl[\"count\"] = df_pl.sum(axis=1)\n",
    "    df_pl = df_pl.sort_values(by=\"count\", ascending=False).drop(columns=[\"count\"])\n",
    "    plt.figure(figsize=(8, N / 4))\n",
    "\n",
    "    ax = df_pl.plot(kind=\"barh\", stacked=True, figsize=(12, N / 4), colormap=plt.cm.tab20)\n",
    "    plt.title(model_name)\n",
    "    plt.yticks(range(N), map(lambda x: legende_dict[x], range(N)))\n",
    "    plt.legend()\n",
    "    plt.margins(0.04, 0)\n",
    "    if save:\n",
    "        plt.savefig(figure_name, bbox_inches=\"tight\", dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20bce54-d6a9-468c-bbe7-b54a300e14b1",
   "metadata": {},
   "source": [
    "## Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95dac47-b54c-4313-9636-183fcad6f35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean_df(votes, \"opening_msg\")\n",
    "print(\"Number of unique observations / documents :\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2f1a42-a6d1-47be-9f0a-5a2eb0d42361",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = df[\"opening_msg\"].to_list()\n",
    "# docs_stopwords = [drop_words(x) for x in docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d433a94-9d66-42e1-9e1f-d29f955792e7",
   "metadata": {},
   "source": [
    "## Step 1: Get topics with BerTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4983aab0-fa30-4dfe-a591-99d02d8a1adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_models = [\"sentence-transformers/roberta-base-nli-stsb-mean-tokens\"]\n",
    "min_cluster_size = 50\n",
    "for model in list_models:\n",
    "    topic_model, embeddings, topics, probs = get_topic_model(\n",
    "        docs,\n",
    "        model,\n",
    "        min_cluster_size,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197ad9ae-d0dd-431d-8ee7-26f7acf6bb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# topic_model = BERTopic.load(path=f\"../data/bertopic_july_20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e117cd68-e1f6-4a34-8531-a78d1e3051fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = topic_model.get_document_info(docs).sort_values(by=\"Topic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7211bcb2-70aa-4e61-9951-d63e9072e56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"Topic\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1765564-85c8-45f5-827d-00c0c6c7bf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_categories(df1[df1[\"Topic\"].isin(range(0, 100))], topic_model, \"BertTopic\", \"../figures/topics_bert.jpg\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91bbb12-f21b-41db-bee4-7d5badfc0f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "hierarchical_topics = topic_model.hierarchical_topics(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8f41bf-2541-4653-876a-262ca19ff2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = topic_model.visualize_hierarchy(hierarchical_topics=hierarchical_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c30d9e-7986-4af5-9bb3-b855c4090e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109a31e0-724d-4485-b616-8bb763de82e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_html(\"../figures/dendogram.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c44059-dd7e-41a3-a9b7-0e3121bc9b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(\"../figures/dendogram.jpg\", bbox_inches=\"tight\", dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3878d472-1fb6-4b2f-bbc2-494cc670b207",
   "metadata": {},
   "source": [
    "## Step 2 : sampling of most relevant documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce92efc-6015-4e4e-b4e7-00cea8b70037",
   "metadata": {},
   "source": [
    "#### Sampling : this part was copied from the Arena Explorer notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd404194-d5fa-4157-a2c0-338475b14e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = docs\n",
    "sampled_prompts = defaultdict(list)\n",
    "topic_info = topic_model.get_topic_info()\n",
    "doc_info = topic_model.get_document_info(doc)\n",
    "\n",
    "for topic_id in topic_info[\"Topic\"][1:]:\n",
    "    filtered_docs = doc_info[\n",
    "        (doc_info[\"Topic\"] == topic_id)\n",
    "        & (doc_info[\"Probability\"] >= doc_info[\"Probability\"].quantile(0.8))\n",
    "        & (doc_info[\"Document\"].str.split().str.len() >= 5)\n",
    "    ]\n",
    "\n",
    "    res = filtered_docs\n",
    "    cap = 100\n",
    "    if len(filtered_docs) >= 20:\n",
    "        while len(res) < 20:\n",
    "            res = filtered_docs[filtered_docs[\"Document\"].str.split().str.len() <= cap]\n",
    "            cap += 50\n",
    "\n",
    "    sampled_docs = res.sample(n=min(20, len(res)), random_state=42, replace=False)\n",
    "\n",
    "    sampled_prompts[topic_id] = sampled_docs[\"Document\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7cd656-06d5-4229-81ec-a338de18223a",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"../data\"\n",
    "\n",
    "with open(f\"{save_path}/example_prompts.pkl\", \"wb\") as f:\n",
    "    pickle.dump(sampled_prompts, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e8d5e2-4195-4655-9d74-aae639b99b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_topics = topic_model.reduce_outliers(list(doc), topics, strategy=\"c-tf-idf\", threshold=0.1)\n",
    "new_topics = topic_model.reduce_outliers(list(doc), new_topics, strategy=\"distributions\")\n",
    "topic_model.update_topics(doc, topics=new_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77caf684-5062-4c14-8acf-28a3f0fd765c",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_info = topic_model.get_topic_info()\n",
    "doc_info = topic_model.get_document_info(docs)\n",
    "topic_info[topic_info[\"Topic\"].isin(range(0, 30))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6521a839-519a-4c62-a36f-aae5b973b84f",
   "metadata": {},
   "source": [
    "## Step 3: summarize each topic using an LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f51298-9b92-4c66-9c34-870fe0453f3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rank-comparia-SXEyBiqD-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
