services:
  fastchat-controller:
    build:
      context: "../"
      dockerfile: docker/Dockerfile
    image: fastchat:latest
    ports:
      - "21001:21001"
    command: ["python3.9", "-m", "fastchat.serve.controller", "--host", "0.0.0.0", "--port", "21001"]
  # fastchat-model-worker:
  #   build:
  #     context: .
  #     dockerfile: Dockerfile
  #   # volumes:
  #   #   - huggingface:/root/.cache/huggingface
  #   image: fastchat:latest
  #   # deploy:
  #   #   resources:
  #   #     reservations:
  #   #       devices:
  #   #         - driver: nvidia
  #   #           count: 1
  #   #           capabilities: [gpu]
  #   volumes:
  #     - ../model-info-file.json:/model-info-file.json
  #   entrypoint: ["python3.9", "-m", "fastchat.serve.huggingface_api_worker", "--model-info-file", "/model-info-file.json", "--worker-address", "http://fastchat-model-worker:21002", "--controller-address", "http://fastchat-controller:21001", "--host", "0.0.0.0", "--port", "21002"]
  # fastchat-api-server:
  #   build:
  #     context: ..
  #     dockerfile: docker/Dockerfile
  #   image: fastchat:latest
  #   ports:
  #     - "8000:8000"
  #   command: ["python3.9", "-m", "fastchat.serve.openai_api_server", "--controller-address", "http://fastchat-controller:21001", "--host", "0.0.0.0", "--port", "8000"]
  fastchat-gradio-web-server:
    env_file: .env
    environment:
      LOGDIR: /data
      LANGUIA_REGISTER_API_ENDPOINT_FILE: "/register-api-endpoint-file.json"
      LANGUIA_CONTROLLER_URL: "http://fastchat-controller:21001"
    build:
      context: ..
      dockerfile: docker/Dockerfile
    image: fastchat:latest
    ports:
      - "8001:8001"
    volumes:
      - ../data:/data
      - ../register-api-endpoint-file.json:/register-api-endpoint-file.json
    # WIP: dev config
      # - ../fastchat:/app/fastchat
    # command: ["gradio", "fastchat/serve/gradio_web_server_multi_languia.py"]
    command: ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8001"]
