"""
Environmental impact calculations and reveal screen data generation.

This module computes the ecological impact of LLM inference using the ecologits library,
converting technical metrics (energy, CO2) into user-friendly comparisons (LED lightbulbs, video streaming).

Functions:
- convert_range_to_value: Normalize impact ranges to single values
- calculate_lightbulb_consumption: Energy equivalent in LED light hours
- calculate_streaming_hours: CO2 equivalent in video streaming hours
- build_reveal_dict: Main function generating reveal screen data
"""

import logging

from backend.language_models.utils import convert_range_to_value, get_llm_impact
from backend.arena.utils import sum_tokens


def calculate_lightbulb_consumption(impact_energy_value):
    """
    Calculates the energy consumption of a 5W LED light and determines the most sensible time unit.

    Args:
      impact_energy_value: Energy consumption in kilowatt-hours (kWh).

    Returns:
      A tuple containing:
        - An integer representing the consumption time.
        - A string representing the most sensible time unit ('days', 'hours', 'minutes', or 'seconds').
    """
    # Calculate consumption time using Wh
    watthours = impact_energy_value * 1000
    consumption_hours = watthours / 5
    consumption_days = watthours / (5 * 24)
    consumption_minutes = watthours * 60 / (5)
    consumption_seconds = watthours * 60 * 60 / (5)

    # Determine the most sensible unit based on magnitude
    if consumption_days >= 1:
        return int(consumption_days), "j"
    elif consumption_hours >= 1:
        return int(consumption_hours), "h"
    elif consumption_minutes >= 1:
        return int(consumption_minutes), "min"
    else:
        return int(consumption_seconds), "s"


def calculate_streaming_hours(impact_gwp_value_or_range):
    """
    Calculates equivalent streaming hours and determines a sensible time unit.

    Args:
      impact_gwp_value: CO2 emissions in kilograms.

    Returns:
      A tuple containing:
        - An integer representing the streaming hours.
        - A string representing the most sensible time unit ('days', 'hours', 'minutes', or 'seconds').
    """

    if hasattr(impact_gwp_value_or_range, "min"):
        impact_gwp_value = (
            impact_gwp_value_or_range.min + impact_gwp_value_or_range.max
        ) / 2
    else:
        impact_gwp_value = impact_gwp_value_or_range
    # Calculate streaming hours: https://impactco2.fr/outils/usagenumerique/streamingvideo
    streaming_hours = (impact_gwp_value * 10000) / 317

    # Determine sensible unit based on magnitude
    if streaming_hours >= 24:  # 1 day in hours
        return int(streaming_hours / 24), "j"
    elif streaming_hours >= 1:
        return int(streaming_hours), "h"
    elif streaming_hours * 60 >= 1:
        return int(streaming_hours * 60), "min"
    else:
        return int(streaming_hours * 60 * 60), "s"


def build_reveal_dict(conv_a_dict: dict, conv_b_dict: dict, chosen_model: str):
    """
    Build reveal screen data with model comparison and environmental impact metrics.

    Calculates environmental impact (energy, CO2 emissions) and creates data for the
    reveal screen shown after voting. Includes model metadata, token counts, and
    user-friendly comparisons (LED lightbulb hours, video streaming equivalents).

    Args:
        conv_a_dict: Conversation dict for model A with messages and model_name
        conv_b_dict: Conversation dict for model B with messages and model_name
        chosen_model: User's choice ("model-a", "model-b", or "both-equal")

    Returns:
        dict: Reveal data containing:
            - b64: Base64-encoded JSON summary (compact storage/transmission)
            - model_a/model_b: Full model metadata dicts
            - chosen_model: User's model preference
            - model_a/b_kwh: Energy consumption in kilowatt-hours
            - model_a/b_co2: CO2 emissions in kilograms
            - model_a/b_tokens: Total output tokens generated by each model
            - streaming_a/b + streaming_a/b_unit: Equivalent video streaming hours
            - lightbulb_a/b + lightbulb_a/b_unit: Equivalent 5W LED light hours

    Process:
        1. Load model definitions from config
        2. Calculate total output tokens for each conversation
        3. Compute environmental impact using ecologits library
        4. Convert impact values to user-friendly comparisons (lightbulb, streaming)
        5. Encode summary to base64 for efficient storage
        6. Return comprehensive metrics for reveal screen display
    """
    from backend.language_models.data import get_models
    import base64
    import json

    models = get_models().all

    logger = logging.getLogger("languia")

    # Load complete model metadata from config
    model_a = models.get(conv_a_dict["model_name"])
    model_b = models.get(conv_b_dict["model_name"])

    # Calculate total tokens generated by each model
    model_a_tokens = sum_tokens(conv_a_dict.get("messages", []))
    logger.debug(f"output_tokens (model a): {model_a_tokens}")

    model_b_tokens = sum_tokens(conv_b_dict.get("messages", []))
    logger.debug(f"output_tokens (model b): {model_b_tokens}")

    # Default values in case impact calculation fails
    model_a_kwh = 0.0
    model_b_kwh = 0.0
    model_a_co2 = 0.0
    model_b_co2 = 0.0
    lightbulb_a, lightbulb_a_unit = 0, "h"
    lightbulb_b, lightbulb_b_unit = 0, "h"
    streaming_a, streaming_a_unit = 0, "h"
    streaming_b, streaming_b_unit = 0, "h"

    # Calculate environmental impact using ecologits library
    # Uses model parameters, active parameters (for MoE), and token count
    try:
        model_a_impact = get_llm_impact(model_a, model_a_tokens, None)
        if model_a_impact:
            # Extract and normalize energy and CO2 values (handles value ranges)
            model_a_kwh = convert_range_to_value(model_a_impact.energy.value)
            model_a_co2 = convert_range_to_value(model_a_impact.gwp.value)
            # Convert energy to LED lightbulb comparison (5W LED light)
            lightbulb_a, lightbulb_a_unit = calculate_lightbulb_consumption(model_a_kwh)
            # Convert CO2 to video streaming comparison
            streaming_a, streaming_a_unit = calculate_streaming_hours(model_a_co2)
    except Exception as e:
        logger.warning(f"Could not calculate impact for model A ({conv_a_dict['model_name']}): {e}")

    try:
        model_b_impact = get_llm_impact(model_b, model_b_tokens, None)
        if model_b_impact:
            model_b_kwh = convert_range_to_value(model_b_impact.energy.value)
            model_b_co2 = convert_range_to_value(model_b_impact.gwp.value)
            lightbulb_b, lightbulb_b_unit = calculate_lightbulb_consumption(model_b_kwh)
            streaming_b, streaming_b_unit = calculate_streaming_hours(model_b_co2)
    except Exception as e:
        logger.warning(f"Could not calculate impact for model B ({conv_b_dict['model_name']}): {e}")

    # Create compact summary for encoding
    data = {
        "a": conv_a_dict["model_name"],  # Model A identifier
        "b": conv_b_dict["model_name"],  # Model B identifier
        "ta": model_a_tokens,  # Model A token count
        "tb": model_b_tokens,  # Model B token count
    }

    # Add user's choice to summary (for verification/tracking)
    if chosen_model == "model-a":
        data["c"] = "a"
    elif chosen_model == "model-b":
        data["c"] = "b"

    # Encode summary as base64 for safe storage/transmission
    jsonstring = json.dumps(data).encode("ascii")
    b64 = base64.b64encode(jsonstring).decode("ascii")

    # Get model dump (handle both LanguageModel objects and dicts)
    model_a_dict = model_a.model_dump() if hasattr(model_a, "model_dump") else (model_a if model_a else {})
    model_b_dict = model_b.model_dump() if hasattr(model_b, "model_dump") else (model_b if model_b else {})

    # Return comprehensive reveal data for frontend display
    return dict(
        b64=b64,  # Encoded summary
        model_a=model_a_dict,  # Full model A metadata
        model_b=model_b_dict,  # Full model B metadata
        chosen_model=chosen_model,  # User's preference
        # Energy metrics
        model_a_kwh=model_a_kwh,
        model_b_kwh=model_b_kwh,
        # Environmental metrics (CO2)
        model_a_co2=model_a_co2,
        model_b_co2=model_b_co2,
        # Token usage
        model_a_tokens=model_a_tokens,
        model_b_tokens=model_b_tokens,
        # Video streaming equivalent (user-friendly CO2 comparison)
        streaming_a=streaming_a,
        streaming_a_unit=streaming_a_unit,
        streaming_b=streaming_b,
        streaming_b_unit=streaming_b_unit,
        # LED lightbulb equivalent (user-friendly energy comparison)
        lightbulb_a=lightbulb_a,
        lightbulb_a_unit=lightbulb_a_unit,
        lightbulb_b=lightbulb_b,
        lightbulb_b_unit=lightbulb_b_unit,
    )
