"""
Data validation models using Pydantic.

Defines all data structures for:
- Conversation data (messages, participant info, metadata)
"""

from datetime import datetime
from typing import Annotated, Any, Literal, Union, get_args
from uuid import uuid4

from pydantic import (
    BaseModel,
    ConfigDict,
    Field,
    PlainSerializer,
    computed_field,
    model_validator,
)

from backend.config import CountryCode, CustomModelsSelection, SelectionMode
from backend.language_models.models import Endpoint, LanguageModel

MessageRole = Literal["user", "assistant", "system"]
BotPos = Literal["a", "b"]


# New message hierarchy from commit 6b42a0964b34
class BaseMessage(BaseModel):
    """
    Base message class with strict typing.

    All messages have a role and content.
    """

    role: MessageRole
    content: str


class SystemMessage(BaseMessage):
    """System prompt message."""

    role: Literal["system"] = "system"


class UserMessage(BaseMessage):
    """User input message."""

    role: Literal["user"] = "user"


class AssistantMessage(BaseMessage):
    """
    Assistant response message with required metadata.

    Metadata must include generation_id, bot, and output_tokens.
    """

    class AssistantMessageMetadata(BaseModel):
        generation_id: str
        bot: BotPos
        output_tokens: int | None = None  # FIXME required?
        duration: float | None = None

    role: Literal["assistant"] = "assistant"
    error: str | None = None
    reasoning: str | None = None
    metadata: AssistantMessageMetadata
    reaction: Union["ReactionData", None] = None

    # use assignment validation since messages are updated gradually
    model_config = ConfigDict(validate_assignment=True)


# Union type for any message
AnyMessage = SystemMessage | UserMessage | AssistantMessage


# New Conversation model (runtime, single model)
class Conversation(BaseModel):
    """
    Represents a conversation with a single AI model.

    Stores messages, model information, and metadata about the conversation.
    Each conversation has a unique ID and tracks the model's endpoint for API calls.
    """

    conv_id: str = Field(default_factory=lambda: str(uuid4()).replace("-", ""))
    model_name: str
    endpoint: Endpoint
    messages: list[AnyMessage]

    @property
    def has_system_msg(self) -> bool:
        return len(self.messages) > 0 and isinstance(self.messages[0], SystemMessage)

    @computed_field  # type: ignore[prop-decorator]
    @property
    def system_msg(self) -> str | None:
        return self.messages[0].content if self.has_system_msg else None

    # FIXME this replace sum_tokens
    @computed_field  # type: ignore[prop-decorator]
    @property
    def tokens(self) -> int:
        """
        Sum the total output tokens across all bot messages in a conversation.

        Returns:
            int: Total output tokens generated by the model
        """
        # Add up output_tokens from metadata of all assistant messages
        return sum(
            msg.metadata.output_tokens
            for msg in self.messages
            if isinstance(msg, AssistantMessage) and msg.metadata.output_tokens
        )


def create_conversation(llm: LanguageModel, user_msg: UserMessage) -> Conversation:
    """Create a single conversation with system prompt if configured."""
    messages: list[AnyMessage] = (
        [SystemMessage(content=llm.system_prompt), user_msg]
        if llm.system_prompt
        else [user_msg]
    )

    return Conversation(model_name=llm.id, endpoint=llm.endpoint, messages=messages)


# New Conversations model (paired conversations for arena)
class Conversations(BaseModel):
    """
    Paired conversations for arena comparison.

    Wraps two Conversation objects for type-safe handling.

    Args:
        session_hash: Unique session identifier
        conv_a: First conversation state (dict with messages, model_name, etc.)
        conv_b: Second conversation state (dict with messages, model_name, etc.)
        mode: Model selection mode (e.g., "random", "big-vs-small")
        category: Prompt category (e.g., "writing", "coding")


    """

    created_at: Annotated[datetime, PlainSerializer(lambda v: v.isoformat())] = Field(
        default_factory=datetime.now
    )
    mode: SelectionMode
    custom_models_selection: CustomModelsSelection
    category: str | None = None
    conversation_a: Conversation
    conversation_b: Conversation

    @computed_field  # type: ignore[prop-decorator]
    @property
    def conv_turns(self) -> int:
        """
        Count the number of conversation turns (user messages or exchanges).

        A turn is one user message and one llm response pair.
        """
        conv = self.conversation_a
        return (len(conv.messages) - (1 if conv.has_system_msg else 0)) // 2

    @computed_field  # type: ignore[prop-decorator]
    @property
    def conversation_pair_id(self) -> str:
        return f"{self.conversation_a.conv_id}-{self.conversation_b.conv_id}"

    @computed_field  # type: ignore[prop-decorator]
    @property
    def model_pair_name(self) -> list[str]:
        return sorted([self.conversation_a.model_name, self.conversation_b.model_name])

    @computed_field  # type: ignore[prop-decorator]
    @property
    def opening_msg(self) -> str:
        conv = self.conversation_a
        return conv.messages[1 if conv.has_system_msg else 0].content

    @computed_field  # type: ignore[prop-decorator]
    @property
    def is_unedited_prompt(self) -> bool:
        if not self.category:
            return False

        from backend.config import prompts_table

        # Check if the exact message exists in the category's prompt list
        return self.opening_msg in prompts_table[self.category]

    def store_to_session(self, session_hash: str) -> None:
        """
        Store conversation pair to Redis.
        """
        from backend.arena.session import store_session_conversations

        data = self.model_dump()

        store_session_conversations(session_hash, data)

    @staticmethod
    def from_session(session_hash: str) -> "Conversations":
        """
        Build a Conversations from data stored in Redis for an active session.
        """
        from backend.arena.session import retrieve_session_conversations

        data = retrieve_session_conversations(session_hash)

        return Conversations(**data)


def create_conversations(
    llm_a: LanguageModel,
    llm_b: LanguageModel,
    user_prompt: str,
    mode: SelectionMode,
    custom_models_selection: CustomModelsSelection,
    category: str | None = None,
) -> Conversations:
    """Create paired conversations for arena comparison."""
    user_msg = UserMessage(content=user_prompt)
    conv_a = create_conversation(llm_a, user_msg)
    conv_b = create_conversation(llm_b, user_msg)

    return Conversations(
        conversation_a=conv_a,
        conversation_b=conv_b,
        mode=mode,
        custom_models_selection=custom_models_selection,
        category=category,
    )


# Request/Response models for FastAPI endpoints


class AddTextRequest(BaseModel):
    """Request body for adding a message to an existing conversation."""

    session_hash: str
    message: str = Field(min_length=1)


class RetryRequest(BaseModel):
    """Request body for retrying the last bot response."""

    session_hash: str


PositiveReaction = Literal["useful", "complete", "creative", "clear_formatting"]
POSITIVE_REACTIONS: tuple[PositiveReaction, ...] = get_args(PositiveReaction)
NegativeReaction = Literal["incorrect", "superficial", "instructions_not_followed"]
NEGATIVE_REACTIONS: tuple[NegativeReaction, ...] = get_args(NegativeReaction)
REACTIONS = POSITIVE_REACTIONS + NEGATIVE_REACTIONS


class ReactionData(BaseModel):
    bot: BotPos
    index: int
    value: str
    liked: bool | None
    prefs: list[PositiveReaction] | list[NegativeReaction]
    comment: str | None


class ReactRequest(BaseModel):
    """Request body for updating message reactions."""

    reaction_json: ReactionData


class VoteRequest(BaseModel):
    """Request body for submitting a vote after conversation."""

    which_model_radio_output: str  # "model-a", "model-b", or "both-equal"
    positive_a_output: list[PositiveReaction] = Field(default_factory=list)
    positive_b_output: list[PositiveReaction] = Field(default_factory=list)
    negative_a_output: list[NegativeReaction] = Field(default_factory=list)
    negative_b_output: list[NegativeReaction] = Field(default_factory=list)
    comments_a_output: str = ""
    comments_b_output: str = ""


class RevealData(BaseModel):
    """Response data revealing model identities after vote."""

    model_a: str
    model_b: str
    model_a_metadata: dict[str, Any]
    model_b_metadata: dict[str, Any]
