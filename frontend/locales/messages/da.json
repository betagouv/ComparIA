{
    "a11y": {
        "externalLink": "{text}"
    },
    "actions": {
        "accessData": "Adgang til data",
        "contact": "Kontakt os",
        "contactUs": "Kontakt os",
        "copyLink": {
            "do": "Kopiér linket",
            "done": "Link kopieret til udklipsholder"
        },
        "copyMessage": {
            "do": "Kopiér beskeden",
            "done": "Besked kopieret"
        },
        "downloadData": "Download data",
        "home": "Hjemmeside",
        "returnHome": "Tilbage til startsiden",
        "seeMore": "Se mere",
        "selectLanguage": "Vælg sprog",
        "vote": "Giv feedback"
    },
    "arenaHome": {
        "compareModels": {
            "count": "{count}/2 modeller",
            "help": "Hvis du kun vælger én, vil den anden blive valgt tilfældigt",
            "question": "Hvilke modeller vil du gerne sammenligne?"
        },
        "modelSelection": "Modelvalg",
        "prompt": {
            "label": "Skriv din første besked",
            "placeholder": "Skriv din første besked her"
        },
        "selectModels": {
            "help": "Vælg sammenligningstypen",
            "question": "Hvilke modeller vil du gerne sammenligne?"
        },
        "suggestions": {
            "choices": {
                "administrative": {
                    "iconAlt": "Administrativ",
                    "title": "Skriv et administrativt dokument"
                },
                "coach": {
                    "iconAlt": "Rådgivning",
                    "title": "Giv mig råd omkring sundhed og fitness"
                },
                "explanations": {
                    "iconAlt": "Forklaring",
                    "title": "Forklar et koncept"
                },
                "iasummit": {
                    "iconAlt": "AI Action Summit",
                    "title": "Spørgsmål fra en borgerhøring om kunstig intelligens",
                    "tooltip": "Disse spørgsmål er resultatet af en borgerhøring om AI, der blev afholdt fra 16.09.2024 til 08.11.2024. Formålet var at inddrage borgere og civilsamfundet bredt i AI Action Summit og indsamle deres idéer til, hvordan AI kan blive en mulighed for alle, samtidig med at misbrug og forkert brug begrænses."
                },
                "ideas": {
                    "iconAlt": "Idéer",
                    "title": "Generér nye idéer"
                },
                "languages": {
                    "iconAlt": "Oversættelse",
                    "title": "Skriv på et andet sprog"
                },
                "recipes": {
                    "iconAlt": "Madlavning",
                    "title": "Vis mig nye opskrifter"
                },
                "recommendations": {
                    "iconAlt": "Forslag",
                    "title": "Foreslå film, bøger, musik"
                },
                "stories": {
                    "iconAlt": "Historier",
                    "title": "Fortæl mig en historie"
                }
            },
            "generateAnother": "Generér en ny prompt",
            "title": "Foreslåede prompts"
        },
        "title": "Hvordan kan jeg hjælpe dig i dag?"
    },
    "chatbot": {
        "continuePrompt": "Fortsæt chatten med AI-modellerne",
        "conversation": "Chat",
        "errors": {
            "other": {
                "message": "Der er opstået en midlertidig fejl.",
                "retry": "Du kan prøve at skrive til modellerne igen.",
                "title": "Ups, midlertidig fejl",
                "vote": "Eller afslut oplevelsen ved at angive din præference for disse modeller."
            },
            "tooLong": {
                "message": "Hver model er begrænset i størrelsen af de samtaler, den kan håndtere.",
                "retry": "Du kan genstarte en chat med to nye modeller.",
                "title": "Ups, samtalen er for lang for en af modellerne.",
                "vote": "Du kan stadig angive dine præferencer for disse modeller eller starte en samtale med to nye."
            }
        },
        "loading": "Indlæser svar",
        "reasoning": {
            "finished": "Tænkning afsluttet",
            "inProgress": "Tænker…"
        },
        "revealButton": "Afslør modellerne"
    },
    "closeModal": "Luk pop op-vinduet",
    "components": {
        "pagination": {
            "first": "Første side",
            "label": "Sider",
            "last": "Sidste side",
            "next": "Næste side",
            "nth": "Side {count}",
            "previous": "Forrige side"
        },
        "table": {
            "linePerPage": "Antal linjer per side",
            "pageCount": "{count} linjer per side",
            "triage": "Sortér"
        },
        "theme": {
            "legend": "Vælg et tema for at tilpasse sidens udseende.",
            "options": {
                "dark": "Mørk tema",
                "light": "Lyst tema",
                "system": "System",
                "systemSub": "Brug system indstillinger"
            },
            "title": "Visningsindstillinger"
        }
    },
    "datasets": {
        "access": {
            "catch": "Modeludgivere, forskere, virksomheder, nu er det jeres tur!",
            "desc": "Platformens spørgsmål og præferencer er primært på fransk, dansk, svensk og litauisk, hvilket afspejler organisk, reel brug – ikke kunstige spørgsmål. Disse datasæt er offentligt tilgængelige på <a {linkProps}>data.gouv.fr</a> og Hugging Face.",
            "repos": {
                "conversations": {
                    "desc": "Alle spørgsmål og svar",
                    "title": "/samtaler"
                },
                "reactions": {
                    "desc": "Alle reaktioner på beskeder",
                    "title": "/reaktioner"
                },
                "votes": {
                    "desc": "Alle de udtrykte præferencer",
                    "title": "/stemmer"
                }
            },
            "share": "Vis os, hvordan I bruger datasættene",
            "title": "Få adgang til compar:IA datasæt"
        },
        "reuse": {
            "bunka": {
                "analyze": {
                    "desc": "Analyse af brugeres samtaler med registrering af opgaver (oprettelse, informationssøgning osv.), emner (kunst og kultur, uddannelse osv.), komplekse følelser (nysgerrighed, entusiasme osv.), sproglig tone (formel, professionel osv.)",
                    "title": "Få adgang til analysen"
                },
                "conversations": {
                    "desc": "Interaktiv visualisering af samtaler, hvor hver klynge repræsenterer et tilbagevendende tema, som brugerne diskuterer (f.eks. uddannelse, sundhed, miljø eller endda filosofi).",
                    "title": "Udforsk datavisualiseringen"
                },
                "desc": "Bunka.ai-teamet gennemførte en storstilet undersøgelse af bruger-AI-interaktioner på chatbot-området, hvor de kortlagde dominerende temaer, nøgleopgaver og balancen mellem automatisering og menneskelig forstærkning. Deres analyse, der er baseret på 25.000 reelle samtaler, giver en sjælden empirisk indsigt i, hvordan mennesker rent faktisk bruger AI.",
                "method": "Lær mere om metodikken"
            },
            "desc": "Eksempler på brug af compar:IA datasæt",
            "title": "Hvordan bruges disse data?"
        }
    },
    "errors": {
        "404": {
            "desc": "Hvis du har indtastet URL'en i din browser, skal du kontrollere, om den er korrekt. Siden er muligvis ikke længere tilgængelig. <br />Du kan fortsætte ved at besøge vores hjemmeside. <br /> Hvis du har svært ved at finde den side, du leder efter, skal du kontakte os, så vi kan videresende dig til den korrekte URL.",
            "error": "Fejl 404",
            "sorry": "Den side, du søger, kan ikke findes. Vi beklager ulejligheden.",
            "title": "Siden blev ikke fundet"
        },
        "unexpected": {
            "desc": "Prøv at opdatere siden eller prøv igen senere.",
            "error": "Fejl {code}",
            "sorry": "Vi beklager, der er et problem med tjenesten, vi arbejder på at løse det så hurtigt som muligt.",
            "title": "Uventet fejl"
        },
        "unknown": "Der er opstået en fejl"
    },
    "faq": {
        "datasets": {
            "questions": {
                "1": {
                    "desc": "<p> Præferencedata bruges til at forbedre modeller under fremtidig træning. </p><p> Ved blindt at sammenligne svarene fra to modeller udtrykker brugere deres præferencer og angiver, hvilke svar der er mest relevante. Disse præferencedata kan bruges til at forbedre modeljustering, det vil sige at træne dem til at generere svar, der er mere i overensstemmelse med brugernes forventninger og præferencer. </p><p> Dette er en iterativ proces, hvor modellen gradvist lærer at generere bedre svar baseret på feedback fra mennesker om svarenes kvalitet. Ved at blive eksponeret for præferencedata justerer modellerne deres svarstil. </p>",
                    "title": "Har præferencedata en umiddelbar effekt på forbedringen af modellerne?"
                },
                "2": {
                    "desc": "<p>Det særlige ved de data, der indsamles på platformen, er, at de er på dansk, og at de svarer til brugernes faktiske opgaver. Disse data afspejler menneskelige præferencer i en sproglig og kulturel kontekst. De gør det muligt i anden omgang at justere modellerne, så de bliver mere relevante og tilpasset danske brugers behov, samtidig med at de udfylder eventuelle skævheder eller mangler i de nuværende modeller.</p>",
                    "title": "Hvorfor er præferencedata værdifulde?"
                },
                "3": {
                    "desc": "<p>AI Arenaen positionerer sig som et evaluerings- og tilpasningsværktøj, der er specifikt til dansk, med fokus på svarenes kvalitet og indsamling af præferencedata, og adskiller sig dermed fra den globale rangeringstilgang hos <a href='https://lmarena.ai/' target='_blank'>chatbot arena</a> udviklet af <a href='http://lmsys.org' target='_blank'>lmsys.org</a> og den etiske justering af AI-modeller hos <a href='https://hannahkirk.github.io/prism-alignment/' target='_blank'>Prism Alignment Project</a>.</p>",
                    "title": "Hvad er det særlige ved AI Arenaen sammenlignet med andre lignende initiativer?"
                }
            },
            "title": "Datasæt"
        },
        "ecology": {
            "questions": {
                "1": {
                    "desc": "<p>AI Arenaen bruger den metode, der er udviklet af <a target='_blank' href='https://ecologits.ai/latest/'><strong>Ecologits</strong> (GenAI Impact)</a> til at levere et energiregnskab, der gør det muligt for brugerne at sammenligne den miljømæssige påvirkning fra forskellige AI-modeller for den samme forespørgsel. Denne gennemsigtighed er afgørende for at fremme udviklingen og implementeringen af mere miljøansvarlige AI-modeller.</p><p>Ecologits anvender principperne for livscyklusvurdering (LCA) i overensstemmelse med ISO 14044-standarden ved i øjeblikket at fokusere på påvirkningen fra <strong>inferens</strong> (det vil sige brugen af modeller til at besvare forespørgsler) og <strong>fremstillingen af grafikkort</strong> (udvinding af ressourcer, fremstilling og transport).</p><p>Modellens elforbrug estimeres under hensyntagen til forskellige parametre såsom størrelsen af den anvendte AI-model, placeringen af de servere, hvor modellerne er implementeret, og antallet af output-tokens. Beregningen af indikatoren for globalt opvarmningspotentiale udtrykt i CO2-ækvivalenter er afledt af målingen af modellens elforbrug.</p><p>Det er vigtigt at bemærke, at metoderne til vurdering af AI's miljøpåvirkning stadig er under udvikling samt at det er estimat.</p>",
                    "title": "Hvordan beregnes miljøindikatorerne?"
                },
                "2": {
                    "desc": "<p>Placeringen af datacentre spiller en rolle for AI's CO2-fodaftryk. Hvis en model trænes eller bruges i et land, der er stærkt afhængigt af fossile brændstoffer, vil dens miljøpåvirkning være større, end hvis den hostes i et land, der primært bruger vedvarende energi.</p><p>Metoden til analyse af AI's miljøpåvirkning udviklet af <a target='_blank' href='https://ecologits.ai/latest/'>Ecologits (fra GenAI Impact)</a>, integrerer data om energimixet i de forskellige lande, hvor serverne befinder sig. Dette gør det muligt at opnå et mere præcist og nuanceret estimat af det faktiske CO2-fodaftryk fra inferens på de forskellige generative AI-modeller.</p>",
                    "title": "Tager miljøindikatorerne hensyn til energimixet i de forskellige lande?"
                },
                "3": {
                    "desc": "<p>De nuværende miljøpåvirkningsindikatorer fokuserer primært på påvirkningen fra <strong>inferens</strong>, det vil sige brugen af AI-modeller til at besvare forespørgsler. Denne tilgang kan give den illusion, at inferens er mindre energikrævende end træning af modeller. Men <strong>virkeligheden er mere kompleks.</strong> Lad os tage analogien med bilen:</p><ul><li>At bygge en bil (træningen) er en engangsproces, der kræver mange ressourcer.</li><li>Hver biltur (inferens) forbruger mindre energi, men disse ture gentages dagligt, og deres antal er potentielt enormt.</li></ul><p>På samme måde <strong>kan den akkumulerede påvirkning fra inferens, i skalaen af millioner af brugere, der foretager daglige forespørgsler, vise sig at være større end påvirkningen fra den indledende træning.</strong> Derfor er det afgørende, at værktøjerne til vurdering af AI's CO2-fodaftryk tager hensyn til <strong>hele livscyklussen</strong> for modellerne, fra træning til brug i produktion</p>",
                    "title": "Tager miljøpåvirkningsindikatorerne hensyn til de ressourcer, der bruges til at træne modellerne?"
                }
            },
            "title": "Miljøindikatorer"
        },
        "i18n": {
            "questions": {
                "1": {
                    "desc": "<p>Ja, internationaliseringen af AI Arenaen er i gang. Projektet havde først success I Frankrig og er nu kommet til Danmark, samt Litauen og Sverige. Denne første fase gør det muligt at teste tilgangen og tilpasse interfacet til forskellige sproglige og kulturelle kontekster i Europa. På sigt kan kredsen udvides til flere europæiske sprog afhængigt af erfaringerne fra disse pilotlande. Målet er gradvist at opbygge et reelt europæisk digitalt fællesgode til evaluering af dialogbaserede AI-systemer, med en samarbejdsbaseret styring, der stadig skal defineres mellem de forskellige deltagende lande.</p>",
                    "title": "Er AI Arenaen kun på dansk eller er der planer for andre europæiske sprog?"
                },
                "2": {
                    "desc": "<p>Udviklingen af en europæisk platform til sammenligning af dialogbaserede AI-systemer giver flere konkrete fordele. Den gør det muligt at indsamle præferencedata, der afspejler de reelle behov hos europæiske brugere, og dermed forbedre modellernes relevans for dette publikum. Den sikrer således en bedre repræsentation af europæiske sprog og kulturer, som ofte er underrepræsenteret i globale evalueringer domineret af engelsk. Den sikrer også overholdelse af europæiske reguleringer (GDPR, AI Act) og integrerer evalueringskriterier, der er i overensstemmelse med europæiske prioriteter som miljømæssig bæredygtighed og algoritmisk gennemsigtighed. Endelig fremmer den fremkomsten af et konkurrencedygtigt og selvstændigt europæisk AI-økosystem.</p>",
                    "title": "Hvad er fordelene ved en specifikt europæisk platform til indsamling af præferencer?"
                }
            },
            "title": "Internationalisering"
        },
        "models": {
            "questions": {
                "1": {
                    "desc": "<p>Vi vælger modellerne baseret på deres popularitet, diversitet og relevans for brugerne. Vi bestræber os særligt på at gøre såkaldte <em>open weights</em> (semi-åbne) samt <em>open source</em> (åbne) modeller af forskellig størrelse tilgængelige.</p>",
                    "title": "Hvordan vælger I de modeller, der er i sammenligningsværktøjet?"
                },
                "2": {
                    "desc": "<p>Inferens, det vil sige muligheden for at sende forespørgsler til modellerne, er muliggjort takket være donationer fra cloud-udbydere, der støtter projektet: Google Cloud Platform, Hugging Face, Microsoft Azure, OVH, Scaleway.</p>",
                    "title": "Hvordan er det muligt at gøre denne tjeneste gratis?"
                },
                "3": {
                    "desc": "<p>Kvantiserede modeller er optimeret til at forbruge færre ressourcer ved at forenkle visse beregninger, samtidig med at de sigter mod den bedste svarkvalitet.</p><p>Kvantisering er en optimeringsteknik, der består i at reducere præcisionen af de tal, der bruges til at repræsentere parametrene i en AI-model. Dette gør det muligt at <strong>reducere modellens størrelse</strong> og <strong>fremskynde beregningerne</strong>, hvilket er særligt fordelagtigt ved inferens på maskiner med begrænsede ressourcer. Kvantisering af en model kan således også reducere miljøpåvirkningen.</p>",
                    "title": "Hvad er \"kvanticerede modeller\"?"
                },
                "4": {
                    "desc": "<p><strong>En models evne til at tale flere sprog er knyttet til den sproglige diversitet i dens træningsdata og ikke til landet den var udviklet i</strong>. <strong>LLM'er bruger enorme korpusser på mange sprog</strong>, men fordelingen af sprog i træningsdataene er ikke ensartet. En overrepræsentation af engelsk kan føre til begrænsninger i andre sprog. Disse begrænsninger viser sig for eksempel ved <strong>anglicismer eller en manglende evne til at generere indhold på visse sprog, der er klassificeret som \"truede\" af UNESCO</strong>.</p><p><strong>En models nøjagtighed og ordforrådsrigdom er afhængig af de data, der bruges til dens træning</strong>.</p>",
                    "title": "Er der en sammenhæng mellem nationaliteten af den virksomhed eller det forskningsinstitution, der står bag modellen, og dens evne til at tale flere sprog?"
                },
                "5": {
                    "desc": "<p>Der er få aktører, der er \"transparente\" omkring de datakilder, der bruges i træningskorpusserne. Disse oplysninger er ofte fortrolige af juridiske og kommercielle årsager.</p>",
                    "title": "Kan vi se modellernes træningsdata?"
                }
            },
            "title": "Modeller"
        },
        "title": "Ofte stillede spørgsmål",
        "usage": {
            "questions": {
                "1": {
                    "desc": "<p>De nuværende dialogbaserede sprogmodeller er <strong>ude af stand til at citere kilderne</strong>, som de har brugt til at generere et svar. De fungerer ved at forudsige det næste mest sandsynlige ord baseret på den statistiske fordeling i træningsdataene. Selvom de kan syntetisere information fra forskellige kilder, bevarer de ikke spor af oprindelsen af disse informationer.</p><p>Der findes dog teknikker som <strong>Kildebaseret generering</strong> (Retrieval-Augmented Generation, RAG), der sigter mod at afhjælpe denne begrænsning. Kildebaseret generering gør det muligt for modeller at få adgang til eksterne vidensbaser og <strong>levere kontekstualiseret information med kildehenvisninger</strong>. Denne tilgang er afgørende for at forbedre gennemsigtigheden og pålideligheden af de svar, der genereres af modellerne.</p>",
                    "title": "Kan modellerne citere deres kilder?"
                },
                "2": {
                    "desc": "<p>Du har stillet spørgsmålet \"hvem vandt fodboldkampen i går, og angiv dine kilder\", og du blev skuffet over svarene? Det er normalt…</p><p><strong>De \"rå\" dialogbaserede AI-systemer kan ikke besvare spørgsmål om de seneste nyheder.</strong> De er trænet på statiske datasæt og kan ikke interagere med nettet eller åbne links. De har ikke evnen til at opdatere sig i realtid med de begivenheder, der finder sted i verden. De oplysninger, som modellen har adgang til, er begrænset til datoen for dens seneste træning.</p><p>Hvis du derfor stiller et spørgsmål om en nylig aktuel begivenhed, vil modellen basere sig på potentielt forældede oplysninger med risiko for at generere unøjagtige svar.</p><p>I tilfældet med Perplexity, Copilot eller ChatGPT er de såkaldte \"rå\" dialogbaserede AI-systemer kombineret med andre teknologiske komponenter, der gør det muligt at forbinde til internettet for at få adgang til realtidsoplysninger. Man taler da om \"dialogbaserede agenter\".</p>",
                    "title": "Hvis jeg stiller et spørgsmål om de seneste nyheder, kan modellen så svare?"
                },
                "3": {
                    "desc": "<p>Hvis du inkluderer en URL i et spørgsmål, kan det dialogbaserede system ikke få adgang til den direkte. Sprogmodellerne behandler teksten i forespørgslen, men har ikke evnen til at interagere med nettet eller åbne links. De er trænet på et fast tekstdatasæt, og deres svar er baseret på disse træningsdata. Når et spørgsmål stilles, bruger modellerne denne træning til at generere et svar, men kan ikke få adgang til nye oplysninger online.</p><p>Som en analogi kan du forestille dig en studerende, der tager en eksamen uden adgang til internettet. Vedkommende kan bruge sin erhvervede viden til at besvare spørgsmålene, men kan ikke tjekke hjemmesider for at få yderligere information.</p>",
                    "title": "Hvis jeg inkluderer et URL-link i et spørgsmål, kan modellen så få adgang til det?"
                },
                "4": {
                    "desc": "<p>Det sker, at modellerne mister tråden i en samtale på grund af deres <strong>begrænsede kontekstvindue.</strong> Dette \"vindue\" repræsenterer mængden af forudgående information, som modellen kan fastholde, og fungerer som en korttidshukommelse. Jo mindre vinduet er, desto mere tilbøjelig er modellen til at glemme nøgleelementer i samtalen, hvilket fører til usammenhængende svar. Lange eller komplekse samtaler kan hurtigt fylde kontekstvinduet, hvilket øger risikoen for et usammenhængende svar.</p><p>Som en analogi kan du forestille dig en person, der kun husker de seneste fem sætninger i en samtale. Hvis samtalen er kort, kan personen følge med. Men hvis samtalen bliver lang, vil personen glemme afgørende information, hvilket vil gøre vedkommendes svar usammenhængende. På samme måde kan en AI-model med et lille kontekstvindue \"miste tråden\" i en samtale, når der udveksles for mange oplysninger, glemme pointer og producere svar, der ikke længere giver mening.</p>",
                    "title": "Hvorfor mister nogle modeller hurtigt tråden i samtalen?"
                },
                "5": {
                    "desc": "<p>Formuleringen af spørgsmål, eller \"prompts\", påvirker samtalens sammenhæng. For at opnå de bedste resultater fra en sprogmodel er det essentielt at mestre kunsten at <em>prompte</em>, det vil sige formuleringen af forespørgsler eller instruktioner. <strong>Klarhed er altafgørende</strong>:</p><ul><li>Brug et simpelt og direkte sprog, og undgå for lange eller komplekse spørgsmål. Opdel forespørgsler i flere simplere spørgsmål for mere præcise svar.</li><li><strong>Præcisér om nødvendigt specifikke formatkrav</strong>: Hvis du har brug for et svar i et bestemt format (liste, tabel, resumé osv.), så angiv det i prompten. Du kan også præcisere de trin, der skal følges, og de ønskede kvalitetskriterier.</li><li><strong>Specificer modellens rolle</strong>: Start for eksempel med \"Agér som en ekspert i...\" eller \"Forestil dig, at du er en lærer...\" for at styre tonen og perspektivet i svaret.</li><li><strong>Kontekstualiser dine spørgsmål</strong>: hvis nødvendigt, giv relevante eksempler for at guide modellen.</li><li><strong>Tilskynd til ræsonnement</strong>: brug opfordring til trin-for-trin ræsonnement (<em>Chain-of-Thought Prompting</em>) for at bede modellen om at forklare sin tankegang, hvilket gør svarene mere robuste.</li></ul><p>Samtalemodeller er følsomme over for variationer i formuleringen: et simpelt sprog, korte spørgsmål og en omformulering hvis nødvendigt kan hjælpe med at guide modellen mod relevante svar. Test og finpuds dine prompts for at finde den mest effektive formulering!</p>",
                    "title": "Hvad er de gode praksisser for at prompte?"
                },
                "6": {
                    "desc": "<p>Dialogbaseret AI svarer direkte ved at formulere sætninger ud fra et stort datasæt, som modellen er blevet trænet på, mens en søgemaskine foreslår links og ressourcer, som brugeren selv kan udforske.</p>",
                    "title": "Hvad er forskellen mellem at stille et spørgsmål til en dialogbaseret AI-model og at lave en søgning på Google?"
                }
            },
            "title": "Brug"
        }
    },
    "footer": {
        "backHome": "TIlbage til hjem - compar:IA",
        "helpUs": "Hjælp os med at forbedre produktet!",
        "license": {
            "linkTitle": "Etalab-licens - nyt vindue",
            "mention": "Medmindre andet udtrykkeligt er angivet som tredjeparts intellektuel ejendom, tilbydes indholdet på dette websted under <a {linkProps}>Etalab 2.0-licensen</a>"
        },
        "links": {
            "accessibility": "Tilgængelighed: ikke compliant",
            "legal": "Juridisk meddelelse",
            "privacy": "Privatlivspolitik",
            "sources": "Kildekode",
            "tos": "Brugsbetingelser"
        },
        "writeUs": "Hvis du støder på et problem eller har feedback til chatbot-arenaen, er du velkommen til at skrive til os <a {linkProps}>ved hjælp af denne formular</a> – vi læser alle beskeder. Tak!"
    },
    "general": {
        "a11y": {
            "desc": "Denne tilgængelighedserklæring gælder for webstedet <strong> comparia.beta.gouv.fr </strong> .",
            "disclaimer": "<strong> compar:IA </strong> forpligter sig til at gøre sine digitale tjenester tilgængelige i overensstemmelse med artikel 47 i lov nr. 2005-102 a' 11. februar 2005.",
            "improveAdress": "Adresse: DINUM, 20 avenue de Ségur 75007 Paris",
            "improveDelay": "Vi forsøger at svare inden for 2 hverdage.",
            "improveDesc": "Hvis du ikke kan få adgang til noget indhold eller nogen tjeneste, kan du kontakte administratoren af beta.gouv.fr for at blive henvist til et tilgængeligt alternativ eller få indholdet i et andet format.",
            "improveMail": "E-mail: <a {linkProps}>contact@beta.gouv.fr</a>",
            "improveTitle": "Forbedring og kontakt",
            "remedyAdvocate": "Skriv en besked til <a {linkProps}>Ombudsmanden</a>",
            "remedyAdvocateAdress": "Send et brev med posten (gratis, uden frimærke): Ombudsmanden - Gratis svar 71120 75342 Paris CEDEX 07",
            "remedyDelegateAdvocate": "Kontakt repræsentanten for <a {linkProps}>ombudsmanden i dit område</a>",
            "remedyDesc": "Denne procedure skal anvendes i følgende tilfælde: Du har rapporteret en tilgængelighedsfejl til webstedsadministratoren, som forhindrer dig i at få adgang til indhold eller en af portalens tjenester, og du har ikke modtaget et tilfredsstillende svar.",
            "remedyList": "Du kan:",
            "remedyTitle": "Klageadgang",
            "stateDesc": "Hjemmesiden comparia.beta.gouv.fr overholder ikke RGAA 4.1. Webstedet er endnu ikke blevet auditeret <strong>. Det er dog designet til at være tilgængeligt for så mange mennesker som muligt </strong> . Du bør derfor kunne:",
            "stateNavigate": "navigere på alle sider på webstedet ved hjælp af et tastatur",
            "statePrefs": "tilpasse siden til dine præferencer (skriftstørrelse, skærmzoom, ændring af typografi osv.) uden tab af indhold",
            "stateScreenReader": "se hjemmesiden med en skærmlæser.",
            "stateTitle": "Overholdelsesstatus",
            "title": "Erklæring om tilgængelighed"
        },
        "legal": {
            "a11yDesc": "Overholdelse af standarder for digital tilgængelighed er et fremtidigt mål, men vi stræber efter at gøre dette websted tilgængeligt for alle.",
            "a11yTitle": "Tilgængelighed",
            "directorDesc": "Romain Delassus, chef for den digitale afdeling i Kulturministeriet",
            "directorTitle": "Publikationens direktør",
            "editorDesc": "Denne hjemmeside er udgivet af det franske kulturministerium, 182 Rue Saint-Honoré, 75001 Paris",
            "editorTitle": "Udgivet",
            "hostingDesc": "Denne hjemmeside hostes af OVH SAS (<a {linkProps}>https://www.ovh.com</a>), som ligger på adressen 2 Rue Kellermann, 59100 Roubaix, Frankrig.",
            "hostingTitle": "Hosting af hjemmesiden",
            "reportA11y": "Hvis du støder på et tilgængelighedsproblem, der forhindrer dig i at få adgang til indhold eller funktioner på webstedet, må du endelig give os besked.",
            "reportA11yDesc": "For at lære mere om statens politik for digital tilgængelighed: <a {linkProps}>references.modernisation.gouv.fr/accessibilite-numerique</a>",
            "reportDesc": "Hvis du ikke modtager et hurtigt svar fra os, har du ret til at indgive din klage eller en anmodning om henvisning til Ombudsmanden.",
            "reportTitle": "Rapporter et problem",
            "securityCertif": "Hjemmesiden er beskyttet af et elektronisk certifikat, der i de fleste browsere vises som et hængelås. Denne beskyttelse hjælper med at sikre fortroligheden af udvekslinger.",
            "securityNoMail": "Under ingen omstændigheder vil de tjenester, der er forbundet med platformen, lede til e-mails, der beder om indtastning af personlige oplysninger.",
            "securityTitle": "Sikkerhed",
            "sources": "Medmindre andet er angivet, er alle tekster på denne hjemmeside underlagt <a {etalabLinkProps}>Etalab Open 2.0-licensen</a>. Kildekoden til denne applikation kan frit genbruges og er tilgængelig på <a {githubLinkProps}>GitHub</a>.",
            "title": "Juridisk meddelelse"
        },
        "privacy": {
            "cookiesBannerDesc": "Det er rigtigt, du behøvede ikke at klikke på et vindue, der dækkede halvdelen af siden, for at sige, at du accepterer brugen af cookies – selvom du ikke ved, hvad det betyder!",
            "cookiesBannerNoNeed": "Intet usædvanligt, ingen særlig behandling i forbindelse med et .gouv.fr-domæne. Vi overholder blot loven, som fastslår, at visse værktøjer til publikumssporing, der er korrekt konfigureret til at respektere privatlivets fred, er undtaget fra forudgående godkendelse.",
            "cookiesBannerTitle": "Hvorfor vises der ikke et banner om cookie-samtykke på dette websted?",
            "cookiesBannerTools": "Vi bruger <a {matomoLinkProps}>Matomo</a>, et <a {libreLinkProps}>gratis</a> værktøj, der er konfigureret til at overholde CNIL's \"Cookies\" <a {cnilLinkProps}>anbefaling</a>. Det betyder, at din IP-adresse for eksempel anonymiseres, inden den registreres. Det er derfor umuligt at knytte dine besøg på dette websted til din person.",
            "cookiesDesc": "Denne hjemmeside placerer en lille tekstfil (en \"cookie\") på din computer, når du besøger den. Dette giver os mulighed for at måle antallet af besøg og forstå, hvilke sider der er mest besøgte.",
            "cookiesDescMore": "Du kan fravælge sporing af din browsing på dette websted. Dette beskytter dit privatliv, men det forhindrer også ejeren i at lære af dine handlinger og skabe en bedre oplevelse for dig og andre brugere.",
            "cookiesTitle": "Cookies og samtykke",
            "dataAccessDatasets": "Brugerdialog og præferencedata distribueres under Etalabs Open License 2.0 på Hugging Face-platformen samt på Data.gouv.fr via Kulturministeriets konto (<a {linkProps}>https://huggingface.co/ministere-culture</a>).",
            "dataAccessDesc": "Selvfølgelig! Webstedets brugsstatistikker er frit tilgængelige på <a {linkProps}>stats.beta.gouv.fr</a>.",
            "dataAccessTitle": "Jeg bidrager til at berige dine data, kan jeg få adgang til dem?",
            "dataExtraCountry": "Destinationsland: Frankrig",
            "dataExtraHost": "Underleverandør: OVH",
            "dataExtraTitle": "Hvem hjælper os med at behandle dataene?",
            "dataExtraWarranty": "Garantier: <a {linkProps}>https://storage.gra.cloud.ovh.net/v1/AUTH_325716a587c64897acbef9a4a4726e38/contracts/9e74492-OVH_Data_Protection_Agreement-FR-6.0.pdf</a>",
            "dataExtraWhat": "Udført behandling: Hosting",
            "dataRespDesc": "Det franske kulturministeriums digitale afdeling er ansvarlig for behandlingen af dine personoplysninger.",
            "dataRespTitle": "Hvem er ansvarlig for databehandlingen?",
            "dataTimeDesc": "Data vedrørende brugere og deres samtaler med modeller gemmes fra det tidspunkt, hvor præferenceafstemningen registreres.",
            "dataTimeTitle": "Hvor længe opbevarer vi disse data?",
            "dataUseDesc": "Under alle omstændigheder forpligter udgiveren sig til at implementere foranstaltninger, der sikrer anonymiseringen af dialogdata, inden disse gøres offentligt tilgængelige.",
            "dataUseTitle": "Hvilken behandling foretages der af samtaledataene?",
            "desc": "Tjenesten udgives af det franske kulturministeriums digitale afdeling.",
            "privacyData": "De data, der indsamles på hjemmesiden, er følgende:",
            "privacyDataArena": "Data relateret til brugeres samtaler med modellerne: spørgsmål stillet af brugere, modellernes svar og brugerpræferencer udtrykt mellem de to modeller",
            "privacyDataForm": "Data relateret til spørgeskemaet \"Hjælp os med at forbedre compar:IA\".",
            "privacyDesc": "Tjenesten behandler ikke personoplysninger som defineret af CNIL, dvs. oplysninger, der direkte eller indirekte kan henføres til en identificerbar fysisk person.",
            "privacyResp": "Brugeren er ansvarlig for de data eller det indhold, som vedkommende indtaster i den prompt, som platformen stiller til rådighed. Ved at acceptere <a {linkProps}>brugsbetingelserne</a> accepterer brugeren ikke at overføre oplysninger, der kan identificere vedkommende selv eller en tredjepart.",
            "privacyTitle": "Behandler vi personoplysninger?",
            "title": "Fortrolighedspolitik"
        },
        "tos": {
            "contactDesc": "Hvis du har spørgsmål om tjenesten, kan du skrive til <a {linkProps}>contact@comparia.beta.gouv.fr</a>.",
            "contactTitle": "9. Kontakt",
            "defsEditor": "\"Udgiver\" henviser til Kulturministeriets digitale afdeling.",
            "defsModels": "\"Modeller\" henviser til de store sprogmodeller (LLM'er), der genbruges under deres brugslicens af platformen for at opfylde dens formål.",
            "defsPlatform": "\"Platform\" henviser til den hjemmeside, der gør tjenesterne tilgængelige.",
            "defsServices": "\"Tjenester\" henviser til de funktioner, som platformen tilbyder for at opfylde sine formål.",
            "defsTitle": "2. Definitioner",
            "defsUser": "\"Bruger\" henviser til enhver fysisk person, der bruger platformen og drager fordel af dens tjenester.",
            "descDatasets": "Disse datasæt vil blive gjort tilgængelige under en åben licens, især for at fremme forskningsformål.",
            "descEditor": "Arenaen er en platform, udgivet af det franske kulturministeriums digitale afdeling, til sammenligning af samtalemodeller rettet mod den brede offentlighed med det formål at (1) øge borgernes bevidsthed om store sprogmodeller (LLM'er) og (2) indsamle brugerpræferencer for at skabe afstemningsdatasæt.",
            "descTitle": "3. Platformsbeskrivelse",
            "descUse": "Brugeren stiller et spørgsmål på et givet sprog og modtager svar fra to anonyme store sprogmodeller (LLM'er). Hun/han stemmer på den model, der giver hendes/hans foretrukne svar, og får derefter vist modellernes identitet. Dette deltagende produktionssystem, der er inspireret af platformen \"<a {linkProps}>chatbot arena</a>\" (LMarena), gør det muligt at oprette datasæt med menneskelige præferencer for ægte opgaver på dansk, som kan bruges til modeltræning.",
            "dispoDesc": "Platformen er tilgængelig, undtagen i tilfælde af force majeure eller begivenheder, der ligger uden for udgiverens kontrol.",
            "dispoResp": "I denne henseende kan udgiveren ikke holdes ansvarlig for tab eller skader af nogen art, der måtte opstå som følge af en fejlfunktion eller utilgængelighed af tjenesten. Sådanne situationer giver ikke ret til økonomisk kompensation.",
            "dispoRight": "Udgiveren forbeholder sig ret til uden forudgående varsel at suspendere, afbryde eller begrænse adgangen til alle eller en del af tjenesterne, især i forbindelse med vedligeholdelses- og opdateringsarbejder, der er nødvendige for, at tjenesten og det tilhørende udstyr kan fungere korrekt, eller af andre årsager, herunder tekniske årsager.",
            "dispoTitle": "7. Tjenestens tilgængelighed",
            "dispoWarranty": "Det kan ikke garanteres, at tjenesten vil være fri for fejl eller uregelmæssigheder. Tjenesten leveres derfor uden nogen form for garanti med hensyn til dens tilgængelighed og ydeevne.",
            "evoDesc": "Brugsvilkårene kan til enhver tid ændres eller suppleres uden forudgående varsel, afhængigt af ændringer i tjenesterne, ændringer i lovgivningen eller af andre årsager, der anses for nødvendige.",
            "evoDescMore": "Disse ændringer og opdateringer er bindende for brugeren, som derfor bør regelmæssigt henvise til dette afsnit for at kontrollere de aktuelle generelle vilkår.",
            "evoTitle": "8. Ændringer af brugsbetingelserne",
            "featuresDatasets": "Tjenesten indsamler data om brugerdialog og præferencer. De delte datasæt vil omfatte brugerens spørgsmål, svar fra de to modeller, afstemningen og brugerens præferencer.",
            "featuresDatasetsMore": "Udgiveren forbeholder sig ret til at distribuere brugerens dialog- og præferencedata under en etalab 2.0-licens. Datasættet distribueres på Data.gouv og Hugging Face-platformen via det franske kulturministeriums konto (<a {linkProps}>https://huggingface.co/ministere-culture</a>).",
            "featuresDesc": "For at opfylde det dobbelte mål om at øge borgernes bevidsthed om store sprogmodeller og indsamle brugerpræferencer tilbyder platformen følgende tjenester uden adgangsbegrænsninger:",
            "featuresDescMore": "En menneske-maskine-grænseflade, der giver brugerne mulighed for at føre en dialog med to samtalemodeller samtidigt og stemme på det foretrukne svar.",
            "featuresModels": "De modeller, der er integreret i platformen, implementeres på forskellige partneres inferensservere (Scaleway, OVH, Hugging Face, Google Cloud, Mistral AI). Betingelserne for standardiseret inferens er specificeret på platformen for at sikre gennemsigtighed i brugen af modellerne.",
            "featuresModelsMore": "Modelsammenligningsgrænsefladen.",
            "featuresTitle": "4. Funktioner",
            "featuresVote": "Når afstemningen er afsluttet, kan brugeren se listen over modeller, der er integreret i chatbot-arenaen, og få adgang til en liste med oplysninger om disse modeller. Oplysningerne om modellerne er hentet fra forskellige kilder.",
            "featuresVoteMore": "Deling og adgang til datasæt, der er resultatet af indsamling af brugerpræferencer.",
            "licenceCode": "Platformens kildekode er åben og tilgængelig her: <a {linkProps}>https://github.com/betagouv/ComparIA</a>",
            "licenceLLM": "De LLM'er, der bruges til at drive tjenesterne, er underlagt følgende licenser:",
            "licenceLLMEvolution": "Listen over sprogmodeller, der er integreret i platformen, kan ændres over tid og opdateres ved hver ændring.",
            "licenceLLMLicence": "Licens",
            "licenceLLMModel": "Samtale AI-model",
            "licenceLLMNoticeLink": "Link til model-licenserne",
            "licenceLLMUnavailable": "Ikke tilgængelig",
            "licenceTitle": "6. Kode og licenser",
            "respEditor": "Generelt fraskriver udgiveren sig ethvert ansvar i tilfælde af manglende overholdelse af brugsbetingelserne.",
            "respLegal": "Platformen er ikke beregnet til at blive brugt til at generere ulovligt indhold eller indhold, der strider mod den offentlige orden, og mere generelt til generering, der overtræder den gældende lovgivning.",
            "respLegalMore": "I denne henseende må brugeren ikke indtaste indhold eller oplysninger i prompten, der er i strid med gældende lovgivningsmæssige og reguleringsmæssige bestemmelser.",
            "respPrivacy": "Da de data, som brugeren indtaster på platformen, er beregnet til at blive gjort tilgængelige, forpligter brugeren sig til ikke at overføre oplysninger, der kan identificere brugeren eller en tredjepart.",
            "respPrivacyMore": "Under alle omstændigheder forpligter udgiveren sig til at implementere midler til at sikre anonymiseringen af dialogdata, inden disse gøres tilgængelige.",
            "respTitle": "5. Ansvar",
            "respUser": "Brugeren er ansvarlig for de data eller det indhold, som vedkommende indtaster i den prompt, som platformen stiller til rådighed.",
            "scopeDesc": "Adgang til platformen er gratis, kræver ikke registrering og indebærer anvendelse af specifikke betingelser, der er angivet i disse brugsbetingelser.",
            "scopeTitle": "1. Anvendelsesområde",
            "title": "Brugsbetingelser"
        }
    },
    "generated": {
        "licenses": {
            "os": {
                "Apache 2.0": {
                    "license_desc": "<p>Denne licens gør det muligt at bruge, modificere og distribuere modellen frit, herunder til kommercielle formål. Ud over brugsfriheden garanterer den juridisk beskyttelse ved at inkludere en patentlicensklausul, der fungerer som en forsikring: hvis du bruger denne model, forpligter bidragyderne sig til ikke at sagsøge dig for krænkelse af deres patenter relateret til projektet. Denne gensidige beskyttelse undgår juridiske konflikter mellem brugere og udviklere. Ved distribution af modificerede versioner skal betydelige ændringer angives med passende bemærkninger, hvilket garanterer gennemsigtighed for brugeren.</p>"
                },
                "CC-BY-NC-4.0": {
                    "license_desc": "<p>Denne licens gør det muligt at dele og tilpasse indholdet frit, forudsat at man krediterer ophavsmanden, men forbyder enhver kommerciel brug. Den tilbyder fleksibilitet til ikke-kommercielle formål, samtidig med at den beskytter ophavsmandens rettigheder.</p>",
                    "reuse_specificities": "men kun til ikke-kommercielle formål"
                },
                "Gemma": {
                    "license_desc": "<p>Denne licens er designet til at tilskynde til brug, modificering og redistribution af software, men inkluderer en klausul, der fastslår, at alle modificerede eller forbedrede versioner skal deles med fællesskabet under den samme kildelicens, hvilket således fremmer samarbejde og gennemsigtighed i softwareudvikling.</p>"
                },
                "Jamba Open Model": {
                    "commercial_use_specificities": "under 50 millioner dollars i årlig omsætning",
                    "license_desc": "<p>Denne licens gør det muligt at bruge, reproducere, modificere og distribuere koden frit med kreditering, men pålægger restriktioner for organisationer, der overstiger 50 millioner dollars i årlig omsætning.</p>"
                },
                "Llama 3 Community": {
                    "commercial_use_specificities": "Under 700 millioner brugere",
                    "license_desc": "<p>Denne licens gør det muligt at bruge, modificere og distribuere koden frit med kreditering, men pålægger restriktioner for operationer, der overstiger 700 millioner månedlige brugere, og forbyder genanvendelse af koden eller det genererede indhold til træning eller forbedring af konkurrerende modeller, hvilket således beskytter Metas teknologiske investeringer og brand.</p>"
                },
                "Llama 3.1": {
                    "commercial_use_specificities": "Under 700 millioner brugere",
                    "license_desc": "<p>Denne licens gør det muligt at bruge, reproducere, modificere og distribuere koden frit med kreditering, men pålægger restriktioner for operationer, der overstiger 700 millioner månedlige brugere. Genanvendelse af koden eller det genererede indhold til træning eller forbedring af afledte modeller er tilladt, forudsat at man viser \"built with llama\" og inkluderer \"Llama\" i deres navn ved enhver distribution.</p>"
                },
                "Llama 3.3": {
                    "commercial_use_specificities": "under 700 millioner brugere",
                    "license_desc": "<p>Denne <strong>ikke-eksklusive, globale og royalty-fri</strong> licens gør det muligt at bruge, reproducere, modificere og distribuere koden og Llama 3.3-materialerne frit med kreditering. Den tillader især genanvendelse til forbedring af afledte modeller, men pålægger restriktioner for kommercielle operationer af meget stor skala.</p>"
                },
                "Llama 4": {
                    "commercial_use_specificities": "under 700 millioner brugere\n",
                    "license_desc": "<p>Denne ikke-eksklusive, globale og royalty-fri licens gør det muligt at bruge, reproducere, modificere og distribuere Llama 4-materialerne (modeller og dokumentation) med kreditering. Den pålægger dog to væsentlige restriktioner: (1) virksomheder, der overstiger 700 millioner aktive månedlige brugere, skal indhente en særlig licens fra Meta, og (2) <strong>total udelukkelse</strong> af personer bosiddende i EU og virksomheder med hovedsæde i EU fra direkte brug af de multimodale modeller på grund af regulatorisk usikkerhed relateret til den europæiske AI Act. Europæiske slutbrugere kan dog få adgang til tjenester, der integrerer Llama 4, forudsat at de leveres fra uden for EU.</p>"
                },
                "MIT": {
                    "license_desc": "<p>MIT-licensen er en permissiv fri software-licens: den tillader enhver at genbruge, modificere og distribuere modellen, selv til kommercielle formål, forudsat at den oprindelige licens og ophavsretsnoter inkluderes.</p>"
                },
                "Mistral AI Research License": {
                    "license_desc": "<p>Denne ikke-eksklusive og royalty-fri licens tillader brug, kopiering, modificering og distribution af Mistral-modellerne og deres afledte versioner (inklusiv modificerede eller fintuned versioner). Den er dog strengt begrænset til forskningsformål.</p>",
                    "reuse_specificities": "men kun til ikke-kommercielle formål"
                }
            },
            "proprio": {
                "Alibaba": {
                    "license_desc": "Modellen er tilgængelig under en betalt licens og tilgængelig via API på Alibaba-selskabets platforme, hvilket kræver betaling pr. brug baseret på antallet af behandlede tokens eller på den reserverede infrastruktur."
                },
                "Amazon": {
                    "license_desc": "Modellen er tilgængelig under en betalt licens og tilgængelig via Amazon Bedrock, hvilket kræver betaling pr. brug baseret på antallet af behandlede tokens eller på den reserverede infrastruktur.",
                    "reuse_specificities": "undtagen til at destillere eller træne andre modeller på Amazons platforme."
                },
                "Anthropic": {
                    "license_desc": "Modellen er tilgængelig under en betalt licens og tilgængelig via API på Anthropic-selskabets platforme eller partnerselskabers platforme, hvilket kræver betaling pr. brug baseret på antallet af behandlede tokens eller på den reserverede infrastruktur."
                },
                "Google": {
                    "license_desc": "Modellen er tilgængelig under en betalt licens og tilgængelig via API på Google-selskabets platforme, hvilket kræver betaling pr. brug baseret på antallet af behandlede tokens eller på Googles reserverede infrastruktur.",
                    "reuse_specificities": "undtagen til at træne andre modeller på Vertex AI"
                },
                "Liquid": {
                    "license_desc": "Modellen er tilgængelig under en betalt licens og tilgængelig via API på Liquid AI-selskabets platforme, hvilket kræver betaling pr. brug baseret på antallet af behandlede tokens."
                },
                "Mistral AI": {
                    "license_desc": "Modellen er tilgængelig under en betalt licens og tilgængelig via Mistral API, Amazon Sagemaker og flere andre hosting-udbydere, hvilket kræver betaling pr. brug baseret på antallet af behandlede tokens eller på den reserverede infrastruktur."
                },
                "OpenAI": {
                    "license_desc": "Modellen er tilgængelig under en betalt licens og tilgængelig via API på OpenAI-selskabets platforme eller via Microsoft Azure-tjenesterne, hvilket kræver betaling pr. brug baseret på antallet af behandlede tokens eller på den reserverede infrastruktur."
                },
                "xAI": {
                    "license_desc": "Modellen er tilgængelig under en betalt licens og tilgængelig via X og xAI, hvilket kræver betaling pr. brug baseret på antallet af behandlede tokens eller på den reserverede infrastruktur."
                }
            }
        },
        "models": {
            "Aya 23 8B": {
                "desc": "<p>Lille multilingual model, trænet specifikt i stor udstrækning på sprog, der generelt er underrepræsenterede.</p>",
                "fyi": "<p>Aya 23 8B fra Cohere er en lille model fra Command R-familien, som specielt er blevet trænet på et multilingvalt korpus.</p>",
                "size_desc": "<p>En model af lille størrelse er mindre kompleks og ressourcekrævende sammenlignet med større modeller, samtidig med at den tilbyder tilstrækkelig ydeevne til forskellige opgaver (resumé, oversættelse, tekstklassificering...)</p>"
            },
            "Aya Expanse 32B": {
                "desc": "<p>Mellemstor multilingual model, der er i stand til at behandle 23 sprog.</p>",
                "fyi": "<p>Cohere, den canadiske virksomhed bag denne model, blev grundlagt i 2019 af tidligere forskere fra Google Brain, herunder Aidan Gomez, medforfatter til det berømte paper \"Attention Is All You Need\", som revolutionerede AI. Dens primære særkende ligger i dens eksklusive fokus på generativ AI til virksomheder, særligt regulerede sektorer som finans, sundhed, fremstilling og energi samt den offentlige sektor. Virksomheden er også pioner inden for multilingvale tilgange og opretholder et nonprofit-forskningslaboratorium for at støtte åben innovation.</p>\n<p>Denne model er designet til at tilbyde gode kapaciteter i hvert af de 23 sprog i dens træningskorpus.</p>",
                "size_desc": "<p>Med 32 milliarder parametre tilhører denne model kategorien af mellemstore modeller. Den kan hostes på en server udstyret med et enkelt kraftfuldt grafikkort, hvilket bidrager til at begrænse infrastrukturomkostningerne.</p>\n<p>Den har et kontekstvindue på op til 130.000 tokens, hvilket er nyttigt til analyse af lange dokumenter.</p>"
            },
            "Aya Expanse 8B": {
                "desc": "<p>Lille multilingual model, anden iteration af Aya-serien, trænet specifikt i stor udstrækning på sprog, der generelt er underrepræsenterede.</p>",
                "fyi": "<p>Aya Expanse 8B fra Cohere, en canadisk virksomhed, er en lille model fra Command R-familien, som specielt er blevet trænet på et multilingvalt korpus.</p>",
                "size_desc": "<p>En model af lille størrelse er mindre kompleks og ressourcekrævende sammenlignet med større modeller, samtidig med at den tilbyder tilstrækkelig ydeevne til forskellige opgaver (resumé, oversættelse, tekstklassificering...)</p>"
            },
            "Aya23-35B": {
                "desc": "<p>Mellemstor multilingual model, trænet specifikt i stor udstrækning på sprog, der generelt er underrepræsenterede.</p>",
                "fyi": "<p>Aya 23 35B fra Cohere er en mellemstor model fra Command R-familien, som specielt er blevet trænet på et multilingvalt korpus.</p>",
                "size_desc": "<p>Mellemstore modeller tilbyder en god balance mellem kompleksitet, omkostninger og ydeevne: de er meget mindre ressourcekrævende end store modeller, samtidig med at de er i stand til at håndtere komplekse opgaver såsom sentimentanalyse eller ræsonnement.</p>"
            },
            "Chocolatine 14B": {
                "desc": "<p>Baseret på Microsofts Phi-3 Medium-model er denne model blevet specialiseret i det franske sprog.</p>",
                "fyi": "<p>Baseret på Microsofts Phi-3 Medium-model er denne model blevet specialiseret i det franske sprog. Modellens navn 'Chocolatine' er en hentydning til CroissantLLM-projektet, som var et af de første initiativer til at skabe en open source-model af lille størrelse optimeret til fransk.</p>",
                "size_desc": "<p>En model af lille størrelse er mindre kompleks og ressourcekrævende sammenlignet med større modeller, samtidig med at den tilbyder tilstrækkelig ydeevne til forskellige opgaver (resumé, oversættelse, tekstklassificering...)</p>"
            },
            "Chocolatine 2 14B": {
                "desc": "<p>Baseret på Qwen2.5-modellen fra Alibaba-selskabet er denne model blevet specialiseret i det franske sprog.</p>",
                "fyi": "<p>Baseret på Qwen2.5-modellen fra Alibaba-selskabet er denne model blevet specialiseret i det franske sprog. Modellens navn 'Chocolatine' er en hentydning til CroissantLLM-projektet, som var et af de første initiativer til at skabe en open source-model af lille størrelse optimeret til fransk.</p>",
                "size_desc": "<p>En model af lille størrelse er mindre kompleks og ressourcekrævende sammenlignet med større modeller, samtidig med at den tilbyder tilstrækkelig ydeevne til forskellige opgaver (resumé, oversættelse, tekstklassificering...)</p>"
            },
            "Claude 3.5 Sonnet v2": {
                "desc": "<p>Meget ydeevnestærk model inden for kodning, skabt efter en forbedring af post-training sammenlignet med Claude 3</p>",
                "fyi": "<p>Den bedste model i Claude 3.5-familien, denne model er specialiseret i generering af litterære tekster og en mere naturlig tone. Version v2 blev udgivet i oktober 2024.</p>",
                "size_desc": "<p>Disse modeller med flere hundrede milliarder parametre er de mest komplekse og avancerede med hensyn til ydeevne og præcision. De beregnings- og hukommelsesressourcer, der er nødvendige for at implementere disse modeller, er af en sådan art, at de er beregnet til de mest avancerede applikationer og højt specialiserede miljøer.</p>"
            },
            "Claude 3.7 Sonnet": {
                "desc": "<p>Meget stor multimodal og multilingual model, ydeevnestærk til kodegenerering, med to svarmetoder: brugeren kan vælge mellem en ræsonnementsmetode for mere dybdegående svar eller en hurtig metode til direkte at generere det endelige svar.</p>",
                "fyi": "<p>Claude 4 Opus er den mest avancerede version af Claude 4-familien. Den er optimeret til rå kraft og komplekse opgaver, der kræver vedvarende ræsonnement over lange perioder: den kan for eksempel arbejde på langsigtede opgaver (Anthropic erklærer, at den kan arbejde op til syv timer uafhængigt). Til gengæld er Opus dyrere at bruge, langsommere til at svare og kræver flere ressourcer for at fungere.</p>\n<p>Modellen tilbyder to anvendelsesmetoder: en refleksionsmetode med trin-for-trin ræsonnement til komplekse problemer og en hurtig metode til direkte svar. I modsætning til andre modeller er ræsonnementsmetoden ikke primært blevet trænet på matematiske data, men tilpasset til praktiske use cases.</p>",
                "size_desc": "<p>Modellens nøjagtige størrelse er ikke kendt. Indicier tyder på, at det er en meget stor model, der kræver servere udstyret med flere kraftfulde grafikkort for at fungere. De tilgængelige estimater er baseret på indirekte indicier som inferensomkostninger og svarlantens. Den har et kontekstvindue på op til 200.000 tokens, egnet til analyse af lange dokumenter eller kode-repositories.</p>"
            },
            "Claude 4 Sonnet": {
                "desc": "<p>Meget stor multimodal og multilingual model, der er meget kraftfuld inden for kodning. Brugeren eller udvikleren, som anvender denne model, kan vælge mellem flere niveauer af ræsonnement.</p>",
                "fyi": "<p>Claude 4 Sonnet er en mere kompakt version af Claude 4 Opus optimeret til hastighed, effektivitet og tilgængelighed. Den er lidt mindre god til opgaver, der kræver komplekst ræsonnement i flere trin. Ikke desto mindre er den markant billigere, hurtigere og forbruger mindre energi end Opus 4.</p>\n<p>Modellen tilbyder muligheden for at vælge intensiteten af \"ræsonnement\". I modsætning til andre modeller er ræsonnementsmetoden ikke primært blevet trænet på matematiske data, men især på praktiske use cases.</p>",
                "size_desc": "<p>Den nøjagtige størrelse er ikke kendt. Indicier tyder på, at det er en meget stor model, der kræver servere udstyret med flere kraftfulde grafikkort for at fungere. De tilgængelige estimater er baseret på indirekte indicier som inferensomkostninger og svarlantens. Modellen har et kontekstvindue på op til 1.000.000 tokens, egnet til analyse af meget lange dokumenter eller kode-repositories.</p>"
            },
            "Claude 4.5 Sonnet": {
                "desc": "<p>Meget stor multimodal og multilingual model, ekstremt ydeevnestærk inden for kodning, ræsonnement og matematik. Brugeren eller udvikleren, som anvender denne model, kan vælge mellem flere niveauer af ræsonnement.</p>",
                "fyi": "<p>Claude Sonnet 4.5 er en direkte evolution af Sonnet 4. \".5\" betegner de store ændringer, der er introduceret under post-træningen, som resulterer i betydelige forbedringer inden for ræsonnement, matematik og især i den konkrete brug af computere. På tidspunktet for lanceringen betragtes den som verdens bedste model til kodning og udmærker sig i løsning af lange og komplekse flertrinsopgaver. Dens præstationer på benchmarks som SWE-bench Verified og OSWorld markerer en klar fremgang sammenlignet med tidligere versioner, med en evne til at opretholde sin \"koncentration\" i mere end tredive timer på det samme problem.</p>",
                "size_desc": "<p>Den nøjagtige størrelse er ikke kendt. Alt tyder på, at det er en meget stor model, der kræver servere udstyret med flere kraftfulde grafikkort for at få den til at fungere. Estimaterne af størrelse og energiforbrug er baseret på indirekte indicier som inferensomkostninger og observeret latens. Claude Sonnet 4.5 har et kontekstvindue på op til 1.000.000 tokens, egnet til analyse af hele kode-repositories eller meget store dokumenter.</p>"
            },
            "Command A": {
                "desc": "<p>Stor model, ydeevnestærk til programmering, brug af eksterne værktøjer og \"retrieval augmented generation\" (RAG).</p>",
                "fyi": "<p>Cohere, den canadiske virksomhed bag denne model, blev grundlagt i 2019 af tidligere forskere fra Google Brain, herunder Aidan Gomez, medforfatter til det berømte paper <a href=\"https://arxiv.org/abs/1706.03762\">\"Attention Is All You Need\"</a> udgivet i 2017, som revolutionerede AI. Virksomheden skiller sig ud ved sit eksklusive fokus på generativ AI til virksomheder, særligt regulerede sektorer som finans, sundhed, fremstilling og energi samt den offentlige sektor. Virksomheden er også pioner inden for multilingvale tilgange og opretholder et nonprofit-forskningslaboratorium for at støtte åben innovation.</p>\n<p>Denne model er designet til at fungere på mere end 23 sprog og til nemt at integrere i virksomhedssystemer. Den er en af de få modeller, der distribueres under <strong>CC-BY-NC 4.0-licensen, som tillader deling og modificering, men forbyder enhver kommerciel brug.</strong> Dette licensvalg afspejler Coheres ønske om at bidrage til forskning og open source-fællesskabet, samtidig med at virksomheden bevarer kontrollen over kommerciel anvendelse for at beskytte sin forretningsmodel... Dette udelukker for eksempel integration af modellen i produkter eller tjenester solgt af en virksomhed til kunder, men tillader akademisk brug, test eller interne projekter begrænset til en ikke-kommerciel ramme.</p>",
                "size_desc": "<p>Med 111 milliarder parametre tilhører denne model de store modeller. Den kræver mindst to kraftfulde grafikkort til hosting, hvilket medfører en betydelig driftsomkostning.</p>\n<p>Dens kontekstvindue når op på 256.000 tokens, egnet til analyse af store dokumentsamlinger eller kodebaser.</p>"
            },
            "Command R": {
                "desc": "<p>Med 111 milliarder parametre tilhører denne model de store modeller. Den kræver mindst to kraftfulde grafikkort til hosting, hvilket medfører en betydelig driftsomkostning.</p>\n<p>Dens kontekstvindue når op på 256.000 tokens, egnet til analyse af store dokumentsamlinger eller kodebaser.</p>",
                "fyi": "<p>Cohere, den canadiske virksomhed bag denne model, blev grundlagt i 2019 af tidligere forskere fra Google Brain, herunder Aidan Gomez, medforfatter til det berømte paper \"Attention Is All You Need\", som revolutionerede AI. Dens primære særkende ligger i dens eksklusive fokus på generativ AI til virksomheder, særligt regulerede sektorer som finans, sundhed, fremstilling og energi samt den offentlige sektor. Virksomheden er også pioner inden for multilingvale tilgange og opretholder et nonprofit-forskningslaboratorium for at støtte åben innovation.</p>\n<p>Denne model er blevet evalueret på mere end 10 sprog. Dens kontekstvindue når op på 128.000 tokens, hvilket letter analysen af lange dokumenter. Dette vindue er blevet fordoblet i den følgende version af modellen (Command A).</p>",
                "size_desc": "<p>Med 35 milliarder parametre tilhører denne model kategorien af mellemstore modeller. Den kan hostes på en server udstyret med et enkelt kraftfuldt grafikkort, hvilket bidrager til at begrænse infrastrukturomkostningerne.</p>"
            },
            "Command R+": {
                "desc": "<p>Multilingual model specialiseret i 10 sprog, specialiseret til business use cases.</p>",
                "fyi": "<p>Storebror i Coheres Command R-familie, denne sprogmodel er orienteret mod professionel brug og designet specifikt til opgaver inden for søgning og informationsudtræk.</p>",
                "size_desc": "<p>Store modeller kræver betydelige ressourcer, men tilbyder den bedste ydeevne til avancerede opgaver som kreativ skrivning, dialogmodellering og applikationer, der kræver en nuanceret forståelse af konteksten.</p>"
            },
            "DeepSeek R1": {
                "desc": "<p>Meget stor model, der er meget ydeevnestærk på matematiske, videnskabelige og programmeringsopgaver, som simulerer et ræsonnemenstrin, før den genererer sit svar.</p>",
                "fyi": "<p>Denne model er baseret på en Mixture of Experts-arkitektur (MoE) med 61 lag. Den har i alt 671 milliarder parametre, hvoraf 37 milliarder aktiveres per token. Træningen har anvendt forstærkningslæring i stor skala med flere trin af SFT-justering (<em>supervised fine-tuning</em>: en superviseret fintuning, hvor modellen lærer fra eksempler på korrekte svar) og bootstrap-data.</p>",
                "size_desc": "<p>Med 671 milliarder parametre er DeepSeek R1 en meget stor model, der kræver flere kraftfulde grafikkort for at fungere. Ræsonnementsmodeller af denne type arbejder længere tid for at producere et svar, hvilket øger energiforbruget. Dog aktiverer Mixture of Experts-arkitekturen (MoE) kun en del af parametrene ved hver token, hvilket begrænser dens energiaftryk. Kontekstvinduet når op på 163.840 tokens, hvilket er egnet til analyse af lange dokumenter.</p>"
            },
            "DeepSeek R1 0528": {
                "desc": "<p>Meget stor model, specialiseret i matematiske, videnskabelige og programmeringsopgaver. Den simulerer et ræsonnemenstrin, før den genererer sit svar, og med opdateringen fra maj 2025 har den opnået større analysedybde og præcision takket være en optimering af post-træningen.</p>",
                "fyi": "<p>Denne model er baseret på en Mixture of Experts-arkitektur (MoE) med 61 lag. Den har i alt 671 milliarder parametre, hvoraf 37 milliarder aktiveres per token. Træningen har anvendt forstærkningslæring i stor skala med flere trin af SFT-justering (<em>supervised fine-tuning</em>: en superviseret fintuning, hvor modellen lærer fra eksempler på korrekte svar) og bootstrap-data. Dens seneste version (DeepSeek-R1-0528) forbedrer betydeligt dens ræsonnementskkapaciteter, reducerer hallucinationsraten og styrker effektiviteten inden for programmering, logik og funktionskald. På AIME 2025-testen er dens score steget fra 70 % til 87,5 %, hvilket bringer den tættere på modeller som o3 og Gemini 2.5 Pro.</p>",
                "size_desc": "<p>Med 671 milliarder parametre er DeepSeek R1 en meget stor model, der kræver flere kraftfulde grafikkort for at fungere. Ræsonnementsmodeller af denne type arbejder længere tid for at producere et svar, hvilket øger energiforbruget. Dog aktiverer Mixture of Experts-arkitekturen (MoE) kun en del af parametrene ved hver token, hvilket begrænser dens energiaftryk. Kontekstvinduet når op på 163.840 tokens, hvilket er egnet til analyse af lange dokumenter.</p>"
            },
            "DeepSeek R1 Llama 70B": {
                "desc": "<p>Stor model baseret på Meta Llama 3.3 70B, genoptrænet med ræsonnementseksempler fra DeepSeek R1-modellen. Den tilbyder gode kapaciteter inden for matematik og kodning.</p>",
                "fyi": "<p>Modellen er ikke blevet trænet fra bunden. Den er baseret på Llama 3.3 70B, genoptrænet ved brug af resultater genereret af DeepSeek R1. Denne proces har gjort det muligt at give Llama 3.3 70B en evne til at simulere ræsonnement, uden mulighed for brugeren til at vælge at aktivere eller deaktivere denne funktion.</p>\n<p>I overensstemmelse med forpligtelserne i Llama 3.3-licensen skal virksomheden bevare nævnelsen af kildemodellen i modellens navn, som er underlagt den samme licensordning.</p>",
                "size_desc": "<p>Med 70 milliarder parametre er denne model klassificeret blandt de store modeller. Den kræver flere kraftfulde grafikkort for at fungere, hvilket medfører høje driftsomkostninger. Ræsonnementsmodeller arbejder også længere tid for at producere et svar, hvilket øger deres energiforbrug.</p>\n<p>Kontekstvinduet er på 16.000 tokens, hvilket kan være begrænsende for analyse af meget store dokumenter.</p>"
            },
            "DeepSeek V3": {
                "desc": "<p>Meget stor model designet til komplekse opgaver: kodegenerering, brug af værktøjer, analyse af lange dokumenter. Den kan behandle mange sprog, men den er særligt egnet til engelsk og kinesisk.</p>",
                "fyi": "<p>Denne model er baseret på en Mixture of Experts-arkitektur (MoE) med 671 milliarder parametre, men aktiverer kun 37 milliarder per genereret token. Den er effektiv til funktionskald, generering af strukturerede output (JSON) og kodegenerering.</p>",
                "size_desc": "<p>DeepSeek V3 er en meget stor model, der kræver flere grafikkort for at fungere. Mixture of Experts-arkitekturen (MoE) gør det dog muligt kun at aktivere en del af parametrene, hvilket reducerer aftrykket sammenlignet med en tæt model af samme størrelse.</p>\n<p>Kontekstvinduet når op på 128.000 tokens, hvilket er nyttigt til analyse af lange dokumenter.</p>"
            },
            "DeepSeek v3": {
                "desc": "<p>Udgivet i december 2024, har DeepSeek V3-modellen en Mixture-of-Experts-arkitektur, der gør det muligt for den at være meget stor, samtidig med at inferensomkostningerne reduceres.</p>"
            }
        }
    },
    "header": {
        "banner": "Chatbot-arenaen er nu tilgængelig på litauisk 🇱🇹, svensk 🇸🇪 og dansk 🇩🇰!",
        "chatbot": {
            "newDiscussion": "Ny samtale",
            "step": "Trin",
            "stepOne": {
                "description": "Vær opmærksom på både indhold og form, og vurdér derefter hvert svar.",
                "title": "Hvad synes du om svarene?"
            },
            "stepTwo": {
                "description": "Se den miljømæssige påvirkning af dine samtaler med hver model",
                "title": "Modellerne er afsløret!"
            }
        },
        "help": {
            "link": {
                "content": "Hjælp os med at forbedre compar:IA",
                "title": "Giv feedback på arenaen – åbner et nyt vindue"
            }
        },
        "homeTitle": "Hjem - compar:IA",
        "logoAlt": "Den Franske Republik",
        "menu": "Menu",
        "startDiscussion": "Start samtalen",
        "subtitle": "Chatbot-arenaen",
        "title": {
            "compar": "compar",
            "ia": "AI"
        },
        "votes": {
            "count": "{count} stemmer",
            "legend": "Legend",
            "objective": "Mål: {count}",
            "tooltip": "Diskuter, stem og hjælp os med at nå dette mål!<br /><strong>Dine stemmer betyder noget</strong>: de leverer data til compar:IA-datasættet, som er frit tilgængeligt, for at hjælpe med at forbedre fremtidige modeller på lavresourcesprog.<br />Denne digitale fælles ressource bidrager til bedre <strong>respekt for sproglig og kulturel mangfoldighed i fremtidige sprogmodeller.</strong>"
        }
    },
    "home": {
        "europe": {
            "desc": "Litauen, Sverige og Danmark slutter sig til Frankrig i at indføre sammenligningsværktøjet for at forbedre fremtidige AI-modeller på deres nationale sprog.",
            "languages": {
                "da": "på dansk",
                "fr": "på fransk",
                "lt": "på litauisk",
                "sv": "på svensk"
            },
            "question": "Vil du gerne have chatbot-arenaen på dit sprog?",
            "title": "Sammenligneren <span {props}>bliver europæisk!</span>"
        },
        "faq": {
            "discover": "Se andre spørgsmål",
            "title": "Dine ofte stillede spørgsmål"
        },
        "intro": {
            "desc": "Før en blind samtale med to AI'er og vurdér deres svar",
            "steps": {
                "a11yDesc": "1. Jeg chatter med to skjulte AI'er: Chat så længe du vil. 2. Jeg angiver mine præferencer: Dermed hjælper du med at forbedre AI-modellerne. 3. Modellernes identiteter afsløres: Få mere at vide om dem og deres egenskaber.",
                "title": "Sådan fungerer det"
            },
            "title": "Stol ikke på svarene <span {props}>fra en enkelt AI</span>",
            "tos": {
                "accept": "Jeg accepterer <a {linkProps}>brugsbetingelserne</a>",
                "error": "Du skal acceptere brugsbetingelserne for at fortsætte",
                "help": "Data deles til forskningsformål"
            }
        },
        "origin": {
            "project": {
                "desc": "Chatbot-arenaen blev designet og udviklet som en del af et statsligt startup-projekt ledet af det franske kulturministerium og integreret i programmet <a {linkProps}>Beta.gouv.fr</a> af det tværministerielle digitale direktorat (DINUM). Dette initiativ støtter franske offentlige myndigheder i at opbygge nyttige, enkle og brugervenlige digitale tjenester.",
                "title": "Hvem tog initiativ til projektet?"
            },
            "team": {
                "desc": "Chatbot-området ledes inden for det franske kulturministerium af et tværfagligt team – AI-eksperter, udviklere, implementeringsspecialister og designere – med en mission om at gøre dialogbaseret AI mere gennemsigtig og tilgængelig for alle.",
                "title": "Hvem er vi?"
            }
        },
        "usage": {
            "desc": "Værktøjet er også rettet mod AI-eksperter og undervisere til mere specifikke anvendelsestilfælde",
            "educate": {
                "desc": "Brug chatbot-arenaen som et pædagogisk redskab til at diskutere AI med dit publikum",
                "title": "Uddan og skab bevidsthed"
            },
            "explore": {
                "desc": "Find alle modelspecifikationer og brugsbetingelserne på ét sted",
                "title": "Udforsk modellerne"
            },
            "title": "Specifikke use cases for compar:IA",
            "use": {
                "desc": "Udviklere, forskere, modeludgivere – få adgang til compar:IA's datasæt for at forbedre modeller til sprog med begrænsede ressourcer",
                "title": "Genbrug data"
            }
        },
        "use": {
            "compare": {
                "alt": "Sammenlign",
                "desc": "Diskuter og udvikl din kritiske tænkning ved at give udtryk for dine præferencer",
                "title": "Sammenlign svarene fra forskellige AI-modeller"
            },
            "desc": "compar:IA er et gratis værktøj, der hjælper med at øge borgernes bevidsthed om generativ AI og dens udfordringer.",
            "measure": {
                "alt": "Mål",
                "desc": "Opdag den miljømæssige påvirkning af dine samtaler med hver model",
                "title": "Mål det miljømæssige fodaftryk af spørgsmål stillet til AI"
            },
            "test": {
                "alt": "Test",
                "desc": "Test forskellige modeller: åbne, proprietære, små, store...",
                "title": "Test de nyeste AI i økosystemet på ét sted"
            },
            "title": "Hvad bruges compar:IA til?"
        },
        "vote": {
            "datasetAccess": "Få adgang til datasættene",
            "desc": "Dine præferencer beriger compar:IA-datasættene, som har til formål at forbedre fremtidige AI-modeller på fransk, svensk, litauisk og dansk",
            "steps": {
                "datasets": {
                    "desc": "Alle spørgsmål og afstemninger samles i datasæt og offentliggøres efter anonymisering.",
                    "title": "Datasæt efter sprog"
                },
                "finetune": {
                    "desc": "Virksomheder og akademiske institutioner kan bruge datasættene til at træne nye modeller, der i højere grad respekterer sproglig og kulturel mangfoldighed.",
                    "title": "Modeller, der er finjusteret til specifikke sprog"
                },
                "prefs": {
                    "desc": "Efter at have snakket med AI'erne, bliver du bedt om at angive din præference for en model ud fra givne kriterier, såsom relevansen eller nytten af svarene.",
                    "title": "Dine præferencer"
                }
            },
            "title": "Hvorfor er din stemme vigtig?"
        }
    },
    "models": {
        "extra": {
            "experts": {
                "api-only": "For at læse mere, se den <a {linkProps}>officielle modelhjemmeside</a>",
                "open-weights": "For at læse mere, se <a {linkProps}>modelsiden på Hugging Face</a>"
            },
            "impacts": "Miljøpåvirkningsberegninger er baseret på <a {linkProps1}>EcoLogits</a> og <a {linkProps2}>Impact CO<sub>2</sub></a> projekterne.",
            "title": "For at lære mere"
        },
        "licenses": {
            "type": {
                "openSource": "Open source",
                "proprietary": "Ophavsretligt beskyttet",
                "semiOpen": "Halvåben"
            }
        },
        "list": {
            "filters": {
                "display": "Vis filtre",
                "editor": {
                    "legend": "Udgiver"
                },
                "license": {
                    "legend": "Licens"
                },
                "size": {
                    "labels": {
                        "L": "70 til 150 milliarder",
                        "M": "20 til 70 milliarder",
                        "S": "7 til 20 milliarder",
                        "XL": "> 150 milliarder",
                        "XS": "< 7 milliarder"
                    },
                    "legend": "Størrelse (i millarder parametre)"
                }
            },
            "intro": "Udforsk de forskellige samtale AI-modeller, deres specifikationer og licenser.",
            "model": "model",
            "models": "modeller",
            "noresults": "Ingen modeller matcher dine søgekriterier.",
            "title": "Udforsk modellerne",
            "triage": {
                "label": "Sortér efter",
                "options": {
                    "date-desc": "Udgivelsesdato (nyeste til ældste)",
                    "name-asc": "Modelnavn (A til Z)",
                    "org-asc": "Udgiver (A til Z)",
                    "params-asc": "Størrelse (mindste til største)"
                }
            }
        },
        "names": {
            "a": "Model A",
            "b": "Model B"
        },
        "openWeight": {
            "tooltips": {
                "copyleft": "Når modellen er ændret, skal den distribueres på ny under samme licens som kildemodellen.",
                "free": "Når modellen er ændret, kan den distribueres under en anden licens end kildemodellen.",
                "openSource": "Træningsdata, koden og vægtene for denne model (dvs. de parametre, der er lært under træningen) kan downloades og ændres af offentligheden, så de kan køre og ændre modellen på deres egen hardware. Om en model er \"open source\" er mere restriktivt end \"open weights\", især på grund af behovet for gennemsigtighed i træningskorpuset. Få modeller betragtes som \"open source\"",
                "openWeight": "En såkaldt \"open weights\"-model, hvor vægtene, dvs. de parametre, der er lært under træningen, kan downloades af offentligheden, så de kan køre modellen på deres egen hardware. Om en model er \"open source\" er mere restriktivt (hovedsageligt i relation til gennemsigtigheden af træningskorpuset). Få modeller betragtes som \"open source\".",
                "params": "Parametre eller vægte, talt i milliarder, er de variabler, som en model lærer under træningen, og som bestemmer dens svar. Jo større antallet af parametre er, jo større er deres læringsevne.",
                "ram": "RAM (random access memory) gemmer data, der behandles af en LLM i realtid. Jo større modellen er, jo mere RAM kræver den for at køre."
            }
        },
        "parameters": "{number} parametre",
        "ram": "{min} til {max} GB",
        "release": "Udgivet {date}",
        "size": {
            "estimated": "Estimeret størrelse ({size})",
            "title": "Størrelse"
        }
    },
    "modes": {
        "big-vs-small": {
            "altLabel": "David mod Goliat-modelvalg",
            "description": "En lille model mod en stor model, begge valgt tilfældigt",
            "label": "David mod Goliat",
            "title": "David mod Goliat-tilstand"
        },
        "custom": {
            "altLabel": "Manuel modeludvælgelse",
            "description": "Kan du genkende de to modeller, du valgte?",
            "label": "Manuel udvælgelse",
            "title": "Manuel udvælgelse"
        },
        "random": {
            "altLabel": "Vilkårligt modelvalg",
            "description": "To modeller valgt vilkårligt fra den fulde liste",
            "label": "Tilfældig",
            "title": "Tilfældig"
        },
        "reasoning": {
            "altLabel": "Valg af ræsonnementmodel",
            "description": "To tilfældigt udvalgte ræsonnementmodeller",
            "label": "Ræsonnement",
            "title": "Ræsonnement"
        },
        "small-models": {
            "altLabel": "Sparsom modeludvælgelse",
            "description": "To små modeller valgt tilfældigt",
            "label": "Sparsom",
            "title": "Sparetilstand"
        }
    },
    "product": {
        "comparator": {
            "challenges": {
                "bias": {
                    "desc": "Fremhæv AI bias, der skyldes underrepræsentation af ikke-engelske data i modeller, og øg bevidstheden om deres virkelige indvirkning.",
                    "title": "Kulturel og sproglig bias"
                },
                "impacts": {
                    "desc": "Vis den miljømæssige påvirkning af generativ AI, som stadig er stort set ukendt for offentligheden.",
                    "title": "Miljøpåvirkning"
                },
                "pluralism": {
                    "desc": "Sikr at borgerne har adgang til en bred vifte af AI-modeller, så de kan træffe informerede valg og udvikle en kritisk forståelse af disse teknologier.",
                    "title": "Model-diversitet"
                },
                "thinking": {
                    "desc": "Frem kritisk tænkning om generativ AI's rolle i personlige og professionelle praksisser.",
                    "title": "Kritisk tænkning og samfundsmæssige spørgsmål"
                },
                "title": "Platformen adresserer flere udfordringer"
            },
            "cta": "Gå til sammenligningsværktøjet",
            "europe": {
                "adventure": "Fra sommeren 2025 tilslutter Litauen, Sverige og Danmark sig initiativet!",
                "catch": "Vil du gerne have chatbot-arenaen på dit sprog?",
                "desc": "Arenaen er nu tilgængelig for deres borgere på nationale sprog med en central mission: at opbygge præferencedatasæt for at forbedre fremtidige AI-modellers ydeevne på sprog med begrænsede ressourcer.",
                "title": "Arenaen <span {props}>bliver europæisk</span>!"
            },
            "title": "Arenaen gør det muligt at oprette <span {props}>præference-datasæt</span> med fokus på <span {props}>reel brug</span> i <span {props}>europæiske sprog</span>."
        },
        "partners": {
            "academy": {
                "catch": "Arbejder du med et forskningsprojekt? Har du forslag eller brug for afklaring om vores metodik eller datasæt?",
                "desc": "Vi er fast besluttede på at sikre, at de datasæt, vi genererer, fremmer tværfaglig forskning og bygger bro mellem humaniora, samfundsvidenskab og data science.",
                "title": "Akademiske partnere"
            },
            "diffusion": {
                "catch": "Vil du gerne bruge chatbot-arenaen i en professionel sammenhæng?",
                "cta": "Giv os besked",
                "desc": "Vi opbygger et netværk af partnere, der integrerer chatbot-området i deres tjenester og uddannelsestilbud.",
                "title": "Kommunikationspartnere"
            },
            "institution": {
                "title": "Institutionelle partnere"
            },
            "services": {
                "desc": "Beregninger af miljøpåvirkningen er baseret på ovenstående værktøjer.",
                "title": "Anvendte tjenester"
            }
        },
        "problem": {
            "alignment": {
                "alignment": {
                    "a": "Justering kommer efter en sprogmodels prætræningsfase og fungerer som det sidste trin til \"forfining\" eller \"polering\". Under prætræningen lærer modellen at forudsige det næste ord og får dermed evnen til at generere sammenhængende tekst – men justeringen er det, der tilpasser den til menneskelige præferencer.",
                    "b": "Justeringsfasen træner modellen til bedre at imødekomme menneskelige behov ved at gøre den <strong>mere relevant</strong> (besvare spørgsmål mere præcist), <strong>mere ærlig</strong> (indrømme, når der mangler tilstrækkelige data), og <strong>mere sikker</strong> (undgå skadeligt eller upassende indhold).",
                    "c": "<strong>Uden justering kan en LLM være teknisk kapabel, men upraktisk at bruge, da den ikke forstår, hvad brugerne virkelig forventer i en samtale.</strong>",
                    "title": "Justering: en kritisk fase efter træningen"
                },
                "datasets": {
                    "a": "Justeringen er afhængig af højt specialiserede datasæt, der er omhyggeligt designet til at lære modellen \"korrekt\" adfærd.",
                    "b": "<strong>Præferencedata</strong> er en vigtig komponent i justeringen og fungerer sammen med <strong>ekspertdata</strong> (ekspertudarbejdede samtaler mellem mennesker og AI med præcise retningslinjer for tone og stil), <strong>sikkerhedsdata</strong> (udvalgte eksempler, der lærer modeller at afvise skadelige anmodninger), og <strong>domænespecifikke datasæt</strong> (tilpasset til områder som medicin, jura eller uddannelse).",
                    "c": "Præferencedata præsenterer flere mulige svar på det samme spørgsmål, rangordnet af menneskelige evaluatorer på baggrund af kriterier som relevans, nytteværdi eller skadepotentiale. Brugerne angiver, hvilket svar der fungerer bedst, og disse kuraterede datasæt bruges derefter til at finjustere modellerne, så de stemmer overens med de udtrykte menneskelige præferencer.",
                    "title": "Specifikke datasæt"
                },
                "desc": "Justering: En teknik til reduktion af bias baseret på crowdsourcing af brugerpræferencer for at forbedre modeladfærd",
                "diversity": {
                    "a": "For at afspejle mangfoldigheden af kulturer og sprog i modelresultaterne skal <strong>justeringsdatasæt indeholde en bred vifte af sprog</strong>, kontekster og virkelige brugeropgaver. Diversificering af justeringsdata forbedrer i sidste ende en models ydeevne på to vigtige måder:",
                    "b": "For det første <strong>reducerer den kulturel bias</strong> ved at forhindre, at et enkelt – ofte engelsksproget – perspektiv dominerer AI'ens svar. Modellen lærer, at gyldige svar varierer alt efter den kulturelle kontekst, og anerkender flere legitime måder at besvare det samme spørgsmål på.",
                    "c": "For det andet muliggør eksponering for sproglig og kulturel mangfoldighed kontekstbevidste svar: en fransk bruger får rådgivning, der er tilpasset de franske systemer, mens en dansk bruger modtager information, der er tilpasset den nationale kontekst.",
                    "d": "Resultatet? En mere inkluderende samtalebaseret AI – en AI, der anerkender og tilpasser sig forskellige kulturelle perspektiver.",
                    "title": "Diversificer datakilder for at reducere bias"
                },
                "english": {
                    "a": "Præferencedata er dyre at producere, fordi <strong>hvert eksempel kræver en dygtig menneskelig evaluering</strong>. Platforme som chat.lmsys.org hjælper med at crowdsource disse datasæt, men få brugere bidrager på deres modersmål, hvilket betyder, at sprog med få ressourcer er underrepræsenterede.",
                    "b": "Der findes kun få eller ingen præferencedatasæt for europæiske sprog. I LMSYS' datasæt udgør franske søgninger for eksempel mindre end 1% af det samlede antal.",
                    "c": "compar:IA er en chatbot-arena, der er designet til at samle multilingvale samtaler, som indfanger regionsspecifikke kulturelle referencer som daglige gøremål, lokale kulinariske traditioner, uddannelsessystemer eller historiske og litterære milepæle.",
                    "title": "De europæiske sprog lider under en mangel på præferencedata"
                },
                "title": "Hvordan kan vi reducere kulturel og sproglig bias i disse modeller?"
            },
            "diversity": {
                "diversity": {
                    "desc": "Disse bias kan føre til ufuldstændige eller direkte forkerte svar, der negligerer mangfoldigheden i de europæiske sprog og kulturer.",
                    "title": "Overset kulturel og sproglig mangfoldighed"
                },
                "english": {
                    "desc": "Samtalebaseret AI er afhængig af store sprogmodeller (LLM'er), der primært er trænet på engelske data, hvilket skaber sproglige og kulturelle skævheder i deres output.",
                    "title": "Træningsdata overvejende på engelsk"
                },
                "stereotypes": {
                    "desc": "Samtalebaserede AI-systemer ser ud til at være flydende i alle sprog – men deres output kan stadig være stereotypisk eller diskriminerende.",
                    "title": "Bias-forstærkende svar"
                }
            },
            "title": "Respekterer samtalebaserede AI-modeller <span {props}>mangfoldigheden</span> i de europæiske sprog?"
        },
        "title": "Alt, hvad du behøver at vide om chatbot-arenaen"
    },
    "reveal": {
        "equivalent": {
            "co2": {
                "label": "CO <sub> 2 </sub> udledt",
                "tooltip": "Den udledte CO <sub> 2 </sub> svarer til den mængde kuldioxid, der udledes ved den energi, der bruges til at drive modellen. Den afspejler den miljømæssige påvirkning, der er forbundet med energiforbruget. Beregningen af watt-time/CO <sub> 2 </sub>-ækvivalensen varierer afhængigt af hvert lands energimix. De servere, der anvendes til modelinferens, er dog ikke alle placeret i Europa. Ækvivalensberegningen er således baseret på den globale gennemsnitlige CO <sub> 2 </sub>-emissionsrate pr. forbrugt energi."
            },
            "lightbulb": {
                "label": "LED-pære",
                "tooltip": "Data beregnet på baggrund af forbruget af en standard 5W LED-pære (E14)"
            },
            "streaming": {
                "label": "online videoer",
                "tooltip": "Data beregnet på baggrund af CO2-aftrykket fra en times streaming af video i høj opløsning på et fjernsyn med Wi-Fi-forbindelse (kilde <a {linkProps}>ADEME</a>)"
            },
            "title": "Hvilket svarer til:"
        },
        "feedback": {
            "description": "Del compar:AI med andre ved at dele de AI-modeller, du har interageret med! Kun navnene og energipåvirkningen af diskussionen vil være synlige via dette link, uden adgang til beskederne i samtalen.",
            "example": "Eksempel på delte resultater",
            "moreOnVotes": "Lær mere om stemmer",
            "shareResult": "Del dit resultat"
        },
        "impacts": {
            "energy": {
                "label": "energiforbrug",
                "tooltip": "Målt i watt-timer repræsenterer energiforbruget den elektricitet, som modellen bruger til at behandle en forespørgsel og generere det tilsvarende svar. Generelt gælder det, at jo større en model er (i milliarder af parametre), jo mere energi kræves der for at producere et token."
            },
            "size": {
                "count": "milliarder parametre.",
                "estimated": "(ca.)",
                "label": "modelstørrelse",
                "quantized": "(kvantiseret)"
            },
            "title": "Chatens energiforbrug",
            "tokens": {
                "label": "tekststørrelse",
                "tokens": "tokens",
                "tooltip": "AI analyserer og genererer sætninger ud fra ord eller dele af ord på cirka fire bogstaver; denne tekstdel kaldes et token. Jo længere en tekst er, jo større er antallet af tokens."
            }
        }
    },
    "seo": {
        "desc": "compar:IA er et værktøj, der gør det muligt at sammenligne forskellige samtale-AI-modeller blindt, øge bevidstheden om problemerne omkring generativ AI (pluralitet, bias, miljøpåvirkning) og hjælpe med at opbygge datasæt for sprogpræferencer for sprog med færre ressourcer.",
        "title": "compar:IA, arenaen for AI-chatbots",
        "titles": {
            "accessibilite": "Erklæring om tilgængelighed",
            "arene": "Chat",
            "comparator": "Arenaen",
            "datasets": "Datasæt",
            "donnees-personnelles": "Fortrolighedspolitik",
            "faq": "Ofte stillede spørgsmål",
            "history": "Projektets historie",
            "home": "Hjem",
            "mentions-legales": "Juridisk meddelelse",
            "modalites": "Brugsbetingelser",
            "modeles": "Modelliste",
            "news": "Nyheder",
            "partners": "Partnere",
            "problem": "Den indledende udfordring",
            "product": "Produkt og partnere",
            "share": "Mine resultater"
        }
    },
    "vote": {
        "bothEqual": "Begge er lige gode",
        "choices": {
            "altText": "{choice} for modellen {model}",
            "negative": {
                "incorrect": "Forkert",
                "instructions-not-followed": "Instruktionerne er ikke blevet fulgt",
                "question": "Hvorfor kunne du ikke lide svaret?",
                "superficial": "Overfladisk"
            },
            "positive": {
                "clear-formatting": "Klar formattering",
                "complete": "Fuldstændigt",
                "creative": "Kreativt",
                "question": "Hvad kunne du lide ved svaret?",
                "useful": "Brugbart"
            }
        },
        "comment": {
            "add": "Tilføj kommentarer",
            "placeholder": "Du kan tilføje detaljer om model {model}s svar"
        },
        "dislike": {
            "label": "Jeg kan ikke lide",
            "selectedLabel": "Jeg kan ikke lide (udvalgt)"
        },
        "introA": "Før vi finder ud af modellernes identitet, har vi brug for din stemme.",
        "introB": "Det giver os mulighed for at forbedre compar:IA-datasættene, hvis formål er at forfine fremtidige AI-modeller på sprog med færre ressourcer",
        "like": {
            "label": "Jeg kan godt lide",
            "selectedLabel": "Jeg kan godt lide (udvalgte)"
        },
        "qualify": {
            "addDetails": "Tilføj detaljer",
            "placeholder": "Svarene fra {model} modellen er...",
            "question": "Hvordan vil du beskrive dens svar?"
        },
        "title": "Hvilken AI-model foretrækker du?",
        "yours": "Din stemme"
    },
    "welcome": {
        "errors": "AI kan begå fejl: vi opfordrer dig til at kontrollere de leverede oplysninger",
        "go": "Så er vi klar",
        "privacy": "Del ikke personlige oplysninger såsom dit navn, efternavn eller adresse",
        "title": "Velkommen til compar:IA!",
        "use": "Brug ikke sammenligningsværktøjet til ulovlige eller skadelige formål"
    },
    "words": {
        "back": "Tilbage",
        "close": "Luk",
        "random": "Tilfældig",
        "regenerate": "Regenerer",
        "reset": "Nulstil",
        "restart": "Start forfra",
        "retry": "Start forfra",
        "send": "Send",
        "tooltip": "Tip",
        "validate": "Validér"
    }
}
