{
    "header": {
        "title": {
            "compar": "jämföra",
            "ia": "AI"
        },
        "subtitle": "Jämförelseverktyg för konversations-AI"
    },
    "arenaHome": {
        "title": "Hur kan jag hjälpa dig idag?",
        "modelSelection": "Val av modell",
        "prompt": {
            "label": "Skriv ditt första meddelande",
            "placeholder": "Skriv ditt första meddelande här"
        },
        "selectModels": {
            "question": "Vilka modeller vill du jämföra?",
            "help": "Välj jämförelseläge"
        },
        "compareModels": {
            "question": "Vilka modeller vill du jämföra?",
            "count": "{count}/2 modeller",
            "help": "Om bara en modell är vald, kommer den andra väljas slumpmässigt"
        },
        "suggestions": {
            "title": "Föreslagna prompter",
            "generateAnother": "Generera ny prompt",
            "choices": {
                "iasummit": {
                    "iconAlt": "AI Action Summit",
                    "title": "Prompter från en medborgarkonsultation om AI",
                    "tooltip": "Dessa frågor är resultatet av en medborgarkonsultation om IA som hölls 16/9 till 8/11 2024. Syftet var att låta medborgare och samhälle delta i AI Action Summit, och samla deras idéer om hur AI kan skapa möjligheter för alla, medan missbruk minimeras."
                },
                "ideas": {
                    "iconAlt": "Idéer",
                    "title": "Generera nya idéer"
                },
                "explanations": {
                    "iconAlt": "Förklaring",
                    "title": "Förklara ett koncept"
                },
                "languages": {
                    "iconAlt": "Översättning",
                    "title": "Skriv på annat språk"
                },
                "administrative": {
                    "iconAlt": "Administrativ",
                    "title": "Skriv ett administrativt dokument"
                },
                "recipes": {
                    "title": "Visa mig nya recept",
                    "iconAlt": "Recept"
                },
                "coach": {
                    "iconAlt": "Tips",
                    "title": "Ge mig råd om hälsa och träning"
                },
                "stories": {
                    "iconAlt": "Berättelser",
                    "title": "Berätta en historia"
                },
                "recommendations": {
                    "iconAlt": "Rekommendationer",
                    "title": "Föreslå filmer, böcker, musik"
                }
            }
        }
    },
    "closeModal": "Stäng popup-fönstret",
    "models": {
        "licenses": {
            "type": {
                "proprietary": "Proprietär",
                "openSource": "Öppen källkod",
                "semiOpen": "Semi-öppen"
            },
            "name": "Licens {licence}",
            "commercial": "Kommersiell licens",
            "noDesc": "Licensinformation saknas för denna modell.",
            "descriptions": {
                "MIT": "MIT-licensen är en licens för fri programvara. Den tillåter att vem som helst återanvänder, ändrar eller sprider en modell, även för kommersiella ändamål, förutsatt att den ursprungliga licensen och upphovsrättstexten skickas med.",
                "Apache 2.0": "Denna licens låter dig använda, ändra eller sprida en modell, även för kommersiella ändamål. Utöver det garanteras rättsligt skydd genom en klausul om icke-intrång och transparens. Alla ändringar måste därför vara dokumenterade och spårbara.",
                "Gemma": "Denna licens är skapad för att uppmuntra att mjukvaran används, ändras och sprids, men innehåller en klausul som säger att alla ändrade versioner måste delas under samma licens, för att främja samarbete och transparens inom mjukvaruutveckling.",
                "Llama 3 Community": "Denna licens tillåter att koden fritt används, ändras och sprids, så länge upphovsmannen nämns, men sätter begränsningar för processer med över 700 miljoner användare per månad, och förbjuder att kod eller genererat material återanvänds för att träna eller utveckla konkurrerande modeller, för att därigenom skydda Metas investeringar och varumärke.",
                "Llama 3.1": "Denna licens tillåter att koden fritt används, ändras och sprids, så länge upphovsmannen nämns, men sätter begränsningar för processer med över 700 miljoner användare per månad. Kod och genererat material får återanvändas för att träna eller utveckla modeller som bygger vidare på denna, så länge texten \"built with llama\" visas och ordet \"Llama\" ingår i titeln.",
                "Llama 3.3": "Denna licens tillåter att koden fritt används, ändras och sprids, så länge upphovsmannen nämns, men sätter begränsningar för processer med över 700 miljoner användare per månad. Kod och genererat material får återanvändas för att träna eller utveckla modeller som bygger vidare på denna, så länge texten \"built with llama\" visas och ordet \"Llama\" ingår i titeln.",
                "Llama 4": "Denna licens tillåter att koden fritt används, ändras och sprids, så länge upphovsmannen nämns, men sätter begränsningar för processer med över 700 miljoner användare per månad. Kod och genererat material får återanvändas för att träna eller utveckla modeller som bygger vidare på denna, så länge texten \"built with llama\" visas och ordet \"Llama\" ingår i titeln.",
                "Jamba Open Model": "Denna licens tillåter att koden fritt används, reproduceras och sprids, så länge upphovsmannen nämns, men sätter begränsningar för organisationer vars omsättning överskrider 50 miljoner USD.",
                "CC-BY-NC-4.0": "Denna licens tillåter att du sprider och ändrar innehållet, så länge upphovsmannen nämns, med förbjuder kommersiell användning. Det ger flexibilitet för icke-kommersiell användning, medan skaparens rättigheter bevaras.",
                "propriétaire Gemini": "Modellen är tillgänglig under en betald licens och åtkomlig via Gemini API som finns tillgängligt på Google AI Studio och Vertex AI, vilket kräver en avgift per användning baserat på antalet bearbetade tokens eller enligt företagets villkor.",
                "propriétaire Mistral": "Modellen är tillgänglig under en betald licens och åtkomlig via Mistral och andra partner-API:er. Den kräver en avgift per användning baserad på antalet bearbetade tokens.",
                "propriétaire xAI": "Modellen är tillgänglig via xAI API. Det kräver betalning per användning baserat på antalet bearbetade tokens, eller enligt företagets villkor.",
                "propriétaire Liquid": "Modellen är tillgänglig under en betald licens och åtkomlig via API på Liquid AIs plattformar. Den kräver en avgift per användning baserad på antalet bearbetade tokens.",
                "propriétaire OpenAI": "Modellen är tillgänglig under en betald licens och åtkomlig via API på OpenAIs plattformar. Den kräver en avgift per användning baserad på antalet bearbetade tokens, eller enligt företagets villkor.",
                "propriétaire Anthropic": "Modellen är tillgänglig under en betald licens och åtkomlig via API på Anthropics plattformar. Den kräver en avgift per användning baserad på antalet bearbetade tokens, eller enligt företagets villkor.",
                "Mistral AI Non-Production": "Denna licens tillåter att du sprider och ändrar innehållet, så länge upphovsmannen nämns, med förbjuder kommersiell användning. Det ger flexibilitet för icke-kommersiell användning, medan skaparens rättigheter bevaras."
            }
        },
        "release": "Utgiven {date}",
        "size": {
            "estimated": "Uppskattad storlek ({size})",
            "title": "Storlek",
            "descriptions": {
                "XS": "Mycket små modeller, med färre än 7 miljarder parametrar, är de minst komplexa och mest resurseffektiva och ger tillräcklig prestanda för enkla uppgifter som textklassificering.",
                "S": "En liten modell är mindre komplex och resurskrävande jämfört med större modeller, och ger fortfarande tillräcklig prestanda för många uppgifter (sammanfattning, översättning, textklassificering etc.)",
                "M": "Medelstora modeller erbjuder en bra balans mellan enkelhet och prestanda. De är mycket mindre resurskrävande än stora modeller, men kan fortfarande hantera komplexa uppgifter som sentimentanalys och resonemang.",
                "L": "Stora modeller kräver betydande resurser, men erbjuder bäst prestanda för avancerade uppgifter som kreativt skrivande, dialogmodellering och tillämpningar som kräver en noggrann förståelse av kontext.",
                "XL": "Dessa modeller, med hundratals miljarder parametrar, är de mest komplexa och avancerade vad gäller prestanda och noggrannhet. De kräver stora beräknings- och minnesresurser och är avsedda för mycket avancerade applikationer och högt specialiserade miljöer."
            }
        },
        "parameters": "{number} parametrar",
        "names": {
            "a": "Modell A",
            "b": "Modell B"
        },
        "conditions": "Användarvillkor",
        "openWeight": {
            "conditions": {
                "copyleft": "Copyleft",
                "free": "Tillåtande",
                "restricted": "Villkorlig"
            },
            "tooltips": {
                "openSource": "Träningsdata, kod och vikter för denna modell (dvs. parametrarna som lärs in under träningen) kan laddas ner och modifieras fritt. Att en modell är \"öppen källkod\" ställer hårdare krav än \"öppna vikter\", särskilt på grund av behovet av transparens i träningsmaterialet, och få modeller anses vara \"öppen källkod\".",
                "openWeight": "En så kallad \"open weights\"-modell, vilket innebär att dess vikter – de parametrar som lärs in under träning – kan laddas ner fritt, vilket gör att det går att köra modellen på sin egen dator. Att en modell är \"öppen källkod\" ställer hårdare krav än \"öppna vikter\", särskilt på grund av behovet av transparens i träningsmaterialet, och få modeller anses vara \"öppen källkod\".",
                "params": "Parametrar eller vikter – ofta flera miljarder – är de variabler som lärs in av en modell under träning och som bestämmer dess svar. Ju fler parametrar, desto större inlärningskapacitet har modellen.",
                "free": "När modellen har modifierats kan den spridas under en annan licens än källmodellen.",
                "copyleft": "När modellen har modifierats får den bara spridas med samma licens som källmodellen.",
                "ram": "RAM-minnet (Random Access Memory) lagrar data som bearbetas av en LLM i realtid. Ju större modellen är, desto mer RAM behöver den för att köras."
            },
            "descriptions": {
                "XS": "Med {paramsCount} miljarder parametrar tillhör den här modellen kategorin mycket små modeller (färre än 7 miljarder parametrar).",
                "S": "Med {paramsCount} miljarder parametrar tillhör den här modellen kategorin små modeller (mellan 7 och 20 miljarder parametrar).",
                "M": "Med {paramsCount} miljarder parametrar tillhör den här modellen kategorin medelstora modeller (mellan 20 och 70 miljarder parametrar).",
                "L": "Med {paramsCount} miljarder parametrar tillhör den här modellen kategorin stora modeller (mellan 70 och 100 miljarder parametrar).",
                "XL": "Med {paramsCount} miljarder parametrar tillhör den här modellen kategorin mycket stora modeller."
            },
            "use": {
                "commercial": "Kommersiell användning",
                "modification": "Ändring godkänd",
                "licenseType": "Licenstyp",
                "attribution": "Attribution krävs",
                "requiredRam": "Krav på RAM-minne"
            }
        },
        "ram": "{min} till {max} GB",
        "extra": {
            "title": "För att lära dig mer",
            "experts": {
                "open-weights": "För att lära dig mer, gå till <a {linkProps}>modellens sida på Hugging Face</a>",
                "api-only": "För att lära dig mer, titta på <a {linkProps}>modellens officiella webbplats</a>"
            },
            "impacts": "Miljöpåverkansberäkningarna baseras på projekten <a {linkProps1}>EcoLogits</a> och <a {linkProps2}>Impact CO<sub>2</sub></a>."
        },
        "list": {
            "title": "Utforska modellerna",
            "intro": "Utforska de olika konversationsbaserade AI-modellerna, deras specifikationer och licenser.",
            "filters": {
                "editor": {
                    "legend": "Utgivare"
                },
                "size": {
                    "labels": {
                        "XS": "< 7 miljarder",
                        "S": "7 till 20 miljarder",
                        "M": "20 till 70 miljarder",
                        "L": "70 till 150 miljarder",
                        "XL": "> 150 miljarder"
                    }
                },
                "license": {
                    "legend": "Användarlicens"
                },
                "display": "Visa filter"
            },
            "triage": {
                "label": "Sortera efter",
                "options": {
                    "name-asc": "Modellnamn (bokstavsordning)",
                    "date-desc": "Utgivningsdatum (från nyaste till äldsta)",
                    "params-asc": "Storlek (från minsta till största)",
                    "org-asc": "Utgivare (bokstavsordning)"
                }
            },
            "model": "modell",
            "models": "modeller",
            "noresults": "Inga modeller matchar dina sökkriterier."
        }
    },
    "modes": {
        "random": {
            "title": "Slumpläge",
            "label": "Slump"
        }
    }
}
